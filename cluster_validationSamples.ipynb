{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "import scanpy\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import models.loadImg as loadImg\n",
    "import models.modelsCNN as modelsCNN\n",
    "import models.optimizer as optimizer\n",
    "\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import gc\n",
    "from skimage import io\n",
    "import umap\n",
    "from sklearn.cluster import MiniBatchKMeans,AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"0,1,2,3\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\" \n",
    "use_cuda=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['br1003a_1_cytokeratin_555_aSMA_647_hoechst', 'br1003a_3_collagen1_647_hoechst', 'br1003a_4_cytokeratin_555_gh2ax_647_hoechst', 'br301_4_cytokeratin_555_aSMA_647_hoechst', 'br301_6_collagen1_647_hoechst', 'br8018a_1_cytokeratin_555_aSMA_647_hoechst', 'br8018a_3_collagen1_647_hoechst', 'br8018a_4_cytokeratin_555_gh2ax_647_hoechst']\n",
      "['br1003a_2_cytokeratin_555_ki67_647_hoechst', 'br301_5_cytokeratin_555_ki67_647_hoechst', 'br301_7_gh2ax_647_cytokeratin_555_hoechst', 'br8018a_2_cytokeratin_555_ki67_647_hoechst']\n"
     ]
    }
   ],
   "source": [
    "radius=48\n",
    "datadir='/media/xinyi/dcis2idc/data'\n",
    "sampleList_new=[]\n",
    "sampleList=[]\n",
    "for s in os.listdir('/media/xinyi/dcis2idc/data'):\n",
    "    if 'hoechst'  in s and ('_1_' in s or '_3_' in s or '_4_' in s or '_6_' in s):\n",
    "        sampleList.append(s)\n",
    "    elif 'hoechst' in s:\n",
    "        sampleList_new.append(s)\n",
    "print(sampleList)\n",
    "print(sampleList_new)\n",
    "trainingCores={'br1003a':[],'br8018a':[],'br301':[]}\n",
    "for s in range(1,11):\n",
    "# for s in range(5,11):\n",
    "    trainingCores['br1003a'].append('B'+str(s))\n",
    "    trainingCores['br1003a'].append('D'+str(s))\n",
    "    trainingCores['br1003a'].append('E'+str(s))\n",
    "    trainingCores['br1003a'].append('F'+str(s))\n",
    "    trainingCores['br1003a'].append('J'+str(s))\n",
    "trainingCores['br1003a'].append('J'+str(11))\n",
    "for s in range(1,11):\n",
    "    trainingCores['br8018a'].append('C'+str(s))\n",
    "    trainingCores['br8018a'].append('D'+str(s))\n",
    "    trainingCores['br8018a'].append('E'+str(s))\n",
    "    trainingCores['br8018a'].append('G'+str(s))\n",
    "trainingCores['br8018a'].append('H'+str(9))\n",
    "trainingCores['br8018a'].append('H'+str(10))\n",
    "\n",
    "\n",
    "trainingCores_new={'br1003a':[],'br8018a':[],'br301':[]}\n",
    "for s in range(1,7):\n",
    "    for sr in ['A','B','C','D','E']:\n",
    "        trainingCores_new['br301'].append(sr+str(s))\n",
    "for s in range(1,11):\n",
    "    for sr in ['A','B','C','D','E','F','I','J']:\n",
    "        trainingCores_new['br1003a'].append(sr+str(s))\n",
    "for s in range(1,11):\n",
    "    for sr in ['A','B','C','D','E','F','G','H']:\n",
    "        trainingCores_new['br8018a'].append(sr+str(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst\n",
      "B1\n",
      "D1\n",
      "J1\n",
      "B2\n",
      "D2\n",
      "J2\n",
      "B3\n",
      "D3\n",
      "J3\n",
      "B4\n",
      "D4\n",
      "J4\n",
      "B5\n",
      "J6\n",
      "B7\n",
      "D7\n",
      "J7\n",
      "B8\n",
      "J8\n",
      "B9\n",
      "J9\n",
      "B10\n",
      "J10\n",
      "br1003a_3_collagen1_647_hoechst\n",
      "B1\n",
      "D1\n",
      "J1\n",
      "B2\n",
      "D2\n",
      "J2\n",
      "B3\n",
      "D3\n",
      "J3\n",
      "D4\n",
      "J4\n",
      "B5\n",
      "D5\n",
      "J5\n",
      "D6\n",
      "J6\n",
      "B7\n",
      "D7\n",
      "J7\n",
      "B8\n",
      "D8\n",
      "J8\n",
      "B9\n",
      "D9\n",
      "J9\n",
      "B10\n",
      "D10\n",
      "J10\n",
      "J11\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst\n",
      "B1\n",
      "D1\n",
      "B2\n",
      "D2\n",
      "B3\n",
      "D3\n",
      "B4\n",
      "D4\n",
      "B5\n",
      "D5\n",
      "B6\n",
      "D6\n",
      "B7\n",
      "D7\n",
      "B8\n",
      "D8\n",
      "B9\n",
      "D9\n",
      "B10\n",
      "D10\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst\n",
      "br301_6_collagen1_647_hoechst\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst\n",
      "C1\n",
      "D1\n",
      "E1\n",
      "G1\n",
      "C2\n",
      "D2\n",
      "E2\n",
      "G2\n",
      "C3\n",
      "D3\n",
      "E3\n",
      "G3\n",
      "C4\n",
      "D4\n",
      "E4\n",
      "G4\n",
      "C5\n",
      "D5\n",
      "E5\n",
      "G5\n",
      "C6\n",
      "D6\n",
      "E6\n",
      "G6\n",
      "C7\n",
      "D7\n",
      "E7\n",
      "G7\n",
      "C8\n",
      "D8\n",
      "E8\n",
      "G8\n",
      "C9\n",
      "D9\n",
      "E9\n",
      "G9\n",
      "C10\n",
      "D10\n",
      "E10\n",
      "G10\n",
      "H9\n",
      "br8018a_3_collagen1_647_hoechst\n",
      "C1\n",
      "D1\n",
      "E1\n",
      "G1\n",
      "C2\n",
      "D2\n",
      "E2\n",
      "G2\n",
      "D3\n",
      "E3\n",
      "G3\n",
      "C4\n",
      "D4\n",
      "G4\n",
      "C5\n",
      "D5\n",
      "E5\n",
      "G5\n",
      "C6\n",
      "D6\n",
      "G6\n",
      "C7\n",
      "D7\n",
      "C8\n",
      "D8\n",
      "E8\n",
      "G8\n",
      "C9\n",
      "D9\n",
      "E9\n",
      "C10\n",
      "D10\n",
      "E10\n",
      "G10\n",
      "br8018a_4_cytokeratin_555_gh2ax_647_hoechst\n",
      "C1\n",
      "D1\n",
      "E1\n",
      "C2\n",
      "D3\n",
      "E3\n",
      "C4\n",
      "G4\n",
      "C5\n",
      "D5\n",
      "G5\n",
      "C6\n",
      "E6\n",
      "G6\n",
      "C7\n",
      "E7\n",
      "G7\n",
      "C8\n",
      "D8\n",
      "E8\n",
      "G8\n",
      "C9\n",
      "D9\n",
      "E9\n",
      "H9\n",
      "H10\n"
     ]
    }
   ],
   "source": [
    "datadir='/media/xinyi/dcis2idc/data'\n",
    "allImg=loadImg.loadImg(datadir,sampleList,trainingCores,'segmented_nucleus','zproject/dna',radius,minmax=True)\n",
    "with open(os.path.join(datadir,'processed','train_cnnvae_valcores'), 'wb') as output:\n",
    "    pickle.dump(allImg, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "br1003a_2_cytokeratin_555_ki67_647_hoechst\n",
      "A1\n",
      "B1\n",
      "C1\n",
      "D1\n",
      "I1\n",
      "J1\n",
      "A2\n",
      "B2\n",
      "C2\n",
      "D2\n",
      "I2\n",
      "J2\n",
      "A3\n",
      "B3\n",
      "C3\n",
      "D3\n",
      "I3\n",
      "J3\n",
      "B4\n",
      "C4\n",
      "D4\n",
      "I4\n",
      "J4\n",
      "A5\n",
      "B5\n",
      "C5\n",
      "D5\n",
      "I5\n",
      "B6\n",
      "C6\n",
      "D6\n",
      "J6\n",
      "A7\n",
      "B7\n",
      "C7\n",
      "D7\n",
      "I7\n",
      "A8\n",
      "B8\n",
      "C8\n",
      "D8\n",
      "I8\n",
      "B9\n",
      "C9\n",
      "I9\n",
      "A10\n",
      "B10\n",
      "C10\n",
      "D10\n",
      "I10\n",
      "br301_5_cytokeratin_555_ki67_647_hoechst\n",
      "A1\n",
      "B1\n",
      "C1\n",
      "D1\n",
      "E1\n",
      "A2\n",
      "B2\n",
      "C2\n",
      "D2\n",
      "E2\n",
      "A3\n",
      "B3\n",
      "C3\n",
      "D3\n",
      "E3\n",
      "A4\n",
      "B4\n",
      "C4\n",
      "D4\n",
      "E4\n",
      "A5\n",
      "B5\n",
      "C5\n",
      "D5\n",
      "E5\n",
      "A6\n",
      "B6\n",
      "C6\n",
      "D6\n",
      "E6\n",
      "br301_7_gh2ax_647_cytokeratin_555_hoechst\n",
      "A1\n",
      "B1\n",
      "C1\n",
      "D1\n",
      "E1\n",
      "A2\n",
      "B2\n",
      "C2\n",
      "D2\n",
      "E2\n",
      "A3\n",
      "B3\n",
      "C3\n",
      "D3\n",
      "E3\n",
      "A4\n",
      "B4\n",
      "C4\n",
      "D4\n",
      "E4\n",
      "A5\n",
      "B5\n",
      "C5\n",
      "D5\n",
      "E5\n",
      "A6\n",
      "B6\n",
      "C6\n",
      "E6\n",
      "br8018a_2_cytokeratin_555_ki67_647_hoechst\n",
      "A1\n",
      "B1\n",
      "C1\n",
      "D1\n",
      "E1\n",
      "F1\n",
      "G1\n",
      "A2\n",
      "B2\n",
      "C2\n",
      "E2\n",
      "F2\n",
      "G2\n",
      "H2\n",
      "A3\n",
      "B3\n",
      "C3\n",
      "D3\n",
      "E3\n",
      "F3\n",
      "G3\n",
      "H3\n",
      "A4\n",
      "C4\n",
      "D4\n",
      "E4\n",
      "F4\n",
      "G4\n",
      "H4\n",
      "A5\n",
      "B5\n",
      "C5\n",
      "D5\n",
      "E5\n",
      "F5\n",
      "G5\n",
      "H5\n",
      "A6\n",
      "B6\n",
      "C6\n",
      "D6\n",
      "E6\n",
      "F6\n",
      "G6\n",
      "A7\n",
      "B7\n",
      "C7\n",
      "D7\n",
      "E7\n",
      "F7\n",
      "A8\n",
      "B8\n",
      "C8\n",
      "E8\n",
      "F8\n",
      "A9\n",
      "B9\n",
      "C9\n",
      "E9\n",
      "F9\n",
      "A10\n",
      "B10\n",
      "C10\n",
      "D10\n",
      "E10\n"
     ]
    }
   ],
   "source": [
    "allImg_new=loadImg.loadImg(datadir,sampleList_new,trainingCores_new,'segmented_nucleus','zproject/dna',radius,minmax=True)\n",
    "with open(os.path.join(datadir,'processed','train_cnnvae_valsamples'), 'wb') as output:\n",
    "    pickle.dump(allImg_new, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VAE settings\n",
    "seed=3\n",
    "epochs=10000\n",
    "saveFreq=2000\n",
    "lr=0.00001 #initial learning rate\n",
    "lr_adv=0.001\n",
    "weight_decay=0 #Weight for L2 loss on embedding matrix.\n",
    "\n",
    "# batchsize=4\n",
    "batchsize=8000\n",
    "kernel_size=4\n",
    "stride=2\n",
    "padding=1\n",
    "\n",
    "# fc_dim1=6000\n",
    "hidden1=64 #Number of channels in hidden layer 1\n",
    "hidden2=128 \n",
    "hidden3=256\n",
    "hidden4=256\n",
    "hidden5=96\n",
    "fc_dim1=96*3*3\n",
    "fc_dim2=6000\n",
    "# fc_dim3=128\n",
    "# fc_dim4=128\n",
    "# gcn_dim1=2600\n",
    "# adv_hidden=128\n",
    "\n",
    "dropout=0.01\n",
    "kl_weight=0.0000001\n",
    "model_str='cnn_vae'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "name='exp0'\n",
    "logsavepath='/media/xinyi/dcis2idc/log/cnnvae'+name\n",
    "modelsavepath='/media/xinyi/dcis2idc/models/cnnvae'+name\n",
    "plotsavepath='/media/xinyi/dcis2idc/plots/cnnvae'+name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set cuda and seed\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.enabled = True\n",
    "    \n",
    "loss_match=torch.nn.MSELoss()\n",
    "# Create model\n",
    "if model_str=='cnn_vae':\n",
    "    modelcnn = modelsCNN.CNN_VAE(kernel_size, stride, padding, 1, hidden1, hidden2, hidden3, hidden4, hidden5, fc_dim1,fc_dim2)\n",
    "    loss_kl=optimizer.optimizer_kl\n",
    "    loss_x=torch.nn.MSELoss()\n",
    "if model_str=='cnn_vae_sharded':\n",
    "    modelcnn = modelsCNN.CNN_VAE_sharded(kernel_size, stride, padding, 1, hidden1, hidden2, hidden3, hidden4, hidden5, fc_dim1,fc_dim2)\n",
    "    loss_kl=optimizer.optimizer_kl\n",
    "    loss_x=torch.nn.MSELoss()\n",
    "    use_cuda=False\n",
    "\n",
    "if model_str=='cnn_vae_alexnet':\n",
    "    modelcnn = modelsCNN.CNN_VAE_alexnet(fc_dim1)\n",
    "    loss_kl=optimizer.optimizer_kl\n",
    "    loss_x=torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "    \n",
    "modelcnn.cuda()       \n",
    "optimizerCNN = optim.Adam(modelcnn.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "ep=311"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute latent\n",
    "\n",
    "use_cuda=True\n",
    "modelcnn.load_state_dict(torch.load(os.path.join(modelsavepath,str(ep)+'.pt')))\n",
    "latent=np.zeros((allImg.shape[0],fc_dim2))\n",
    "with torch.no_grad():\n",
    "    modelcnn.cuda()\n",
    "    modelcnn.eval()\n",
    "    nplotBatches=int(np.ceil(allImg.shape[0]/batchsize))\n",
    "    for i in range(nplotBatches):\n",
    "        plotInput=torch.tensor(allImg[i*batchsize:min((i+1)*batchsize,allImg.shape[0])])\n",
    "        if use_cuda:\n",
    "            plotInput=plotInput.cuda().float()\n",
    "        recon,z, mu, logvar = modelcnn(plotInput)\n",
    "        latent[i*batchsize:min((i+1)*batchsize,allImg.shape[0])]=mu.cpu().detach().numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute latent_new - new samples\n",
    "\n",
    "latent_new=np.zeros((allImg_new.shape[0],fc_dim2))\n",
    "with torch.no_grad():\n",
    "    modelcnn.cuda()\n",
    "    modelcnn.eval()\n",
    "    nplotBatches=int(np.ceil(allImg_new.shape[0]/batchsize))\n",
    "    for i in range(nplotBatches):\n",
    "        plotInput=torch.tensor(allImg_new[i*batchsize:min((i+1)*batchsize,allImg_new.shape[0])])\n",
    "        if use_cuda:\n",
    "            plotInput=plotInput.cuda().float()\n",
    "        recon,z, mu, logvar = modelcnn(plotInput)\n",
    "        latent_new[i*batchsize:min((i+1)*batchsize,allImg_new.shape[0])]=mu.cpu().detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(datadir,'processed','latent311_valcores'), 'wb') as input:\n",
    "    pickle.dump(latent,input,pickle.HIGHEST_PROTOCOL)\n",
    "with open(os.path.join(datadir,'processed','latent311_valsamples'), 'wb') as input:\n",
    "    pickle.dump(latent_new,input,pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst\n",
      "B1\n",
      "D1\n",
      "J1\n",
      "B2\n",
      "D2\n",
      "J2\n",
      "B3\n",
      "D3\n",
      "J3\n",
      "B4\n",
      "D4\n",
      "J4\n",
      "B5\n",
      "J6\n",
      "B7\n",
      "D7\n",
      "J7\n",
      "B8\n",
      "J8\n",
      "B9\n",
      "J9\n",
      "B10\n",
      "J10\n",
      "br1003a_3_collagen1_647_hoechst\n",
      "B1\n",
      "D1\n",
      "J1\n",
      "B2\n",
      "D2\n",
      "J2\n",
      "B3\n",
      "D3\n",
      "J3\n",
      "D4\n",
      "J4\n",
      "B5\n",
      "D5\n",
      "J5\n",
      "D6\n",
      "J6\n",
      "B7\n",
      "D7\n",
      "J7\n",
      "B8\n",
      "D8\n",
      "J8\n",
      "B9\n",
      "D9\n",
      "J9\n",
      "B10\n",
      "D10\n",
      "J10\n",
      "J11\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst\n",
      "B1\n",
      "D1\n",
      "B2\n",
      "D2\n",
      "B3\n",
      "D3\n",
      "B4\n",
      "D4\n",
      "B5\n",
      "D5\n",
      "B6\n",
      "D6\n",
      "B7\n",
      "D7\n",
      "B8\n",
      "D8\n",
      "B9\n",
      "D9\n",
      "B10\n",
      "D10\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst\n",
      "br301_6_collagen1_647_hoechst\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst\n",
      "C1\n",
      "D1\n",
      "E1\n",
      "G1\n",
      "C2\n",
      "D2\n",
      "E2\n",
      "G2\n",
      "C3\n",
      "D3\n",
      "E3\n",
      "G3\n",
      "C4\n",
      "D4\n",
      "E4\n",
      "G4\n",
      "C5\n",
      "D5\n",
      "E5\n",
      "G5\n",
      "C6\n",
      "D6\n",
      "E6\n",
      "G6\n",
      "C7\n",
      "D7\n",
      "E7\n",
      "G7\n",
      "C8\n",
      "D8\n",
      "E8\n",
      "G8\n",
      "C9\n",
      "D9\n",
      "E9\n",
      "G9\n",
      "C10\n",
      "D10\n",
      "E10\n",
      "G10\n",
      "H9\n",
      "br8018a_3_collagen1_647_hoechst\n",
      "C1\n",
      "D1\n",
      "E1\n",
      "G1\n",
      "C2\n",
      "D2\n",
      "E2\n",
      "G2\n",
      "D3\n",
      "E3\n",
      "G3\n",
      "C4\n",
      "D4\n",
      "G4\n",
      "C5\n",
      "D5\n",
      "E5\n",
      "G5\n",
      "C6\n",
      "D6\n",
      "G6\n",
      "C7\n",
      "D7\n",
      "C8\n",
      "D8\n",
      "E8\n",
      "G8\n",
      "C9\n",
      "D9\n",
      "E9\n",
      "C10\n",
      "D10\n",
      "E10\n",
      "G10\n",
      "br8018a_4_cytokeratin_555_gh2ax_647_hoechst\n",
      "C1\n",
      "D1\n",
      "E1\n",
      "C2\n",
      "D3\n",
      "E3\n",
      "C4\n",
      "G4\n",
      "C5\n",
      "D5\n",
      "G5\n",
      "C6\n",
      "E6\n",
      "G6\n",
      "C7\n",
      "E7\n",
      "G7\n",
      "C8\n",
      "D8\n",
      "E8\n",
      "G8\n",
      "C9\n",
      "D9\n",
      "E9\n",
      "H9\n",
      "H10\n",
      "br1003a_2_cytokeratin_555_ki67_647_hoechst\n",
      "A1\n",
      "B1\n",
      "C1\n",
      "D1\n",
      "I1\n",
      "J1\n",
      "A2\n",
      "B2\n",
      "C2\n",
      "D2\n",
      "I2\n",
      "J2\n",
      "A3\n",
      "B3\n",
      "C3\n",
      "D3\n",
      "I3\n",
      "J3\n",
      "B4\n",
      "C4\n",
      "D4\n",
      "I4\n",
      "J4\n",
      "A5\n",
      "B5\n",
      "C5\n",
      "D5\n",
      "I5\n",
      "B6\n",
      "C6\n",
      "D6\n",
      "J6\n",
      "A7\n",
      "B7\n",
      "C7\n",
      "D7\n",
      "I7\n",
      "A8\n",
      "B8\n",
      "C8\n",
      "D8\n",
      "I8\n",
      "B9\n",
      "C9\n",
      "I9\n",
      "A10\n",
      "B10\n",
      "C10\n",
      "D10\n",
      "I10\n",
      "br301_5_cytokeratin_555_ki67_647_hoechst\n",
      "A1\n",
      "B1\n",
      "C1\n",
      "D1\n",
      "E1\n",
      "A2\n",
      "B2\n",
      "C2\n",
      "D2\n",
      "E2\n",
      "A3\n",
      "B3\n",
      "C3\n",
      "D3\n",
      "E3\n",
      "A4\n",
      "B4\n",
      "C4\n",
      "D4\n",
      "E4\n",
      "A5\n",
      "B5\n",
      "C5\n",
      "D5\n",
      "E5\n",
      "A6\n",
      "B6\n",
      "C6\n",
      "D6\n",
      "E6\n",
      "br301_7_gh2ax_647_cytokeratin_555_hoechst\n",
      "A1\n",
      "B1\n",
      "C1\n",
      "D1\n",
      "E1\n",
      "A2\n",
      "B2\n",
      "C2\n",
      "D2\n",
      "E2\n",
      "A3\n",
      "B3\n",
      "C3\n",
      "D3\n",
      "E3\n",
      "A4\n",
      "B4\n",
      "C4\n",
      "D4\n",
      "E4\n",
      "A5\n",
      "B5\n",
      "C5\n",
      "D5\n",
      "E5\n",
      "A6\n",
      "B6\n",
      "C6\n",
      "E6\n",
      "br8018a_2_cytokeratin_555_ki67_647_hoechst\n",
      "A1\n",
      "B1\n",
      "C1\n",
      "D1\n",
      "E1\n",
      "F1\n",
      "G1\n",
      "A2\n",
      "B2\n",
      "C2\n",
      "E2\n",
      "F2\n",
      "G2\n",
      "H2\n",
      "A3\n",
      "B3\n",
      "C3\n",
      "D3\n",
      "E3\n",
      "F3\n",
      "G3\n",
      "H3\n",
      "A4\n",
      "C4\n",
      "D4\n",
      "E4\n",
      "F4\n",
      "G4\n",
      "H4\n",
      "A5\n",
      "B5\n",
      "C5\n",
      "D5\n",
      "E5\n",
      "F5\n",
      "G5\n",
      "H5\n",
      "A6\n",
      "B6\n",
      "C6\n",
      "D6\n",
      "E6\n",
      "F6\n",
      "G6\n",
      "A7\n",
      "B7\n",
      "C7\n",
      "D7\n",
      "E7\n",
      "F7\n",
      "A8\n",
      "B8\n",
      "C8\n",
      "E8\n",
      "F8\n",
      "A9\n",
      "B9\n",
      "C9\n",
      "E9\n",
      "F9\n",
      "A10\n",
      "B10\n",
      "C10\n",
      "D10\n",
      "E10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "235"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get sample names\n",
    "def loadOneSampleName(samplename,segmentationPath,imgPath,centroidPath,radius,minmax):\n",
    "    segmentednuclei=io.imread(segmentationPath)\n",
    "    pos=pd.read_csv(centroidPath)\n",
    "    rep=pos.shape[0]\n",
    "    for i in range(pos.shape[0]):\n",
    "        if int(pos.iloc[i,2])-radius<0 or int(pos.iloc[i,2])+radius>(segmentednuclei.shape[0]) or int(pos.iloc[i,3])-radius<0 or int(pos.iloc[i,3])+radius>(segmentednuclei.shape[1]):\n",
    "            rep-=1\n",
    "    sampleNameList=np.repeat(samplename,rep)\n",
    "    return sampleNameList\n",
    "    \n",
    "def loadImgName(datadir,sampleList,coreList,segmentationPath,imgPath,radius,minmax=True):\n",
    "    allImg=None\n",
    "    \n",
    "    for s in sampleList:\n",
    "        print(s)\n",
    "        coreS=None\n",
    "        for k in coreList.keys():\n",
    "            if k in s:\n",
    "                coreS=coreList[k]\n",
    "                break\n",
    "        for c in coreS:\n",
    "            if not os.path.exists(os.path.join(datadir,s,segmentationPath,c+'.tif')) or (not os.path.exists(os.path.join(datadir,s,imgPath,c+'.tif'))) or (not os.path.exists(os.path.join(datadir,s,'spatial_positioning',c+'.csv'))):\n",
    "                continue\n",
    "            print(c)\n",
    "            samplename=s+'_'+c\n",
    "            if allImg is None:\n",
    "                allImg=loadOneSampleName(samplename,os.path.join(datadir,s,segmentationPath,c+'.tif'), os.path.join(datadir,s,imgPath,c+'.tif'), os.path.join(datadir,s,'spatial_positioning',c+'.csv'), radius,minmax)\n",
    "            else:\n",
    "                allImg = np.concatenate((allImg, loadOneSampleName(samplename,os.path.join(datadir,s,segmentationPath,c+'.tif'), os.path.join(datadir,s,imgPath,c+'.tif'), os.path.join(datadir,s,'spatial_positioning',c+'.csv'), radius,minmax)), axis=0)\n",
    "    return allImg\n",
    "\n",
    "gc.collect()\n",
    "allImgNames=loadImgName(datadir,sampleList,trainingCores,'segmented_nucleus','zproject/dna',radius,minmax=True)\n",
    "with open(os.path.join(datadir,'processed','train_cnnvae_names_valcores'), 'wb') as output:\n",
    "    pickle.dump(allImgNames, output, pickle.HIGHEST_PROTOCOL)\n",
    "allImgNames_new=loadImgName(datadir,sampleList_new,trainingCores_new,'segmented_nucleus','zproject/dna',radius,minmax=True)\n",
    "with open(os.path.join(datadir,'processed','train_cnnvae_names_valsamples'), 'wb') as output:\n",
    "    pickle.dump(allImgNames_new, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get coord\n",
    "coordlist=np.zeros((allImgNames.shape[0],2))\n",
    "uniquenames,nameIdx=np.unique(allImgNames,return_index=True)\n",
    "for sidx in range(uniquenames.size):\n",
    "    s=uniquenames[sidx]\n",
    "    startidx=nameIdx[sidx]\n",
    "    posPath=os.path.join(datadir,'_'.join(s.split('_')[:-1]),'spatial_positioning',s.split('_')[-1] +'.csv')\n",
    "    pos=pd.read_csv(posPath)\n",
    "    \n",
    "    segmentationPath=os.path.join(datadir,'_'.join(s.split('_')[:-1]),'segmented_nucleus',s.split('_')[-1] +'.tif')\n",
    "    segmentednuclei=io.imread(segmentationPath)\n",
    "    for i in range(pos.shape[0]):\n",
    "        if int(pos.iloc[i,2])-radius<0 or int(pos.iloc[i,2])+radius>(segmentednuclei.shape[0]) or int(pos.iloc[i,3])-radius<0 or int(pos.iloc[i,3])+radius>(segmentednuclei.shape[1]):\n",
    "            continue\n",
    "        coordlist[startidx]=np.array((pos.iloc[i,2],pos.iloc[i,3]))\n",
    "        startidx+=1\n",
    "\n",
    "with open(os.path.join(datadir,'processed','train_cnnvae_coord_valcores'), 'wb') as output:\n",
    "    pickle.dump(coordlist, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get coord\n",
    "coordlist_new=np.zeros((allImgNames_new.shape[0],2))\n",
    "uniquenames,nameIdx=np.unique(allImgNames_new,return_index=True)\n",
    "for sidx in range(uniquenames.size):\n",
    "    s=uniquenames[sidx]\n",
    "    startidx=nameIdx[sidx]\n",
    "    posPath=os.path.join(datadir,'_'.join(s.split('_')[:-1]),'spatial_positioning',s.split('_')[-1] +'.csv')\n",
    "    pos=pd.read_csv(posPath)\n",
    "    \n",
    "    segmentationPath=os.path.join(datadir,'_'.join(s.split('_')[:-1]),'segmented_nucleus',s.split('_')[-1] +'.tif')\n",
    "    segmentednuclei=io.imread(segmentationPath)\n",
    "    for i in range(pos.shape[0]):\n",
    "        if int(pos.iloc[i,2])-radius<0 or int(pos.iloc[i,2])+radius>(segmentednuclei.shape[0]) or int(pos.iloc[i,3])-radius<0 or int(pos.iloc[i,3])+radius>(segmentednuclei.shape[1]):\n",
    "            continue\n",
    "        coordlist_new[startidx]=np.array((pos.iloc[i,2],pos.iloc[i,3]))\n",
    "        startidx+=1\n",
    "\n",
    "with open(os.path.join(datadir,'processed','train_cnnvae_coord_valsamples'), 'wb') as output:\n",
    "    pickle.dump(coordlist_new, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get cellID -- label not row index\n",
    "cellIDlist={}\n",
    "uniquenames,nameIdx=np.unique(allImgNames,return_index=True)\n",
    "for sidx in range(uniquenames.size):\n",
    "    s=uniquenames[sidx]\n",
    "    posPath=os.path.join(datadir,'_'.join(s.split('_')[:-1]),'spatial_positioning',s.split('_')[-1] +'.csv')\n",
    "    pos=pd.read_csv(posPath)\n",
    "    \n",
    "    includedPos=coordlist[allImgNames==s]\n",
    "    cellIDlist[s]=np.zeros(includedPos.shape[0])\n",
    "    for i in range(includedPos.shape[0]):\n",
    "        cellIDlist[s][i]=pos.to_numpy()[np.logical_and(pos.iloc[:,2]==includedPos[i,0],pos.iloc[:,3]==includedPos[i,1]),1]\n",
    "    assert np.sum(cellIDlist[s]==0)==0\n",
    "    \n",
    "with open(os.path.join(datadir,'processed','train_cnnvae_cellLabels_valcores'), 'wb') as output:\n",
    "    pickle.dump(cellIDlist,output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get cellID -- label not row index\n",
    "cellIDlist_new={}\n",
    "uniquenames,nameIdx=np.unique(allImgNames_new,return_index=True)\n",
    "for sidx in range(uniquenames.size):\n",
    "    s=uniquenames[sidx]\n",
    "    posPath=os.path.join(datadir,'_'.join(s.split('_')[:-1]),'spatial_positioning',s.split('_')[-1] +'.csv')\n",
    "    pos=pd.read_csv(posPath)\n",
    "    \n",
    "    includedPos=coordlist_new[allImgNames_new==s]\n",
    "    cellIDlist_new[s]=np.zeros(includedPos.shape[0])\n",
    "    for i in range(includedPos.shape[0]):\n",
    "        cellIDlist_new[s][i]=pos.to_numpy()[np.logical_and(pos.iloc[:,2]==includedPos[i,0],pos.iloc[:,3]==includedPos[i,1]),1]\n",
    "    assert np.sum(cellIDlist_new[s]==0)==0\n",
    "    \n",
    "with open(os.path.join(datadir,'processed','train_cnnvae_cellLabels_valsamples'), 'wb') as output:\n",
    "    pickle.dump(cellIDlist_new,output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allImg_new=None\n",
    "gc.collect()\n",
    "allImg=None\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load\n",
    "ep=311\n",
    "name='exp0'\n",
    "logsavepath='/media/xinyi/dcis2idc/log/cnnvae'+name\n",
    "modelsavepath='/media/xinyi/dcis2idc/models/cnnvae'+name\n",
    "plotsavepath='/media/xinyi/dcis2idc/plots/cnnvae'+name\n",
    "\n",
    "with open(os.path.join(datadir,'processed','latent311_valcores'), 'rb') as input:\n",
    "    latent=pickle.load(input)\n",
    "with open(os.path.join(datadir,'processed','latent311_valsamples'), 'rb') as input:\n",
    "    latent_new=pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustersavedir_valcores=os.path.join(sampledir,'cluster_valcores_reordered')\n",
    "clusterplotdir_valcores=os.path.join(clustersavedir_valcores,'plots')\n",
    "clustersavedir_valsamples=os.path.join(sampledir,'cluster_valsamples_reordered')\n",
    "clusterplotdir_valsamples=os.path.join(clustersavedir_valsamples,'plots')\n",
    "\n",
    "plotepoch=ep\n",
    "ncluster=8\n",
    "n_neighbors=10\n",
    "min_dist=0.25\n",
    "n_pcs=50\n",
    "savenamecluster='minibatchkmean_ncluster'+str(ncluster)+'n_pcs'+str(n_pcs)+'epoch'+str(plotepoch)\n",
    "with open(os.path.join(clustersavedir_valcores,savenamecluster+'_all'), 'rb') as output:\n",
    "    clusterRes_reordered=pickle.load(output)\n",
    "with open(os.path.join(clustersavedir_valsamples,'minibatchkmean_ncluster'+str(ncluster)+'n_pcs'+str(n_pcs)+'epoch'+str(plotepoch)+'_all'), 'rb') as output:\n",
    "    clusterRes_reordered_new=pickle.load(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "plottype='umap'\n",
    "sampledir=plotsavepath\n",
    "savedir=os.path.join(sampledir,'embedding_'+plottype)\n",
    "clustersavedir=os.path.join(sampledir,'cluster')\n",
    "neworder=[1, 5, 3, 7, 2, 0, 4, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load umap and kmeans -- save reordered cluster\n",
    "ncluster=8\n",
    "n_neighbors=10\n",
    "min_dist=0.25\n",
    "n_pcs=50\n",
    "plotepoch=ep\n",
    "# savenameAdd='_nn'+str(n_neighbors)+'mdist0'+str(int(min_dist*100))+'epoch'+str(ep)\n",
    "# with open(os.path.join(modelsavepath,'umap_plottingIdx_progBalanced_'+str(0)+savenameAdd), 'rb') as output:\n",
    "#     reducer=pickle.load(output)\n",
    "\n",
    "savenameAdd='_plottingIdx_progBalanced_'+str(0)\n",
    "savenamecluster='minibatchkmean_ncluster'+str(ncluster)+'n_pcs'+str(n_pcs)+'epoch'+str(plotepoch)+savenameAdd\n",
    "with open(os.path.join(clustersavedir,savenamecluster+'_estimator'), 'rb') as output:\n",
    "    kmeansestimator=pickle.load(output)\n",
    "\n",
    "savenamepca='pca_epoch'+str(plotepoch)+savenameAdd\n",
    "with open(os.path.join(clustersavedir,savenamepca), 'rb') as output:\n",
    "    pca=pickle.load(output)\n",
    "    \n",
    "subclusternumbers=[4,6,8,6,6,6,6,4]\n",
    "kmeansestimator_sub={}\n",
    "pca_sub={}\n",
    "for c in range(ncluster):\n",
    "    subclustersavedir=os.path.join(clustersavedir,savenamecluster+'_subcluster'+str(c))\n",
    "    savenamecluster_sub='minibatchkmean_ncluster'+str(subclusternumbers[c])+'n_pcs'+str(n_pcs)+'epoch'+str(plotepoch)+savenameAdd\n",
    "    with open(os.path.join(subclustersavedir,savenamecluster_sub+'_estimator'), 'rb') as output:\n",
    "        kmeansestimator_sub[c]=pickle.load(output)\n",
    "    with open(os.path.join(subclustersavedir,savenamepca), 'rb') as output:\n",
    "        pca_sub[c]=pickle.load(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21439"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict kmeans\n",
    "clustersavedir_valcores=os.path.join(sampledir,'cluster_valcores_reordered')\n",
    "if not os.path.exists(clustersavedir_valcores):\n",
    "    os.mkdir(clustersavedir_valcores)\n",
    "clusterplotdir_valcores=os.path.join(clustersavedir_valcores,'plots')\n",
    "if not os.path.exists(clusterplotdir_valcores):\n",
    "    os.mkdir(clusterplotdir_valcores)\n",
    "clusterRes=kmeansestimator.predict(pca.transform(latent)[:,:n_pcs])\n",
    "clusterRes_reordered=np.zeros_like(clusterRes)\n",
    "for c in range(ncluster):\n",
    "    cold=neworder[c]\n",
    "    clusterRes_reordered[clusterRes==cold]=c\n",
    "\n",
    "with open(os.path.join(clustersavedir_valcores,'minibatchkmean_ncluster'+str(ncluster)+'n_pcs'+str(n_pcs)+'epoch'+str(plotepoch)+'_all'), 'wb') as output:\n",
    "    pickle.dump(clusterRes_reordered, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "savenamecluster='minibatchkmean_ncluster'+str(ncluster)+'n_pcs'+str(n_pcs)+'epoch'+str(plotepoch)+savenameAdd\n",
    "for cnew in np.unique(clusterRes_reordered):\n",
    "    c=neworder[cnew]\n",
    "    subclustersavedir_valcores=os.path.join(clustersavedir_valcores,savenamecluster+'_subcluster'+str(c))\n",
    "    subclusterplotdir_valcores=os.path.join(subclustersavedir_valcores,'plots')\n",
    "    if not os.path.exists(subclustersavedir_valcores):\n",
    "        os.mkdir(subclustersavedir_valcores)\n",
    "    if not os.path.exists(subclusterplotdir_valcores):\n",
    "        os.mkdir(subclusterplotdir_valcores)\n",
    "    clusterRes_sub=kmeansestimator_sub[c].predict(pca_sub[c].transform(latent[clusterRes_reordered==cnew])[:,:n_pcs])\n",
    "    with open(os.path.join(subclustersavedir_valcores,'minibatchkmean_ncluster'+str(subclusternumbers[c])+'n_pcs'+str(n_pcs)+'epoch'+str(plotepoch)+'_all'), 'wb') as output:\n",
    "        pickle.dump(clusterRes_sub, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict kmeans\n",
    "clustersavedir_valsamples=os.path.join(sampledir,'cluster_valsamples_reordered')\n",
    "if not os.path.exists(clustersavedir_valsamples):\n",
    "    os.mkdir(clustersavedir_valsamples)\n",
    "clusterplotdir_valsamples=os.path.join(clustersavedir_valsamples,'plots')\n",
    "if not os.path.exists(clusterplotdir_valsamples):\n",
    "    os.mkdir(clusterplotdir_valsamples)\n",
    "clusterRes_new=kmeansestimator.predict(pca.transform(latent_new)[:,:n_pcs])\n",
    "clusterRes_reordered_new=np.zeros_like(clusterRes_new)\n",
    "for c in range(ncluster):\n",
    "    cold=neworder[c]\n",
    "    clusterRes_reordered_new[clusterRes_new==cold]=c\n",
    "\n",
    "with open(os.path.join(clustersavedir_valsamples,'minibatchkmean_ncluster'+str(ncluster)+'n_pcs'+str(n_pcs)+'epoch'+str(plotepoch)+'_all'), 'wb') as output:\n",
    "    pickle.dump(clusterRes_reordered_new, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "gc.collect()\n",
    "# embedding=reducer.transform(latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cnew in np.unique(clusterRes_reordered_new):\n",
    "    c=neworder[cnew]\n",
    "    subclustersavedir_valsamples=os.path.join(clustersavedir_valsamples,savenamecluster+'_subcluster'+str(c))\n",
    "    subclusterplotdir_valsamples=os.path.join(subclustersavedir_valsamples,'plots')\n",
    "    if not os.path.exists(subclustersavedir_valsamples):\n",
    "        os.mkdir(subclustersavedir_valsamples)\n",
    "    if not os.path.exists(subclusterplotdir_valsamples):\n",
    "        os.mkdir(subclusterplotdir_valsamples)\n",
    "    clusterRes_sub_new=kmeansestimator_sub[c].predict(pca_sub[c].transform(latent_new[clusterRes_reordered_new==cnew])[:,:n_pcs])\n",
    "    with open(os.path.join(subclustersavedir_valsamples,'minibatchkmean_ncluster'+str(subclusternumbers[c])+'n_pcs'+str(n_pcs)+'epoch'+str(plotepoch)+'_all'), 'wb') as output:\n",
    "        pickle.dump(clusterRes_sub_new, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

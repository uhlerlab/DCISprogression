{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "import scanpy\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import models.loadImg as loadImg\n",
    "import models.modelsCNN as modelsCNN\n",
    "import models.optimizer as optimizer\n",
    "\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import gc\n",
    "from skimage import io\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"2\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\" \n",
    "use_cuda=True\n",
    "datadir='/media/xinyi/dcis2idc/data'\n",
    "name='exp0'\n",
    "plotsavepath='/media/xinyi/dcis2idc/plots/cnnvae'+name\n",
    "plottype='umap'\n",
    "sampledir=plotsavepath\n",
    "savedir=os.path.join(sampledir,'embedding_'+plottype)\n",
    "clustersavedir=os.path.join(sampledir,'cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(datadir,'processed','train_cnnvae_names'), 'rb') as input:\n",
    "    allImgNames=pickle.load(input)\n",
    "\n",
    "br1003aSpecs=pd.read_excel('/media/xinyi/dcis2idc/data/BR1003a specs.xlsx',header=10)\n",
    "br301Specs=pd.read_excel('/media/xinyi/dcis2idc/data/BR301 specs.xlsx',header=10)\n",
    "br8018aSpecs=pd.read_excel('/media/xinyi/dcis2idc/data/BR8018a specs.xlsx',header=10)\n",
    "br1003aSpecs.index=br1003aSpecs.loc[:,'Position']\n",
    "br301Specs.index=br301Specs.loc[:,'Position']\n",
    "br8018aSpecs.index=br8018aSpecs.loc[:,'Position']\n",
    "progList=np.copy(allImgNames)\n",
    "for s in np.unique(allImgNames):\n",
    "    ssplit=s.split('_')\n",
    "    if 'br1003a'==ssplit[0]:\n",
    "        prog_s=br1003aSpecs.loc[(ssplit[-1],'Pathology diagnosis')]\n",
    "    elif 'br301'==ssplit[0]:\n",
    "        prog_s=br301Specs.loc[(ssplit[-1],'Pathology diagnosis')]\n",
    "    elif 'br8018a'==ssplit[0]:\n",
    "        prog_s=br8018aSpecs.loc[(ssplit[-1],'Pathology diagnosis')]\n",
    "    progList[allImgNames==s]=prog_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_A1 Hyperplasia\n",
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_A2 Hyperplasia\n",
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_A4 Hyperplasia\n",
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_A5 Hyperplasia\n",
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_A6 Hyperplasia\n",
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_A7 Hyperplasia\n",
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_A8 Hyperplasia\n",
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_A9 Hyperplasia\n",
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_C1 Atypical hyperplasia\n",
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_C10 Hyperplasia\n",
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_C2 Hyperplasia\n",
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_C3 Atypical hyperplasia\n",
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_C4 Atypical hyperplasia\n",
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_C5 Atypical hyperplasia\n",
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_C6 Atypical hyperplasia\n",
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_C7 Hyperplasia\n",
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_C8 Hyperplasia\n",
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_C9 Hyperplasia\n",
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_I1 Breast tissue\n",
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_I10 Breast tissue\n",
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_I2 Breast tissue\n",
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_I3 Breast tissue\n",
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_I7 Breast tissue\n",
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_I8 Breast tissue\n",
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_I9 Breast tissue\n",
      "br1003a_3_collagen1_647_hoechst_A1 Hyperplasia\n",
      "br1003a_3_collagen1_647_hoechst_A2 Hyperplasia\n",
      "br1003a_3_collagen1_647_hoechst_A3 Hyperplasia\n",
      "br1003a_3_collagen1_647_hoechst_A5 Hyperplasia\n",
      "br1003a_3_collagen1_647_hoechst_A6 Hyperplasia\n",
      "br1003a_3_collagen1_647_hoechst_A7 Hyperplasia\n",
      "br1003a_3_collagen1_647_hoechst_A8 Hyperplasia\n",
      "br1003a_3_collagen1_647_hoechst_A9 Hyperplasia\n",
      "br1003a_3_collagen1_647_hoechst_C1 Atypical hyperplasia\n",
      "br1003a_3_collagen1_647_hoechst_C10 Hyperplasia\n",
      "br1003a_3_collagen1_647_hoechst_C2 Hyperplasia\n",
      "br1003a_3_collagen1_647_hoechst_C3 Atypical hyperplasia\n",
      "br1003a_3_collagen1_647_hoechst_C4 Atypical hyperplasia\n",
      "br1003a_3_collagen1_647_hoechst_C5 Atypical hyperplasia\n",
      "br1003a_3_collagen1_647_hoechst_C6 Atypical hyperplasia\n",
      "br1003a_3_collagen1_647_hoechst_C7 Hyperplasia\n",
      "br1003a_3_collagen1_647_hoechst_C8 Hyperplasia\n",
      "br1003a_3_collagen1_647_hoechst_C9 Hyperplasia\n",
      "br1003a_3_collagen1_647_hoechst_I1 Breast tissue\n",
      "br1003a_3_collagen1_647_hoechst_I10 Breast tissue\n",
      "br1003a_3_collagen1_647_hoechst_I2 Breast tissue\n",
      "br1003a_3_collagen1_647_hoechst_I3 Breast tissue\n",
      "br1003a_3_collagen1_647_hoechst_I7 Breast tissue\n",
      "br1003a_3_collagen1_647_hoechst_I8 Breast tissue\n",
      "br1003a_3_collagen1_647_hoechst_I9 Breast tissue\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_A1 Hyperplasia\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_A10 Hyperplasia\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_A2 Hyperplasia\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_A3 Hyperplasia\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_A4 Hyperplasia\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_A5 Hyperplasia\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_A6 Hyperplasia\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_A7 Hyperplasia\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_A8 Hyperplasia\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_A9 Hyperplasia\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_C1 Atypical hyperplasia\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_C10 Hyperplasia\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_C2 Hyperplasia\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_C4 Atypical hyperplasia\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_C5 Atypical hyperplasia\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_C6 Atypical hyperplasia\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_C7 Hyperplasia\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_C8 Hyperplasia\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_C9 Hyperplasia\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_I1 Breast tissue\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_I2 Breast tissue\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_I3 Breast tissue\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_I7 Breast tissue\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_I8 Breast tissue\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_I9 Breast tissue\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_A1 Ductal carcinoma in situ and breast tissue\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_A2 Ductal carcinoma in situ with early infiltratio\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_A3 Ductal carcinoma in situ\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_A4 Ductal carcinoma in situ\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_A5 Ductal carcinoma in situ and breast tissue\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_A6 Ductal carcinoma in situ and breast tissue\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_B1 Invasive ductal carcinoma\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_B2 Ductal carcinoma in situ and breast tissue\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_B3 Ductal carcinoma in situ and breast tissue\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_B4 Ductal carcinoma in situ and breast tissue\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_B5 Invasive ductal carcinoma and breast tissue\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_B6 Invasive ductal carcinoma and breast tissue\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_C1 Ductal carcinoma in situ with early infiltratio\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_C2 Ductal carcinoma in situ with early infiltratio\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_C3 Micropapillary type ductal carcinoma in situ wi\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_C4 Micropapillary type ductal carcinoma in situ wi\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_C5 Ductal carcinoma in situ with early infiltratio\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_C6 Ductal carcinoma in situ with early infiltratio\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_D1 Ductal carcinoma in situ with early infiltratio\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_D2 Ductal carcinoma in situ with early infiltratio\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_D3 Invasive ductal carcinoma and breast tissue\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_D4 Invasive ductal carcinoma\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_D5 Ductal carcinoma in situ with early infiltratio\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_D6 Ductal carcinoma in situ with early infiltratio\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_E1 Ductal carcinoma in situ with early infiltratio\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_E2 Ductal carcinoma in situ with early infiltratio\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_E3 Invasive ductal carcinoma and breast tissue\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_E4 Invasive ductal carcinoma\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_E5 Ductal carcinoma in situ with early infiltratio\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_E6 Ductal carcinoma in situ with early infiltratio\n",
      "br301_6_collagen1_647_hoechst_A1 Ductal carcinoma in situ and breast tissue\n",
      "br301_6_collagen1_647_hoechst_A2 Ductal carcinoma in situ with early infiltratio\n",
      "br301_6_collagen1_647_hoechst_A3 Ductal carcinoma in situ\n",
      "br301_6_collagen1_647_hoechst_A4 Ductal carcinoma in situ\n",
      "br301_6_collagen1_647_hoechst_A5 Ductal carcinoma in situ and breast tissue\n",
      "br301_6_collagen1_647_hoechst_A6 Ductal carcinoma in situ and breast tissue\n",
      "br301_6_collagen1_647_hoechst_B1 Invasive ductal carcinoma\n",
      "br301_6_collagen1_647_hoechst_B2 Ductal carcinoma in situ and breast tissue\n",
      "br301_6_collagen1_647_hoechst_B3 Ductal carcinoma in situ and breast tissue\n",
      "br301_6_collagen1_647_hoechst_B4 Ductal carcinoma in situ and breast tissue\n",
      "br301_6_collagen1_647_hoechst_B5 Invasive ductal carcinoma and breast tissue\n",
      "br301_6_collagen1_647_hoechst_B6 Invasive ductal carcinoma and breast tissue\n",
      "br301_6_collagen1_647_hoechst_C1 Ductal carcinoma in situ with early infiltratio\n",
      "br301_6_collagen1_647_hoechst_C2 Ductal carcinoma in situ with early infiltratio\n",
      "br301_6_collagen1_647_hoechst_C3 Micropapillary type ductal carcinoma in situ wi\n",
      "br301_6_collagen1_647_hoechst_C4 Micropapillary type ductal carcinoma in situ wi\n",
      "br301_6_collagen1_647_hoechst_C5 Ductal carcinoma in situ with early infiltratio\n",
      "br301_6_collagen1_647_hoechst_C6 Ductal carcinoma in situ with early infiltratio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "br301_6_collagen1_647_hoechst_D1 Ductal carcinoma in situ with early infiltratio\n",
      "br301_6_collagen1_647_hoechst_D2 Ductal carcinoma in situ with early infiltratio\n",
      "br301_6_collagen1_647_hoechst_D3 Invasive ductal carcinoma and breast tissue\n",
      "br301_6_collagen1_647_hoechst_D4 Invasive ductal carcinoma\n",
      "br301_6_collagen1_647_hoechst_D5 Ductal carcinoma in situ with early infiltratio\n",
      "br301_6_collagen1_647_hoechst_D6 Ductal carcinoma in situ with early infiltratio\n",
      "br301_6_collagen1_647_hoechst_E1 Ductal carcinoma in situ with early infiltratio\n",
      "br301_6_collagen1_647_hoechst_E2 Ductal carcinoma in situ with early infiltratio\n",
      "br301_6_collagen1_647_hoechst_E3 Invasive ductal carcinoma and breast tissue\n",
      "br301_6_collagen1_647_hoechst_E4 Invasive ductal carcinoma\n",
      "br301_6_collagen1_647_hoechst_E5 Ductal carcinoma in situ with early infiltratio\n",
      "br301_6_collagen1_647_hoechst_E6 Ductal carcinoma in situ with early infiltratio\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_A1 Invasive ductal carcinoma\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_A10 Invasive ductal carcinoma\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_A2 Invasive ductal carcinoma\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_A3 Invasive ductal carcinoma\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_A4 Invasive ductal carcinoma\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_A5 Invasive ductal carcinoma\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_A6 Invasive ductal carcinoma\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_A7 Invasive ductal carcinoma\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_A8 Invasive ductal carcinoma\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_A9 Invasive ductal carcinoma\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_B1 Invasive ductal carcinoma\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_B10 Invasive ductal carcinoma\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_B2 Invasive ductal carcinoma\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_B3 Invasive ductal carcinoma\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_B4 Invasive ductal carcinoma\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_B5 Invasive ductal carcinoma\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_B6 Invasive ductal carcinoma (breast tissue)\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_B7 Invasive ductal carcinoma\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_B8 Invasive ductal carcinoma\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_F1 Invasive ductal carcinoma\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_F10 Invasive ductal carcinoma\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_F2 Invasive ductal carcinoma\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_F3 Invasive ductal carcinoma\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_F4 Invasive ductal carcinoma\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_F5 Invasive ductal carcinoma\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_F6 Invasive ductal carcinoma\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_F7 Invasive ductal carcinoma\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_F8 Invasive ductal carcinoma\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_F9 Invasive ductal carcinoma\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_H1 Cancer adjacent normal breast tissue\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_H2 Cancer adjacent normal breast tissue\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_H3 Cancer adjacent normal breast tissue\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_H4 Cancer adjacent normal breast tissue\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_H5 Cancer adjacent normal breast tissue\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_H6 Cancer adjacent normal breast tissue\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_H7 Cancer adjacent normal breast tissue\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_H8 Cancer adjacent normal breast tissue\n",
      "br8018a_3_collagen1_647_hoechst_A1 Invasive ductal carcinoma\n",
      "br8018a_3_collagen1_647_hoechst_A2 Invasive ductal carcinoma\n",
      "br8018a_3_collagen1_647_hoechst_A3 Invasive ductal carcinoma\n",
      "br8018a_3_collagen1_647_hoechst_A4 Invasive ductal carcinoma\n",
      "br8018a_3_collagen1_647_hoechst_A6 Invasive ductal carcinoma\n",
      "br8018a_3_collagen1_647_hoechst_A7 Invasive ductal carcinoma\n",
      "br8018a_3_collagen1_647_hoechst_A8 Invasive ductal carcinoma\n",
      "br8018a_3_collagen1_647_hoechst_A9 Invasive ductal carcinoma\n",
      "br8018a_3_collagen1_647_hoechst_B1 Invasive ductal carcinoma\n",
      "br8018a_3_collagen1_647_hoechst_B10 Invasive ductal carcinoma\n",
      "br8018a_3_collagen1_647_hoechst_B2 Invasive ductal carcinoma\n",
      "br8018a_3_collagen1_647_hoechst_B3 Invasive ductal carcinoma\n",
      "br8018a_3_collagen1_647_hoechst_B4 Invasive ductal carcinoma\n",
      "br8018a_3_collagen1_647_hoechst_B5 Invasive ductal carcinoma\n",
      "br8018a_3_collagen1_647_hoechst_B6 Invasive ductal carcinoma (breast tissue)\n",
      "br8018a_3_collagen1_647_hoechst_B7 Invasive ductal carcinoma\n",
      "br8018a_3_collagen1_647_hoechst_B8 Invasive ductal carcinoma\n",
      "br8018a_3_collagen1_647_hoechst_B9 Invasive ductal carcinoma\n",
      "br8018a_3_collagen1_647_hoechst_F10 Invasive ductal carcinoma\n",
      "br8018a_3_collagen1_647_hoechst_F3 Invasive ductal carcinoma\n",
      "br8018a_3_collagen1_647_hoechst_F4 Invasive ductal carcinoma\n",
      "br8018a_3_collagen1_647_hoechst_F6 Invasive ductal carcinoma\n",
      "br8018a_3_collagen1_647_hoechst_F7 Invasive ductal carcinoma\n",
      "br8018a_3_collagen1_647_hoechst_F8 Invasive ductal carcinoma\n",
      "br8018a_3_collagen1_647_hoechst_F9 Invasive ductal carcinoma\n",
      "br8018a_4_cytokeratin_555_gh2ax_647_hoechst_A2 Invasive ductal carcinoma\n",
      "br8018a_4_cytokeratin_555_gh2ax_647_hoechst_A3 Invasive ductal carcinoma\n",
      "br8018a_4_cytokeratin_555_gh2ax_647_hoechst_A5 Invasive ductal carcinoma\n",
      "br8018a_4_cytokeratin_555_gh2ax_647_hoechst_A7 Invasive ductal carcinoma\n",
      "br8018a_4_cytokeratin_555_gh2ax_647_hoechst_A8 Invasive ductal carcinoma\n",
      "br8018a_4_cytokeratin_555_gh2ax_647_hoechst_B4 Invasive ductal carcinoma\n",
      "br8018a_4_cytokeratin_555_gh2ax_647_hoechst_B5 Invasive ductal carcinoma\n",
      "br8018a_4_cytokeratin_555_gh2ax_647_hoechst_B6 Invasive ductal carcinoma (breast tissue)\n",
      "br8018a_4_cytokeratin_555_gh2ax_647_hoechst_B7 Invasive ductal carcinoma\n",
      "br8018a_4_cytokeratin_555_gh2ax_647_hoechst_F3 Invasive ductal carcinoma\n",
      "br8018a_4_cytokeratin_555_gh2ax_647_hoechst_F4 Invasive ductal carcinoma\n",
      "br8018a_4_cytokeratin_555_gh2ax_647_hoechst_F7 Invasive ductal carcinoma\n",
      "br8018a_4_cytokeratin_555_gh2ax_647_hoechst_F8 Invasive ductal carcinoma\n",
      "br8018a_4_cytokeratin_555_gh2ax_647_hoechst_H1 Cancer adjacent normal breast tissue\n",
      "br8018a_4_cytokeratin_555_gh2ax_647_hoechst_H3 Cancer adjacent normal breast tissue\n",
      "br8018a_4_cytokeratin_555_gh2ax_647_hoechst_H5 Cancer adjacent normal breast tissue\n",
      "br8018a_4_cytokeratin_555_gh2ax_647_hoechst_H6 Cancer adjacent normal breast tissue\n",
      "br8018a_4_cytokeratin_555_gh2ax_647_hoechst_H8 Cancer adjacent normal breast tissue\n"
     ]
    }
   ],
   "source": [
    "progNames,progCounts=np.unique(progList,return_counts=True)\n",
    "progSampleRate={}\n",
    "for p in range(progNames.size):\n",
    "    progSampleRate[progNames[p]]=np.min(progCounts)/progCounts[p]\n",
    "    \n",
    "\n",
    "\n",
    "ep=311\n",
    "np.random.seed(6)\n",
    "# plotPCT=4500\n",
    "plottingIdx_i=np.array([])\n",
    "n_pcs=50\n",
    "uniqueImgNames,imgNameIdx=np.unique(allImgNames,return_index=True)\n",
    "for i in range(1):\n",
    "    for sidx in range(uniqueImgNames.size):\n",
    "        s=uniqueImgNames[sidx]\n",
    "        p=progList[imgNameIdx[sidx]]\n",
    "        print(s+' '+p)\n",
    "        nsamples=int(np.sum(allImgNames==s)*progSampleRate[p])\n",
    "        plottingIdx_i=np.concatenate((plottingIdx_i,\n",
    "                                    np.random.choice(np.arange(allImgNames.shape[0])[allImgNames==s],nsamples,replace=False)))\n",
    "    \n",
    "ncluster=8\n",
    "plotsavenameAdd='_plottingIdx_progBalanced_'+str(i)\n",
    "savenamecluster='minibatchkmean_ncluster'+str(ncluster)+'n_pcs'+str(n_pcs)+'epoch'+str(ep)+plotsavenameAdd\n",
    "with open(os.path.join(clustersavedir,savenamecluster), 'rb') as output:\n",
    "    clusterRes=pickle.load(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "subclusternumbers=[4,6,8,6,6,6,6,4]\n",
    "clusterRes_sub=np.zeros(clusterRes.size)-1\n",
    "for i in np.unique(clusterRes):\n",
    "    subcluster=subclusternumbers[i]\n",
    "    subclustersavedir=os.path.join(clustersavedir,savenamecluster+'_subcluster'+str(i))\n",
    "\n",
    "    savenameclustersub='minibatchkmean_ncluster'+str(subcluster)+'n_pcs'+str(n_pcs)+'epoch'+str(ep)+plotsavenameAdd\n",
    "    with open(os.path.join(subclustersavedir,savenameclustersub), 'rb') as output:\n",
    "        subclusterRes=pickle.load(output)\n",
    "        \n",
    "    clusterRes_sub[clusterRes==i]=subclusterRes\n",
    "\n",
    "print(np.sum(clusterRes_sub==-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(datadir,'processed','train_cnnvae_cellLabels'), 'rb') as output:\n",
    "    cellIDlist=pickle.load(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_A1\n",
      "(380, 201)\n",
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_A2\n",
      "(508, 201)\n",
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_A4\n",
      "(360, 201)\n",
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_A5\n",
      "(358, 201)\n",
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_A6\n",
      "(525, 201)\n",
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_A7\n",
      "(314, 201)\n",
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_A8\n",
      "(862, 201)\n",
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_A9\n",
      "(484, 201)\n",
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_C1\n",
      "(2997, 201)\n",
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_C10\n",
      "(773, 201)\n",
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_C2\n",
      "(1286, 201)\n",
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_C3\n",
      "(1131, 201)\n",
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_C4\n",
      "(2694, 201)\n",
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_C5\n",
      "(954, 201)\n",
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_C6\n",
      "(780, 201)\n",
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_C7\n",
      "(667, 201)\n",
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_C8\n",
      "(392, 201)\n",
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_C9\n",
      "(1112, 201)\n",
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_I1\n",
      "(1287, 201)\n",
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_I10\n",
      "(1495, 201)\n",
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_I2\n",
      "(1610, 201)\n",
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_I3\n",
      "(1532, 201)\n",
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_I7\n",
      "(1385, 201)\n",
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_I8\n",
      "(1789, 201)\n",
      "br1003a_1_cytokeratin_555_aSMA_647_hoechst_I9\n",
      "(856, 201)\n",
      "br1003a_3_collagen1_647_hoechst_A1\n",
      "(459, 201)\n",
      "br1003a_3_collagen1_647_hoechst_A2\n",
      "(664, 201)\n",
      "br1003a_3_collagen1_647_hoechst_A3\n",
      "(475, 201)\n",
      "br1003a_3_collagen1_647_hoechst_A5\n",
      "(507, 201)\n",
      "br1003a_3_collagen1_647_hoechst_A6\n",
      "(361, 201)\n",
      "br1003a_3_collagen1_647_hoechst_A7\n",
      "(716, 201)\n",
      "br1003a_3_collagen1_647_hoechst_A8\n",
      "(481, 201)\n",
      "br1003a_3_collagen1_647_hoechst_A9\n",
      "(274, 201)\n",
      "br1003a_3_collagen1_647_hoechst_C1\n",
      "(2720, 201)\n",
      "br1003a_3_collagen1_647_hoechst_C10\n",
      "(779, 201)\n",
      "br1003a_3_collagen1_647_hoechst_C2\n",
      "(1286, 201)\n",
      "br1003a_3_collagen1_647_hoechst_C3\n",
      "(1172, 201)\n",
      "br1003a_3_collagen1_647_hoechst_C4\n",
      "(2233, 201)\n",
      "br1003a_3_collagen1_647_hoechst_C5\n",
      "(1350, 201)\n",
      "br1003a_3_collagen1_647_hoechst_C6\n",
      "(1136, 201)\n",
      "br1003a_3_collagen1_647_hoechst_C7\n",
      "(890, 201)\n",
      "br1003a_3_collagen1_647_hoechst_C8\n",
      "(556, 201)\n",
      "br1003a_3_collagen1_647_hoechst_C9\n",
      "(824, 201)\n",
      "br1003a_3_collagen1_647_hoechst_I1\n",
      "(1003, 201)\n",
      "br1003a_3_collagen1_647_hoechst_I10\n",
      "(1564, 201)\n",
      "br1003a_3_collagen1_647_hoechst_I2\n",
      "(1201, 201)\n",
      "br1003a_3_collagen1_647_hoechst_I3\n",
      "(1379, 201)\n",
      "br1003a_3_collagen1_647_hoechst_I7\n",
      "(1300, 201)\n",
      "br1003a_3_collagen1_647_hoechst_I8\n",
      "(1609, 201)\n",
      "br1003a_3_collagen1_647_hoechst_I9\n",
      "(853, 201)\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_A1\n",
      "(253, 201)\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_A10\n",
      "(361, 201)\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_A2\n",
      "(336, 201)\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_A3\n",
      "(436, 201)\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_A4\n",
      "(188, 201)\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_A5\n",
      "(512, 201)\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_A6\n",
      "(235, 201)\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_A7\n",
      "(545, 201)\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_A8\n",
      "(451, 201)\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_A9\n",
      "(138, 201)\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_C1\n",
      "(2711, 201)\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_C10\n",
      "(939, 201)\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_C2\n",
      "(1111, 201)\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_C4\n",
      "(1151, 201)\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_C5\n",
      "(2269, 201)\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_C6\n",
      "(920, 201)\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_C7\n",
      "(1025, 201)\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_C8\n",
      "(282, 201)\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_C9\n",
      "(1098, 201)\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_I1\n",
      "(937, 201)\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_I2\n",
      "(1149, 201)\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_I3\n",
      "(1117, 201)\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_I7\n",
      "(552, 201)\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_I8\n",
      "(928, 201)\n",
      "br1003a_4_cytokeratin_555_gh2ax_647_hoechst_I9\n",
      "(670, 201)\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_A1\n",
      "(3318, 201)\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_A2\n",
      "(1504, 201)\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_A3\n",
      "(9225, 201)\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_A4\n",
      "(3724, 201)\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_A5\n",
      "(915, 201)\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_A6\n",
      "(1187, 201)\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_B1\n",
      "(241, 201)\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_B2\n",
      "(2916, 201)\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_B3\n",
      "(2204, 201)\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_B4\n",
      "(2548, 201)\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_B5\n",
      "(2173, 201)\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_B6\n",
      "(2702, 201)\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_C1\n",
      "(851, 201)\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_C2\n",
      "(1305, 201)\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_C3\n",
      "(8036, 201)\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_C4\n",
      "(4798, 201)\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_C5\n",
      "(1260, 201)\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_C6\n",
      "(1578, 201)\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_D1\n",
      "(634, 201)\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_D2\n",
      "(617, 201)\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_D3\n",
      "(1573, 201)\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_D4\n",
      "(509, 201)\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_D5\n",
      "(1106, 201)\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_D6\n",
      "(751, 201)\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_E1\n",
      "(794, 201)\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_E2\n",
      "(692, 201)\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_E3\n",
      "(4444, 201)\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_E4\n",
      "(887, 201)\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_E5\n",
      "(784, 201)\n",
      "br301_4_cytokeratin_555_aSMA_647_hoechst_E6\n",
      "(674, 201)\n",
      "br301_6_collagen1_647_hoechst_A1\n",
      "(3422, 201)\n",
      "br301_6_collagen1_647_hoechst_A2\n",
      "(1052, 201)\n",
      "br301_6_collagen1_647_hoechst_A3\n",
      "(10088, 201)\n",
      "br301_6_collagen1_647_hoechst_A4\n",
      "(1184, 201)\n",
      "br301_6_collagen1_647_hoechst_A5\n",
      "(564, 201)\n",
      "br301_6_collagen1_647_hoechst_A6\n",
      "(1005, 201)\n",
      "br301_6_collagen1_647_hoechst_B1\n",
      "(342, 201)\n",
      "br301_6_collagen1_647_hoechst_B2\n",
      "(1725, 201)\n",
      "br301_6_collagen1_647_hoechst_B3\n",
      "(2325, 201)\n",
      "br301_6_collagen1_647_hoechst_B4\n",
      "(2088, 201)\n",
      "br301_6_collagen1_647_hoechst_B5\n",
      "(3392, 201)\n",
      "br301_6_collagen1_647_hoechst_B6\n",
      "(4106, 201)\n",
      "br301_6_collagen1_647_hoechst_C1\n",
      "(696, 201)\n",
      "br301_6_collagen1_647_hoechst_C2\n",
      "(1148, 201)\n",
      "br301_6_collagen1_647_hoechst_C3\n",
      "(5698, 201)\n",
      "br301_6_collagen1_647_hoechst_C4\n",
      "(5690, 201)\n",
      "br301_6_collagen1_647_hoechst_C5\n",
      "(664, 201)\n",
      "br301_6_collagen1_647_hoechst_C6\n",
      "(1198, 201)\n",
      "br301_6_collagen1_647_hoechst_D1\n",
      "(966, 201)\n",
      "br301_6_collagen1_647_hoechst_D2\n",
      "(699, 201)\n",
      "br301_6_collagen1_647_hoechst_D3\n",
      "(2081, 201)\n",
      "br301_6_collagen1_647_hoechst_D4\n",
      "(570, 201)\n",
      "br301_6_collagen1_647_hoechst_D5\n",
      "(1723, 201)\n",
      "br301_6_collagen1_647_hoechst_D6\n",
      "(650, 201)\n",
      "br301_6_collagen1_647_hoechst_E1\n",
      "(1006, 201)\n",
      "br301_6_collagen1_647_hoechst_E2\n",
      "(490, 201)\n",
      "br301_6_collagen1_647_hoechst_E3\n",
      "(3749, 201)\n",
      "br301_6_collagen1_647_hoechst_E4\n",
      "(918, 201)\n",
      "br301_6_collagen1_647_hoechst_E5\n",
      "(667, 201)\n",
      "br301_6_collagen1_647_hoechst_E6\n",
      "(704, 201)\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_A1\n",
      "(212, 201)\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_A10\n",
      "(135, 201)\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_A2\n",
      "(252, 201)\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_A3\n",
      "(457, 201)\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_A4\n",
      "(356, 201)\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_A5\n",
      "(165, 201)\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_A6\n",
      "(416, 201)\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_A7\n",
      "(537, 201)\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_A8\n",
      "(203, 201)\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_A9\n",
      "(278, 201)\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_B1\n",
      "(275, 201)\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_B10\n",
      "(31, 201)\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_B2\n",
      "(379, 201)\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_B3\n",
      "(461, 201)\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_B4\n",
      "(426, 201)\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_B5\n",
      "(412, 201)\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_B6\n",
      "(8109, 201)\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_B7\n",
      "(299, 201)\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_B8\n",
      "(233, 201)\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_F1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(276, 201)\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_F10\n",
      "(312, 201)\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_F2\n",
      "(302, 201)\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_F3\n",
      "(227, 201)\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_F4\n",
      "(395, 201)\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_F5\n",
      "(169, 201)\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_F6\n",
      "(289, 201)\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_F7\n",
      "(308, 201)\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_F8\n",
      "(472, 201)\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_F9\n",
      "(358, 201)\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_H1\n",
      "(816, 201)\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_H2\n",
      "(3293, 201)\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_H3\n",
      "(2464, 201)\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_H4\n",
      "(1920, 201)\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_H5\n",
      "(1439, 201)\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_H6\n",
      "(2562, 201)\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_H7\n",
      "(1716, 201)\n",
      "br8018a_1_cytokeratin_555_aSMA_647_hoechst_H8\n",
      "(2838, 201)\n",
      "br8018a_3_collagen1_647_hoechst_A1\n",
      "(177, 201)\n",
      "br8018a_3_collagen1_647_hoechst_A2\n",
      "(242, 201)\n",
      "br8018a_3_collagen1_647_hoechst_A3\n",
      "(242, 201)\n",
      "br8018a_3_collagen1_647_hoechst_A4\n",
      "(274, 201)\n",
      "br8018a_3_collagen1_647_hoechst_A6\n",
      "(270, 201)\n",
      "br8018a_3_collagen1_647_hoechst_A7\n",
      "(460, 201)\n",
      "br8018a_3_collagen1_647_hoechst_A8\n",
      "(199, 201)\n",
      "br8018a_3_collagen1_647_hoechst_A9\n",
      "(182, 201)\n",
      "br8018a_3_collagen1_647_hoechst_B1\n",
      "(283, 201)\n",
      "br8018a_3_collagen1_647_hoechst_B10\n",
      "(309, 201)\n",
      "br8018a_3_collagen1_647_hoechst_B2\n",
      "(389, 201)\n",
      "br8018a_3_collagen1_647_hoechst_B3\n",
      "(522, 201)\n",
      "br8018a_3_collagen1_647_hoechst_B4\n",
      "(475, 201)\n",
      "br8018a_3_collagen1_647_hoechst_B5\n",
      "(355, 201)\n",
      "br8018a_3_collagen1_647_hoechst_B6\n",
      "(7843, 201)\n",
      "br8018a_3_collagen1_647_hoechst_B7\n",
      "(351, 201)\n",
      "br8018a_3_collagen1_647_hoechst_B8\n",
      "(230, 201)\n",
      "br8018a_3_collagen1_647_hoechst_B9\n",
      "(339, 201)\n",
      "br8018a_3_collagen1_647_hoechst_F10\n",
      "(467, 201)\n",
      "br8018a_3_collagen1_647_hoechst_F3\n",
      "(202, 201)\n",
      "br8018a_3_collagen1_647_hoechst_F4\n",
      "(362, 201)\n",
      "br8018a_3_collagen1_647_hoechst_F6\n",
      "(297, 201)\n",
      "br8018a_3_collagen1_647_hoechst_F7\n",
      "(341, 201)\n",
      "br8018a_3_collagen1_647_hoechst_F8\n",
      "(476, 201)\n",
      "br8018a_3_collagen1_647_hoechst_F9\n",
      "(419, 201)\n",
      "br8018a_4_cytokeratin_555_gh2ax_647_hoechst_A2\n",
      "(259, 201)\n",
      "br8018a_4_cytokeratin_555_gh2ax_647_hoechst_A3\n",
      "(453, 201)\n",
      "br8018a_4_cytokeratin_555_gh2ax_647_hoechst_A5\n",
      "(150, 201)\n",
      "br8018a_4_cytokeratin_555_gh2ax_647_hoechst_A7\n",
      "(488, 201)\n",
      "br8018a_4_cytokeratin_555_gh2ax_647_hoechst_A8\n",
      "(211, 201)\n",
      "br8018a_4_cytokeratin_555_gh2ax_647_hoechst_B4\n",
      "(484, 201)\n",
      "br8018a_4_cytokeratin_555_gh2ax_647_hoechst_B5\n",
      "(276, 201)\n",
      "br8018a_4_cytokeratin_555_gh2ax_647_hoechst_B6\n",
      "(8272, 201)\n",
      "br8018a_4_cytokeratin_555_gh2ax_647_hoechst_B7\n",
      "(356, 201)\n",
      "br8018a_4_cytokeratin_555_gh2ax_647_hoechst_F3\n",
      "(228, 201)\n",
      "br8018a_4_cytokeratin_555_gh2ax_647_hoechst_F4\n",
      "(409, 201)\n",
      "br8018a_4_cytokeratin_555_gh2ax_647_hoechst_F7\n",
      "(308, 201)\n",
      "br8018a_4_cytokeratin_555_gh2ax_647_hoechst_F8\n",
      "(605, 201)\n",
      "br8018a_4_cytokeratin_555_gh2ax_647_hoechst_H1\n",
      "(1764, 201)\n",
      "br8018a_4_cytokeratin_555_gh2ax_647_hoechst_H3\n",
      "(1925, 201)\n",
      "br8018a_4_cytokeratin_555_gh2ax_647_hoechst_H5\n",
      "(311, 201)\n",
      "br8018a_4_cytokeratin_555_gh2ax_647_hoechst_H6\n",
      "(2234, 201)\n",
      "br8018a_4_cytokeratin_555_gh2ax_647_hoechst_H8\n",
      "(936, 201)\n"
     ]
    }
   ],
   "source": [
    "#load NMCO\n",
    "uniquenames,nameIdx=np.unique(allImgNames,return_index=True)\n",
    "\n",
    "allstats=None\n",
    "alllabels=None\n",
    "alllabels_sub=None\n",
    "allvarnames=None\n",
    "for sidx in range(uniquenames.size):\n",
    "    s=np.unique(allImgNames)[sidx]\n",
    "\n",
    "    path_s=os.path.join(datadir,'_'.join(s.split('_')[:-1]),'nmco_features',s.split('_')[-1] +'.csv')\n",
    "    if not os.path.exists(path_s):\n",
    "        print('DNE '+path_s)\n",
    "    print(s)\n",
    "    plottingIdx_i_s=plottingIdx_i.astype(int)[allImgNames[plottingIdx_i.astype(int)]==s]-nameIdx[sidx]\n",
    "    assert np.min(plottingIdx_i_s)>=0\n",
    "\n",
    "    stats_s=pd.read_csv(path_s)\n",
    "    stats_s.index=stats_s.loc[:,'label']\n",
    "    stats_s=stats_s.loc[cellIDlist[s][plottingIdx_i_s]].to_numpy()[:,2:-2]\n",
    "    print(stats_s.shape)\n",
    "\n",
    "\n",
    "#         ssplit=s.split('_')\n",
    "    slabels=clusterRes[allImgNames[plottingIdx_i.astype(int)]==s]\n",
    "    slabels_sub=clusterRes_sub[allImgNames[plottingIdx_i.astype(int)]==s]\n",
    "\n",
    "    if allstats is None:\n",
    "        allstats=stats_s\n",
    "        alllabels=np.copy(slabels)\n",
    "        alllabels_sub=np.copy(slabels_sub)\n",
    "    else:\n",
    "        allstats=np.concatenate((allstats,stats_s),axis=0)\n",
    "        alllabels=np.concatenate((alllabels,np.copy(slabels)))\n",
    "        alllabels_sub=np.concatenate((alllabels_sub,np.copy(slabels_sub)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=3\n",
    "epochs=6000\n",
    "saveFreq=200\n",
    "lr=0.001 #initial learning rate\n",
    "weight_decay=0 #Weight for L2 loss on embedding matrix.\n",
    "\n",
    "# batchsize=4\n",
    "batchsize=8000\n",
    "model_str='fc3'\n",
    "\n",
    "kernel_size=4\n",
    "stride=2\n",
    "padding=1\n",
    "\n",
    "fc_dim1=128\n",
    "fc_dim2=128\n",
    "fc_dim3=128\n",
    "\n",
    "\n",
    "dropout=0.01\n",
    "kl_weight=0.0000001\n",
    "\n",
    "name='exp0_clusterClf_nmco_subclusters_'+savenamecluster+'fcl3'\n",
    "logsavepath='/media/xinyi/dcis2idc/log/cnnvae'+name\n",
    "modelsavepath='/media/xinyi/dcis2idc/models/cnnvae'+name\n",
    "plotsavepath='/media/xinyi/dcis2idc/plots/cnnvae'+name\n",
    "\n",
    "\n",
    "if not os.path.exists(logsavepath):\n",
    "    os.mkdir(logsavepath)\n",
    "if not os.path.exists(modelsavepath):\n",
    "    os.mkdir(modelsavepath)\n",
    "if not os.path.exists(plotsavepath):\n",
    "    os.mkdir(plotsavepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    t = time.time()\n",
    "    model.train()\n",
    "    \n",
    "    loss_all=0\n",
    "    for i in range(int(np.ceil(trainIdx.shape[0]/batchsize))):\n",
    "        trainIdx_i=trainIdx[i*batchsize:min((i+1)*batchsize,trainIdx.shape[0])]\n",
    "        \n",
    "#         trainInput=trainInputnp[trainIdx]\n",
    "#         labels=trainLabelsnp[trainIdx]\n",
    "        if use_cuda:\n",
    "            trainInput=torch.tensor(stats_sub[trainIdx_i]).cuda().float()\n",
    "            labels=torch.tensor(labels_sub[trainIdx_i]).cuda().long()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred = model(trainInput)\n",
    "#         print(trainInput)\n",
    "#         print(pred)\n",
    "\n",
    "\n",
    "        loss=lossCE(pred,labels)\n",
    "        loss_all+=loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    loss_all=loss_all/int(np.ceil(trainIdx.shape[0]/batchsize))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        loss_val_all=0\n",
    "        nvalBatches=int(np.ceil(valIdx.shape[0]/batchsize))\n",
    "        for i in range(nvalBatches):\n",
    "            valIdx_i=valIdx[i*batchsize:min((i+1)*batchsize,valIdx.shape[0])]\n",
    "            if use_cuda:\n",
    "                valInput=torch.tensor(stats_sub[valIdx_i]).cuda().float()\n",
    "                labels=torch.tensor(labels_sub[valIdx_i]).cuda().long()\n",
    "                \n",
    "            pred= model(valInput)\n",
    "\n",
    "            loss_val=lossCE(pred,labels).item()\n",
    "\n",
    "            loss_val_all+=loss_val\n",
    "\n",
    "        loss_val_all=loss_val_all/nvalBatches\n",
    "    if epoch%20==0:\n",
    "        print('Epoch: {:04d}'.format(epoch),\n",
    "              'loss_train: {:.4f}'.format(loss_all),\n",
    "              'loss_val: {:.4f}'.format(loss_val_all))\n",
    "    return loss_all,loss_val_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0000 loss_train: 1.3693 loss_val: 1.3263\n",
      "Epoch: 0020 loss_train: 0.1974 loss_val: 0.1396\n",
      "Epoch: 0040 loss_train: 0.1425 loss_val: 0.1033\n",
      "Epoch: 0060 loss_train: 0.1148 loss_val: 0.0888\n",
      "Epoch: 0080 loss_train: 0.0978 loss_val: 0.0837\n",
      "Epoch: 0100 loss_train: 0.0883 loss_val: 0.0781\n",
      "Epoch: 0120 loss_train: 0.0758 loss_val: 0.0707\n",
      "Epoch: 0140 loss_train: 0.0723 loss_val: 0.0695\n",
      "Epoch: 0160 loss_train: 0.0682 loss_val: 0.0721\n",
      "Epoch: 0180 loss_train: 0.0641 loss_val: 0.0715\n",
      "Epoch: 0200 loss_train: 0.0602 loss_val: 0.0649\n",
      "Epoch: 0220 loss_train: 0.0548 loss_val: 0.0685\n",
      "Epoch: 0240 loss_train: 0.0554 loss_val: 0.0695\n",
      "Epoch: 0260 loss_train: 0.0538 loss_val: 0.0751\n",
      "Epoch: 0280 loss_train: 0.0483 loss_val: 0.0742\n",
      "Epoch: 0300 loss_train: 0.0481 loss_val: 0.0784\n",
      "Epoch: 0320 loss_train: 0.0468 loss_val: 0.0706\n",
      "Epoch: 0340 loss_train: 0.0427 loss_val: 0.0785\n",
      "Epoch: 0360 loss_train: 0.0416 loss_val: 0.0683\n",
      "Epoch: 0380 loss_train: 0.0436 loss_val: 0.0863\n",
      "Epoch: 0400 loss_train: 0.0375 loss_val: 0.0758\n",
      "Epoch: 0420 loss_train: 0.0381 loss_val: 0.0747\n",
      "Epoch: 0440 loss_train: 0.0392 loss_val: 0.0746\n",
      "Epoch: 0460 loss_train: 0.0355 loss_val: 0.0860\n",
      "Epoch: 0480 loss_train: 0.0345 loss_val: 0.0816\n",
      "Epoch: 0500 loss_train: 0.0339 loss_val: 0.0989\n",
      "Epoch: 0520 loss_train: 0.0312 loss_val: 0.0809\n",
      "Epoch: 0540 loss_train: 0.0327 loss_val: 0.0799\n",
      "Epoch: 0560 loss_train: 0.0348 loss_val: 0.0769\n",
      "Epoch: 0580 loss_train: 0.0310 loss_val: 0.0737\n",
      "Epoch: 0600 loss_train: 0.0292 loss_val: 0.0712\n",
      "Epoch: 0620 loss_train: 0.0332 loss_val: 0.0744\n",
      "Epoch: 0640 loss_train: 0.0262 loss_val: 0.0876\n",
      "Epoch: 0660 loss_train: 0.0292 loss_val: 0.0940\n",
      "Epoch: 0680 loss_train: 0.0285 loss_val: 0.0776\n",
      "Epoch: 0700 loss_train: 0.0260 loss_val: 0.0984\n",
      "Epoch: 0720 loss_train: 0.0283 loss_val: 0.0782\n",
      "Epoch: 0740 loss_train: 0.0275 loss_val: 0.0836\n",
      "Epoch: 0760 loss_train: 0.0253 loss_val: 0.0887\n",
      "Epoch: 0780 loss_train: 0.0269 loss_val: 0.0915\n",
      "Epoch: 0800 loss_train: 0.0252 loss_val: 0.0898\n",
      "Epoch: 0820 loss_train: 0.0262 loss_val: 0.0929\n",
      "Epoch: 0840 loss_train: 0.0271 loss_val: 0.0958\n",
      "Epoch: 0860 loss_train: 0.0283 loss_val: 0.0858\n",
      "Epoch: 0880 loss_train: 0.0269 loss_val: 0.0981\n",
      "Epoch: 0900 loss_train: 0.0237 loss_val: 0.0986\n",
      "Epoch: 0920 loss_train: 0.0280 loss_val: 0.0969\n",
      "Epoch: 0940 loss_train: 0.0265 loss_val: 0.0929\n",
      "Epoch: 0960 loss_train: 0.0236 loss_val: 0.0948\n",
      "Epoch: 0980 loss_train: 0.0230 loss_val: 0.0884\n",
      "Epoch: 1000 loss_train: 0.0255 loss_val: 0.1000\n",
      "Epoch: 1020 loss_train: 0.0245 loss_val: 0.1011\n",
      "Epoch: 1040 loss_train: 0.0258 loss_val: 0.0937\n",
      "Epoch: 1060 loss_train: 0.0208 loss_val: 0.0964\n",
      "Epoch: 1080 loss_train: 0.0239 loss_val: 0.1099\n",
      "Epoch: 1100 loss_train: 0.0250 loss_val: 0.1207\n",
      "Epoch: 1120 loss_train: 0.0244 loss_val: 0.1065\n",
      "Epoch: 1140 loss_train: 0.0226 loss_val: 0.1106\n",
      "Epoch: 1160 loss_train: 0.0228 loss_val: 0.1045\n",
      "Epoch: 1180 loss_train: 0.0227 loss_val: 0.0981\n",
      "Epoch: 1200 loss_train: 0.0213 loss_val: 0.1016\n",
      "Epoch: 1220 loss_train: 0.0195 loss_val: 0.1024\n",
      "Epoch: 1240 loss_train: 0.0222 loss_val: 0.1058\n",
      "Epoch: 1260 loss_train: 0.0229 loss_val: 0.0961\n",
      "Epoch: 1280 loss_train: 0.0230 loss_val: 0.1024\n",
      "Epoch: 1300 loss_train: 0.0177 loss_val: 0.0967\n",
      "Epoch: 1320 loss_train: 0.0228 loss_val: 0.1077\n",
      "Epoch: 1340 loss_train: 0.0270 loss_val: 0.0946\n",
      "Epoch: 1360 loss_train: 0.0194 loss_val: 0.1056\n",
      "Epoch: 1380 loss_train: 0.0180 loss_val: 0.0919\n",
      "Epoch: 1400 loss_train: 0.0196 loss_val: 0.1066\n",
      "Epoch: 1420 loss_train: 0.0181 loss_val: 0.1115\n",
      "Epoch: 1440 loss_train: 0.0192 loss_val: 0.1148\n",
      "Epoch: 1460 loss_train: 0.0185 loss_val: 0.1044\n",
      "Epoch: 1480 loss_train: 0.0188 loss_val: 0.1188\n",
      "Epoch: 1500 loss_train: 0.0190 loss_val: 0.0979\n",
      "Epoch: 1520 loss_train: 0.0191 loss_val: 0.1229\n",
      "Epoch: 1540 loss_train: 0.0177 loss_val: 0.1099\n",
      "Epoch: 1560 loss_train: 0.0190 loss_val: 0.1322\n",
      "Epoch: 1580 loss_train: 0.0198 loss_val: 0.1037\n",
      "Epoch: 1600 loss_train: 0.0199 loss_val: 0.1026\n",
      "Epoch: 1620 loss_train: 0.0195 loss_val: 0.1154\n",
      "Epoch: 1640 loss_train: 0.0214 loss_val: 0.0918\n",
      "Epoch: 1660 loss_train: 0.0191 loss_val: 0.1118\n",
      "Epoch: 1680 loss_train: 0.0196 loss_val: 0.1030\n",
      "Epoch: 1700 loss_train: 0.0186 loss_val: 0.1099\n",
      "Epoch: 1720 loss_train: 0.0189 loss_val: 0.1014\n",
      "Epoch: 1740 loss_train: 0.0218 loss_val: 0.1162\n",
      "Epoch: 1760 loss_train: 0.0184 loss_val: 0.1109\n",
      "Epoch: 1780 loss_train: 0.0203 loss_val: 0.1152\n",
      "Epoch: 1800 loss_train: 0.0165 loss_val: 0.1169\n",
      "Epoch: 1820 loss_train: 0.0172 loss_val: 0.1088\n",
      "Epoch: 1840 loss_train: 0.0178 loss_val: 0.1206\n",
      "Epoch: 1860 loss_train: 0.0185 loss_val: 0.1000\n",
      "Epoch: 1880 loss_train: 0.0188 loss_val: 0.1224\n",
      "Epoch: 1900 loss_train: 0.0165 loss_val: 0.1126\n",
      "Epoch: 1920 loss_train: 0.0179 loss_val: 0.1264\n",
      "Epoch: 1940 loss_train: 0.0196 loss_val: 0.1068\n",
      "Epoch: 1960 loss_train: 0.0165 loss_val: 0.1137\n",
      "Epoch: 1980 loss_train: 0.0153 loss_val: 0.1113\n",
      "Epoch: 2000 loss_train: 0.0206 loss_val: 0.1172\n",
      "Epoch: 2020 loss_train: 0.0171 loss_val: 0.1215\n",
      "Epoch: 2040 loss_train: 0.0166 loss_val: 0.1041\n",
      "Epoch: 2060 loss_train: 0.0168 loss_val: 0.1072\n",
      "Epoch: 2080 loss_train: 0.0153 loss_val: 0.1191\n",
      "Epoch: 2100 loss_train: 0.0158 loss_val: 0.1175\n",
      "Epoch: 2120 loss_train: 0.0157 loss_val: 0.1065\n",
      "Epoch: 2140 loss_train: 0.0155 loss_val: 0.1286\n",
      "Epoch: 2160 loss_train: 0.0184 loss_val: 0.1249\n",
      "Epoch: 2180 loss_train: 0.0178 loss_val: 0.0961\n",
      "Epoch: 2200 loss_train: 0.0159 loss_val: 0.1170\n",
      "Epoch: 2220 loss_train: 0.0185 loss_val: 0.1075\n",
      "Epoch: 2240 loss_train: 0.0166 loss_val: 0.1086\n",
      "Epoch: 2260 loss_train: 0.0195 loss_val: 0.1198\n",
      "Epoch: 2280 loss_train: 0.0158 loss_val: 0.1274\n",
      "Epoch: 2300 loss_train: 0.0150 loss_val: 0.1199\n",
      "Epoch: 2320 loss_train: 0.0130 loss_val: 0.1429\n",
      "Epoch: 2340 loss_train: 0.0178 loss_val: 0.1223\n",
      "Epoch: 2360 loss_train: 0.0194 loss_val: 0.1158\n",
      "Epoch: 2380 loss_train: 0.0141 loss_val: 0.1237\n",
      "Epoch: 2400 loss_train: 0.0152 loss_val: 0.1449\n",
      "Epoch: 2420 loss_train: 0.0165 loss_val: 0.1233\n",
      "Epoch: 2440 loss_train: 0.0198 loss_val: 0.1310\n",
      "Epoch: 2460 loss_train: 0.0163 loss_val: 0.1101\n",
      "Epoch: 2480 loss_train: 0.0160 loss_val: 0.1283\n",
      "Epoch: 2500 loss_train: 0.0153 loss_val: 0.1128\n",
      "Epoch: 2520 loss_train: 0.0178 loss_val: 0.1282\n",
      "Epoch: 2540 loss_train: 0.0124 loss_val: 0.1207\n",
      "Epoch: 2560 loss_train: 0.0163 loss_val: 0.1226\n",
      "Epoch: 2580 loss_train: 0.0136 loss_val: 0.1184\n",
      "Epoch: 2600 loss_train: 0.0159 loss_val: 0.1332\n",
      "Epoch: 2620 loss_train: 0.0167 loss_val: 0.1200\n",
      "Epoch: 2640 loss_train: 0.0144 loss_val: 0.1203\n",
      "Epoch: 2660 loss_train: 0.0157 loss_val: 0.1349\n",
      "Epoch: 2680 loss_train: 0.0141 loss_val: 0.1151\n",
      "Epoch: 2700 loss_train: 0.0148 loss_val: 0.1374\n",
      "Epoch: 2720 loss_train: 0.0145 loss_val: 0.1459\n",
      "Epoch: 2740 loss_train: 0.0160 loss_val: 0.1210\n",
      "Epoch: 2760 loss_train: 0.0141 loss_val: 0.1245\n",
      "Epoch: 2780 loss_train: 0.0148 loss_val: 0.1346\n",
      "Epoch: 2800 loss_train: 0.0178 loss_val: 0.1263\n",
      "Epoch: 2820 loss_train: 0.0137 loss_val: 0.1248\n",
      "Epoch: 2840 loss_train: 0.0174 loss_val: 0.1181\n",
      "Epoch: 2860 loss_train: 0.0143 loss_val: 0.1322\n",
      "Epoch: 2880 loss_train: 0.0163 loss_val: 0.1316\n",
      "Epoch: 2900 loss_train: 0.0136 loss_val: 0.1484\n",
      "Epoch: 2920 loss_train: 0.0160 loss_val: 0.1304\n",
      "Epoch: 2940 loss_train: 0.0166 loss_val: 0.1371\n",
      "Epoch: 2960 loss_train: 0.0192 loss_val: 0.1287\n",
      "Epoch: 2980 loss_train: 0.0146 loss_val: 0.1339\n",
      "Epoch: 3000 loss_train: 0.0144 loss_val: 0.1284\n",
      "Epoch: 3020 loss_train: 0.0164 loss_val: 0.1290\n",
      "Epoch: 3040 loss_train: 0.0137 loss_val: 0.1370\n",
      "Epoch: 3060 loss_train: 0.0178 loss_val: 0.1257\n",
      "Epoch: 3080 loss_train: 0.0142 loss_val: 0.1231\n",
      "Epoch: 3100 loss_train: 0.0143 loss_val: 0.1337\n",
      "Epoch: 3120 loss_train: 0.0156 loss_val: 0.1276\n",
      "Epoch: 3140 loss_train: 0.0149 loss_val: 0.1455\n",
      "Epoch: 3160 loss_train: 0.0170 loss_val: 0.1360\n",
      "Epoch: 3180 loss_train: 0.0140 loss_val: 0.1418\n",
      "Epoch: 3200 loss_train: 0.0143 loss_val: 0.1355\n",
      "Epoch: 3220 loss_train: 0.0149 loss_val: 0.1327\n",
      "Epoch: 3240 loss_train: 0.0139 loss_val: 0.1237\n",
      "Epoch: 3260 loss_train: 0.0120 loss_val: 0.1386\n",
      "Epoch: 3280 loss_train: 0.0124 loss_val: 0.1320\n",
      "Epoch: 3300 loss_train: 0.0137 loss_val: 0.1286\n",
      "Epoch: 3320 loss_train: 0.0138 loss_val: 0.1428\n",
      "Epoch: 3340 loss_train: 0.0143 loss_val: 0.1516\n",
      "Epoch: 3360 loss_train: 0.0137 loss_val: 0.1241\n",
      "Epoch: 3380 loss_train: 0.0150 loss_val: 0.1280\n",
      "Epoch: 3400 loss_train: 0.0121 loss_val: 0.1561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3420 loss_train: 0.0097 loss_val: 0.1379\n",
      "Epoch: 3440 loss_train: 0.0140 loss_val: 0.1417\n",
      "Epoch: 3460 loss_train: 0.0131 loss_val: 0.1448\n",
      "Epoch: 3480 loss_train: 0.0151 loss_val: 0.1199\n",
      "Epoch: 3500 loss_train: 0.0137 loss_val: 0.1107\n",
      "Epoch: 3520 loss_train: 0.0125 loss_val: 0.1451\n",
      "Epoch: 3540 loss_train: 0.0160 loss_val: 0.1464\n",
      "Epoch: 3560 loss_train: 0.0144 loss_val: 0.1257\n",
      "Epoch: 3580 loss_train: 0.0142 loss_val: 0.1371\n",
      "Epoch: 3600 loss_train: 0.0121 loss_val: 0.1229\n",
      "Epoch: 3620 loss_train: 0.0129 loss_val: 0.1278\n",
      "Epoch: 3640 loss_train: 0.0122 loss_val: 0.1349\n",
      "Epoch: 3660 loss_train: 0.0152 loss_val: 0.1363\n",
      "Epoch: 3680 loss_train: 0.0165 loss_val: 0.1158\n",
      "Epoch: 3700 loss_train: 0.0137 loss_val: 0.1488\n",
      "Epoch: 3720 loss_train: 0.0136 loss_val: 0.1290\n",
      "Epoch: 3740 loss_train: 0.0174 loss_val: 0.1383\n",
      "Epoch: 3760 loss_train: 0.0154 loss_val: 0.1264\n",
      "Epoch: 3780 loss_train: 0.0140 loss_val: 0.1339\n",
      "Epoch: 3800 loss_train: 0.0114 loss_val: 0.1327\n",
      "Epoch: 3820 loss_train: 0.0138 loss_val: 0.1393\n",
      "Epoch: 3840 loss_train: 0.0132 loss_val: 0.1621\n",
      "Epoch: 3860 loss_train: 0.0132 loss_val: 0.1266\n",
      "Epoch: 3880 loss_train: 0.0135 loss_val: 0.1323\n",
      "Epoch: 3900 loss_train: 0.0117 loss_val: 0.1448\n",
      "Epoch: 3920 loss_train: 0.0154 loss_val: 0.1472\n",
      "Epoch: 3940 loss_train: 0.0134 loss_val: 0.1246\n",
      "Epoch: 3960 loss_train: 0.0133 loss_val: 0.1300\n",
      "Epoch: 3980 loss_train: 0.0132 loss_val: 0.1264\n",
      "Epoch: 4000 loss_train: 0.0148 loss_val: 0.1421\n",
      "Epoch: 4020 loss_train: 0.0129 loss_val: 0.1305\n",
      "Epoch: 4040 loss_train: 0.0108 loss_val: 0.1266\n",
      "Epoch: 4060 loss_train: 0.0125 loss_val: 0.1196\n",
      "Epoch: 4080 loss_train: 0.0125 loss_val: 0.1202\n",
      "Epoch: 4100 loss_train: 0.0126 loss_val: 0.1421\n",
      "Epoch: 4120 loss_train: 0.0163 loss_val: 0.1674\n",
      "Epoch: 4140 loss_train: 0.0123 loss_val: 0.1352\n",
      "Epoch: 4160 loss_train: 0.0134 loss_val: 0.1218\n",
      "Epoch: 4180 loss_train: 0.0104 loss_val: 0.1377\n",
      "Epoch: 4200 loss_train: 0.0102 loss_val: 0.1445\n",
      "Epoch: 4220 loss_train: 0.0139 loss_val: 0.1348\n",
      "Epoch: 4240 loss_train: 0.0170 loss_val: 0.1685\n",
      "Epoch: 4260 loss_train: 0.0144 loss_val: 0.1648\n",
      "Epoch: 4280 loss_train: 0.0137 loss_val: 0.1558\n",
      "Epoch: 4300 loss_train: 0.0112 loss_val: 0.1634\n",
      "Epoch: 4320 loss_train: 0.0141 loss_val: 0.1136\n",
      "Epoch: 4340 loss_train: 0.0123 loss_val: 0.1453\n",
      "Epoch: 4360 loss_train: 0.0117 loss_val: 0.1422\n",
      "Epoch: 4380 loss_train: 0.0133 loss_val: 0.1318\n",
      "Epoch: 4400 loss_train: 0.0163 loss_val: 0.1470\n",
      "Epoch: 4420 loss_train: 0.0128 loss_val: 0.1454\n",
      "Epoch: 4440 loss_train: 0.0120 loss_val: 0.1614\n",
      "Epoch: 4460 loss_train: 0.0103 loss_val: 0.1568\n",
      "Epoch: 4480 loss_train: 0.0122 loss_val: 0.1587\n",
      "Epoch: 4500 loss_train: 0.0102 loss_val: 0.1575\n",
      "Epoch: 4520 loss_train: 0.0138 loss_val: 0.1586\n",
      "Epoch: 4540 loss_train: 0.0142 loss_val: 0.1283\n",
      "Epoch: 4560 loss_train: 0.0132 loss_val: 0.1455\n",
      "Epoch: 4580 loss_train: 0.0128 loss_val: 0.1322\n",
      "Epoch: 4600 loss_train: 0.0123 loss_val: 0.1461\n",
      "Epoch: 4620 loss_train: 0.0119 loss_val: 0.1555\n",
      "Epoch: 4640 loss_train: 0.0115 loss_val: 0.1406\n",
      "Epoch: 4660 loss_train: 0.0121 loss_val: 0.1510\n",
      "Epoch: 4680 loss_train: 0.0128 loss_val: 0.1254\n",
      "Epoch: 4700 loss_train: 0.0131 loss_val: 0.1550\n",
      "Epoch: 4720 loss_train: 0.0108 loss_val: 0.1365\n",
      "Epoch: 4740 loss_train: 0.0099 loss_val: 0.1653\n",
      "Epoch: 4760 loss_train: 0.0105 loss_val: 0.1392\n",
      "Epoch: 4780 loss_train: 0.0170 loss_val: 0.1525\n",
      "Epoch: 4800 loss_train: 0.0122 loss_val: 0.1433\n",
      "Epoch: 4820 loss_train: 0.0124 loss_val: 0.1347\n",
      "Epoch: 4840 loss_train: 0.0142 loss_val: 0.1544\n",
      "Epoch: 4860 loss_train: 0.0119 loss_val: 0.1361\n",
      "Epoch: 4880 loss_train: 0.0105 loss_val: 0.1459\n",
      "Epoch: 4900 loss_train: 0.0108 loss_val: 0.1428\n",
      "Epoch: 4920 loss_train: 0.0110 loss_val: 0.1354\n",
      "Epoch: 4940 loss_train: 0.0088 loss_val: 0.1279\n",
      "Epoch: 4960 loss_train: 0.0116 loss_val: 0.1336\n",
      "Epoch: 4980 loss_train: 0.0110 loss_val: 0.1436\n",
      "Epoch: 5000 loss_train: 0.0114 loss_val: 0.1529\n",
      "Epoch: 5020 loss_train: 0.0104 loss_val: 0.1516\n",
      "Epoch: 5040 loss_train: 0.0130 loss_val: 0.1435\n",
      "Epoch: 5060 loss_train: 0.0123 loss_val: 0.1401\n",
      "Epoch: 5080 loss_train: 0.0104 loss_val: 0.1493\n",
      "Epoch: 5100 loss_train: 0.0120 loss_val: 0.1573\n",
      "Epoch: 5120 loss_train: 0.0103 loss_val: 0.1501\n",
      "Epoch: 5140 loss_train: 0.0107 loss_val: 0.1389\n",
      "Epoch: 5160 loss_train: 0.0113 loss_val: 0.1402\n",
      "Epoch: 5180 loss_train: 0.0127 loss_val: 0.1555\n",
      "Epoch: 5200 loss_train: 0.0131 loss_val: 0.1559\n",
      "Epoch: 5220 loss_train: 0.0155 loss_val: 0.1529\n",
      "Epoch: 5240 loss_train: 0.0113 loss_val: 0.1478\n",
      "Epoch: 5260 loss_train: 0.0103 loss_val: 0.1553\n",
      "Epoch: 5280 loss_train: 0.0102 loss_val: 0.1648\n",
      "Epoch: 5300 loss_train: 0.0098 loss_val: 0.1428\n",
      "Epoch: 5320 loss_train: 0.0109 loss_val: 0.1675\n",
      "Epoch: 5340 loss_train: 0.0110 loss_val: 0.1565\n",
      "Epoch: 5360 loss_train: 0.0137 loss_val: 0.1437\n",
      "Epoch: 5380 loss_train: 0.0108 loss_val: 0.1873\n",
      "Epoch: 5400 loss_train: 0.0118 loss_val: 0.1523\n",
      "Epoch: 5420 loss_train: 0.0121 loss_val: 0.1509\n",
      "Epoch: 5440 loss_train: 0.0137 loss_val: 0.1471\n",
      "Epoch: 5460 loss_train: 0.0143 loss_val: 0.1319\n",
      "Epoch: 5480 loss_train: 0.0117 loss_val: 0.1521\n",
      "Epoch: 5500 loss_train: 0.0111 loss_val: 0.1534\n",
      "Epoch: 5520 loss_train: 0.0130 loss_val: 0.1427\n",
      "Epoch: 5540 loss_train: 0.0137 loss_val: 0.1488\n",
      "Epoch: 5560 loss_train: 0.0098 loss_val: 0.1503\n",
      "Epoch: 5580 loss_train: 0.0105 loss_val: 0.1472\n",
      "Epoch: 5600 loss_train: 0.0112 loss_val: 0.1373\n",
      "Epoch: 5620 loss_train: 0.0108 loss_val: 0.1537\n",
      "Epoch: 5640 loss_train: 0.0095 loss_val: 0.1615\n",
      "Epoch: 5660 loss_train: 0.0111 loss_val: 0.1644\n",
      "Epoch: 5680 loss_train: 0.0097 loss_val: 0.1617\n",
      "Epoch: 5700 loss_train: 0.0106 loss_val: 0.1556\n",
      "Epoch: 5720 loss_train: 0.0110 loss_val: 0.1572\n",
      "Epoch: 5740 loss_train: 0.0128 loss_val: 0.1462\n",
      "Epoch: 5760 loss_train: 0.0113 loss_val: 0.1396\n",
      "Epoch: 5780 loss_train: 0.0114 loss_val: 0.1378\n",
      "Epoch: 5800 loss_train: 0.0117 loss_val: 0.1602\n",
      "Epoch: 5820 loss_train: 0.0110 loss_val: 0.1391\n",
      "Epoch: 5840 loss_train: 0.0125 loss_val: 0.1628\n",
      "Epoch: 5860 loss_train: 0.0108 loss_val: 0.1495\n",
      "Epoch: 5880 loss_train: 0.0132 loss_val: 0.1497\n",
      "Epoch: 5900 loss_train: 0.0128 loss_val: 0.1733\n",
      "Epoch: 5920 loss_train: 0.0098 loss_val: 0.1582\n",
      "Epoch: 5940 loss_train: 0.0130 loss_val: 0.1558\n",
      "Epoch: 5960 loss_train: 0.0107 loss_val: 0.1622\n",
      "Epoch: 5980 loss_train: 0.0107 loss_val: 0.1503\n",
      " total time: 328.9948s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0000 loss_train: 1.7729 loss_val: 1.7163\n",
      "Epoch: 0020 loss_train: 0.2814 loss_val: 0.1742\n",
      "Epoch: 0040 loss_train: 0.1891 loss_val: 0.1213\n",
      "Epoch: 0060 loss_train: 0.1482 loss_val: 0.1153\n",
      "Epoch: 0080 loss_train: 0.1311 loss_val: 0.1145\n",
      "Epoch: 0100 loss_train: 0.1200 loss_val: 0.1050\n",
      "Epoch: 0120 loss_train: 0.1138 loss_val: 0.1009\n",
      "Epoch: 0140 loss_train: 0.1062 loss_val: 0.0923\n",
      "Epoch: 0160 loss_train: 0.1033 loss_val: 0.1151\n",
      "Epoch: 0180 loss_train: 0.0953 loss_val: 0.1006\n",
      "Epoch: 0200 loss_train: 0.0929 loss_val: 0.0979\n",
      "Epoch: 0220 loss_train: 0.0891 loss_val: 0.0934\n",
      "Epoch: 0240 loss_train: 0.0850 loss_val: 0.0914\n",
      "Epoch: 0260 loss_train: 0.0867 loss_val: 0.0933\n",
      "Epoch: 0280 loss_train: 0.0822 loss_val: 0.1211\n",
      "Epoch: 0300 loss_train: 0.0811 loss_val: 0.0928\n",
      "Epoch: 0320 loss_train: 0.0769 loss_val: 0.1021\n",
      "Epoch: 0340 loss_train: 0.0755 loss_val: 0.1016\n",
      "Epoch: 0360 loss_train: 0.0772 loss_val: 0.1001\n",
      "Epoch: 0380 loss_train: 0.0732 loss_val: 0.0942\n",
      "Epoch: 0400 loss_train: 0.0737 loss_val: 0.0975\n",
      "Epoch: 0420 loss_train: 0.0704 loss_val: 0.1051\n",
      "Epoch: 0440 loss_train: 0.0690 loss_val: 0.1062\n",
      "Epoch: 0460 loss_train: 0.0726 loss_val: 0.0990\n",
      "Epoch: 0480 loss_train: 0.0685 loss_val: 0.1007\n",
      "Epoch: 0500 loss_train: 0.0661 loss_val: 0.1238\n",
      "Epoch: 0520 loss_train: 0.0655 loss_val: 0.1151\n",
      "Epoch: 0540 loss_train: 0.0644 loss_val: 0.1111\n",
      "Epoch: 0560 loss_train: 0.0677 loss_val: 0.1135\n",
      "Epoch: 0580 loss_train: 0.0688 loss_val: 0.1049\n",
      "Epoch: 0600 loss_train: 0.0651 loss_val: 0.1089\n",
      "Epoch: 0620 loss_train: 0.0642 loss_val: 0.1138\n",
      "Epoch: 0640 loss_train: 0.0634 loss_val: 0.1137\n",
      "Epoch: 0660 loss_train: 0.0627 loss_val: 0.1100\n",
      "Epoch: 0680 loss_train: 0.0612 loss_val: 0.1066\n",
      "Epoch: 0700 loss_train: 0.0619 loss_val: 0.1120\n",
      "Epoch: 0720 loss_train: 0.0608 loss_val: 0.1222\n",
      "Epoch: 0740 loss_train: 0.0618 loss_val: 0.0998\n",
      "Epoch: 0760 loss_train: 0.0597 loss_val: 0.1241\n",
      "Epoch: 0780 loss_train: 0.0618 loss_val: 0.1377\n",
      "Epoch: 0800 loss_train: 0.0609 loss_val: 0.1314\n",
      "Epoch: 0820 loss_train: 0.0620 loss_val: 0.1263\n",
      "Epoch: 0840 loss_train: 0.0606 loss_val: 0.1381\n",
      "Epoch: 0860 loss_train: 0.0570 loss_val: 0.1167\n",
      "Epoch: 0880 loss_train: 0.0554 loss_val: 0.1297\n",
      "Epoch: 0900 loss_train: 0.0597 loss_val: 0.1300\n",
      "Epoch: 0920 loss_train: 0.0601 loss_val: 0.1181\n",
      "Epoch: 0940 loss_train: 0.0604 loss_val: 0.1333\n",
      "Epoch: 0960 loss_train: 0.0591 loss_val: 0.1126\n",
      "Epoch: 0980 loss_train: 0.0589 loss_val: 0.1259\n",
      "Epoch: 1000 loss_train: 0.0621 loss_val: 0.1227\n",
      "Epoch: 1020 loss_train: 0.0552 loss_val: 0.1325\n",
      "Epoch: 1040 loss_train: 0.0558 loss_val: 0.1338\n",
      "Epoch: 1060 loss_train: 0.0563 loss_val: 0.1334\n",
      "Epoch: 1080 loss_train: 0.0551 loss_val: 0.1239\n",
      "Epoch: 1100 loss_train: 0.0573 loss_val: 0.1266\n",
      "Epoch: 1120 loss_train: 0.0562 loss_val: 0.1266\n",
      "Epoch: 1140 loss_train: 0.0544 loss_val: 0.1345\n",
      "Epoch: 1160 loss_train: 0.0545 loss_val: 0.1339\n",
      "Epoch: 1180 loss_train: 0.0545 loss_val: 0.1528\n",
      "Epoch: 1200 loss_train: 0.0530 loss_val: 0.1325\n",
      "Epoch: 1220 loss_train: 0.0541 loss_val: 0.1333\n",
      "Epoch: 1240 loss_train: 0.0536 loss_val: 0.1335\n",
      "Epoch: 1260 loss_train: 0.0568 loss_val: 0.1487\n",
      "Epoch: 1280 loss_train: 0.0586 loss_val: 0.1435\n",
      "Epoch: 1300 loss_train: 0.0498 loss_val: 0.1310\n",
      "Epoch: 1320 loss_train: 0.0534 loss_val: 0.1349\n",
      "Epoch: 1340 loss_train: 0.0528 loss_val: 0.1229\n",
      "Epoch: 1360 loss_train: 0.0536 loss_val: 0.1309\n",
      "Epoch: 1380 loss_train: 0.0565 loss_val: 0.1349\n",
      "Epoch: 1400 loss_train: 0.0541 loss_val: 0.1311\n",
      "Epoch: 1420 loss_train: 0.0534 loss_val: 0.1276\n",
      "Epoch: 1440 loss_train: 0.0513 loss_val: 0.1317\n",
      "Epoch: 1460 loss_train: 0.0514 loss_val: 0.1622\n",
      "Epoch: 1480 loss_train: 0.0509 loss_val: 0.1479\n",
      "Epoch: 1500 loss_train: 0.0529 loss_val: 0.1350\n",
      "Epoch: 1520 loss_train: 0.0511 loss_val: 0.1418\n",
      "Epoch: 1540 loss_train: 0.0502 loss_val: 0.1680\n",
      "Epoch: 1560 loss_train: 0.0534 loss_val: 0.1545\n",
      "Epoch: 1580 loss_train: 0.0533 loss_val: 0.1427\n",
      "Epoch: 1600 loss_train: 0.0521 loss_val: 0.1253\n",
      "Epoch: 1620 loss_train: 0.0483 loss_val: 0.1307\n",
      "Epoch: 1640 loss_train: 0.0493 loss_val: 0.1474\n",
      "Epoch: 1660 loss_train: 0.0534 loss_val: 0.1282\n",
      "Epoch: 1680 loss_train: 0.0520 loss_val: 0.1432\n",
      "Epoch: 1700 loss_train: 0.0525 loss_val: 0.1337\n",
      "Epoch: 1720 loss_train: 0.0488 loss_val: 0.1363\n",
      "Epoch: 1740 loss_train: 0.0483 loss_val: 0.1201\n",
      "Epoch: 1760 loss_train: 0.0510 loss_val: 0.1241\n",
      "Epoch: 1780 loss_train: 0.0486 loss_val: 0.1203\n",
      "Epoch: 1800 loss_train: 0.0492 loss_val: 0.1465\n",
      "Epoch: 1820 loss_train: 0.0491 loss_val: 0.1238\n",
      "Epoch: 1840 loss_train: 0.0467 loss_val: 0.1330\n",
      "Epoch: 1860 loss_train: 0.0511 loss_val: 0.1226\n",
      "Epoch: 1880 loss_train: 0.0462 loss_val: 0.1373\n",
      "Epoch: 1900 loss_train: 0.0478 loss_val: 0.1316\n",
      "Epoch: 1920 loss_train: 0.0454 loss_val: 0.1309\n",
      "Epoch: 1940 loss_train: 0.0503 loss_val: 0.1318\n",
      "Epoch: 1960 loss_train: 0.0466 loss_val: 0.1427\n",
      "Epoch: 1980 loss_train: 0.0469 loss_val: 0.1243\n",
      "Epoch: 2000 loss_train: 0.0487 loss_val: 0.1194\n",
      "Epoch: 2020 loss_train: 0.0458 loss_val: 0.1453\n",
      "Epoch: 2040 loss_train: 0.0484 loss_val: 0.1413\n",
      "Epoch: 2060 loss_train: 0.0451 loss_val: 0.1370\n",
      "Epoch: 2080 loss_train: 0.0416 loss_val: 0.1479\n",
      "Epoch: 2100 loss_train: 0.0482 loss_val: 0.1148\n",
      "Epoch: 2120 loss_train: 0.0458 loss_val: 0.1227\n",
      "Epoch: 2140 loss_train: 0.0454 loss_val: 0.1567\n",
      "Epoch: 2160 loss_train: 0.0472 loss_val: 0.1424\n",
      "Epoch: 2180 loss_train: 0.0427 loss_val: 0.1296\n",
      "Epoch: 2200 loss_train: 0.0485 loss_val: 0.1341\n",
      "Epoch: 2220 loss_train: 0.0461 loss_val: 0.1205\n",
      "Epoch: 2240 loss_train: 0.0444 loss_val: 0.1333\n",
      "Epoch: 2260 loss_train: 0.0448 loss_val: 0.1360\n",
      "Epoch: 2280 loss_train: 0.0456 loss_val: 0.1323\n",
      "Epoch: 2300 loss_train: 0.0439 loss_val: 0.1436\n",
      "Epoch: 2320 loss_train: 0.0460 loss_val: 0.1428\n",
      "Epoch: 2340 loss_train: 0.0471 loss_val: 0.1374\n",
      "Epoch: 2360 loss_train: 0.0476 loss_val: 0.1264\n",
      "Epoch: 2380 loss_train: 0.0449 loss_val: 0.1437\n",
      "Epoch: 2400 loss_train: 0.0456 loss_val: 0.1410\n",
      "Epoch: 2420 loss_train: 0.0415 loss_val: 0.1265\n",
      "Epoch: 2440 loss_train: 0.0479 loss_val: 0.1351\n",
      "Epoch: 2460 loss_train: 0.0452 loss_val: 0.1260\n",
      "Epoch: 2480 loss_train: 0.0438 loss_val: 0.1367\n",
      "Epoch: 2500 loss_train: 0.0434 loss_val: 0.1401\n",
      "Epoch: 2520 loss_train: 0.0455 loss_val: 0.1439\n",
      "Epoch: 2540 loss_train: 0.0448 loss_val: 0.1579\n",
      "Epoch: 2560 loss_train: 0.0471 loss_val: 0.1361\n",
      "Epoch: 2580 loss_train: 0.0453 loss_val: 0.1301\n",
      "Epoch: 2600 loss_train: 0.0429 loss_val: 0.1342\n",
      "Epoch: 2620 loss_train: 0.0420 loss_val: 0.1545\n",
      "Epoch: 2640 loss_train: 0.0466 loss_val: 0.1166\n",
      "Epoch: 2660 loss_train: 0.0440 loss_val: 0.1263\n",
      "Epoch: 2680 loss_train: 0.0446 loss_val: 0.1452\n",
      "Epoch: 2700 loss_train: 0.0433 loss_val: 0.1365\n",
      "Epoch: 2720 loss_train: 0.0426 loss_val: 0.1467\n",
      "Epoch: 2740 loss_train: 0.0422 loss_val: 0.1447\n",
      "Epoch: 2760 loss_train: 0.0443 loss_val: 0.1419\n",
      "Epoch: 2780 loss_train: 0.0438 loss_val: 0.1281\n",
      "Epoch: 2800 loss_train: 0.0418 loss_val: 0.1312\n",
      "Epoch: 2820 loss_train: 0.0425 loss_val: 0.1468\n",
      "Epoch: 2840 loss_train: 0.0413 loss_val: 0.1430\n",
      "Epoch: 2860 loss_train: 0.0456 loss_val: 0.1315\n",
      "Epoch: 2880 loss_train: 0.0451 loss_val: 0.1319\n",
      "Epoch: 2900 loss_train: 0.0404 loss_val: 0.1285\n",
      "Epoch: 2920 loss_train: 0.0446 loss_val: 0.1299\n",
      "Epoch: 2940 loss_train: 0.0417 loss_val: 0.1332\n",
      "Epoch: 2960 loss_train: 0.0439 loss_val: 0.1336\n",
      "Epoch: 2980 loss_train: 0.0418 loss_val: 0.1247\n",
      "Epoch: 3000 loss_train: 0.0439 loss_val: 0.1464\n",
      "Epoch: 3020 loss_train: 0.0470 loss_val: 0.1147\n",
      "Epoch: 3040 loss_train: 0.0427 loss_val: 0.1299\n",
      "Epoch: 3060 loss_train: 0.0416 loss_val: 0.1095\n",
      "Epoch: 3080 loss_train: 0.0439 loss_val: 0.1150\n",
      "Epoch: 3100 loss_train: 0.0409 loss_val: 0.1233\n",
      "Epoch: 3120 loss_train: 0.0402 loss_val: 0.1281\n",
      "Epoch: 3140 loss_train: 0.0399 loss_val: 0.1239\n",
      "Epoch: 3160 loss_train: 0.0456 loss_val: 0.1249\n",
      "Epoch: 3180 loss_train: 0.0424 loss_val: 0.1238\n",
      "Epoch: 3200 loss_train: 0.0429 loss_val: 0.1331\n",
      "Epoch: 3220 loss_train: 0.0409 loss_val: 0.1141\n",
      "Epoch: 3240 loss_train: 0.0395 loss_val: 0.1182\n",
      "Epoch: 3260 loss_train: 0.0383 loss_val: 0.1142\n",
      "Epoch: 3280 loss_train: 0.0387 loss_val: 0.1092\n",
      "Epoch: 3300 loss_train: 0.0390 loss_val: 0.1136\n",
      "Epoch: 3320 loss_train: 0.0403 loss_val: 0.1160\n",
      "Epoch: 3340 loss_train: 0.0408 loss_val: 0.1178\n",
      "Epoch: 3360 loss_train: 0.0409 loss_val: 0.1335\n",
      "Epoch: 3380 loss_train: 0.0419 loss_val: 0.1302\n",
      "Epoch: 3400 loss_train: 0.0389 loss_val: 0.1109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3420 loss_train: 0.0404 loss_val: 0.1098\n",
      "Epoch: 3440 loss_train: 0.0399 loss_val: 0.1199\n",
      "Epoch: 3460 loss_train: 0.0415 loss_val: 0.1309\n",
      "Epoch: 3480 loss_train: 0.0415 loss_val: 0.1209\n",
      "Epoch: 3500 loss_train: 0.0404 loss_val: 0.1347\n",
      "Epoch: 3520 loss_train: 0.0414 loss_val: 0.1293\n",
      "Epoch: 3540 loss_train: 0.0383 loss_val: 0.1301\n",
      "Epoch: 3560 loss_train: 0.0441 loss_val: 0.1138\n",
      "Epoch: 3580 loss_train: 0.0415 loss_val: 0.1399\n",
      "Epoch: 3600 loss_train: 0.0448 loss_val: 0.1234\n",
      "Epoch: 3620 loss_train: 0.0414 loss_val: 0.1243\n",
      "Epoch: 3640 loss_train: 0.0386 loss_val: 0.1289\n",
      "Epoch: 3660 loss_train: 0.0364 loss_val: 0.1244\n",
      "Epoch: 3680 loss_train: 0.0378 loss_val: 0.1246\n",
      "Epoch: 3700 loss_train: 0.0418 loss_val: 0.1242\n",
      "Epoch: 3720 loss_train: 0.0383 loss_val: 0.1301\n",
      "Epoch: 3740 loss_train: 0.0378 loss_val: 0.1397\n",
      "Epoch: 3760 loss_train: 0.0394 loss_val: 0.1301\n",
      "Epoch: 3780 loss_train: 0.0370 loss_val: 0.1262\n",
      "Epoch: 3800 loss_train: 0.0414 loss_val: 0.1242\n",
      "Epoch: 3820 loss_train: 0.0398 loss_val: 0.1279\n",
      "Epoch: 3840 loss_train: 0.0379 loss_val: 0.1279\n",
      "Epoch: 3860 loss_train: 0.0402 loss_val: 0.1235\n",
      "Epoch: 3880 loss_train: 0.0389 loss_val: 0.1319\n",
      "Epoch: 3900 loss_train: 0.0389 loss_val: 0.1261\n",
      "Epoch: 3920 loss_train: 0.0388 loss_val: 0.1255\n",
      "Epoch: 3940 loss_train: 0.0401 loss_val: 0.1267\n",
      "Epoch: 3960 loss_train: 0.0391 loss_val: 0.1297\n",
      "Epoch: 3980 loss_train: 0.0421 loss_val: 0.1388\n",
      "Epoch: 4000 loss_train: 0.0400 loss_val: 0.1256\n",
      "Epoch: 4020 loss_train: 0.0407 loss_val: 0.1208\n",
      "Epoch: 4040 loss_train: 0.0385 loss_val: 0.1201\n",
      "Epoch: 4060 loss_train: 0.0372 loss_val: 0.1150\n",
      "Epoch: 4080 loss_train: 0.0434 loss_val: 0.1166\n",
      "Epoch: 4100 loss_train: 0.0371 loss_val: 0.1168\n",
      "Epoch: 4120 loss_train: 0.0385 loss_val: 0.1237\n",
      "Epoch: 4140 loss_train: 0.0363 loss_val: 0.1326\n",
      "Epoch: 4160 loss_train: 0.0393 loss_val: 0.1308\n",
      "Epoch: 4180 loss_train: 0.0389 loss_val: 0.1269\n",
      "Epoch: 4200 loss_train: 0.0376 loss_val: 0.1315\n",
      "Epoch: 4220 loss_train: 0.0389 loss_val: 0.1264\n",
      "Epoch: 4240 loss_train: 0.0399 loss_val: 0.1338\n",
      "Epoch: 4260 loss_train: 0.0414 loss_val: 0.1351\n",
      "Epoch: 4280 loss_train: 0.0357 loss_val: 0.1316\n",
      "Epoch: 4300 loss_train: 0.0379 loss_val: 0.1233\n",
      "Epoch: 4320 loss_train: 0.0377 loss_val: 0.1307\n",
      "Epoch: 4340 loss_train: 0.0396 loss_val: 0.1392\n",
      "Epoch: 4360 loss_train: 0.0377 loss_val: 0.1281\n",
      "Epoch: 4380 loss_train: 0.0382 loss_val: 0.1314\n",
      "Epoch: 4400 loss_train: 0.0342 loss_val: 0.1329\n",
      "Epoch: 4420 loss_train: 0.0355 loss_val: 0.1257\n",
      "Epoch: 4440 loss_train: 0.0380 loss_val: 0.1222\n",
      "Epoch: 4460 loss_train: 0.0353 loss_val: 0.1267\n",
      "Epoch: 4480 loss_train: 0.0372 loss_val: 0.1278\n",
      "Epoch: 4500 loss_train: 0.0401 loss_val: 0.1287\n",
      "Epoch: 4520 loss_train: 0.0339 loss_val: 0.1203\n",
      "Epoch: 4540 loss_train: 0.0393 loss_val: 0.1129\n",
      "Epoch: 4560 loss_train: 0.0361 loss_val: 0.1288\n",
      "Epoch: 4580 loss_train: 0.0377 loss_val: 0.1342\n",
      "Epoch: 4600 loss_train: 0.0382 loss_val: 0.1342\n",
      "Epoch: 4620 loss_train: 0.0363 loss_val: 0.1214\n",
      "Epoch: 4640 loss_train: 0.0347 loss_val: 0.1340\n",
      "Epoch: 4660 loss_train: 0.0378 loss_val: 0.1262\n",
      "Epoch: 4680 loss_train: 0.0378 loss_val: 0.1298\n",
      "Epoch: 4700 loss_train: 0.0383 loss_val: 0.1261\n",
      "Epoch: 4720 loss_train: 0.0381 loss_val: 0.1292\n",
      "Epoch: 4740 loss_train: 0.0380 loss_val: 0.1194\n",
      "Epoch: 4760 loss_train: 0.0364 loss_val: 0.1467\n",
      "Epoch: 4780 loss_train: 0.0448 loss_val: 0.1393\n",
      "Epoch: 4800 loss_train: 0.0384 loss_val: 0.1145\n",
      "Epoch: 4820 loss_train: 0.0390 loss_val: 0.1165\n",
      "Epoch: 4840 loss_train: 0.0364 loss_val: 0.1272\n",
      "Epoch: 4860 loss_train: 0.0359 loss_val: 0.1284\n",
      "Epoch: 4880 loss_train: 0.0382 loss_val: 0.1143\n",
      "Epoch: 4900 loss_train: 0.0355 loss_val: 0.1241\n",
      "Epoch: 4920 loss_train: 0.0407 loss_val: 0.1264\n",
      "Epoch: 4940 loss_train: 0.0401 loss_val: 0.1270\n",
      "Epoch: 4960 loss_train: 0.0389 loss_val: 0.1323\n",
      "Epoch: 4980 loss_train: 0.0384 loss_val: 0.1341\n",
      "Epoch: 5000 loss_train: 0.0358 loss_val: 0.1333\n",
      "Epoch: 5020 loss_train: 0.0363 loss_val: 0.1531\n",
      "Epoch: 5040 loss_train: 0.0347 loss_val: 0.1248\n",
      "Epoch: 5060 loss_train: 0.0434 loss_val: 0.1301\n",
      "Epoch: 5080 loss_train: 0.0352 loss_val: 0.1358\n",
      "Epoch: 5100 loss_train: 0.0357 loss_val: 0.1340\n",
      "Epoch: 5120 loss_train: 0.0365 loss_val: 0.1245\n",
      "Epoch: 5140 loss_train: 0.0362 loss_val: 0.1472\n",
      "Epoch: 5160 loss_train: 0.0359 loss_val: 0.1496\n",
      "Epoch: 5180 loss_train: 0.0369 loss_val: 0.1357\n",
      "Epoch: 5200 loss_train: 0.0363 loss_val: 0.1273\n",
      "Epoch: 5220 loss_train: 0.0373 loss_val: 0.1393\n",
      "Epoch: 5240 loss_train: 0.0369 loss_val: 0.1423\n",
      "Epoch: 5260 loss_train: 0.0366 loss_val: 0.1353\n",
      "Epoch: 5280 loss_train: 0.0355 loss_val: 0.1344\n",
      "Epoch: 5300 loss_train: 0.0378 loss_val: 0.1274\n",
      "Epoch: 5320 loss_train: 0.0349 loss_val: 0.1244\n",
      "Epoch: 5340 loss_train: 0.0386 loss_val: 0.1355\n",
      "Epoch: 5360 loss_train: 0.0372 loss_val: 0.1398\n",
      "Epoch: 5380 loss_train: 0.0374 loss_val: 0.1384\n",
      "Epoch: 5400 loss_train: 0.0356 loss_val: 0.1382\n",
      "Epoch: 5420 loss_train: 0.0354 loss_val: 0.1267\n",
      "Epoch: 5440 loss_train: 0.0361 loss_val: 0.1497\n",
      "Epoch: 5460 loss_train: 0.0396 loss_val: 0.1395\n",
      "Epoch: 5480 loss_train: 0.0340 loss_val: 0.1382\n",
      "Epoch: 5500 loss_train: 0.0357 loss_val: 0.1416\n",
      "Epoch: 5520 loss_train: 0.0346 loss_val: 0.1482\n",
      "Epoch: 5540 loss_train: 0.0339 loss_val: 0.1334\n",
      "Epoch: 5560 loss_train: 0.0350 loss_val: 0.1369\n",
      "Epoch: 5580 loss_train: 0.0339 loss_val: 0.1429\n",
      "Epoch: 5600 loss_train: 0.0365 loss_val: 0.1282\n",
      "Epoch: 5620 loss_train: 0.0370 loss_val: 0.1222\n",
      "Epoch: 5640 loss_train: 0.0382 loss_val: 0.1279\n",
      "Epoch: 5660 loss_train: 0.0339 loss_val: 0.1331\n",
      "Epoch: 5680 loss_train: 0.0353 loss_val: 0.1341\n",
      "Epoch: 5700 loss_train: 0.0363 loss_val: 0.1215\n",
      "Epoch: 5720 loss_train: 0.0363 loss_val: 0.1358\n",
      "Epoch: 5740 loss_train: 0.0382 loss_val: 0.1296\n",
      "Epoch: 5760 loss_train: 0.0406 loss_val: 0.1166\n",
      "Epoch: 5780 loss_train: 0.0380 loss_val: 0.1185\n",
      "Epoch: 5800 loss_train: 0.0353 loss_val: 0.1124\n",
      "Epoch: 5820 loss_train: 0.0354 loss_val: 0.1246\n",
      "Epoch: 5840 loss_train: 0.0329 loss_val: 0.1188\n",
      "Epoch: 5860 loss_train: 0.0346 loss_val: 0.1144\n",
      "Epoch: 5880 loss_train: 0.0324 loss_val: 0.1231\n",
      "Epoch: 5900 loss_train: 0.0345 loss_val: 0.1171\n",
      "Epoch: 5920 loss_train: 0.0334 loss_val: 0.1169\n",
      "Epoch: 5940 loss_train: 0.0366 loss_val: 0.1247\n",
      "Epoch: 5960 loss_train: 0.0360 loss_val: 0.1202\n",
      "Epoch: 5980 loss_train: 0.0362 loss_val: 0.1271\n",
      " total time: 585.1522s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0000 loss_train: 2.0567 loss_val: 2.0180\n",
      "Epoch: 0020 loss_train: 0.4670 loss_val: 0.2995\n",
      "Epoch: 0040 loss_train: 0.3381 loss_val: 0.2266\n",
      "Epoch: 0060 loss_train: 0.2964 loss_val: 0.2056\n",
      "Epoch: 0080 loss_train: 0.2672 loss_val: 0.1931\n",
      "Epoch: 0100 loss_train: 0.2469 loss_val: 0.1862\n",
      "Epoch: 0120 loss_train: 0.2283 loss_val: 0.1806\n",
      "Epoch: 0140 loss_train: 0.2173 loss_val: 0.1779\n",
      "Epoch: 0160 loss_train: 0.2111 loss_val: 0.1734\n",
      "Epoch: 0180 loss_train: 0.1998 loss_val: 0.1729\n",
      "Epoch: 0200 loss_train: 0.1881 loss_val: 0.1685\n",
      "Epoch: 0220 loss_train: 0.1847 loss_val: 0.1659\n",
      "Epoch: 0240 loss_train: 0.1826 loss_val: 0.1688\n",
      "Epoch: 0260 loss_train: 0.1745 loss_val: 0.1584\n",
      "Epoch: 0280 loss_train: 0.1653 loss_val: 0.1606\n",
      "Epoch: 0300 loss_train: 0.1664 loss_val: 0.1644\n",
      "Epoch: 0320 loss_train: 0.1595 loss_val: 0.1659\n",
      "Epoch: 0340 loss_train: 0.1610 loss_val: 0.1586\n",
      "Epoch: 0360 loss_train: 0.1526 loss_val: 0.1564\n",
      "Epoch: 0380 loss_train: 0.1483 loss_val: 0.1597\n",
      "Epoch: 0400 loss_train: 0.1513 loss_val: 0.1580\n",
      "Epoch: 0420 loss_train: 0.1450 loss_val: 0.1644\n",
      "Epoch: 0440 loss_train: 0.1455 loss_val: 0.1675\n",
      "Epoch: 0460 loss_train: 0.1441 loss_val: 0.1626\n",
      "Epoch: 0480 loss_train: 0.1399 loss_val: 0.1657\n",
      "Epoch: 0500 loss_train: 0.1370 loss_val: 0.1654\n",
      "Epoch: 0520 loss_train: 0.1394 loss_val: 0.1657\n",
      "Epoch: 0540 loss_train: 0.1336 loss_val: 0.1626\n",
      "Epoch: 0560 loss_train: 0.1364 loss_val: 0.1598\n",
      "Epoch: 0580 loss_train: 0.1326 loss_val: 0.1627\n",
      "Epoch: 0600 loss_train: 0.1339 loss_val: 0.1669\n",
      "Epoch: 0620 loss_train: 0.1320 loss_val: 0.1591\n",
      "Epoch: 0640 loss_train: 0.1309 loss_val: 0.1600\n",
      "Epoch: 0660 loss_train: 0.1246 loss_val: 0.1614\n",
      "Epoch: 0680 loss_train: 0.1261 loss_val: 0.1662\n",
      "Epoch: 0700 loss_train: 0.1268 loss_val: 0.1698\n",
      "Epoch: 0720 loss_train: 0.1265 loss_val: 0.1668\n",
      "Epoch: 0740 loss_train: 0.1279 loss_val: 0.1620\n",
      "Epoch: 0760 loss_train: 0.1259 loss_val: 0.1657\n",
      "Epoch: 0780 loss_train: 0.1214 loss_val: 0.1720\n",
      "Epoch: 0800 loss_train: 0.1252 loss_val: 0.1757\n",
      "Epoch: 0820 loss_train: 0.1195 loss_val: 0.1804\n",
      "Epoch: 0840 loss_train: 0.1194 loss_val: 0.1713\n",
      "Epoch: 0860 loss_train: 0.1166 loss_val: 0.1781\n",
      "Epoch: 0880 loss_train: 0.1196 loss_val: 0.1819\n",
      "Epoch: 0900 loss_train: 0.1160 loss_val: 0.1719\n",
      "Epoch: 0920 loss_train: 0.1194 loss_val: 0.1742\n",
      "Epoch: 0940 loss_train: 0.1176 loss_val: 0.1805\n",
      "Epoch: 0960 loss_train: 0.1166 loss_val: 0.1757\n",
      "Epoch: 0980 loss_train: 0.1193 loss_val: 0.1773\n",
      "Epoch: 1000 loss_train: 0.1179 loss_val: 0.1808\n",
      "Epoch: 1020 loss_train: 0.1140 loss_val: 0.1780\n",
      "Epoch: 1040 loss_train: 0.1142 loss_val: 0.1781\n",
      "Epoch: 1060 loss_train: 0.1160 loss_val: 0.1771\n",
      "Epoch: 1080 loss_train: 0.1188 loss_val: 0.1735\n",
      "Epoch: 1100 loss_train: 0.1144 loss_val: 0.1720\n",
      "Epoch: 1120 loss_train: 0.1083 loss_val: 0.1871\n",
      "Epoch: 1140 loss_train: 0.1131 loss_val: 0.1794\n",
      "Epoch: 1160 loss_train: 0.1165 loss_val: 0.1818\n",
      "Epoch: 1180 loss_train: 0.1095 loss_val: 0.1830\n",
      "Epoch: 1200 loss_train: 0.1101 loss_val: 0.1938\n",
      "Epoch: 1220 loss_train: 0.1091 loss_val: 0.1906\n",
      "Epoch: 1240 loss_train: 0.1118 loss_val: 0.1850\n",
      "Epoch: 1260 loss_train: 0.1088 loss_val: 0.1834\n",
      "Epoch: 1280 loss_train: 0.1087 loss_val: 0.1805\n",
      "Epoch: 1300 loss_train: 0.1083 loss_val: 0.1887\n",
      "Epoch: 1320 loss_train: 0.1085 loss_val: 0.1915\n",
      "Epoch: 1340 loss_train: 0.1081 loss_val: 0.1923\n",
      "Epoch: 1360 loss_train: 0.1073 loss_val: 0.1869\n",
      "Epoch: 1380 loss_train: 0.1089 loss_val: 0.1962\n",
      "Epoch: 1400 loss_train: 0.1077 loss_val: 0.1952\n",
      "Epoch: 1420 loss_train: 0.1042 loss_val: 0.1924\n",
      "Epoch: 1440 loss_train: 0.1092 loss_val: 0.1857\n",
      "Epoch: 1460 loss_train: 0.1064 loss_val: 0.1966\n",
      "Epoch: 1480 loss_train: 0.1011 loss_val: 0.2006\n",
      "Epoch: 1500 loss_train: 0.1042 loss_val: 0.1894\n",
      "Epoch: 1520 loss_train: 0.1087 loss_val: 0.1976\n",
      "Epoch: 1540 loss_train: 0.1070 loss_val: 0.1889\n",
      "Epoch: 1560 loss_train: 0.1058 loss_val: 0.2056\n",
      "Epoch: 1580 loss_train: 0.1030 loss_val: 0.1942\n",
      "Epoch: 1600 loss_train: 0.1094 loss_val: 0.1925\n",
      "Epoch: 1620 loss_train: 0.1038 loss_val: 0.1991\n",
      "Epoch: 1640 loss_train: 0.1019 loss_val: 0.2095\n",
      "Epoch: 1660 loss_train: 0.1027 loss_val: 0.2031\n",
      "Epoch: 1680 loss_train: 0.1003 loss_val: 0.2036\n",
      "Epoch: 1700 loss_train: 0.1057 loss_val: 0.1957\n",
      "Epoch: 1720 loss_train: 0.1007 loss_val: 0.2118\n",
      "Epoch: 1740 loss_train: 0.1029 loss_val: 0.1990\n",
      "Epoch: 1760 loss_train: 0.1049 loss_val: 0.1937\n",
      "Epoch: 1780 loss_train: 0.1058 loss_val: 0.2039\n",
      "Epoch: 1800 loss_train: 0.1020 loss_val: 0.2006\n",
      "Epoch: 1820 loss_train: 0.1016 loss_val: 0.2055\n",
      "Epoch: 1840 loss_train: 0.1015 loss_val: 0.2148\n",
      "Epoch: 1860 loss_train: 0.0996 loss_val: 0.2029\n",
      "Epoch: 1880 loss_train: 0.1006 loss_val: 0.2020\n",
      "Epoch: 1900 loss_train: 0.0989 loss_val: 0.2032\n",
      "Epoch: 1920 loss_train: 0.1027 loss_val: 0.2069\n",
      "Epoch: 1940 loss_train: 0.1033 loss_val: 0.2021\n",
      "Epoch: 1960 loss_train: 0.0979 loss_val: 0.2061\n",
      "Epoch: 1980 loss_train: 0.0995 loss_val: 0.1999\n",
      "Epoch: 2000 loss_train: 0.0992 loss_val: 0.1993\n",
      "Epoch: 2020 loss_train: 0.0992 loss_val: 0.2098\n",
      "Epoch: 2040 loss_train: 0.1004 loss_val: 0.2000\n",
      "Epoch: 2060 loss_train: 0.0998 loss_val: 0.1995\n",
      "Epoch: 2080 loss_train: 0.0975 loss_val: 0.2029\n",
      "Epoch: 2100 loss_train: 0.0954 loss_val: 0.2167\n",
      "Epoch: 2120 loss_train: 0.0968 loss_val: 0.1948\n",
      "Epoch: 2140 loss_train: 0.0983 loss_val: 0.2218\n",
      "Epoch: 2160 loss_train: 0.0945 loss_val: 0.2080\n",
      "Epoch: 2180 loss_train: 0.0964 loss_val: 0.2085\n",
      "Epoch: 2200 loss_train: 0.0947 loss_val: 0.2161\n",
      "Epoch: 2220 loss_train: 0.0934 loss_val: 0.2155\n",
      "Epoch: 2240 loss_train: 0.1010 loss_val: 0.2113\n",
      "Epoch: 2260 loss_train: 0.0952 loss_val: 0.2032\n",
      "Epoch: 2280 loss_train: 0.1005 loss_val: 0.2085\n",
      "Epoch: 2300 loss_train: 0.0909 loss_val: 0.2130\n",
      "Epoch: 2320 loss_train: 0.0962 loss_val: 0.2097\n",
      "Epoch: 2340 loss_train: 0.0958 loss_val: 0.2071\n",
      "Epoch: 2360 loss_train: 0.0952 loss_val: 0.2162\n",
      "Epoch: 2380 loss_train: 0.0933 loss_val: 0.2084\n",
      "Epoch: 2400 loss_train: 0.0933 loss_val: 0.2100\n",
      "Epoch: 2420 loss_train: 0.0983 loss_val: 0.2128\n",
      "Epoch: 2440 loss_train: 0.0942 loss_val: 0.2094\n",
      "Epoch: 2460 loss_train: 0.0945 loss_val: 0.2163\n",
      "Epoch: 2480 loss_train: 0.0956 loss_val: 0.2062\n",
      "Epoch: 2500 loss_train: 0.0936 loss_val: 0.2170\n",
      "Epoch: 2520 loss_train: 0.0964 loss_val: 0.2114\n",
      "Epoch: 2540 loss_train: 0.0931 loss_val: 0.2179\n",
      "Epoch: 2560 loss_train: 0.0951 loss_val: 0.2266\n",
      "Epoch: 2580 loss_train: 0.0945 loss_val: 0.2124\n",
      "Epoch: 2600 loss_train: 0.0914 loss_val: 0.2133\n",
      "Epoch: 2620 loss_train: 0.0942 loss_val: 0.2110\n",
      "Epoch: 2640 loss_train: 0.0903 loss_val: 0.2279\n",
      "Epoch: 2660 loss_train: 0.0918 loss_val: 0.2224\n",
      "Epoch: 2680 loss_train: 0.0940 loss_val: 0.2205\n",
      "Epoch: 2700 loss_train: 0.0937 loss_val: 0.2165\n",
      "Epoch: 2720 loss_train: 0.0875 loss_val: 0.2326\n",
      "Epoch: 2740 loss_train: 0.0917 loss_val: 0.2313\n",
      "Epoch: 2760 loss_train: 0.0886 loss_val: 0.2256\n",
      "Epoch: 2780 loss_train: 0.0905 loss_val: 0.2147\n",
      "Epoch: 2800 loss_train: 0.0873 loss_val: 0.2250\n",
      "Epoch: 2820 loss_train: 0.0928 loss_val: 0.2223\n",
      "Epoch: 2840 loss_train: 0.0878 loss_val: 0.2278\n",
      "Epoch: 2860 loss_train: 0.0897 loss_val: 0.2255\n",
      "Epoch: 2880 loss_train: 0.0949 loss_val: 0.2240\n",
      "Epoch: 2900 loss_train: 0.0910 loss_val: 0.2155\n",
      "Epoch: 2920 loss_train: 0.0904 loss_val: 0.2191\n",
      "Epoch: 2940 loss_train: 0.0933 loss_val: 0.2296\n",
      "Epoch: 2960 loss_train: 0.0874 loss_val: 0.2164\n",
      "Epoch: 2980 loss_train: 0.0897 loss_val: 0.2224\n",
      "Epoch: 3000 loss_train: 0.0916 loss_val: 0.2316\n",
      "Epoch: 3020 loss_train: 0.0931 loss_val: 0.2234\n",
      "Epoch: 3040 loss_train: 0.0868 loss_val: 0.2264\n",
      "Epoch: 3060 loss_train: 0.0909 loss_val: 0.2115\n",
      "Epoch: 3080 loss_train: 0.0836 loss_val: 0.2256\n",
      "Epoch: 3100 loss_train: 0.0876 loss_val: 0.2326\n",
      "Epoch: 3120 loss_train: 0.0903 loss_val: 0.2192\n",
      "Epoch: 3140 loss_train: 0.0863 loss_val: 0.2233\n",
      "Epoch: 3160 loss_train: 0.0856 loss_val: 0.2289\n",
      "Epoch: 3180 loss_train: 0.0910 loss_val: 0.2253\n",
      "Epoch: 3200 loss_train: 0.0869 loss_val: 0.2170\n",
      "Epoch: 3220 loss_train: 0.0921 loss_val: 0.2222\n",
      "Epoch: 3240 loss_train: 0.0881 loss_val: 0.2253\n",
      "Epoch: 3260 loss_train: 0.0907 loss_val: 0.2330\n",
      "Epoch: 3280 loss_train: 0.0879 loss_val: 0.2267\n",
      "Epoch: 3300 loss_train: 0.0835 loss_val: 0.2170\n",
      "Epoch: 3320 loss_train: 0.0897 loss_val: 0.2138\n",
      "Epoch: 3340 loss_train: 0.0882 loss_val: 0.2238\n",
      "Epoch: 3360 loss_train: 0.0887 loss_val: 0.2192\n",
      "Epoch: 3380 loss_train: 0.0857 loss_val: 0.2427\n",
      "Epoch: 3400 loss_train: 0.0854 loss_val: 0.2327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3420 loss_train: 0.0880 loss_val: 0.2291\n",
      "Epoch: 3440 loss_train: 0.0842 loss_val: 0.2362\n",
      "Epoch: 3460 loss_train: 0.0873 loss_val: 0.2361\n",
      "Epoch: 3480 loss_train: 0.0875 loss_val: 0.2344\n",
      "Epoch: 3500 loss_train: 0.0852 loss_val: 0.2272\n",
      "Epoch: 3520 loss_train: 0.0909 loss_val: 0.2386\n",
      "Epoch: 3540 loss_train: 0.0833 loss_val: 0.2338\n",
      "Epoch: 3560 loss_train: 0.0890 loss_val: 0.2298\n",
      "Epoch: 3580 loss_train: 0.0855 loss_val: 0.2364\n",
      "Epoch: 3600 loss_train: 0.0839 loss_val: 0.2360\n",
      "Epoch: 3620 loss_train: 0.0848 loss_val: 0.2271\n",
      "Epoch: 3640 loss_train: 0.0816 loss_val: 0.2432\n",
      "Epoch: 3660 loss_train: 0.0829 loss_val: 0.2353\n",
      "Epoch: 3680 loss_train: 0.0871 loss_val: 0.2430\n",
      "Epoch: 3700 loss_train: 0.0859 loss_val: 0.2427\n",
      "Epoch: 3720 loss_train: 0.0862 loss_val: 0.2446\n",
      "Epoch: 3740 loss_train: 0.0837 loss_val: 0.2370\n",
      "Epoch: 3760 loss_train: 0.0850 loss_val: 0.2402\n",
      "Epoch: 3780 loss_train: 0.0845 loss_val: 0.2425\n",
      "Epoch: 3800 loss_train: 0.0840 loss_val: 0.2317\n",
      "Epoch: 3820 loss_train: 0.0816 loss_val: 0.2374\n",
      "Epoch: 3840 loss_train: 0.0855 loss_val: 0.2473\n",
      "Epoch: 3860 loss_train: 0.0829 loss_val: 0.2409\n",
      "Epoch: 3880 loss_train: 0.0829 loss_val: 0.2321\n",
      "Epoch: 3900 loss_train: 0.0851 loss_val: 0.2473\n",
      "Epoch: 3920 loss_train: 0.0844 loss_val: 0.2369\n",
      "Epoch: 3940 loss_train: 0.0833 loss_val: 0.2345\n",
      "Epoch: 3960 loss_train: 0.0821 loss_val: 0.2540\n",
      "Epoch: 3980 loss_train: 0.0848 loss_val: 0.2486\n",
      "Epoch: 4000 loss_train: 0.0830 loss_val: 0.2337\n",
      "Epoch: 4020 loss_train: 0.0844 loss_val: 0.2357\n",
      "Epoch: 4040 loss_train: 0.0848 loss_val: 0.2360\n",
      "Epoch: 4060 loss_train: 0.0838 loss_val: 0.2418\n",
      "Epoch: 4080 loss_train: 0.0843 loss_val: 0.2306\n",
      "Epoch: 4100 loss_train: 0.0842 loss_val: 0.2409\n",
      "Epoch: 4120 loss_train: 0.0802 loss_val: 0.2293\n",
      "Epoch: 4140 loss_train: 0.0839 loss_val: 0.2425\n",
      "Epoch: 4160 loss_train: 0.0808 loss_val: 0.2427\n",
      "Epoch: 4180 loss_train: 0.0861 loss_val: 0.2380\n",
      "Epoch: 4200 loss_train: 0.0848 loss_val: 0.2387\n",
      "Epoch: 4220 loss_train: 0.0868 loss_val: 0.2379\n",
      "Epoch: 4240 loss_train: 0.0844 loss_val: 0.2325\n",
      "Epoch: 4260 loss_train: 0.0824 loss_val: 0.2307\n",
      "Epoch: 4280 loss_train: 0.0819 loss_val: 0.2340\n",
      "Epoch: 4300 loss_train: 0.0809 loss_val: 0.2325\n",
      "Epoch: 4320 loss_train: 0.0812 loss_val: 0.2300\n",
      "Epoch: 4340 loss_train: 0.0825 loss_val: 0.2444\n",
      "Epoch: 4360 loss_train: 0.0809 loss_val: 0.2412\n",
      "Epoch: 4380 loss_train: 0.0836 loss_val: 0.2365\n",
      "Epoch: 4400 loss_train: 0.0819 loss_val: 0.2427\n",
      "Epoch: 4420 loss_train: 0.0805 loss_val: 0.2498\n",
      "Epoch: 4440 loss_train: 0.0801 loss_val: 0.2579\n",
      "Epoch: 4460 loss_train: 0.0820 loss_val: 0.2329\n",
      "Epoch: 4480 loss_train: 0.0826 loss_val: 0.2457\n",
      "Epoch: 4500 loss_train: 0.0797 loss_val: 0.2451\n",
      "Epoch: 4520 loss_train: 0.0815 loss_val: 0.2450\n",
      "Epoch: 4540 loss_train: 0.0855 loss_val: 0.2592\n",
      "Epoch: 4560 loss_train: 0.0811 loss_val: 0.2490\n",
      "Epoch: 4580 loss_train: 0.0829 loss_val: 0.2554\n",
      "Epoch: 4600 loss_train: 0.0801 loss_val: 0.2567\n",
      "Epoch: 4620 loss_train: 0.0798 loss_val: 0.2544\n",
      "Epoch: 4640 loss_train: 0.0800 loss_val: 0.2519\n",
      "Epoch: 4660 loss_train: 0.0812 loss_val: 0.2457\n",
      "Epoch: 4680 loss_train: 0.0794 loss_val: 0.2379\n",
      "Epoch: 4700 loss_train: 0.0803 loss_val: 0.2375\n",
      "Epoch: 4720 loss_train: 0.0806 loss_val: 0.2507\n",
      "Epoch: 4740 loss_train: 0.0796 loss_val: 0.2432\n",
      "Epoch: 4760 loss_train: 0.0824 loss_val: 0.2408\n",
      "Epoch: 4780 loss_train: 0.0796 loss_val: 0.2442\n",
      "Epoch: 4800 loss_train: 0.0761 loss_val: 0.2498\n",
      "Epoch: 4820 loss_train: 0.0760 loss_val: 0.2493\n",
      "Epoch: 4840 loss_train: 0.0821 loss_val: 0.2449\n",
      "Epoch: 4860 loss_train: 0.0786 loss_val: 0.2420\n",
      "Epoch: 4880 loss_train: 0.0787 loss_val: 0.2485\n",
      "Epoch: 4900 loss_train: 0.0781 loss_val: 0.2481\n",
      "Epoch: 4920 loss_train: 0.0808 loss_val: 0.2532\n",
      "Epoch: 4940 loss_train: 0.0767 loss_val: 0.2662\n",
      "Epoch: 4960 loss_train: 0.0813 loss_val: 0.2512\n",
      "Epoch: 4980 loss_train: 0.0793 loss_val: 0.2505\n",
      "Epoch: 5000 loss_train: 0.0783 loss_val: 0.2565\n",
      "Epoch: 5020 loss_train: 0.0830 loss_val: 0.2570\n",
      "Epoch: 5040 loss_train: 0.0791 loss_val: 0.2647\n",
      "Epoch: 5060 loss_train: 0.0809 loss_val: 0.2596\n",
      "Epoch: 5080 loss_train: 0.0800 loss_val: 0.2557\n",
      "Epoch: 5100 loss_train: 0.0835 loss_val: 0.2511\n",
      "Epoch: 5120 loss_train: 0.0775 loss_val: 0.2505\n",
      "Epoch: 5140 loss_train: 0.0821 loss_val: 0.2533\n",
      "Epoch: 5160 loss_train: 0.0794 loss_val: 0.2597\n",
      "Epoch: 5180 loss_train: 0.0777 loss_val: 0.2498\n",
      "Epoch: 5200 loss_train: 0.0786 loss_val: 0.2559\n",
      "Epoch: 5220 loss_train: 0.0758 loss_val: 0.2551\n",
      "Epoch: 5240 loss_train: 0.0778 loss_val: 0.2557\n",
      "Epoch: 5260 loss_train: 0.0820 loss_val: 0.2575\n",
      "Epoch: 5280 loss_train: 0.0766 loss_val: 0.2611\n",
      "Epoch: 5300 loss_train: 0.0774 loss_val: 0.2568\n",
      "Epoch: 5320 loss_train: 0.0776 loss_val: 0.2623\n",
      "Epoch: 5340 loss_train: 0.0786 loss_val: 0.2584\n",
      "Epoch: 5360 loss_train: 0.0804 loss_val: 0.2492\n",
      "Epoch: 5380 loss_train: 0.0774 loss_val: 0.2529\n",
      "Epoch: 5400 loss_train: 0.0802 loss_val: 0.2460\n",
      "Epoch: 5420 loss_train: 0.0803 loss_val: 0.2620\n",
      "Epoch: 5440 loss_train: 0.0775 loss_val: 0.2534\n",
      "Epoch: 5460 loss_train: 0.0778 loss_val: 0.2605\n",
      "Epoch: 5480 loss_train: 0.0773 loss_val: 0.2668\n",
      "Epoch: 5500 loss_train: 0.0754 loss_val: 0.2497\n",
      "Epoch: 5520 loss_train: 0.0746 loss_val: 0.2625\n",
      "Epoch: 5540 loss_train: 0.0780 loss_val: 0.2524\n",
      "Epoch: 5560 loss_train: 0.0783 loss_val: 0.2640\n",
      "Epoch: 5580 loss_train: 0.0778 loss_val: 0.2667\n",
      "Epoch: 5600 loss_train: 0.0806 loss_val: 0.2543\n",
      "Epoch: 5620 loss_train: 0.0775 loss_val: 0.2621\n",
      "Epoch: 5640 loss_train: 0.0755 loss_val: 0.2666\n",
      "Epoch: 5660 loss_train: 0.0752 loss_val: 0.2501\n",
      "Epoch: 5680 loss_train: 0.0781 loss_val: 0.2529\n",
      "Epoch: 5700 loss_train: 0.0776 loss_val: 0.2626\n",
      "Epoch: 5720 loss_train: 0.0750 loss_val: 0.2712\n",
      "Epoch: 5740 loss_train: 0.0770 loss_val: 0.2508\n",
      "Epoch: 5760 loss_train: 0.0787 loss_val: 0.2634\n",
      "Epoch: 5780 loss_train: 0.0789 loss_val: 0.2561\n",
      "Epoch: 5800 loss_train: 0.0725 loss_val: 0.2681\n",
      "Epoch: 5820 loss_train: 0.0798 loss_val: 0.2710\n",
      "Epoch: 5840 loss_train: 0.0764 loss_val: 0.2639\n",
      "Epoch: 5860 loss_train: 0.0730 loss_val: 0.2678\n",
      "Epoch: 5880 loss_train: 0.0772 loss_val: 0.2493\n",
      "Epoch: 5900 loss_train: 0.0734 loss_val: 0.2663\n",
      "Epoch: 5920 loss_train: 0.0789 loss_val: 0.2459\n",
      "Epoch: 5940 loss_train: 0.0756 loss_val: 0.2695\n",
      "Epoch: 5960 loss_train: 0.0767 loss_val: 0.2626\n",
      "Epoch: 5980 loss_train: 0.0773 loss_val: 0.2601\n",
      " total time: 421.1915s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0000 loss_train: 1.7729 loss_val: 1.7302\n",
      "Epoch: 0020 loss_train: 0.2743 loss_val: 0.1644\n",
      "Epoch: 0040 loss_train: 0.1932 loss_val: 0.1349\n",
      "Epoch: 0060 loss_train: 0.1638 loss_val: 0.1200\n",
      "Epoch: 0080 loss_train: 0.1405 loss_val: 0.1085\n",
      "Epoch: 0100 loss_train: 0.1261 loss_val: 0.1055\n",
      "Epoch: 0120 loss_train: 0.1207 loss_val: 0.0998\n",
      "Epoch: 0140 loss_train: 0.1096 loss_val: 0.0907\n",
      "Epoch: 0160 loss_train: 0.1023 loss_val: 0.0956\n",
      "Epoch: 0180 loss_train: 0.1017 loss_val: 0.0914\n",
      "Epoch: 0200 loss_train: 0.0954 loss_val: 0.0917\n",
      "Epoch: 0220 loss_train: 0.0885 loss_val: 0.0837\n",
      "Epoch: 0240 loss_train: 0.0834 loss_val: 0.0825\n",
      "Epoch: 0260 loss_train: 0.0817 loss_val: 0.0819\n",
      "Epoch: 0280 loss_train: 0.0814 loss_val: 0.0811\n",
      "Epoch: 0300 loss_train: 0.0769 loss_val: 0.0855\n",
      "Epoch: 0320 loss_train: 0.0766 loss_val: 0.0954\n",
      "Epoch: 0340 loss_train: 0.0739 loss_val: 0.0898\n",
      "Epoch: 0360 loss_train: 0.0701 loss_val: 0.0791\n",
      "Epoch: 0380 loss_train: 0.0674 loss_val: 0.0780\n",
      "Epoch: 0400 loss_train: 0.0674 loss_val: 0.0756\n",
      "Epoch: 0420 loss_train: 0.0666 loss_val: 0.0843\n",
      "Epoch: 0440 loss_train: 0.0652 loss_val: 0.0837\n",
      "Epoch: 0460 loss_train: 0.0646 loss_val: 0.0938\n",
      "Epoch: 0480 loss_train: 0.0653 loss_val: 0.0796\n",
      "Epoch: 0500 loss_train: 0.0599 loss_val: 0.0831\n",
      "Epoch: 0520 loss_train: 0.0601 loss_val: 0.0871\n",
      "Epoch: 0540 loss_train: 0.0582 loss_val: 0.0905\n",
      "Epoch: 0560 loss_train: 0.0566 loss_val: 0.0802\n",
      "Epoch: 0580 loss_train: 0.0591 loss_val: 0.0910\n",
      "Epoch: 0600 loss_train: 0.0567 loss_val: 0.0792\n",
      "Epoch: 0620 loss_train: 0.0599 loss_val: 0.0763\n",
      "Epoch: 0640 loss_train: 0.0542 loss_val: 0.0787\n",
      "Epoch: 0660 loss_train: 0.0671 loss_val: 0.0878\n",
      "Epoch: 0680 loss_train: 0.0570 loss_val: 0.0842\n",
      "Epoch: 0700 loss_train: 0.0547 loss_val: 0.0802\n",
      "Epoch: 0720 loss_train: 0.0512 loss_val: 0.0783\n",
      "Epoch: 0740 loss_train: 0.0614 loss_val: 0.0805\n",
      "Epoch: 0760 loss_train: 0.0567 loss_val: 0.0955\n",
      "Epoch: 0780 loss_train: 0.0653 loss_val: 0.0885\n",
      "Epoch: 0800 loss_train: 0.0535 loss_val: 0.0821\n",
      "Epoch: 0820 loss_train: 0.0530 loss_val: 0.0839\n",
      "Epoch: 0840 loss_train: 0.0487 loss_val: 0.0915\n",
      "Epoch: 0860 loss_train: 0.0479 loss_val: 0.0823\n",
      "Epoch: 0880 loss_train: 0.0497 loss_val: 0.0754\n",
      "Epoch: 0900 loss_train: 0.0524 loss_val: 0.0850\n",
      "Epoch: 0920 loss_train: 0.0558 loss_val: 0.0886\n",
      "Epoch: 0940 loss_train: 0.0475 loss_val: 0.0807\n",
      "Epoch: 0960 loss_train: 0.0535 loss_val: 0.0798\n",
      "Epoch: 0980 loss_train: 0.0457 loss_val: 0.0823\n",
      "Epoch: 1000 loss_train: 0.0467 loss_val: 0.0748\n",
      "Epoch: 1020 loss_train: 0.0454 loss_val: 0.0830\n",
      "Epoch: 1040 loss_train: 0.0493 loss_val: 0.0874\n",
      "Epoch: 1060 loss_train: 0.0494 loss_val: 0.0983\n",
      "Epoch: 1080 loss_train: 0.0453 loss_val: 0.0900\n",
      "Epoch: 1100 loss_train: 0.0511 loss_val: 0.0847\n",
      "Epoch: 1120 loss_train: 0.0480 loss_val: 0.0770\n",
      "Epoch: 1140 loss_train: 0.0465 loss_val: 0.0767\n",
      "Epoch: 1160 loss_train: 0.0552 loss_val: 0.0765\n",
      "Epoch: 1180 loss_train: 0.0503 loss_val: 0.0782\n",
      "Epoch: 1200 loss_train: 0.0481 loss_val: 0.0779\n",
      "Epoch: 1220 loss_train: 0.0518 loss_val: 0.0946\n",
      "Epoch: 1240 loss_train: 0.0497 loss_val: 0.0855\n",
      "Epoch: 1260 loss_train: 0.0441 loss_val: 0.0828\n",
      "Epoch: 1280 loss_train: 0.0447 loss_val: 0.0755\n",
      "Epoch: 1300 loss_train: 0.0413 loss_val: 0.0743\n",
      "Epoch: 1320 loss_train: 0.0501 loss_val: 0.0818\n",
      "Epoch: 1340 loss_train: 0.0408 loss_val: 0.0854\n",
      "Epoch: 1360 loss_train: 0.0430 loss_val: 0.0853\n",
      "Epoch: 1380 loss_train: 0.0434 loss_val: 0.0879\n",
      "Epoch: 1400 loss_train: 0.0394 loss_val: 0.0830\n",
      "Epoch: 1420 loss_train: 0.0448 loss_val: 0.0930\n",
      "Epoch: 1440 loss_train: 0.0558 loss_val: 0.1120\n",
      "Epoch: 1460 loss_train: 0.0453 loss_val: 0.0918\n",
      "Epoch: 1480 loss_train: 0.0418 loss_val: 0.0872\n",
      "Epoch: 1500 loss_train: 0.0511 loss_val: 0.0925\n",
      "Epoch: 1520 loss_train: 0.0388 loss_val: 0.0882\n",
      "Epoch: 1540 loss_train: 0.0454 loss_val: 0.0800\n",
      "Epoch: 1560 loss_train: 0.0417 loss_val: 0.0863\n",
      "Epoch: 1580 loss_train: 0.0437 loss_val: 0.0788\n",
      "Epoch: 1600 loss_train: 0.0424 loss_val: 0.0962\n",
      "Epoch: 1620 loss_train: 0.0547 loss_val: 0.0940\n",
      "Epoch: 1640 loss_train: 0.0415 loss_val: 0.0952\n",
      "Epoch: 1660 loss_train: 0.0372 loss_val: 0.0925\n",
      "Epoch: 1680 loss_train: 0.0404 loss_val: 0.0893\n",
      "Epoch: 1700 loss_train: 0.0440 loss_val: 0.0946\n",
      "Epoch: 1720 loss_train: 0.0434 loss_val: 0.0913\n",
      "Epoch: 1740 loss_train: 0.0379 loss_val: 0.0909\n",
      "Epoch: 1760 loss_train: 0.0401 loss_val: 0.0951\n",
      "Epoch: 1780 loss_train: 0.0464 loss_val: 0.0870\n",
      "Epoch: 1800 loss_train: 0.0488 loss_val: 0.0764\n",
      "Epoch: 1820 loss_train: 0.0425 loss_val: 0.0904\n",
      "Epoch: 1840 loss_train: 0.0414 loss_val: 0.1011\n",
      "Epoch: 1860 loss_train: 0.0489 loss_val: 0.0842\n",
      "Epoch: 1880 loss_train: 0.0431 loss_val: 0.0799\n",
      "Epoch: 1900 loss_train: 0.0392 loss_val: 0.0887\n",
      "Epoch: 1920 loss_train: 0.0418 loss_val: 0.1087\n",
      "Epoch: 1940 loss_train: 0.0430 loss_val: 0.0807\n",
      "Epoch: 1960 loss_train: 0.0400 loss_val: 0.0847\n",
      "Epoch: 1980 loss_train: 0.0421 loss_val: 0.0864\n",
      "Epoch: 2000 loss_train: 0.0431 loss_val: 0.0907\n",
      "Epoch: 2020 loss_train: 0.0450 loss_val: 0.0822\n",
      "Epoch: 2040 loss_train: 0.0409 loss_val: 0.0938\n",
      "Epoch: 2060 loss_train: 0.0406 loss_val: 0.0888\n",
      "Epoch: 2080 loss_train: 0.0356 loss_val: 0.0974\n",
      "Epoch: 2100 loss_train: 0.0464 loss_val: 0.0901\n",
      "Epoch: 2120 loss_train: 0.0378 loss_val: 0.0852\n",
      "Epoch: 2140 loss_train: 0.0356 loss_val: 0.0849\n",
      "Epoch: 2160 loss_train: 0.0385 loss_val: 0.0888\n",
      "Epoch: 2180 loss_train: 0.0360 loss_val: 0.0931\n",
      "Epoch: 2200 loss_train: 0.0349 loss_val: 0.0858\n",
      "Epoch: 2220 loss_train: 0.0358 loss_val: 0.0817\n",
      "Epoch: 2240 loss_train: 0.0399 loss_val: 0.0843\n",
      "Epoch: 2260 loss_train: 0.0391 loss_val: 0.0818\n",
      "Epoch: 2280 loss_train: 0.0371 loss_val: 0.0807\n",
      "Epoch: 2300 loss_train: 0.0361 loss_val: 0.0807\n",
      "Epoch: 2320 loss_train: 0.0330 loss_val: 0.0900\n",
      "Epoch: 2340 loss_train: 0.0444 loss_val: 0.0997\n",
      "Epoch: 2360 loss_train: 0.0364 loss_val: 0.0853\n",
      "Epoch: 2380 loss_train: 0.0351 loss_val: 0.0870\n",
      "Epoch: 2400 loss_train: 0.0357 loss_val: 0.1007\n",
      "Epoch: 2420 loss_train: 0.0364 loss_val: 0.0812\n",
      "Epoch: 2440 loss_train: 0.0472 loss_val: 0.0882\n",
      "Epoch: 2460 loss_train: 0.0386 loss_val: 0.0811\n",
      "Epoch: 2480 loss_train: 0.0406 loss_val: 0.0996\n",
      "Epoch: 2500 loss_train: 0.0371 loss_val: 0.0890\n",
      "Epoch: 2520 loss_train: 0.0325 loss_val: 0.0900\n",
      "Epoch: 2540 loss_train: 0.0354 loss_val: 0.0944\n",
      "Epoch: 2560 loss_train: 0.0326 loss_val: 0.0923\n",
      "Epoch: 2580 loss_train: 0.0342 loss_val: 0.1025\n",
      "Epoch: 2600 loss_train: 0.0407 loss_val: 0.0856\n",
      "Epoch: 2620 loss_train: 0.0397 loss_val: 0.0820\n",
      "Epoch: 2640 loss_train: 0.0422 loss_val: 0.0913\n",
      "Epoch: 2660 loss_train: 0.0345 loss_val: 0.0961\n",
      "Epoch: 2680 loss_train: 0.0341 loss_val: 0.0925\n",
      "Epoch: 2700 loss_train: 0.0355 loss_val: 0.0951\n",
      "Epoch: 2720 loss_train: 0.0411 loss_val: 0.0856\n",
      "Epoch: 2740 loss_train: 0.0401 loss_val: 0.0865\n",
      "Epoch: 2760 loss_train: 0.0337 loss_val: 0.0765\n",
      "Epoch: 2780 loss_train: 0.0337 loss_val: 0.0855\n",
      "Epoch: 2800 loss_train: 0.0371 loss_val: 0.0917\n",
      "Epoch: 2820 loss_train: 0.0325 loss_val: 0.1025\n",
      "Epoch: 2840 loss_train: 0.0367 loss_val: 0.0999\n",
      "Epoch: 2860 loss_train: 0.0320 loss_val: 0.0904\n",
      "Epoch: 2880 loss_train: 0.0336 loss_val: 0.1008\n",
      "Epoch: 2900 loss_train: 0.0312 loss_val: 0.0934\n",
      "Epoch: 2920 loss_train: 0.0381 loss_val: 0.0965\n",
      "Epoch: 2940 loss_train: 0.0308 loss_val: 0.0887\n",
      "Epoch: 2960 loss_train: 0.0308 loss_val: 0.0881\n",
      "Epoch: 2980 loss_train: 0.0387 loss_val: 0.0862\n",
      "Epoch: 3000 loss_train: 0.0321 loss_val: 0.0909\n",
      "Epoch: 3020 loss_train: 0.0292 loss_val: 0.0861\n",
      "Epoch: 3040 loss_train: 0.0327 loss_val: 0.0884\n",
      "Epoch: 3060 loss_train: 0.0338 loss_val: 0.0974\n",
      "Epoch: 3080 loss_train: 0.0337 loss_val: 0.0909\n",
      "Epoch: 3100 loss_train: 0.0326 loss_val: 0.0958\n",
      "Epoch: 3120 loss_train: 0.0340 loss_val: 0.0884\n",
      "Epoch: 3140 loss_train: 0.0319 loss_val: 0.0864\n",
      "Epoch: 3160 loss_train: 0.0311 loss_val: 0.0981\n",
      "Epoch: 3180 loss_train: 0.0301 loss_val: 0.0899\n",
      "Epoch: 3200 loss_train: 0.0287 loss_val: 0.0973\n",
      "Epoch: 3220 loss_train: 0.0308 loss_val: 0.0914\n",
      "Epoch: 3240 loss_train: 0.0330 loss_val: 0.1032\n",
      "Epoch: 3260 loss_train: 0.0446 loss_val: 0.0935\n",
      "Epoch: 3280 loss_train: 0.0320 loss_val: 0.0933\n",
      "Epoch: 3300 loss_train: 0.0329 loss_val: 0.0837\n",
      "Epoch: 3320 loss_train: 0.0322 loss_val: 0.1030\n",
      "Epoch: 3340 loss_train: 0.0318 loss_val: 0.0923\n",
      "Epoch: 3360 loss_train: 0.0345 loss_val: 0.1047\n",
      "Epoch: 3380 loss_train: 0.0327 loss_val: 0.1010\n",
      "Epoch: 3400 loss_train: 0.0369 loss_val: 0.0951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3420 loss_train: 0.0315 loss_val: 0.0915\n",
      "Epoch: 3440 loss_train: 0.0309 loss_val: 0.0993\n",
      "Epoch: 3460 loss_train: 0.0345 loss_val: 0.0936\n",
      "Epoch: 3480 loss_train: 0.0322 loss_val: 0.0995\n",
      "Epoch: 3500 loss_train: 0.0303 loss_val: 0.0949\n",
      "Epoch: 3520 loss_train: 0.0331 loss_val: 0.0858\n",
      "Epoch: 3540 loss_train: 0.0303 loss_val: 0.0996\n",
      "Epoch: 3560 loss_train: 0.0300 loss_val: 0.0945\n",
      "Epoch: 3580 loss_train: 0.0332 loss_val: 0.1018\n",
      "Epoch: 3600 loss_train: 0.0294 loss_val: 0.0972\n",
      "Epoch: 3620 loss_train: 0.0348 loss_val: 0.0942\n",
      "Epoch: 3640 loss_train: 0.0286 loss_val: 0.1042\n",
      "Epoch: 3660 loss_train: 0.0273 loss_val: 0.0912\n",
      "Epoch: 3680 loss_train: 0.0339 loss_val: 0.0993\n",
      "Epoch: 3700 loss_train: 0.0305 loss_val: 0.0800\n",
      "Epoch: 3720 loss_train: 0.0329 loss_val: 0.0794\n",
      "Epoch: 3740 loss_train: 0.0326 loss_val: 0.0872\n",
      "Epoch: 3760 loss_train: 0.0310 loss_val: 0.0989\n",
      "Epoch: 3780 loss_train: 0.0263 loss_val: 0.1110\n",
      "Epoch: 3800 loss_train: 0.0289 loss_val: 0.0966\n",
      "Epoch: 3820 loss_train: 0.0281 loss_val: 0.1079\n",
      "Epoch: 3840 loss_train: 0.0312 loss_val: 0.0907\n",
      "Epoch: 3860 loss_train: 0.0275 loss_val: 0.0899\n",
      "Epoch: 3880 loss_train: 0.0291 loss_val: 0.0979\n",
      "Epoch: 3900 loss_train: 0.0312 loss_val: 0.0941\n",
      "Epoch: 3920 loss_train: 0.0317 loss_val: 0.0970\n",
      "Epoch: 3940 loss_train: 0.0291 loss_val: 0.0953\n",
      "Epoch: 3960 loss_train: 0.0306 loss_val: 0.0922\n",
      "Epoch: 3980 loss_train: 0.0354 loss_val: 0.0987\n",
      "Epoch: 4000 loss_train: 0.0310 loss_val: 0.0942\n",
      "Epoch: 4020 loss_train: 0.0306 loss_val: 0.1035\n",
      "Epoch: 4040 loss_train: 0.0294 loss_val: 0.0963\n",
      "Epoch: 4060 loss_train: 0.0342 loss_val: 0.0921\n",
      "Epoch: 4080 loss_train: 0.0315 loss_val: 0.0971\n",
      "Epoch: 4100 loss_train: 0.0324 loss_val: 0.0998\n",
      "Epoch: 4120 loss_train: 0.0290 loss_val: 0.1054\n",
      "Epoch: 4140 loss_train: 0.0320 loss_val: 0.1041\n",
      "Epoch: 4160 loss_train: 0.0279 loss_val: 0.1087\n",
      "Epoch: 4180 loss_train: 0.0277 loss_val: 0.1146\n",
      "Epoch: 4200 loss_train: 0.0326 loss_val: 0.1075\n",
      "Epoch: 4220 loss_train: 0.0277 loss_val: 0.1025\n",
      "Epoch: 4240 loss_train: 0.0300 loss_val: 0.1017\n",
      "Epoch: 4260 loss_train: 0.0254 loss_val: 0.1052\n",
      "Epoch: 4280 loss_train: 0.0302 loss_val: 0.1041\n",
      "Epoch: 4300 loss_train: 0.0289 loss_val: 0.0991\n",
      "Epoch: 4320 loss_train: 0.0256 loss_val: 0.0948\n",
      "Epoch: 4340 loss_train: 0.0297 loss_val: 0.1060\n",
      "Epoch: 4360 loss_train: 0.0297 loss_val: 0.0933\n",
      "Epoch: 4380 loss_train: 0.0326 loss_val: 0.0896\n",
      "Epoch: 4400 loss_train: 0.0281 loss_val: 0.0975\n",
      "Epoch: 4420 loss_train: 0.0264 loss_val: 0.1072\n",
      "Epoch: 4440 loss_train: 0.0314 loss_val: 0.0919\n",
      "Epoch: 4460 loss_train: 0.0283 loss_val: 0.0926\n",
      "Epoch: 4480 loss_train: 0.0299 loss_val: 0.0938\n",
      "Epoch: 4500 loss_train: 0.0266 loss_val: 0.0854\n",
      "Epoch: 4520 loss_train: 0.0291 loss_val: 0.0814\n",
      "Epoch: 4540 loss_train: 0.0320 loss_val: 0.0991\n",
      "Epoch: 4560 loss_train: 0.0339 loss_val: 0.1001\n",
      "Epoch: 4580 loss_train: 0.0316 loss_val: 0.1019\n",
      "Epoch: 4600 loss_train: 0.0262 loss_val: 0.1003\n",
      "Epoch: 4620 loss_train: 0.0247 loss_val: 0.0896\n",
      "Epoch: 4640 loss_train: 0.0273 loss_val: 0.0983\n",
      "Epoch: 4660 loss_train: 0.0259 loss_val: 0.0944\n",
      "Epoch: 4680 loss_train: 0.0254 loss_val: 0.1047\n",
      "Epoch: 4700 loss_train: 0.0257 loss_val: 0.0947\n",
      "Epoch: 4720 loss_train: 0.0302 loss_val: 0.1012\n",
      "Epoch: 4740 loss_train: 0.0270 loss_val: 0.0943\n",
      "Epoch: 4760 loss_train: 0.0256 loss_val: 0.0885\n",
      "Epoch: 4780 loss_train: 0.0267 loss_val: 0.0976\n",
      "Epoch: 4800 loss_train: 0.0274 loss_val: 0.0910\n",
      "Epoch: 4820 loss_train: 0.0242 loss_val: 0.0926\n",
      "Epoch: 4840 loss_train: 0.0266 loss_val: 0.0972\n",
      "Epoch: 4860 loss_train: 0.0277 loss_val: 0.0972\n",
      "Epoch: 4880 loss_train: 0.0297 loss_val: 0.1075\n",
      "Epoch: 4900 loss_train: 0.0278 loss_val: 0.0925\n",
      "Epoch: 4920 loss_train: 0.0278 loss_val: 0.0975\n",
      "Epoch: 4940 loss_train: 0.0260 loss_val: 0.0919\n",
      "Epoch: 4960 loss_train: 0.0232 loss_val: 0.0975\n",
      "Epoch: 4980 loss_train: 0.0254 loss_val: 0.0931\n",
      "Epoch: 5000 loss_train: 0.0282 loss_val: 0.1158\n",
      "Epoch: 5020 loss_train: 0.0265 loss_val: 0.0884\n",
      "Epoch: 5040 loss_train: 0.0262 loss_val: 0.0875\n",
      "Epoch: 5060 loss_train: 0.0276 loss_val: 0.0947\n",
      "Epoch: 5080 loss_train: 0.0284 loss_val: 0.0983\n",
      "Epoch: 5100 loss_train: 0.0299 loss_val: 0.0903\n",
      "Epoch: 5120 loss_train: 0.0284 loss_val: 0.0943\n",
      "Epoch: 5140 loss_train: 0.0279 loss_val: 0.1046\n",
      "Epoch: 5160 loss_train: 0.0292 loss_val: 0.0975\n",
      "Epoch: 5180 loss_train: 0.0304 loss_val: 0.0991\n",
      "Epoch: 5200 loss_train: 0.0265 loss_val: 0.1071\n",
      "Epoch: 5220 loss_train: 0.0301 loss_val: 0.0984\n",
      "Epoch: 5240 loss_train: 0.0272 loss_val: 0.0889\n",
      "Epoch: 5260 loss_train: 0.0269 loss_val: 0.1055\n",
      "Epoch: 5280 loss_train: 0.0270 loss_val: 0.0997\n",
      "Epoch: 5300 loss_train: 0.0369 loss_val: 0.0972\n",
      "Epoch: 5320 loss_train: 0.0309 loss_val: 0.0938\n",
      "Epoch: 5340 loss_train: 0.0304 loss_val: 0.0988\n",
      "Epoch: 5360 loss_train: 0.0304 loss_val: 0.0978\n",
      "Epoch: 5380 loss_train: 0.0286 loss_val: 0.0964\n",
      "Epoch: 5400 loss_train: 0.0292 loss_val: 0.0904\n",
      "Epoch: 5420 loss_train: 0.0271 loss_val: 0.0847\n",
      "Epoch: 5440 loss_train: 0.0269 loss_val: 0.1039\n",
      "Epoch: 5460 loss_train: 0.0262 loss_val: 0.0933\n",
      "Epoch: 5480 loss_train: 0.0266 loss_val: 0.1002\n",
      "Epoch: 5500 loss_train: 0.0262 loss_val: 0.0985\n",
      "Epoch: 5520 loss_train: 0.0271 loss_val: 0.1013\n",
      "Epoch: 5540 loss_train: 0.0244 loss_val: 0.1086\n",
      "Epoch: 5560 loss_train: 0.0242 loss_val: 0.0954\n",
      "Epoch: 5580 loss_train: 0.0263 loss_val: 0.0929\n",
      "Epoch: 5600 loss_train: 0.0241 loss_val: 0.1075\n",
      "Epoch: 5620 loss_train: 0.0262 loss_val: 0.1047\n",
      "Epoch: 5640 loss_train: 0.0242 loss_val: 0.1005\n",
      "Epoch: 5660 loss_train: 0.0290 loss_val: 0.1085\n",
      "Epoch: 5680 loss_train: 0.0240 loss_val: 0.1041\n",
      "Epoch: 5700 loss_train: 0.0246 loss_val: 0.1148\n",
      "Epoch: 5720 loss_train: 0.0277 loss_val: 0.1111\n",
      "Epoch: 5740 loss_train: 0.0281 loss_val: 0.1050\n",
      "Epoch: 5760 loss_train: 0.0242 loss_val: 0.1030\n",
      "Epoch: 5780 loss_train: 0.0247 loss_val: 0.1024\n",
      "Epoch: 5800 loss_train: 0.0254 loss_val: 0.1164\n",
      "Epoch: 5820 loss_train: 0.0269 loss_val: 0.0994\n",
      "Epoch: 5840 loss_train: 0.0256 loss_val: 0.1124\n",
      "Epoch: 5860 loss_train: 0.0254 loss_val: 0.1062\n",
      "Epoch: 5880 loss_train: 0.0259 loss_val: 0.0996\n",
      "Epoch: 5900 loss_train: 0.0270 loss_val: 0.0970\n",
      "Epoch: 5920 loss_train: 0.0255 loss_val: 0.1095\n",
      "Epoch: 5940 loss_train: 0.0258 loss_val: 0.0989\n",
      "Epoch: 5960 loss_train: 0.0264 loss_val: 0.1054\n",
      "Epoch: 5980 loss_train: 0.0252 loss_val: 0.1003\n",
      " total time: 501.2118s\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEHCAYAAABCwJb2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAeQUlEQVR4nO3de5RU1Zn+8e8LtHRAhBaIyiVCJqjQ3GkR7EFEDHJREBMBIxEclcQxMY4JPzFRiY7OYMJCxAguFI2iUQmRqCMGbxg08dagIjcDCkqDFy6CIGAE3t8fZ9Nple6uhqaruvbzWasXda61N3XqqVP77LPL3B0REYlDrXQXQEREqo9CX0QkIgp9EZGIKPRFRCKi0BcRiYhCX0QkInXSXYDyNGnSxFu1apXuYoiI1CgLFy7c6O5N97cso0O/VatWFBUVpbsYIiI1ipm9V9YyNe+IiEREoS8iEhGFvohIRDK6TV9Eqt8XX3xBcXExu3btSndRpAK5ubm0aNGCnJyclLdR6IvIlxQXF9OgQQNatWqFmaW7OFIGd2fTpk0UFxfTunXrlLdT846IfMmuXbto3LixAj/DmRmNGzeu9Dcyhb6IfI0Cv2Y4kNdJoS8iGWXLli1MnTr1gLYdOHAgW7ZsKXed6667jmeeeeaA9v9VrVq1YuPGjVWyr+qi0BeRjFJe6O/evbvcbefOnUujRo3KXeeGG27g9NNPP9Di1XgKfRHJKOPGjeOdd96hc+fOjB07lueff55evXoxePBg2rVrB8DZZ59Nt27dyM/PZ/r06SXb7jvzXrNmDW3btuWSSy4hPz+ffv36sXPnTgBGjx7N7NmzS9YfP348Xbt2pUOHDqxYsQKADRs28N3vfpf8/Hwuvvhijj322ArP6CdNmkT79u1p3749kydPBuCzzz5j0KBBdOrUifbt2/Pwww+X1LFdu3Z07NiRX/ziF1X6/1cR9d4RkTJd//hSlq3/tEr32a7ZEYw/K7/M5RMmTGDJkiW88cYbADz//PMsWrSIJUuWlPRSufvuuznyyCPZuXMnJ554It/73vdo3Ljxl/azcuVKHnzwQe68806GDRvGn/70J0aOHPm152vSpAmLFi1i6tSpTJw4kbvuuovrr7+e0047jauvvpq//OUvzJgxo9w6LVy4kHvuuYdXXnkFd+ekk06id+/evPvuuzRr1ownnngCgK1bt7Jp0ybmzJnDihUrMLMKm6Oqms70RSTjde/e/UvdEqdMmUKnTp3o0aMHa9euZeXKlV/bpnXr1nTu3BmAbt26sWbNmv3u+5xzzvnaOi+++CIjRowAoH///uTl5ZVbvhdffJGhQ4dSv359Dj/8cM455xxeeOEFOnTowNNPP81VV13FCy+8QMOGDWnYsCG5ublcdNFFPPLII9SrV6+S/xsHR2f6IlKm8s7Iq1P9+vVLHj///PM888wzvPTSS9SrV49TTz11v90W69atW/K4du3aJc07Za1Xu3btCq8ZVNZxxx3HokWLmDt3Ltdccw19+/bluuuu49VXX+XZZ59l9uzZ/O53v+O5556r0uctj870RSSjNGjQgG3btpW5fOvWreTl5VGvXj1WrFjByy+/XOVlKCwsZNasWQA89dRTfPLJJ+Wu36tXL/785z+zY8cOPvvsM+bMmUOvXr1Yv3499erVY+TIkYwdO5ZFixaxfft2tm7dysCBA7nlllt48803q7z85dGZvohklMaNG1NYWEj79u0ZMGAAgwYN+tLy/v37c8cdd9C2bVuOP/54evToUeVlGD9+POeddx4zZ86kZ8+eHH300TRo0KDM9bt27cro0aPp3r07ABdffDFdunRh3rx5jB07llq1apGTk8O0adPYtm0bQ4YMYdeuXbg7kyZNqvLyl8fcvVqfsDIKCgpc4+mLVK/ly5fTtm3bdBcjrT7//HNq165NnTp1eOmll7j00ktLLixnmv29Xma20N0L9re+zvRFRL7i/fffZ9iwYezdu5fDDjuMO++8M91FqjIKfRGRr2jTpg2vv/56uotxSOhCrohIRBT6IiIRUeiLiEREoS8iEhGFvojUeIcffjgA69ev5/vf//5+1zn11FOpqAv45MmT2bFjR8l0KkM1p+LXv/41EydOPOj9VAWFvohkjWbNmpWMoHkgvhr6qQzVXNMo9EUko4wbN47bb7+9ZHrfWfL27dvp27dvyTDIjz766Ne2XbNmDe3btwdg586djBgxgrZt2zJ06NAvjb1z6aWXUlBQQH5+PuPHjweSQdzWr19Pnz596NOnD/DlH0nZ39DJ5Q3hXJY33niDHj160LFjR4YOHVoyxMOUKVNKhlveN9jbX//6Vzp37kznzp3p0qVLucNTpEr99EWkbE+Ogw/fqtp9Ht0BBkwoc/Hw4cO54ooruOyyywCYNWsW8+bNIzc3lzlz5nDEEUewceNGevToweDBg8v8ycBp06ZRr149li9fzuLFi+natWvJsptuuokjjzySPXv20LdvXxYvXszll1/OpEmTmD9/Pk2aNPnSvsoaOjkvLy/lIZz3ueCCC7jtttvo3bs31113Hddffz2TJ09mwoQJrF69mrp165Y0KU2cOJHbb7+dwsJCtm/fTm5ubqr/y2XSmb6IZJQuXbrw8ccfs379et58803y8vJo2bIl7s4vf/lLOnbsyOmnn866dev46KOPytzPggULSsK3Y8eOdOzYsWTZrFmz6Nq1K126dGHp0qUsW7as3DKVNXQypD6EMySDxW3ZsoXevXsDMGrUKBYsWFBSxvPPP5/777+fOnWS8/HCwkKuvPJKpkyZwpYtW0rmHwyd6YtI2co5Iz+Uzj33XGbPns2HH37I8OHDAXjggQfYsGEDCxcuJCcnh1atWu13SOWKrF69mokTJ/Laa6+Rl5fH6NGjD2g/+6Q6hHNFnnjiCRYsWMDjjz/OTTfdxFtvvcW4ceMYNGgQc+fOpbCwkHnz5nHCCScccFlBZ/oikoGGDx/OQw89xOzZszn33HOB5Cz5m9/8Jjk5OcyfP5/33nuv3H2ccsop/OEPfwBgyZIlLF68GIBPP/2U+vXr07BhQz766COefPLJkm3KGta5rKGTK6thw4bk5eWVfEuYOXMmvXv3Zu/evaxdu5Y+ffpw8803s3XrVrZv384777xDhw4duOqqqzjxxBNLfs7xYOhMX0QyTn5+Ptu2baN58+Ycc8wxAJx//vmcddZZdOjQgYKCggrPeC+99FIuvPBC2rZtS9u2benWrRsAnTp1okuXLpxwwgm0bNmSwsLCkm3GjBlD//79adasGfPnzy+ZX9bQyeU15ZTl3nvv5cc//jE7duzg29/+Nvfccw979uxh5MiRbN26FXfn8ssvp1GjRlx77bXMnz+fWrVqkZ+fz4ABAyr9fF+loZVF5Es0tHLNUtmhldW8IyISkZRC38z+y8yWmtkSM3vQzHLNrLWZvWJmq8zsYTM7LKxbN0yvCstbldrP1WH+22Z2xiGqk4iIlKHC0Dez5sDlQIG7twdqAyOAm4Fb3P07wCfARWGTi4BPwvxbwnqYWbuwXT7QH5hqZrWrtjoiIlKeVJt36gDfMLM6QD3gA+A0YN/9zvcCZ4fHQ8I0YXlfS+6eGAI85O6fu/tqYBXQ/aBrICJVLpOv9cm/HMjrVGHou/s6YCLwPknYbwUWAlvcfXdYrRhoHh43B9aGbXeH9RuXnr+fbUqY2RgzKzKzog0bNlS6QiJycHJzc9m0aZOCP8O5O5s2bar0XboVdtk0szySs/TWwBbgjyTNM4eEu08HpkPSe+dQPY+I7F+LFi0oLi5GJ12ZLzc3lxYtWlRqm1T66Z8OrHb3DQBm9ghQCDQyszrhbL4FsC6svw5oCRSH5qCGwKZS8/cpvY2IZIicnBxat26d7mLIIZJKm/77QA8zqxfa5vsCy4D5wL6Bq0cB+4a8eyxME5Y/58n3xMeAEaF3T2ugDfBq1VRDRERSUeGZvru/YmazgUXAbuB1kuaXJ4CHzOzGMG9G2GQGMNPMVgGbSXrs4O5LzWwWyQfGbuAyd99TxfUREZFy6I5cEZEsoztyRUQEUOiLiERFoS8iEhGFvohIRBT6IiIRUeiLiEREoS8iEhGFvohIRBT6IiIRUeiLiEREoS8iEhGFvohIRBT6IiIRUeiLiEREoS8iEhGFvohIRBT6IiIRUeiLiEREoS8iEhGFvohIRBT6IiIRUeiLiEREoS8iEhGFvohIRBT6IiIRUeiLiEREoS8iEhGFvohIRBT6IiIRUeiLiEREoS8iEhGFvohIRBT6IiIRUeiLiEREoS8iEhGFvohIRFIKfTNrZGazzWyFmS03s55mdqSZPW1mK8O/eWFdM7MpZrbKzBabWddS+xkV1l9pZqMOVaVERGT/Uj3TvxX4i7ufAHQClgPjgGfdvQ3wbJgGGAC0CX9jgGkAZnYkMB44CegOjN/3QSEiItWjwtA3s4bAKcAMAHf/p7tvAYYA94bV7gXODo+HAPd54mWgkZkdA5wBPO3um939E+BpoH8V1kVERCqQypl+a2ADcI+ZvW5md5lZfeAod/8grPMhcFR43BxYW2r74jCvrPlfYmZjzKzIzIo2bNhQudqIiEi5Ugn9OkBXYJq7dwE+419NOQC4uwNeFQVy9+nuXuDuBU2bNq2KXYqISJBK6BcDxe7+SpieTfIh8FFotiH8+3FYvg5oWWr7FmFeWfNFRKSaVBj67v4hsNbMjg+z+gLLgMeAfT1wRgGPhsePAReEXjw9gK2hGWge0M/M8sIF3H5hnoiIVJM6Ka73U+ABMzsMeBe4kOQDY5aZXQS8BwwL684FBgKrgB1hXdx9s5n9N/BaWO8Gd99cJbUQEZGUWNIcn5kKCgq8qKgo3cUQEalRzGyhuxfsb5nuyBURiYhCX0QkIgp9EZGIKPRFRCKi0BcRiYhCX0QkIgp9EZGIKPRFRCKi0BcRiYhCX0QkIgp9EZGIKPRFRCKi0BcRiYhCX0QkIgp9EZGIKPRFRCKi0BcRiYhCX0QkIgp9EZGIKPRFRCKi0BcRiYhCX0QkIgp9EZGIKPRFRCKi0BcRiYhCX0QkIgp9EZGIKPRFRCKi0BcRiYhCX0QkIgp9EZGIKPRFRCKi0BcRiYhCX0QkIgp9EZGIKPRFRCKScuibWW0ze93M/i9MtzazV8xslZk9bGaHhfl1w/SqsLxVqX1cHea/bWZnVHltRESkXJU50/8ZsLzU9M3ALe7+HeAT4KIw/yLgkzD/lrAeZtYOGAHkA/2BqWZW++CKLyIilZFS6JtZC2AQcFeYNuA0YHZY5V7g7PB4SJgmLO8b1h8CPOTun7v7amAV0L0K6iAiIilK9Ux/MvD/gL1hujGwxd13h+lioHl43BxYCxCWbw3rl8zfzzYlzGyMmRWZWdGGDRtSr4mIiFSowtA3szOBj919YTWUB3ef7u4F7l7QtGnT6nhKEZFo1ElhnUJgsJkNBHKBI4BbgUZmVieczbcA1oX11wEtgWIzqwM0BDaVmr9P6W1ERKQaVHim7+5Xu3sLd29FciH2OXc/H5gPfD+sNgp4NDx+LEwTlj/n7h7mjwi9e1oDbYBXq6wmIiJSoVTO9MtyFfCQmd0IvA7MCPNnADPNbBWwmeSDAndfamazgGXAbuAyd99zEM8vIiKVZMlJeGYqKCjwoqKidBdDRKRGMbOF7l6wv2W6I1dEJCIKfRGRiCj0RUQiotAXEYmIQl9EJCIKfRGRiCj0RUQiotAXEYmIQl9EJCIKfRGRiCj0RUQiotAXEYmIQl9EJCIKfRGRiCj0RUQiotAXEYmIQl9EJCIKfRGRiCj0RUQiotAXEYmIQl9EJCIKfRGRiCj0RUQiotAXEYmIQl9EJCIKfRGRiCj0RUQiotAXEYmIQl9EJCIKfRGRiCj0RUQiotAXEYmIQl9EJCIKfRGRiCj0RUQiotAXEYlIhaFvZi3NbL6ZLTOzpWb2szD/SDN72sxWhn/zwnwzsylmtsrMFptZ11L7GhXWX2lmow5dtUREZH9SOdPfDfzc3dsBPYDLzKwdMA541t3bAM+GaYABQJvwNwaYBsmHBDAeOAnoDozf90EhIiLVo8LQd/cP3H1ReLwNWA40B4YA94bV7gXODo+HAPd54mWgkZkdA5wBPO3um939E+BpoH9VVkZERMpXqTZ9M2sFdAFeAY5y9w/Cog+Bo8Lj5sDaUpsVh3llzf/qc4wxsyIzK9qwYUNliiciIhVIOfTN7HDgT8AV7v5p6WXu7oBXRYHcfbq7F7h7QdOmTatilyIiEqQU+maWQxL4D7j7I2H2R6HZhvDvx2H+OqBlqc1bhHllzRcRkWqSSu8dA2YAy919UqlFjwH7euCMAh4tNf+C0IunB7A1NAPNA/qZWV64gNsvzBMRkWpSJ4V1CoEfAm+Z2Rth3i+BCcAsM7sIeA8YFpbNBQYCq4AdwIUA7r7ZzP4beC2sd4O7b66KSoiISGosaY7PTAUFBV5UVJTuYoiI1ChmttDdC/a3THfkiohERKEvIhIRhb6ISEQU+iIiEVHoi4hERKEvIhIRhb6ISEQU+iIiEVHoi4hERKEvIhIRhb6ISEQU+iIiEVHoi4hERKEvIhIRhb6ISEQU+iIiEVHoi4hERKEvIhIRhb6ISEQU+iIiEVHoi4hERKEvIhIRhb6ISEQU+iIiEVHoi4hERKEvIhIRhb6ISEQU+iIiEVHoi4hERKEvIhIRhb6ISEQU+iIiEVHoi4hERKEvIhIRhb6ISEQU+iIiEan20Dez/mb2tpmtMrNx1f38IiIxq9bQN7PawO3AAKAdcJ6ZtavOMoiIxKxONT9fd2CVu78LYGYPAUOAZVX5JO+9/Qb+8Ej2UIe9VhvHwKwqn0JE5JDadNTJ9Lzk1irfb3WHfnNgbanpYuCk0iuY2RhgTJjcbmZvH8TzNQE2HsT2mSJb6gGqSybKlnpAVtWlqAljphxoXY4ta0F1h36F3H06ML0q9mVmRe5eUBX7SqdsqQeoLpkoW+oBqksqqvtC7jqgZanpFmGeiIhUg+oO/deANmbW2swOA0YAj1VzGUREolWtzTvuvtvMfgLMA2oDd7v70kP4lFXSTJQBsqUeoLpkomypB6guFTJ3PxT7FRGRDKQ7ckVEIqLQFxGJiEJfRCQiWRf6Zna8mfU0s5ww7EONZ2Y1/nUys3pmVjfd5ThYZlY7i46rbKpLVhxfcOjrUuPDpDQzOwd4FLgRmAFcZmZHpLdUB8bMjjWzfAB33xvm1cixJMLrcj/wpJmdaWbfTneZDoSZDQXuBh4xsx5m1iDdZTpQWVaXrDi+oHrqkjW9d8wsh+Q/a4q7/83Mvgf0AP4J3Ozun6a1gJUQyv4/wAfh72HgGXffbmbmNehFM7PWJF10zweOB3oCHwOPufvr6SxbZYSBAR8FLgY6A32Bx4En3b04jUWrtCyrS1YcX1B9dcmqM33gCKBNeDwH+D8gB/hBTTlLNrP6wAXA+e5+KvAy0Bs438wOr0mBHxwBFLv7a+5+P3APyf0hZ5lZmeODZKCjSAYL/Ku730oyWmwPoH/4Ol4jjq8gm+qSLccXVFNdsib03f0LYBJwjpn1Ck0iLwJvAP+ezrJV0l6gEfBvAOFN+SpwAkn416g2fnd/E9hiZj8N00Ukd2G3JKlTTfE3kgEABwO4+zxgFvA9oF0N+zDOmrpk0fFVbXWpMeGRoheAp4Afmtkp7r7H3f8ANAM6pbdo5bNEbXffCdwGnGJmXcPih4D1JN8AStr4M5WZnWpmw8zsh2HWfcCxZjYCwN1fA14C/jM0y2UkMys0s9PN7HR3/yfJ8XWymfWEkrB8Fvhppn8QZ1ldsuL4gvTUJaNf3Mpy913AA8CbwNVmNsbMRpF8nf0grYUrh5kNIbmodpeZFQKvkLTlDTazbp74LdAk0y9SmVkf4EHgW8AVZjYJeBtYDZxoZj8Pq+4EtgMZ2ZRgZv1I6tEPuMnMfkPyhnRgiJmdG1bdDOwI8zNSltUlK44vSF9dsuZCbmlhMLdC4EfALuDWTL2oY2adSC7UXkkyBvZ/AtcCW4FeJF/tFgC7gWuAXu6+OT2lLV9oC74Z+MDdbzGzXJJ2yTXA74Fvk7wmDYBjSK5bZNzrErox3g0scPcZ4TrLM8BzwASSC239SOrREhjh7m+kqbjlyrK6ZMXxBWmui7tn7R/JoG610l2OCsp4BvDnUtMDgbkkvyh2FDCY5IL0g0CXdJc3hfqMAO4AjgrT9Ujai28ptU4boHG6y7qfslupx5cBY4HcMH04ybWVm0sdW92Bo9Nd7myvS7YcX5lSl7RXPPa/EOz3kfyCWK0wbyCwFOgZpusCh6W7rOXUoWUo4zdIvq08AHwX+EZYXg9YCAxNd1krei1KPT6FpPvc8aXmHUFyEbRnussaWV2y4vjKlLpk3C9nxcDMTgJygc/cvcjM1gDDgY/MbK27zzWz7wDnmtnL7v55OstbHjMbRPI19e8kX0WvJPlW8rNksb3l7h+Y2bMk90xkJDM7E/iVmS0huf4zkaTb733hutB77v6pmS0jw6+FZVldsuL4gsypi0K/mpnZAGAKMB842sxWufuVZnYHcDnJm/MFkq6bdT18/Gea0CbZgqRd+CfAcmAUSbNBD2AaMDKsuw74AXBXWgpbATP7N5LX5D+APUAfkia2s0guak4CXjGzvSQ3Mk1IU1ErlC11yabjC8DMmpMEftrrotCvRuGi2ijgBnefackQEU+Z2Z3ufomZXQv8yMx+RfI18AfpLG953N3NbD1Jd7KVwMfu/hsz201yJtMDeB04kaS7bF93/0faCly+TcBT7v58CJsXSS6cPwqcCSwm6SddAAxy93fSVtKKbQTm1/S6hJOdtWb2EvAPavDxZWbfIHldXiAD6pKVvXcymZldBax395ml5v0d+Ju7jzWzPKA9sNoz9Jb40PSUB7wLTAUWuvtvSi2/muQC1KUZ3jSVDzQBPgRmArPcfWJYVgsYD+xy9/8N8zJ2CAwz+3egFUkb8QLgCXefEJbVtLqcBXwH+B3J67LY3f+n1PIacXxBSXfsfiRNbBNI6nJTqeXVX5d0X9iI4Q84rtTjkcAS4Ful5jUBHiG5GzLt5a2gLvvOFv9K8qYcTNLN7OpS67Qi+ak3S1c5U6jHgFCPx0gG5zuN5OL5T0qtcwYwLd1lraAetUh64ywl6eN9NkkXv7eAn9WkuoRy9iO5i/6MUsfS+8BVNen4CuXsDawoVZdvAe8BV6azLmreOcTCRbVZZvaYu49w9/vN7Hjgb2ZW6O7vu/tGM/snyZs3Y5nZycBvgR+4++tmNp2kq9/JwMuh+eohkmEvupIMJ/FJmopbJjM7FbgVGOnur5rZ48A24IfAH8OZ8W0k4XmcmTVw923pKm95PLk7e7uZ3UvShj+M5FvYacDfzWy3u99ODahLOL5mAmeF16UJUEzyQfaEmX1B0n35ZDL4+CqlG3CXu88zs2+RvL+vAaaa2S6SO6B7Us11UegfQuFGmJ8AV5Dc8v6gu5/n7tcmza08bmZTSc70OwIb0lbY1N3s/7pJ5FfA7919fQjSa0h6JJwEjHb3TH1DfgT8KATL0SRvzmtJvoHNAs4jaWLrBQzL1JD8it0kZ5IzgEtILoK+BQw3s+4kH86ZXpdNwBfAMWbWGPgjSb2WklzY7EbSFFIAXJjBx9c+u4HDwuN9Q6m8Q/K69CMZSfNkqrkuatM/xMysGfApSRfNO4Av3P28sGwosC90Jrv7krQVNAXhTL6+J939apOcPT4ODPSkq9mxwLqwztZ0ljVV4aK5ufuNZnYxyYfvbcBa4HB335jWAqYo9No5190nhNv3JwA3uvv14Q71I2pCXcId6nNIwvJ6kg+xi0kucE5w97VmllcDAh8z6wDMJrlIO8/d7zGz44ALgZfd/dF01CWj++hmA3df7+7bwxvuR8BhZvZgWPwPYK67X5zpgQ/gyQB2+36XwIAtwOYQ+COBXwI5NSXwAdz9Jne/MTy+CziOJCB31YSQLGUncLyZXQL8mOSHhLqb2Y/d/Z81pS6ejDR5JknA3+nue919OsmF3aZhtS3pKl9luPtbwC9Ivvm2DvP+AXwTaBhW21Ld5VLzTjVy901m9iPgt2b2Nsnt76emt1QHxt13k7QlrzWz/yX5ujrak1FCa4Sv9mCx5MdrmpJ8W6lRQhPbWpJmqsvc/XFLBvRaleaiVZq7LwOW7ZsOr0sTwutS+jWrAZ4k6Tn1azN7L8zrRPIjSWmpi5p30sDM/gu4CvhuOBuocUIf8BySG01ySPoWr0xvqQ6MJb9HOpLkesTwmvCta3/MrCXwTXdfGKZreYYPw12ecIxdSHK2fK67L01zkQ6YJcOkf59kCIbfp/N9r9CvZqEf/izg5+6+ON3lOVhmNhp4rYa/IXNIxj95x93fTnd5DlYm98GvjBD6vYEP3X1FusuTLRT6aWBmuZ6M/V/jZUvAiMRCoS8iEhH13hERiYhCX0QkIgp9EZGIKPRFRCKi0BcRiYhCX0QkIv8fXZ8FSazCAocAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0000 loss_train: 1.7742 loss_val: 1.7299\n",
      "Epoch: 0020 loss_train: 0.3806 loss_val: 0.2448\n",
      "Epoch: 0040 loss_train: 0.2531 loss_val: 0.1855\n",
      "Epoch: 0060 loss_train: 0.2132 loss_val: 0.1702\n",
      "Epoch: 0080 loss_train: 0.1855 loss_val: 0.1643\n",
      "Epoch: 0100 loss_train: 0.1620 loss_val: 0.1546\n",
      "Epoch: 0120 loss_train: 0.1498 loss_val: 0.1482\n",
      "Epoch: 0140 loss_train: 0.1380 loss_val: 0.1497\n",
      "Epoch: 0160 loss_train: 0.1273 loss_val: 0.1432\n",
      "Epoch: 0180 loss_train: 0.1252 loss_val: 0.1442\n",
      "Epoch: 0200 loss_train: 0.1146 loss_val: 0.1453\n",
      "Epoch: 0220 loss_train: 0.1098 loss_val: 0.1455\n",
      "Epoch: 0240 loss_train: 0.1039 loss_val: 0.1347\n",
      "Epoch: 0260 loss_train: 0.0999 loss_val: 0.1300\n",
      "Epoch: 0280 loss_train: 0.0973 loss_val: 0.1410\n",
      "Epoch: 0300 loss_train: 0.0963 loss_val: 0.1368\n",
      "Epoch: 0320 loss_train: 0.0855 loss_val: 0.1275\n",
      "Epoch: 0340 loss_train: 0.0854 loss_val: 0.1405\n",
      "Epoch: 0360 loss_train: 0.0808 loss_val: 0.1371\n",
      "Epoch: 0380 loss_train: 0.0808 loss_val: 0.1442\n",
      "Epoch: 0400 loss_train: 0.0795 loss_val: 0.1412\n",
      "Epoch: 0420 loss_train: 0.0766 loss_val: 0.1466\n",
      "Epoch: 0440 loss_train: 0.0711 loss_val: 0.1537\n",
      "Epoch: 0460 loss_train: 0.0705 loss_val: 0.1518\n",
      "Epoch: 0480 loss_train: 0.0706 loss_val: 0.1419\n",
      "Epoch: 0500 loss_train: 0.0743 loss_val: 0.1371\n",
      "Epoch: 0520 loss_train: 0.0672 loss_val: 0.1487\n",
      "Epoch: 0540 loss_train: 0.0697 loss_val: 0.1699\n",
      "Epoch: 0560 loss_train: 0.0719 loss_val: 0.1520\n",
      "Epoch: 0580 loss_train: 0.0630 loss_val: 0.1419\n",
      "Epoch: 0600 loss_train: 0.0640 loss_val: 0.1725\n",
      "Epoch: 0620 loss_train: 0.0638 loss_val: 0.1645\n",
      "Epoch: 0640 loss_train: 0.0675 loss_val: 0.1432\n",
      "Epoch: 0660 loss_train: 0.0643 loss_val: 0.1671\n",
      "Epoch: 0680 loss_train: 0.0669 loss_val: 0.1693\n",
      "Epoch: 0700 loss_train: 0.0592 loss_val: 0.1693\n",
      "Epoch: 0720 loss_train: 0.0574 loss_val: 0.1574\n",
      "Epoch: 0740 loss_train: 0.0578 loss_val: 0.1710\n",
      "Epoch: 0760 loss_train: 0.0579 loss_val: 0.1749\n",
      "Epoch: 0780 loss_train: 0.0563 loss_val: 0.1457\n",
      "Epoch: 0800 loss_train: 0.0613 loss_val: 0.1666\n",
      "Epoch: 0820 loss_train: 0.0548 loss_val: 0.1659\n",
      "Epoch: 0840 loss_train: 0.0548 loss_val: 0.1573\n",
      "Epoch: 0860 loss_train: 0.0521 loss_val: 0.1847\n",
      "Epoch: 0880 loss_train: 0.0486 loss_val: 0.1697\n",
      "Epoch: 0900 loss_train: 0.0564 loss_val: 0.1567\n",
      "Epoch: 0920 loss_train: 0.0571 loss_val: 0.1858\n",
      "Epoch: 0940 loss_train: 0.0522 loss_val: 0.1693\n",
      "Epoch: 0960 loss_train: 0.0515 loss_val: 0.1740\n",
      "Epoch: 0980 loss_train: 0.0489 loss_val: 0.1725\n",
      "Epoch: 1000 loss_train: 0.0522 loss_val: 0.1748\n",
      "Epoch: 1020 loss_train: 0.0450 loss_val: 0.1816\n",
      "Epoch: 1040 loss_train: 0.0562 loss_val: 0.1667\n",
      "Epoch: 1060 loss_train: 0.0531 loss_val: 0.1919\n",
      "Epoch: 1080 loss_train: 0.0509 loss_val: 0.1791\n",
      "Epoch: 1100 loss_train: 0.0534 loss_val: 0.1979\n",
      "Epoch: 1120 loss_train: 0.0458 loss_val: 0.1827\n",
      "Epoch: 1140 loss_train: 0.0445 loss_val: 0.1809\n",
      "Epoch: 1160 loss_train: 0.0409 loss_val: 0.1779\n",
      "Epoch: 1180 loss_train: 0.0453 loss_val: 0.1813\n",
      "Epoch: 1200 loss_train: 0.0499 loss_val: 0.1798\n",
      "Epoch: 1220 loss_train: 0.0423 loss_val: 0.1831\n",
      "Epoch: 1240 loss_train: 0.0475 loss_val: 0.2018\n",
      "Epoch: 1260 loss_train: 0.0445 loss_val: 0.1723\n",
      "Epoch: 1280 loss_train: 0.0505 loss_val: 0.2007\n",
      "Epoch: 1300 loss_train: 0.0456 loss_val: 0.1827\n",
      "Epoch: 1320 loss_train: 0.0448 loss_val: 0.1861\n",
      "Epoch: 1340 loss_train: 0.0417 loss_val: 0.1824\n",
      "Epoch: 1360 loss_train: 0.0442 loss_val: 0.1929\n",
      "Epoch: 1380 loss_train: 0.0480 loss_val: 0.1784\n",
      "Epoch: 1400 loss_train: 0.0460 loss_val: 0.1922\n",
      "Epoch: 1420 loss_train: 0.0446 loss_val: 0.2021\n",
      "Epoch: 1440 loss_train: 0.0443 loss_val: 0.2109\n",
      "Epoch: 1460 loss_train: 0.0485 loss_val: 0.2040\n",
      "Epoch: 1480 loss_train: 0.0470 loss_val: 0.1926\n",
      "Epoch: 1500 loss_train: 0.0405 loss_val: 0.2008\n",
      "Epoch: 1520 loss_train: 0.0426 loss_val: 0.2144\n",
      "Epoch: 1540 loss_train: 0.0437 loss_val: 0.2005\n",
      "Epoch: 1560 loss_train: 0.0418 loss_val: 0.2030\n",
      "Epoch: 1580 loss_train: 0.0424 loss_val: 0.2020\n",
      "Epoch: 1600 loss_train: 0.0526 loss_val: 0.1797\n",
      "Epoch: 1620 loss_train: 0.0468 loss_val: 0.1797\n",
      "Epoch: 1640 loss_train: 0.0393 loss_val: 0.2004\n",
      "Epoch: 1660 loss_train: 0.0478 loss_val: 0.1921\n",
      "Epoch: 1680 loss_train: 0.0400 loss_val: 0.2103\n",
      "Epoch: 1700 loss_train: 0.0423 loss_val: 0.1915\n",
      "Epoch: 1720 loss_train: 0.0392 loss_val: 0.1937\n",
      "Epoch: 1740 loss_train: 0.0388 loss_val: 0.2197\n",
      "Epoch: 1760 loss_train: 0.0397 loss_val: 0.2039\n",
      "Epoch: 1780 loss_train: 0.0423 loss_val: 0.2220\n",
      "Epoch: 1800 loss_train: 0.0410 loss_val: 0.2330\n",
      "Epoch: 1820 loss_train: 0.0405 loss_val: 0.2129\n",
      "Epoch: 1840 loss_train: 0.0370 loss_val: 0.2091\n",
      "Epoch: 1860 loss_train: 0.0401 loss_val: 0.2274\n",
      "Epoch: 1880 loss_train: 0.0367 loss_val: 0.2009\n",
      "Epoch: 1900 loss_train: 0.0425 loss_val: 0.1949\n",
      "Epoch: 1920 loss_train: 0.0442 loss_val: 0.2065\n",
      "Epoch: 1940 loss_train: 0.0375 loss_val: 0.2395\n",
      "Epoch: 1960 loss_train: 0.0448 loss_val: 0.1995\n",
      "Epoch: 1980 loss_train: 0.0409 loss_val: 0.2262\n",
      "Epoch: 2000 loss_train: 0.0412 loss_val: 0.2010\n",
      "Epoch: 2020 loss_train: 0.0385 loss_val: 0.1967\n",
      "Epoch: 2040 loss_train: 0.0405 loss_val: 0.2278\n",
      "Epoch: 2060 loss_train: 0.0392 loss_val: 0.2293\n",
      "Epoch: 2080 loss_train: 0.0383 loss_val: 0.2220\n",
      "Epoch: 2100 loss_train: 0.0370 loss_val: 0.1981\n",
      "Epoch: 2120 loss_train: 0.0387 loss_val: 0.2369\n",
      "Epoch: 2140 loss_train: 0.0384 loss_val: 0.2141\n",
      "Epoch: 2160 loss_train: 0.0382 loss_val: 0.2151\n",
      "Epoch: 2180 loss_train: 0.0339 loss_val: 0.2303\n",
      "Epoch: 2200 loss_train: 0.0440 loss_val: 0.2051\n",
      "Epoch: 2220 loss_train: 0.0389 loss_val: 0.2169\n",
      "Epoch: 2240 loss_train: 0.0380 loss_val: 0.2279\n",
      "Epoch: 2260 loss_train: 0.0384 loss_val: 0.2459\n",
      "Epoch: 2280 loss_train: 0.0404 loss_val: 0.2168\n",
      "Epoch: 2300 loss_train: 0.0411 loss_val: 0.2281\n",
      "Epoch: 2320 loss_train: 0.0357 loss_val: 0.2132\n",
      "Epoch: 2340 loss_train: 0.0372 loss_val: 0.2417\n",
      "Epoch: 2360 loss_train: 0.0395 loss_val: 0.2389\n",
      "Epoch: 2380 loss_train: 0.0374 loss_val: 0.2320\n",
      "Epoch: 2400 loss_train: 0.0423 loss_val: 0.2299\n",
      "Epoch: 2420 loss_train: 0.0385 loss_val: 0.2263\n",
      "Epoch: 2440 loss_train: 0.0419 loss_val: 0.2069\n",
      "Epoch: 2460 loss_train: 0.0468 loss_val: 0.2137\n",
      "Epoch: 2480 loss_train: 0.0351 loss_val: 0.2397\n",
      "Epoch: 2500 loss_train: 0.0335 loss_val: 0.2030\n",
      "Epoch: 2520 loss_train: 0.0375 loss_val: 0.2057\n",
      "Epoch: 2540 loss_train: 0.0394 loss_val: 0.2410\n",
      "Epoch: 2560 loss_train: 0.0351 loss_val: 0.2436\n",
      "Epoch: 2580 loss_train: 0.0403 loss_val: 0.2203\n",
      "Epoch: 2600 loss_train: 0.0391 loss_val: 0.2122\n",
      "Epoch: 2620 loss_train: 0.0376 loss_val: 0.2189\n",
      "Epoch: 2640 loss_train: 0.0373 loss_val: 0.2290\n",
      "Epoch: 2660 loss_train: 0.0340 loss_val: 0.2236\n",
      "Epoch: 2680 loss_train: 0.0323 loss_val: 0.2166\n",
      "Epoch: 2700 loss_train: 0.0375 loss_val: 0.2402\n",
      "Epoch: 2720 loss_train: 0.0326 loss_val: 0.2240\n",
      "Epoch: 2740 loss_train: 0.0331 loss_val: 0.2473\n",
      "Epoch: 2760 loss_train: 0.0330 loss_val: 0.2096\n",
      "Epoch: 2780 loss_train: 0.0336 loss_val: 0.2435\n",
      "Epoch: 2800 loss_train: 0.0332 loss_val: 0.2163\n",
      "Epoch: 2820 loss_train: 0.0317 loss_val: 0.2429\n",
      "Epoch: 2840 loss_train: 0.0359 loss_val: 0.2598\n",
      "Epoch: 2860 loss_train: 0.0353 loss_val: 0.2338\n",
      "Epoch: 2880 loss_train: 0.0330 loss_val: 0.2435\n",
      "Epoch: 2900 loss_train: 0.0340 loss_val: 0.2560\n",
      "Epoch: 2920 loss_train: 0.0328 loss_val: 0.2501\n",
      "Epoch: 2940 loss_train: 0.0332 loss_val: 0.2410\n",
      "Epoch: 2960 loss_train: 0.0295 loss_val: 0.2404\n",
      "Epoch: 2980 loss_train: 0.0334 loss_val: 0.2252\n",
      "Epoch: 3000 loss_train: 0.0301 loss_val: 0.2493\n",
      "Epoch: 3020 loss_train: 0.0365 loss_val: 0.2510\n",
      "Epoch: 3040 loss_train: 0.0379 loss_val: 0.2498\n",
      "Epoch: 3060 loss_train: 0.0343 loss_val: 0.2087\n",
      "Epoch: 3080 loss_train: 0.0335 loss_val: 0.2435\n",
      "Epoch: 3100 loss_train: 0.0333 loss_val: 0.2112\n",
      "Epoch: 3120 loss_train: 0.0337 loss_val: 0.2170\n",
      "Epoch: 3140 loss_train: 0.0286 loss_val: 0.2411\n",
      "Epoch: 3160 loss_train: 0.0373 loss_val: 0.2278\n",
      "Epoch: 3180 loss_train: 0.0306 loss_val: 0.2574\n",
      "Epoch: 3200 loss_train: 0.0343 loss_val: 0.2416\n",
      "Epoch: 3220 loss_train: 0.0348 loss_val: 0.2310\n",
      "Epoch: 3240 loss_train: 0.0335 loss_val: 0.2268\n",
      "Epoch: 3260 loss_train: 0.0360 loss_val: 0.2303\n",
      "Epoch: 3280 loss_train: 0.0398 loss_val: 0.2202\n",
      "Epoch: 3300 loss_train: 0.0321 loss_val: 0.2106\n",
      "Epoch: 3320 loss_train: 0.0348 loss_val: 0.2393\n",
      "Epoch: 3340 loss_train: 0.0336 loss_val: 0.2221\n",
      "Epoch: 3360 loss_train: 0.0318 loss_val: 0.2324\n",
      "Epoch: 3380 loss_train: 0.0336 loss_val: 0.2736\n",
      "Epoch: 3400 loss_train: 0.0339 loss_val: 0.2456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3420 loss_train: 0.0290 loss_val: 0.2407\n",
      "Epoch: 3440 loss_train: 0.0316 loss_val: 0.2205\n",
      "Epoch: 3460 loss_train: 0.0349 loss_val: 0.2237\n",
      "Epoch: 3480 loss_train: 0.0317 loss_val: 0.2168\n",
      "Epoch: 3500 loss_train: 0.0373 loss_val: 0.2417\n",
      "Epoch: 3520 loss_train: 0.0311 loss_val: 0.2309\n",
      "Epoch: 3540 loss_train: 0.0333 loss_val: 0.2304\n",
      "Epoch: 3560 loss_train: 0.0368 loss_val: 0.2366\n",
      "Epoch: 3580 loss_train: 0.0293 loss_val: 0.2284\n",
      "Epoch: 3600 loss_train: 0.0318 loss_val: 0.2578\n",
      "Epoch: 3620 loss_train: 0.0311 loss_val: 0.2122\n",
      "Epoch: 3640 loss_train: 0.0337 loss_val: 0.2399\n",
      "Epoch: 3660 loss_train: 0.0423 loss_val: 0.2365\n",
      "Epoch: 3680 loss_train: 0.0337 loss_val: 0.2158\n",
      "Epoch: 3700 loss_train: 0.0319 loss_val: 0.2162\n",
      "Epoch: 3720 loss_train: 0.0299 loss_val: 0.2443\n",
      "Epoch: 3740 loss_train: 0.0316 loss_val: 0.2463\n",
      "Epoch: 3760 loss_train: 0.0288 loss_val: 0.2691\n",
      "Epoch: 3780 loss_train: 0.0335 loss_val: 0.2441\n",
      "Epoch: 3800 loss_train: 0.0318 loss_val: 0.2380\n",
      "Epoch: 3820 loss_train: 0.0307 loss_val: 0.2426\n",
      "Epoch: 3840 loss_train: 0.0298 loss_val: 0.2189\n",
      "Epoch: 3860 loss_train: 0.0331 loss_val: 0.2191\n",
      "Epoch: 3880 loss_train: 0.0297 loss_val: 0.2269\n",
      "Epoch: 3900 loss_train: 0.0300 loss_val: 0.2481\n",
      "Epoch: 3920 loss_train: 0.0283 loss_val: 0.2252\n",
      "Epoch: 3940 loss_train: 0.0325 loss_val: 0.2618\n",
      "Epoch: 3960 loss_train: 0.0434 loss_val: 0.2351\n",
      "Epoch: 3980 loss_train: 0.0341 loss_val: 0.2764\n",
      "Epoch: 4000 loss_train: 0.0323 loss_val: 0.2376\n",
      "Epoch: 4020 loss_train: 0.0259 loss_val: 0.2357\n",
      "Epoch: 4040 loss_train: 0.0327 loss_val: 0.2436\n",
      "Epoch: 4060 loss_train: 0.0340 loss_val: 0.2546\n",
      "Epoch: 4080 loss_train: 0.0300 loss_val: 0.2285\n",
      "Epoch: 4100 loss_train: 0.0279 loss_val: 0.2364\n",
      "Epoch: 4120 loss_train: 0.0309 loss_val: 0.2203\n",
      "Epoch: 4140 loss_train: 0.0277 loss_val: 0.2302\n",
      "Epoch: 4160 loss_train: 0.0283 loss_val: 0.2207\n",
      "Epoch: 4180 loss_train: 0.0278 loss_val: 0.2305\n",
      "Epoch: 4200 loss_train: 0.0279 loss_val: 0.2401\n",
      "Epoch: 4220 loss_train: 0.0297 loss_val: 0.2053\n",
      "Epoch: 4240 loss_train: 0.0281 loss_val: 0.2343\n",
      "Epoch: 4260 loss_train: 0.0298 loss_val: 0.2386\n",
      "Epoch: 4280 loss_train: 0.0285 loss_val: 0.2333\n",
      "Epoch: 4300 loss_train: 0.0295 loss_val: 0.2561\n",
      "Epoch: 4320 loss_train: 0.0324 loss_val: 0.2354\n",
      "Epoch: 4340 loss_train: 0.0272 loss_val: 0.2435\n",
      "Epoch: 4360 loss_train: 0.0343 loss_val: 0.2422\n",
      "Epoch: 4380 loss_train: 0.0337 loss_val: 0.2278\n",
      "Epoch: 4400 loss_train: 0.0328 loss_val: 0.2363\n",
      "Epoch: 4420 loss_train: 0.0317 loss_val: 0.2335\n",
      "Epoch: 4440 loss_train: 0.0291 loss_val: 0.2228\n",
      "Epoch: 4460 loss_train: 0.0291 loss_val: 0.2555\n",
      "Epoch: 4480 loss_train: 0.0289 loss_val: 0.2134\n",
      "Epoch: 4500 loss_train: 0.0280 loss_val: 0.2404\n",
      "Epoch: 4520 loss_train: 0.0236 loss_val: 0.2275\n",
      "Epoch: 4540 loss_train: 0.0280 loss_val: 0.2443\n",
      "Epoch: 4560 loss_train: 0.0286 loss_val: 0.2223\n",
      "Epoch: 4580 loss_train: 0.0247 loss_val: 0.2384\n",
      "Epoch: 4600 loss_train: 0.0253 loss_val: 0.2483\n",
      "Epoch: 4620 loss_train: 0.0334 loss_val: 0.2223\n",
      "Epoch: 4640 loss_train: 0.0301 loss_val: 0.2547\n",
      "Epoch: 4660 loss_train: 0.0287 loss_val: 0.2136\n",
      "Epoch: 4680 loss_train: 0.0307 loss_val: 0.2097\n",
      "Epoch: 4700 loss_train: 0.0302 loss_val: 0.2215\n",
      "Epoch: 4720 loss_train: 0.0311 loss_val: 0.2525\n",
      "Epoch: 4740 loss_train: 0.0255 loss_val: 0.2412\n",
      "Epoch: 4760 loss_train: 0.0258 loss_val: 0.2663\n",
      "Epoch: 4780 loss_train: 0.0317 loss_val: 0.2254\n",
      "Epoch: 4800 loss_train: 0.0313 loss_val: 0.2357\n",
      "Epoch: 4820 loss_train: 0.0274 loss_val: 0.2744\n",
      "Epoch: 4840 loss_train: 0.0283 loss_val: 0.2088\n",
      "Epoch: 4860 loss_train: 0.0299 loss_val: 0.2309\n",
      "Epoch: 4880 loss_train: 0.0298 loss_val: 0.2485\n",
      "Epoch: 4900 loss_train: 0.0285 loss_val: 0.2172\n",
      "Epoch: 4920 loss_train: 0.0315 loss_val: 0.2161\n",
      "Epoch: 4940 loss_train: 0.0282 loss_val: 0.2301\n",
      "Epoch: 4960 loss_train: 0.0299 loss_val: 0.2299\n",
      "Epoch: 4980 loss_train: 0.0296 loss_val: 0.2371\n",
      "Epoch: 5000 loss_train: 0.0289 loss_val: 0.2235\n",
      "Epoch: 5020 loss_train: 0.0285 loss_val: 0.2355\n",
      "Epoch: 5040 loss_train: 0.0297 loss_val: 0.2536\n",
      "Epoch: 5060 loss_train: 0.0308 loss_val: 0.2410\n",
      "Epoch: 5080 loss_train: 0.0302 loss_val: 0.2509\n",
      "Epoch: 5100 loss_train: 0.0300 loss_val: 0.2385\n",
      "Epoch: 5120 loss_train: 0.0334 loss_val: 0.2433\n",
      "Epoch: 5140 loss_train: 0.0305 loss_val: 0.2251\n",
      "Epoch: 5160 loss_train: 0.0281 loss_val: 0.2297\n",
      "Epoch: 5180 loss_train: 0.0264 loss_val: 0.2401\n",
      "Epoch: 5200 loss_train: 0.0360 loss_val: 0.2293\n",
      "Epoch: 5220 loss_train: 0.0275 loss_val: 0.2141\n",
      "Epoch: 5240 loss_train: 0.0272 loss_val: 0.2327\n",
      "Epoch: 5260 loss_train: 0.0270 loss_val: 0.2361\n",
      "Epoch: 5280 loss_train: 0.0294 loss_val: 0.2529\n",
      "Epoch: 5300 loss_train: 0.0280 loss_val: 0.2435\n",
      "Epoch: 5320 loss_train: 0.0274 loss_val: 0.2579\n",
      "Epoch: 5340 loss_train: 0.0276 loss_val: 0.2488\n",
      "Epoch: 5360 loss_train: 0.0276 loss_val: 0.2363\n",
      "Epoch: 5380 loss_train: 0.0205 loss_val: 0.2225\n",
      "Epoch: 5400 loss_train: 0.0256 loss_val: 0.2323\n",
      "Epoch: 5420 loss_train: 0.0287 loss_val: 0.2434\n",
      "Epoch: 5440 loss_train: 0.0243 loss_val: 0.2450\n",
      "Epoch: 5460 loss_train: 0.0241 loss_val: 0.2401\n",
      "Epoch: 5480 loss_train: 0.0294 loss_val: 0.2578\n",
      "Epoch: 5500 loss_train: 0.0336 loss_val: 0.2380\n",
      "Epoch: 5520 loss_train: 0.0359 loss_val: 0.2384\n",
      "Epoch: 5540 loss_train: 0.0304 loss_val: 0.2685\n",
      "Epoch: 5560 loss_train: 0.0278 loss_val: 0.2414\n",
      "Epoch: 5580 loss_train: 0.0274 loss_val: 0.2496\n",
      "Epoch: 5600 loss_train: 0.0270 loss_val: 0.2372\n",
      "Epoch: 5620 loss_train: 0.0249 loss_val: 0.2564\n",
      "Epoch: 5640 loss_train: 0.0261 loss_val: 0.2095\n",
      "Epoch: 5660 loss_train: 0.0271 loss_val: 0.2524\n",
      "Epoch: 5680 loss_train: 0.0291 loss_val: 0.2317\n",
      "Epoch: 5700 loss_train: 0.0284 loss_val: 0.2221\n",
      "Epoch: 5720 loss_train: 0.0254 loss_val: 0.2392\n",
      "Epoch: 5740 loss_train: 0.0296 loss_val: 0.2392\n",
      "Epoch: 5760 loss_train: 0.0288 loss_val: 0.2663\n",
      "Epoch: 5780 loss_train: 0.0278 loss_val: 0.2414\n",
      "Epoch: 5800 loss_train: 0.0247 loss_val: 0.2375\n",
      "Epoch: 5820 loss_train: 0.0255 loss_val: 0.2319\n",
      "Epoch: 5840 loss_train: 0.0237 loss_val: 0.2247\n",
      "Epoch: 5860 loss_train: 0.0309 loss_val: 0.2442\n",
      "Epoch: 5880 loss_train: 0.0277 loss_val: 0.2059\n",
      "Epoch: 5900 loss_train: 0.0295 loss_val: 0.2138\n",
      "Epoch: 5920 loss_train: 0.0243 loss_val: 0.2600\n",
      "Epoch: 5940 loss_train: 0.0234 loss_val: 0.2402\n",
      "Epoch: 5960 loss_train: 0.0254 loss_val: 0.2302\n",
      "Epoch: 5980 loss_train: 0.0236 loss_val: 0.2321\n",
      " total time: 289.3500s\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEHCAYAAABCwJb2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAeA0lEQVR4nO3deZhU1Z3/8fcXaOmALC0QlSVCJqjQ7LTYpgcBUWRREBfASARHJRozxjHhJyYq0dEZTHiQYBQfFA2ikTBEoo4Y3DBo4tagIiAGjBgaXFgEQcAIfH9/3NM9LdIbNF3VdT6v5+mHuufeqjqHuvWpW+eee8rcHRERiUOdVFdARERqjkJfRCQiCn0RkYgo9EVEIqLQFxGJiEJfRCQi9VJdgfI0b97c27Ztm+pqiIjUKkuWLNnk7i0OtC6tQ79t27YUFhamuhoiIrWKmX1Q1jp174iIREShLyISEYW+iEhE0rpPX0Rq3pdffklRURG7d+9OdVWkAtnZ2bRu3ZqsrKxK30ehLyJfUVRURKNGjWjbti1mlurqSBncnc2bN1NUVES7du0qfT9174jIV+zevZtmzZop8NOcmdGsWbMqfyNT6IvI1yjwa4eDeZ0U+iKSVrZu3crdd999UPcdPHgwW7duLXebm266iWefffagHn9/bdu2ZdOmTdXyWDVFoS8iaaW80N+zZ0+5912wYAFNmzYtd5tbbrmF008//WCrV+sp9EUkrUyYMIH33nuPbt26MX78eF544QV69+7N0KFD6dixIwDnnHMOPXv2JDc3lxkzZpTct/jIe+3atXTo0IHLL7+c3NxcBgwYwK5duwAYO3Ys8+bNK9l+4sSJ9OjRg86dO7Nq1SoANm7cyBlnnEFubi6XXXYZxx13XIVH9FOmTKFTp0506tSJqVOnAvD5558zZMgQunbtSqdOnfj9739f0saOHTvSpUsXfvrTn1br/19FNHpHRMp08xMrWLnhs2p9zI4tGzPx7Nwy10+aNInly5fz5ptvAvDCCy+wdOlSli9fXjJK5f777+eoo45i165dnHTSSZx33nk0a9bsK4+zevVqHnnkEe69915GjBjBH/7wB0aPHv2152vevDlLly7l7rvvZvLkydx3333cfPPNnHbaaVx//fX86U9/YubMmeW2acmSJTzwwAO8+uqruDsnn3wyffr04e9//zstW7bkySefBGDbtm1s3ryZ+fPns2rVKsyswu6o6qYjfRFJe7169frKsMRp06bRtWtX8vPzWbduHatXr/7afdq1a0e3bt0A6NmzJ2vXrj3gY5977rlf2+all15i1KhRAAwcOJCcnJxy6/fSSy8xfPhwGjZsyJFHHsm5557Liy++SOfOnXnmmWe47rrrePHFF2nSpAlNmjQhOzubSy+9lEcffZQGDRpU8X/j0OhIX0TKVN4ReU1q2LBhye0XXniBZ599lpdffpkGDRrQt2/fAw5brF+/fsntunXrlnTvlLVd3bp1KzxnUFXHH388S5cuZcGCBdxwww3079+fm266iddee43nnnuOefPm8Zvf/Ibnn3++Wp+3PDrSF5G00qhRI7Zv317m+m3btpGTk0ODBg1YtWoVr7zySrXXoaCggLlz5wLw9NNP8+mnn5a7fe/evfnjH//Izp07+fzzz5k/fz69e/dmw4YNNGjQgNGjRzN+/HiWLl3Kjh072LZtG4MHD+aOO+7grbfeqvb6l0dH+iKSVpo1a0ZBQQGdOnVi0KBBDBky5CvrBw4cyD333EOHDh044YQTyM/Pr/Y6TJw4kQsvvJDZs2dzyimncMwxx9CoUaMyt+/Rowdjx46lV69eAFx22WV0796dhQsXMn78eOrUqUNWVhbTp09n+/btDBs2jN27d+PuTJkypdrrXx5z9xp9wqrIy8tzzacvUrPeeecdOnTokOpqpNQXX3xB3bp1qVevHi+//DJXXnllyYnldHOg18vMlrh73oG215G+iMh+/vGPfzBixAj27dvHEUccwb333pvqKlUbhb6IyH7at2/PG2+8kepqHBY6kSsiEhGFvohIRBT6IiIRUeiLiEREoS8itd6RRx4JwIYNGzj//PMPuE3fvn2paAj41KlT2blzZ8lyZaZqroxf/OIXTJ48+ZAfpzoo9EUkY7Rs2bJkBs2DsX/oV2aq5tpGoS8iaWXChAncddddJcvFR8k7duygf//+JdMgP/bYY1+779q1a+nUqRMAu3btYtSoUXTo0IHhw4d/Ze6dK6+8kry8PHJzc5k4cSKQTOK2YcMG+vXrR79+/YCv/kjKgaZOLm8K57K8+eab5Ofn06VLF4YPH14yxcO0adNKplsunuztz3/+M926daNbt25079693OkpKkvj9EWkbE9NgI/ert7HPKYzDJpU5uqRI0dyzTXXcNVVVwEwd+5cFi5cSHZ2NvPnz6dx48Zs2rSJ/Px8hg4dWuZPBk6fPp0GDRrwzjvvsGzZMnr06FGy7rbbbuOoo45i79699O/fn2XLlnH11VczZcoUFi1aRPPmzb/yWGVNnZyTk1PpKZyLXXzxxdx555306dOHm266iZtvvpmpU6cyadIk3n//ferXr1/SpTR58mTuuusuCgoK2LFjB9nZ2ZX9Xy6TjvRFJK10796dTz75hA0bNvDWW2+Rk5NDmzZtcHd+9rOf0aVLF04//XTWr1/Pxx9/XObjLF68uCR8u3TpQpcuXUrWzZ07lx49etC9e3dWrFjBypUry61TWVMnQ+WncIZksritW7fSp08fAMaMGcPixYtL6njRRRfx0EMPUa9ecjxeUFDAtddey7Rp09i6dWtJ+aHQkb6IlK2cI/LD6YILLmDevHl89NFHjBw5EoCHH36YjRs3smTJErKysmjbtu0Bp1SuyPvvv8/kyZN5/fXXycnJYezYsQf1OMUqO4VzRZ588kkWL17ME088wW233cbbb7/NhAkTGDJkCAsWLKCgoICFCxdy4oknHnRdQUf6IpKGRo4cyZw5c5g3bx4XXHABkBwlf/Ob3yQrK4tFixbxwQcflPsYp556Kr/73e8AWL58OcuWLQPgs88+o2HDhjRp0oSPP/6Yp556quQ+ZU3rXNbUyVXVpEkTcnJySr4lzJ49mz59+rBv3z7WrVtHv379uP3229m2bRs7duzgvffeo3Pnzlx33XWcdNJJJT/neCgqfaRvZnWBQmC9u59lZu2AOUAzYAnwfXf/p5nVBx4EegKbgZHuvjY8xvXApcBe4Gp3X3jILRCRjJObm8v27dtp1aoVxx57LAAXXXQRZ599Np07dyYvL6/CI94rr7ySSy65hA4dOtChQwd69uwJQNeuXenevTsnnngibdq0oaCgoOQ+48aNY+DAgbRs2ZJFixaVlJc1dXJ5XTllmTVrFldccQU7d+7k29/+Ng888AB79+5l9OjRbNu2DXfn6quvpmnTptx4440sWrSIOnXqkJuby6BBg6r8fPur9NTKZnYtkAc0DqE/F3jU3eeY2T3AW+4+3cx+CHRx9yvMbBQw3N1HmllH4BGgF9ASeBY43t33lvWcmlpZpOZpauXapapTK1eqe8fMWgNDgPvCsgGnAcUDYmcB54Tbw8IyYX3/sP0wYI67f+Hu7wNrSD4ARESkhlS2T38q8P+AfWG5GbDV3Yt/ULIIaBVutwLWAYT128L2JeUHuE8JMxtnZoVmVrhx48bKt0RERCpUYeib2VnAJ+6+pAbqg7vPcPc8d89r0aJFTTyliEg0KnMitwAYamaDgWygMfBroKmZ1QtH862B9WH79UAboMjM6gFNSE7oFpcXK30fEUkj7l7mRU+SPg7m524rPNJ39+vdvbW7twVGAc+7+0XAIqB4ZqMxQPE10Y+HZcL65z2p2ePAKDOrH0b+tAdeq3KNReSwys7OZvPmzQcVKFJz3J3NmzdX+SrdQ7k46zpgjpndCrwBzAzlM4HZZrYG2ELyQYG7rwgjflYCe4Cryhu5IyKp0bp1a4qKitA5tfSXnZ1N69atq3SfSg/ZTAUN2RQRqbpDHrIpIiKZQaEvIhIRhb6ISEQU+iIiEVHoi4hERKEvIhIRhb6ISEQU+iIiEVHoi4hERKEvIhIRhb6ISEQU+iIiEVHoi4hERKEvIhIRhb6ISEQU+iIiEVHoi4hERKEvIhIRhb6ISEQU+iIiEVHoi4hERKEvIhIRhb6ISEQU+iIiEVHoi4hERKEvIhIRhb6ISEQU+iIiEVHoi4hERKEvIhIRhb6ISEQU+iIiEVHoi4hERKEvIhIRhb6ISEQU+iIiEakw9M0s28xeM7O3zGyFmd0cytuZ2atmtsbMfm9mR4Ty+mF5TVjfttRjXR/K3zWzMw9bq0RE5IAqc6T/BXCau3cFugEDzSwfuB24w92/A3wKXBq2vxT4NJTfEbbDzDoCo4BcYCBwt5nVrca2iIhIBSoMfU/sCItZ4c+B04B5oXwWcE64PSwsE9b3NzML5XPc/Qt3fx9YA/SqjkaIiEjlVKpP38zqmtmbwCfAM8B7wFZ33xM2KQJahdutgHUAYf02oFnp8gPcR0REakClQt/d97p7N6A1ydH5iYerQmY2zswKzaxw48aNh+tpRESiVKXRO+6+FVgEnAI0NbN6YVVrYH24vR5oAxDWNwE2ly4/wH1KP8cMd89z97wWLVpUpXoiIlKByozeaWFmTcPtbwBnAO+QhP/5YbMxwGPh9uNhmbD+eXf3UD4qjO5pB7QHXqumdoiISCXUq3gTjgVmhZE2dYC57v6/ZrYSmGNmtwJvADPD9jOB2Wa2BthCMmIHd19hZnOBlcAe4Cp331u9zRERkfJYchCenvLy8rywsDDV1RARqVXMbIm75x1ona7IFRGJiEJfRCQiCn0RkYgo9EVEIqLQFxGJiEJfRCQiCn0RkYgo9EVEIqLQFxGJiEJfRCQiCn0RkYgo9EVEIqLQFxGJiEJfRCQiCn0RkYgo9EVEIqLQFxGJiEJfRCQiCn0RkYgo9EVEIqLQFxGJiEJfRCQiCn0RkYgo9EVEIqLQFxGJiEJfRCQiCn0RkYgo9EVEIqLQFxGJiEJfRCQiCn0RkYgo9EVEIqLQFxGJiEJfRCQiCn0RkYgo9EVEIqLQFxGJSIWhb2ZtzGyRma00sxVm9uNQfpSZPWNmq8O/OaHczGyama0xs2Vm1qPUY40J2682szGHr1kiInIglTnS3wP8xN07AvnAVWbWEZgAPOfu7YHnwjLAIKB9+BsHTIfkQwKYCJwM9AImFn9QiIhIzagw9N39Q3dfGm5vB94BWgHDgFlhs1nAOeH2MOBBT7wCNDWzY4EzgWfcfYu7fwo8AwyszsaIiEj5qtSnb2Ztge7Aq8DR7v5hWPURcHS43QpYV+puRaGsrPL9n2OcmRWaWeHGjRurUj0REalApUPfzI4E/gBc4+6flV7n7g54dVTI3We4e56757Vo0aI6HlJERIJKhb6ZZZEE/sPu/mgo/jh02xD+/SSUrwfalLp761BWVrmIiNSQyozeMWAm8I67Tym16nGgeATOGOCxUuUXh1E8+cC20A20EBhgZjnhBO6AUCYiIjWkXiW2KQC+D7xtZm+Gsp8Bk4C5ZnYp8AEwIqxbAAwG1gA7gUsA3H2Lmf0n8HrY7hZ331IdjRARkcqxpDs+PeXl5XlhYWGqqyEiUquY2RJ3zzvQOl2RKyISEYW+iEhEFPoiIhFR6IuIREShLyISEYW+iEhEFPoiIhFR6IuIREShLyISEYW+iEhEFPoiIhFR6IuIREShLyISEYW+iEhEFPoiIhFR6IuIREShLyISEYW+iEhEFPoiIhFR6IuIREShLyISEYW+iEhEFPoiIhFR6IuIREShLyISEYW+iEhEFPoiIhFR6IuIREShLyISEYW+iEhEFPoiIhFR6IuIREShLyISEYW+iEhEFPoiIhFR6IuIREShLyISkQpD38zuN7NPzGx5qbKjzOwZM1sd/s0J5WZm08xsjZktM7Mepe4zJmy/2szGHJ7miIhIeSpzpP9bYOB+ZROA59y9PfBcWAYYBLQPf+OA6ZB8SAATgZOBXsDE4g8KERGpORWGvrsvBrbsVzwMmBVuzwLOKVX+oCdeAZqa2bHAmcAz7r7F3T8FnuHrHyQiInKYHWyf/tHu/mG4/RFwdLjdClhXaruiUFZW+deY2TgzKzSzwo0bNx5k9URE5EAO+USuuzvg1VCX4seb4e557p7XokWL6npYERHh4EP/49BtQ/j3k1C+HmhTarvWoayschERqUEHG/qPA8UjcMYAj5UqvziM4skHtoVuoIXAADPLCSdwB4QyERGpQfUq2sDMHgH6As3NrIhkFM4kYK6ZXQp8AIwImy8ABgNrgJ3AJQDuvsXM/hN4PWx3i7vvf3JYREQOM0u65NNTXl6eFxYWproaIiK1ipktcfe8A63TFbkiIhFR6IuIREShLyISEYW+iEhEFPoiIhFR6IuIREShLyISEYW+iEhEFPoiIhFR6IuIREShLyISEYW+iEhEFPoiIhFR6IuIREShLyISEYW+iEhEFPoiIhFR6IuIREShLyISEYW+iEhEFPoiIhFR6IuIREShLyISEYW+iEhEFPoiIhFR6IuIREShLyISEYW+iEhEFPoiIhFR6IuIREShLyISEYW+iEhEFPoiIhFR6IuIREShLyISEYW+iEhEFPoiIhGp8dA3s4Fm9q6ZrTGzCTX9/CIiMavR0DezusBdwCCgI3ChmXWsyTqIiMSsXg0/Xy9gjbv/HcDM5gDDgJXV+SQfvPsGWXNG8CVH8KUdgZt6sdKCpboCopeg9th0dAH5l0+r9set6dBvBawrtVwEnFx6AzMbB4wLizvM7N1DeL7mwKZDuH+6yJR2gNqSjjKlHZBRbVnanHF3HmxbjitrRU2HfoXcfQYwozoey8wK3T2vOh4rlTKlHaC2pKNMaQeoLZVR0/0e64E2pZZbhzIREakBNR36rwPtzaydmR0BjAIer+E6iIhEq0a7d9x9j5n9CFgI1AXud/cVh/Epq6WbKA1kSjtAbUlHmdIOUFsqZO5+OB5XRETSkMYyiohERKEvIhIRhb6ISEQyLvTN7AQzO8XMssK0D7WeWe2/pNjMGphZ/VTX41CZWd0M2q8yqS0ZsX/B4W9LrQ+T0szsXOAx4FZgJnCVmTVOba0OjpkdZ2a5AO6+L5TVyqvow+vyEPCUmZ1lZt9OdZ0OhpkNB+4HHjWzfDNrlOo6HawMa0tG7F9QM23JmNE7ZpZF8p81zd3/YmbnAfnAP4Hb3f2zlFawCkLd/wv4MPz9HnjW3XeYmXktetHMrB3JEN2LgBOAU4BPgMfd/Y1U1q0qwsSAjwGXAd2A/sATwFPuXpTCqlVZhrUlI/YvqLm2ZNSRPtAYaB9uzwf+F8gCvldbjpLNrCFwMXCRu/cFXgH6ABeZ2ZG1KfCDxkCRu7/u7g8BD5BcH3K2mZU5P0gaOppkssA/u/uvSWaLzQcGhq/jtWL/CjKpLZmyf0ENtSVjQt/dvwSmAOeaWe/QJfIS8Cbwr6msWxXtA5oC/wIQ3pSvASeShH+t6uN397eArWb272G5kOQq7DYkbaot/kIyAeBQAHdfCMwFzgM61rIP44xpSwbtXzXWlloTHpX0IvA08H0zO9Xd97r774CWQNfUVq18lqjr7ruAO4FTzaxHWD0H2EDyDaCkjz9dmVlfMxthZt8PRQ8Cx5nZKAB3fx14Gfhh6JZLS2ZWYGanm9np7v5Pkv3ru2Z2CpSE5XPAv6f7B3GGtSUj9i9ITVvS+sWtKnffDTwMvAVcb2bjzGwMydfZD1NauXKY2TCSk2r3mVkB8CpJX95QM+vpiV8BzdP9JJWZ9QMeAb4FXGNmU4B3gfeBk8zsJ2HTXcAO0nSKdzMbQNKOAcBtZvZLkjekA8PM7IKw6RZgZyhPSxnWlozYvyB1bcmYE7mlhcncCoAfALuBX6frSR0z60pyovZakjmwfwjcCGwDepN8tVsM7AFuAHq7+5bU1LZ8oS/4duBDd7/DzLJJ+iXXAr8Fvk3ymjQCjiU5b5F2r0sYxng/sNjdZ4bzLM8CzwOTSE60DSBpRxtglLu/maLqlivD2pIR+xekuC3unrF/JJO61Ul1PSqo45nAH0stDwYWkPyi2NHAUJIT0o8A3VNd30q0ZxRwD3B0WG5A0l98R6lt2gPNUl3XA9TdSt2+ChgPZIflI0nOrdxeat/qBRyT6npnelsyZf9Kl7akvOGx/4Vgf5DkF8TqhLLBwArglLBcHzgi1XUtpw1tQh2/QfJt5WHgDOAbYX0DYAkwPNV1rei1KHX7VJLhcyeUKmtMchL0lFTXNbK2ZMT+lS5tSbtfzoqBmZ0MZAOfu3uhma0FRgIfm9k6d19gZt8BLjCzV9z9i1TWtzxmNoTka+pfSb6KXkvyreTHyWp7290/NLPnSK6ZSEtmdhbwczNbTnL+ZzLJsN8Hw3mhD9z9MzNbSZqfC8uwtmTE/gXp0xaFfg0zs0HANGARcIyZrXH3a83sHuBqkjfniyRDN+t7+PhPN6FPsjVJv/CPgHeAMSTdBvnAdGB02HY98D3gvpRUtgJm9i8kr8m/AXuBfiRdbGeTnNScArxqZvtILmSalKKqVihT2pJJ+xeAmbUiCfyUt0WhX4PCSbUxwC3uPtuSKSKeNrN73f1yM7sR+IGZ/Zzka+D3Ulnf8ri7m9kGkuFkq4FP3P2XZraH5EgmH3gDOIlkuGx/d/9byipcvs3A0+7+Qgibl0hOnD8GnAUsIxknnQcMcff3UlbTim0CFtX2toSDnXVm9jLwN2rx/mVm3yB5XV4kDdqSkaN30pmZXQdscPfZpcr+CvzF3cebWQ7QCXjf0/SS+ND1lAP8HbgbWOLuvyy1/nqSE1BXpnnXVC7QHPgImA3MdffJYV0dYCKw293/O5Sl7RQYZvavQFuSPuLFwJPuPimsq21tORv4DvAbktdlmbv/V6n1tWL/gpLh2ANIutgmkbTltlLra74tqT6xEcMfcHyp26OB5cC3SpU1Bx4luRoy5fWtoC3FR4t/JnlTDiUZZnZ9qW3akvzUm6WqnpVox6DQjsdJJuc7jeTk+Y9KbXMmMD3Vda2gHXVIRuOsIBnjfQ7JEL+3gR/XpraEeg4guYr+zFL70j+A62rT/hXq2QdYVaot3wI+AK5NZVvUvXOYhZNqc83scXcf5e4PmdkJwF/MrMDd/+Hum8zsnyRv3rRlZt8FfgV8z93fMLMZJEP9vgu8Erqv5pBMe9GDZDqJT1NU3TKZWV/g18Bod3/NzJ4AtgPfB/4nHBnfSRKex5tZI3ffnqr6lseTq7N3mNkskj78ESTfwk4D/mpme9z9LmpBW8L+NRs4O7wuzYEikg+yJ83sS5Lhy98ljfevUnoC97n7QjP7Fsn7+wbgbjPbTXIF9CnUcFsU+odRuBDmR8A1JJe8P+LuF7r7jUl3K0+Y2d0kR/pdgI0pq2zl3e7/d5HIz4HfuvuGEKQ3kIxIOBkY6+7p+ob8GPhBCJZjSN6cN5J8A5sLXEjSxdYbGJGuIbmfPSRHkjOBy0lOgr4NjDSzXiQfzunels3Al8CxZtYM+B+Sdq0gObHZk6QrJA+4JI33r2J7gCPC7eKpVN4jeV0GkMyk+V1quC3q0z/MzKwl8BnJEM17gC/d/cKwbjhQHDpT3X15yipaCeFIvqEnw/3qkhw9PgEM9mSo2XHA+rDNtlTWtbLCSXNz91vN7DKSD987gXXAke6+KaUVrKQwaucCd58ULt+fBNzq7jeHK9Qb14a2hCvU55OE5c0kH2KXkZzgnOTu68wspxYEPmbWGZhHcpJ2obs/YGbHA5cAr7j7Y6loS1qP0c0E7r7B3XeEN9wPgCPM7JGw+m/AAne/LN0DH8CTCeyKf5fAgK3AlhD4o4GfAVm1JfAB3P02d7813L4POJ4kIHfXhpAsZRdwgpldDlxB8kNCvczsCnf/Z21piyczTZ5FEvD3uvs+d59BcmK3Rdhsa6rqVxXu/jbwU5Jvvu1C2d+AbwJNwmZba7pe6t6pQe6+2cx+APzKzN4lufy9b2prdXDcfQ9JX/I6M/tvkq+rYz2ZJbRW2H8EiyU/XtOC5NtKrRK62NaRdFNd5e5PWDKh15oUV63K3H0lsLJ4ObwuzQmvS+nXrBZ4imTk1C/M7INQ1pXkR5JS0hZ176SAmf0HcB1wRjgaqHXCGPAskgtNskjGFq9Oba0OjiW/Rzqa5HzEyNrwretAzKwN8E13XxKW63iaT8NdnrCPXUJytHyBu69IcZUOmiXTpJ9PMgXDb1P5vlfo17AwDn8u8BN3X5bq+hwqMxsLvF7L35BZJPOfvOfu76a6PocqncfgV0UI/T7AR+6+KtX1yRQK/RQws2xP5v6v9TIlYERiodAXEYmIRu+IiEREoS8iEhGFvohIRBT6IiIRUeiLiEREoS8iEpH/D25WBxY+VwjIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0000 loss_train: 1.7637 loss_val: 1.6991\n",
      "Epoch: 0020 loss_train: 0.2891 loss_val: 0.1999\n",
      "Epoch: 0040 loss_train: 0.1950 loss_val: 0.1400\n",
      "Epoch: 0060 loss_train: 0.1648 loss_val: 0.1252\n",
      "Epoch: 0080 loss_train: 0.1437 loss_val: 0.1168\n",
      "Epoch: 0100 loss_train: 0.1313 loss_val: 0.1120\n",
      "Epoch: 0120 loss_train: 0.1238 loss_val: 0.1104\n",
      "Epoch: 0140 loss_train: 0.1122 loss_val: 0.1040\n",
      "Epoch: 0160 loss_train: 0.1074 loss_val: 0.1049\n",
      "Epoch: 0180 loss_train: 0.1018 loss_val: 0.1064\n",
      "Epoch: 0200 loss_train: 0.0987 loss_val: 0.1046\n",
      "Epoch: 0220 loss_train: 0.0962 loss_val: 0.1043\n",
      "Epoch: 0240 loss_train: 0.0922 loss_val: 0.1034\n",
      "Epoch: 0260 loss_train: 0.0888 loss_val: 0.1058\n",
      "Epoch: 0280 loss_train: 0.0870 loss_val: 0.1091\n",
      "Epoch: 0300 loss_train: 0.0867 loss_val: 0.1051\n",
      "Epoch: 0320 loss_train: 0.0816 loss_val: 0.1061\n",
      "Epoch: 0340 loss_train: 0.0821 loss_val: 0.1104\n",
      "Epoch: 0360 loss_train: 0.0806 loss_val: 0.1067\n",
      "Epoch: 0380 loss_train: 0.0786 loss_val: 0.1097\n",
      "Epoch: 0400 loss_train: 0.0765 loss_val: 0.1100\n",
      "Epoch: 0420 loss_train: 0.0750 loss_val: 0.1096\n",
      "Epoch: 0440 loss_train: 0.0749 loss_val: 0.1054\n",
      "Epoch: 0460 loss_train: 0.0776 loss_val: 0.1099\n",
      "Epoch: 0480 loss_train: 0.0729 loss_val: 0.1100\n",
      "Epoch: 0500 loss_train: 0.0718 loss_val: 0.1129\n",
      "Epoch: 0520 loss_train: 0.0726 loss_val: 0.1145\n",
      "Epoch: 0540 loss_train: 0.0703 loss_val: 0.1158\n",
      "Epoch: 0560 loss_train: 0.0665 loss_val: 0.1152\n",
      "Epoch: 0580 loss_train: 0.0650 loss_val: 0.1170\n",
      "Epoch: 0600 loss_train: 0.0679 loss_val: 0.1113\n",
      "Epoch: 0620 loss_train: 0.0674 loss_val: 0.1093\n",
      "Epoch: 0640 loss_train: 0.0671 loss_val: 0.1210\n",
      "Epoch: 0660 loss_train: 0.0666 loss_val: 0.1119\n",
      "Epoch: 0680 loss_train: 0.0656 loss_val: 0.1153\n",
      "Epoch: 0700 loss_train: 0.0668 loss_val: 0.1114\n",
      "Epoch: 0720 loss_train: 0.0619 loss_val: 0.1202\n",
      "Epoch: 0740 loss_train: 0.0632 loss_val: 0.1197\n",
      "Epoch: 0760 loss_train: 0.0624 loss_val: 0.1192\n",
      "Epoch: 0780 loss_train: 0.0632 loss_val: 0.1192\n",
      "Epoch: 0800 loss_train: 0.0633 loss_val: 0.1165\n",
      "Epoch: 0820 loss_train: 0.0617 loss_val: 0.1145\n",
      "Epoch: 0840 loss_train: 0.0612 loss_val: 0.1138\n",
      "Epoch: 0860 loss_train: 0.0638 loss_val: 0.1151\n",
      "Epoch: 0880 loss_train: 0.0595 loss_val: 0.1194\n",
      "Epoch: 0900 loss_train: 0.0607 loss_val: 0.1284\n",
      "Epoch: 0920 loss_train: 0.0583 loss_val: 0.1125\n",
      "Epoch: 0940 loss_train: 0.0594 loss_val: 0.1211\n",
      "Epoch: 0960 loss_train: 0.0580 loss_val: 0.1225\n",
      "Epoch: 0980 loss_train: 0.0596 loss_val: 0.1156\n",
      "Epoch: 1000 loss_train: 0.0554 loss_val: 0.1237\n",
      "Epoch: 1020 loss_train: 0.0571 loss_val: 0.1253\n",
      "Epoch: 1040 loss_train: 0.0541 loss_val: 0.1256\n",
      "Epoch: 1060 loss_train: 0.0584 loss_val: 0.1272\n",
      "Epoch: 1080 loss_train: 0.0569 loss_val: 0.1214\n",
      "Epoch: 1100 loss_train: 0.0564 loss_val: 0.1194\n",
      "Epoch: 1120 loss_train: 0.0566 loss_val: 0.1232\n",
      "Epoch: 1140 loss_train: 0.0581 loss_val: 0.1209\n",
      "Epoch: 1160 loss_train: 0.0593 loss_val: 0.1249\n",
      "Epoch: 1180 loss_train: 0.0562 loss_val: 0.1208\n",
      "Epoch: 1200 loss_train: 0.0568 loss_val: 0.1253\n",
      "Epoch: 1220 loss_train: 0.0561 loss_val: 0.1279\n",
      "Epoch: 1240 loss_train: 0.0545 loss_val: 0.1170\n",
      "Epoch: 1260 loss_train: 0.0555 loss_val: 0.1257\n",
      "Epoch: 1280 loss_train: 0.0570 loss_val: 0.1261\n",
      "Epoch: 1300 loss_train: 0.0531 loss_val: 0.1320\n",
      "Epoch: 1320 loss_train: 0.0529 loss_val: 0.1310\n",
      "Epoch: 1340 loss_train: 0.0549 loss_val: 0.1263\n",
      "Epoch: 1360 loss_train: 0.0528 loss_val: 0.1217\n",
      "Epoch: 1380 loss_train: 0.0558 loss_val: 0.1237\n",
      "Epoch: 1400 loss_train: 0.0521 loss_val: 0.1265\n",
      "Epoch: 1420 loss_train: 0.0548 loss_val: 0.1320\n",
      "Epoch: 1440 loss_train: 0.0533 loss_val: 0.1255\n",
      "Epoch: 1460 loss_train: 0.0523 loss_val: 0.1225\n",
      "Epoch: 1480 loss_train: 0.0563 loss_val: 0.1251\n",
      "Epoch: 1500 loss_train: 0.0563 loss_val: 0.1279\n",
      "Epoch: 1520 loss_train: 0.0536 loss_val: 0.1210\n",
      "Epoch: 1540 loss_train: 0.0520 loss_val: 0.1286\n",
      "Epoch: 1560 loss_train: 0.0507 loss_val: 0.1307\n",
      "Epoch: 1580 loss_train: 0.0487 loss_val: 0.1261\n",
      "Epoch: 1600 loss_train: 0.0509 loss_val: 0.1370\n",
      "Epoch: 1620 loss_train: 0.0519 loss_val: 0.1306\n",
      "Epoch: 1640 loss_train: 0.0501 loss_val: 0.1336\n",
      "Epoch: 1660 loss_train: 0.0519 loss_val: 0.1311\n",
      "Epoch: 1680 loss_train: 0.0510 loss_val: 0.1387\n",
      "Epoch: 1700 loss_train: 0.0523 loss_val: 0.1246\n",
      "Epoch: 1720 loss_train: 0.0485 loss_val: 0.1315\n",
      "Epoch: 1740 loss_train: 0.0483 loss_val: 0.1287\n",
      "Epoch: 1760 loss_train: 0.0489 loss_val: 0.1384\n",
      "Epoch: 1780 loss_train: 0.0508 loss_val: 0.1377\n",
      "Epoch: 1800 loss_train: 0.0489 loss_val: 0.1338\n",
      "Epoch: 1820 loss_train: 0.0504 loss_val: 0.1428\n",
      "Epoch: 1840 loss_train: 0.0516 loss_val: 0.1395\n",
      "Epoch: 1860 loss_train: 0.0495 loss_val: 0.1388\n",
      "Epoch: 1880 loss_train: 0.0505 loss_val: 0.1346\n",
      "Epoch: 1900 loss_train: 0.0453 loss_val: 0.1475\n",
      "Epoch: 1920 loss_train: 0.0479 loss_val: 0.1396\n",
      "Epoch: 1940 loss_train: 0.0490 loss_val: 0.1356\n",
      "Epoch: 1960 loss_train: 0.0472 loss_val: 0.1370\n",
      "Epoch: 1980 loss_train: 0.0478 loss_val: 0.1457\n",
      "Epoch: 2000 loss_train: 0.0496 loss_val: 0.1314\n",
      "Epoch: 2020 loss_train: 0.0491 loss_val: 0.1419\n",
      "Epoch: 2040 loss_train: 0.0482 loss_val: 0.1392\n",
      "Epoch: 2060 loss_train: 0.0470 loss_val: 0.1517\n",
      "Epoch: 2080 loss_train: 0.0463 loss_val: 0.1468\n",
      "Epoch: 2100 loss_train: 0.0480 loss_val: 0.1431\n",
      "Epoch: 2120 loss_train: 0.0479 loss_val: 0.1361\n",
      "Epoch: 2140 loss_train: 0.0448 loss_val: 0.1285\n",
      "Epoch: 2160 loss_train: 0.0495 loss_val: 0.1385\n",
      "Epoch: 2180 loss_train: 0.0470 loss_val: 0.1436\n",
      "Epoch: 2200 loss_train: 0.0464 loss_val: 0.1507\n",
      "Epoch: 2220 loss_train: 0.0467 loss_val: 0.1436\n",
      "Epoch: 2240 loss_train: 0.0465 loss_val: 0.1329\n",
      "Epoch: 2260 loss_train: 0.0476 loss_val: 0.1434\n",
      "Epoch: 2280 loss_train: 0.0453 loss_val: 0.1382\n",
      "Epoch: 2300 loss_train: 0.0466 loss_val: 0.1320\n",
      "Epoch: 2320 loss_train: 0.0455 loss_val: 0.1471\n",
      "Epoch: 2340 loss_train: 0.0435 loss_val: 0.1482\n",
      "Epoch: 2360 loss_train: 0.0465 loss_val: 0.1387\n",
      "Epoch: 2380 loss_train: 0.0440 loss_val: 0.1456\n",
      "Epoch: 2400 loss_train: 0.0442 loss_val: 0.1527\n",
      "Epoch: 2420 loss_train: 0.0465 loss_val: 0.1461\n",
      "Epoch: 2440 loss_train: 0.0464 loss_val: 0.1420\n",
      "Epoch: 2460 loss_train: 0.0434 loss_val: 0.1514\n",
      "Epoch: 2480 loss_train: 0.0475 loss_val: 0.1581\n",
      "Epoch: 2500 loss_train: 0.0449 loss_val: 0.1424\n",
      "Epoch: 2520 loss_train: 0.0454 loss_val: 0.1495\n",
      "Epoch: 2540 loss_train: 0.0452 loss_val: 0.1436\n",
      "Epoch: 2560 loss_train: 0.0448 loss_val: 0.1296\n",
      "Epoch: 2580 loss_train: 0.0445 loss_val: 0.1257\n",
      "Epoch: 2600 loss_train: 0.0441 loss_val: 0.1381\n",
      "Epoch: 2620 loss_train: 0.0461 loss_val: 0.1399\n",
      "Epoch: 2640 loss_train: 0.0424 loss_val: 0.1486\n",
      "Epoch: 2660 loss_train: 0.0420 loss_val: 0.1362\n",
      "Epoch: 2680 loss_train: 0.0435 loss_val: 0.1327\n",
      "Epoch: 2700 loss_train: 0.0439 loss_val: 0.1509\n",
      "Epoch: 2720 loss_train: 0.0444 loss_val: 0.1431\n",
      "Epoch: 2740 loss_train: 0.0442 loss_val: 0.1275\n",
      "Epoch: 2760 loss_train: 0.0454 loss_val: 0.1423\n",
      "Epoch: 2780 loss_train: 0.0418 loss_val: 0.1529\n",
      "Epoch: 2800 loss_train: 0.0436 loss_val: 0.1388\n",
      "Epoch: 2820 loss_train: 0.0426 loss_val: 0.1464\n",
      "Epoch: 2840 loss_train: 0.0453 loss_val: 0.1468\n",
      "Epoch: 2860 loss_train: 0.0422 loss_val: 0.1430\n",
      "Epoch: 2880 loss_train: 0.0427 loss_val: 0.1452\n",
      "Epoch: 2900 loss_train: 0.0415 loss_val: 0.1395\n",
      "Epoch: 2920 loss_train: 0.0435 loss_val: 0.1628\n",
      "Epoch: 2940 loss_train: 0.0425 loss_val: 0.1502\n",
      "Epoch: 2960 loss_train: 0.0425 loss_val: 0.1452\n",
      "Epoch: 2980 loss_train: 0.0429 loss_val: 0.1463\n",
      "Epoch: 3000 loss_train: 0.0418 loss_val: 0.1537\n",
      "Epoch: 3020 loss_train: 0.0431 loss_val: 0.1404\n",
      "Epoch: 3040 loss_train: 0.0408 loss_val: 0.1391\n",
      "Epoch: 3060 loss_train: 0.0429 loss_val: 0.1502\n",
      "Epoch: 3080 loss_train: 0.0412 loss_val: 0.1477\n",
      "Epoch: 3100 loss_train: 0.0425 loss_val: 0.1460\n",
      "Epoch: 3120 loss_train: 0.0422 loss_val: 0.1322\n",
      "Epoch: 3140 loss_train: 0.0450 loss_val: 0.1524\n",
      "Epoch: 3160 loss_train: 0.0414 loss_val: 0.1408\n",
      "Epoch: 3180 loss_train: 0.0422 loss_val: 0.1423\n",
      "Epoch: 3200 loss_train: 0.0399 loss_val: 0.1513\n",
      "Epoch: 3220 loss_train: 0.0426 loss_val: 0.1687\n",
      "Epoch: 3240 loss_train: 0.0440 loss_val: 0.1513\n",
      "Epoch: 3260 loss_train: 0.0408 loss_val: 0.1552\n",
      "Epoch: 3280 loss_train: 0.0424 loss_val: 0.1620\n",
      "Epoch: 3300 loss_train: 0.0440 loss_val: 0.1429\n",
      "Epoch: 3320 loss_train: 0.0408 loss_val: 0.1478\n",
      "Epoch: 3340 loss_train: 0.0413 loss_val: 0.1457\n",
      "Epoch: 3360 loss_train: 0.0418 loss_val: 0.1486\n",
      "Epoch: 3380 loss_train: 0.0414 loss_val: 0.1453\n",
      "Epoch: 3400 loss_train: 0.0445 loss_val: 0.1429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3420 loss_train: 0.0403 loss_val: 0.1448\n",
      "Epoch: 3440 loss_train: 0.0417 loss_val: 0.1470\n",
      "Epoch: 3460 loss_train: 0.0393 loss_val: 0.1633\n",
      "Epoch: 3480 loss_train: 0.0392 loss_val: 0.1422\n",
      "Epoch: 3500 loss_train: 0.0410 loss_val: 0.1427\n",
      "Epoch: 3520 loss_train: 0.0393 loss_val: 0.1487\n",
      "Epoch: 3540 loss_train: 0.0392 loss_val: 0.1542\n",
      "Epoch: 3560 loss_train: 0.0425 loss_val: 0.1578\n",
      "Epoch: 3580 loss_train: 0.0401 loss_val: 0.1524\n",
      "Epoch: 3600 loss_train: 0.0415 loss_val: 0.1538\n",
      "Epoch: 3620 loss_train: 0.0417 loss_val: 0.1617\n",
      "Epoch: 3640 loss_train: 0.0381 loss_val: 0.1524\n",
      "Epoch: 3660 loss_train: 0.0424 loss_val: 0.1492\n",
      "Epoch: 3680 loss_train: 0.0410 loss_val: 0.1464\n",
      "Epoch: 3700 loss_train: 0.0407 loss_val: 0.1518\n",
      "Epoch: 3720 loss_train: 0.0391 loss_val: 0.1491\n",
      "Epoch: 3740 loss_train: 0.0380 loss_val: 0.1490\n",
      "Epoch: 3760 loss_train: 0.0401 loss_val: 0.1583\n",
      "Epoch: 3780 loss_train: 0.0421 loss_val: 0.1547\n",
      "Epoch: 3800 loss_train: 0.0400 loss_val: 0.1473\n",
      "Epoch: 3820 loss_train: 0.0404 loss_val: 0.1528\n",
      "Epoch: 3840 loss_train: 0.0399 loss_val: 0.1511\n",
      "Epoch: 3860 loss_train: 0.0398 loss_val: 0.1532\n",
      "Epoch: 3880 loss_train: 0.0392 loss_val: 0.1418\n",
      "Epoch: 3900 loss_train: 0.0381 loss_val: 0.1527\n",
      "Epoch: 3920 loss_train: 0.0378 loss_val: 0.1414\n",
      "Epoch: 3940 loss_train: 0.0404 loss_val: 0.1466\n",
      "Epoch: 3960 loss_train: 0.0408 loss_val: 0.1457\n",
      "Epoch: 3980 loss_train: 0.0380 loss_val: 0.1546\n",
      "Epoch: 4000 loss_train: 0.0403 loss_val: 0.1396\n",
      "Epoch: 4020 loss_train: 0.0389 loss_val: 0.1554\n",
      "Epoch: 4040 loss_train: 0.0390 loss_val: 0.1642\n",
      "Epoch: 4060 loss_train: 0.0404 loss_val: 0.1507\n",
      "Epoch: 4080 loss_train: 0.0383 loss_val: 0.1513\n",
      "Epoch: 4100 loss_train: 0.0404 loss_val: 0.1517\n",
      "Epoch: 4120 loss_train: 0.0392 loss_val: 0.1546\n",
      "Epoch: 4140 loss_train: 0.0411 loss_val: 0.1487\n",
      "Epoch: 4160 loss_train: 0.0403 loss_val: 0.1514\n",
      "Epoch: 4180 loss_train: 0.0397 loss_val: 0.1517\n",
      "Epoch: 4200 loss_train: 0.0382 loss_val: 0.1501\n",
      "Epoch: 4220 loss_train: 0.0387 loss_val: 0.1588\n",
      "Epoch: 4240 loss_train: 0.0392 loss_val: 0.1553\n",
      "Epoch: 4260 loss_train: 0.0394 loss_val: 0.1530\n",
      "Epoch: 4280 loss_train: 0.0396 loss_val: 0.1459\n",
      "Epoch: 4300 loss_train: 0.0364 loss_val: 0.1585\n",
      "Epoch: 4320 loss_train: 0.0400 loss_val: 0.1459\n",
      "Epoch: 4340 loss_train: 0.0407 loss_val: 0.1486\n",
      "Epoch: 4360 loss_train: 0.0391 loss_val: 0.1537\n",
      "Epoch: 4380 loss_train: 0.0396 loss_val: 0.1531\n",
      "Epoch: 4400 loss_train: 0.0379 loss_val: 0.1546\n",
      "Epoch: 4420 loss_train: 0.0373 loss_val: 0.1509\n",
      "Epoch: 4440 loss_train: 0.0375 loss_val: 0.1442\n",
      "Epoch: 4460 loss_train: 0.0386 loss_val: 0.1458\n",
      "Epoch: 4480 loss_train: 0.0380 loss_val: 0.1536\n",
      "Epoch: 4500 loss_train: 0.0388 loss_val: 0.1489\n",
      "Epoch: 4520 loss_train: 0.0362 loss_val: 0.1581\n",
      "Epoch: 4540 loss_train: 0.0367 loss_val: 0.1503\n",
      "Epoch: 4560 loss_train: 0.0376 loss_val: 0.1421\n",
      "Epoch: 4580 loss_train: 0.0373 loss_val: 0.1533\n",
      "Epoch: 4600 loss_train: 0.0374 loss_val: 0.1498\n",
      "Epoch: 4620 loss_train: 0.0386 loss_val: 0.1503\n",
      "Epoch: 4640 loss_train: 0.0370 loss_val: 0.1586\n",
      "Epoch: 4660 loss_train: 0.0360 loss_val: 0.1474\n",
      "Epoch: 4680 loss_train: 0.0389 loss_val: 0.1587\n",
      "Epoch: 4700 loss_train: 0.0355 loss_val: 0.1546\n",
      "Epoch: 4720 loss_train: 0.0397 loss_val: 0.1469\n",
      "Epoch: 4740 loss_train: 0.0378 loss_val: 0.1411\n",
      "Epoch: 4760 loss_train: 0.0366 loss_val: 0.1567\n",
      "Epoch: 4780 loss_train: 0.0390 loss_val: 0.1562\n",
      "Epoch: 4800 loss_train: 0.0365 loss_val: 0.1616\n",
      "Epoch: 4820 loss_train: 0.0365 loss_val: 0.1490\n",
      "Epoch: 4840 loss_train: 0.0382 loss_val: 0.1506\n",
      "Epoch: 4860 loss_train: 0.0405 loss_val: 0.1555\n",
      "Epoch: 4880 loss_train: 0.0356 loss_val: 0.1547\n",
      "Epoch: 4900 loss_train: 0.0363 loss_val: 0.1513\n",
      "Epoch: 4920 loss_train: 0.0364 loss_val: 0.1531\n",
      "Epoch: 4940 loss_train: 0.0369 loss_val: 0.1521\n",
      "Epoch: 4960 loss_train: 0.0378 loss_val: 0.1564\n",
      "Epoch: 4980 loss_train: 0.0376 loss_val: 0.1569\n",
      "Epoch: 5000 loss_train: 0.0385 loss_val: 0.1573\n",
      "Epoch: 5020 loss_train: 0.0364 loss_val: 0.1591\n",
      "Epoch: 5040 loss_train: 0.0376 loss_val: 0.1581\n",
      "Epoch: 5060 loss_train: 0.0365 loss_val: 0.1491\n",
      "Epoch: 5080 loss_train: 0.0360 loss_val: 0.1569\n",
      "Epoch: 5100 loss_train: 0.0372 loss_val: 0.1587\n",
      "Epoch: 5120 loss_train: 0.0355 loss_val: 0.1541\n",
      "Epoch: 5140 loss_train: 0.0385 loss_val: 0.1462\n",
      "Epoch: 5160 loss_train: 0.0384 loss_val: 0.1560\n",
      "Epoch: 5180 loss_train: 0.0375 loss_val: 0.1573\n",
      "Epoch: 5200 loss_train: 0.0360 loss_val: 0.1527\n",
      "Epoch: 5220 loss_train: 0.0343 loss_val: 0.1625\n",
      "Epoch: 5240 loss_train: 0.0375 loss_val: 0.1536\n",
      "Epoch: 5260 loss_train: 0.0376 loss_val: 0.1561\n",
      "Epoch: 5280 loss_train: 0.0388 loss_val: 0.1643\n",
      "Epoch: 5300 loss_train: 0.0359 loss_val: 0.1587\n",
      "Epoch: 5320 loss_train: 0.0353 loss_val: 0.1468\n",
      "Epoch: 5340 loss_train: 0.0357 loss_val: 0.1515\n",
      "Epoch: 5360 loss_train: 0.0366 loss_val: 0.1499\n",
      "Epoch: 5380 loss_train: 0.0355 loss_val: 0.1570\n",
      "Epoch: 5400 loss_train: 0.0352 loss_val: 0.1605\n",
      "Epoch: 5420 loss_train: 0.0383 loss_val: 0.1644\n",
      "Epoch: 5440 loss_train: 0.0361 loss_val: 0.1689\n",
      "Epoch: 5460 loss_train: 0.0359 loss_val: 0.1588\n",
      "Epoch: 5480 loss_train: 0.0348 loss_val: 0.1616\n",
      "Epoch: 5500 loss_train: 0.0350 loss_val: 0.1530\n",
      "Epoch: 5520 loss_train: 0.0387 loss_val: 0.1467\n",
      "Epoch: 5540 loss_train: 0.0356 loss_val: 0.1643\n",
      "Epoch: 5560 loss_train: 0.0367 loss_val: 0.1566\n",
      "Epoch: 5580 loss_train: 0.0369 loss_val: 0.1552\n",
      "Epoch: 5600 loss_train: 0.0361 loss_val: 0.1560\n",
      "Epoch: 5620 loss_train: 0.0364 loss_val: 0.1530\n",
      "Epoch: 5640 loss_train: 0.0363 loss_val: 0.1539\n",
      "Epoch: 5660 loss_train: 0.0373 loss_val: 0.1580\n",
      "Epoch: 5680 loss_train: 0.0357 loss_val: 0.1489\n",
      "Epoch: 5700 loss_train: 0.0320 loss_val: 0.1631\n",
      "Epoch: 5720 loss_train: 0.0355 loss_val: 0.1536\n",
      "Epoch: 5740 loss_train: 0.0337 loss_val: 0.1600\n",
      "Epoch: 5760 loss_train: 0.0354 loss_val: 0.1505\n",
      "Epoch: 5780 loss_train: 0.0362 loss_val: 0.1646\n",
      "Epoch: 5800 loss_train: 0.0356 loss_val: 0.1567\n",
      "Epoch: 5820 loss_train: 0.0347 loss_val: 0.1558\n",
      "Epoch: 5840 loss_train: 0.0346 loss_val: 0.1549\n",
      "Epoch: 5860 loss_train: 0.0360 loss_val: 0.1529\n",
      "Epoch: 5880 loss_train: 0.0353 loss_val: 0.1530\n",
      "Epoch: 5900 loss_train: 0.0379 loss_val: 0.1518\n",
      "Epoch: 5920 loss_train: 0.0366 loss_val: 0.1586\n",
      "Epoch: 5940 loss_train: 0.0348 loss_val: 0.1579\n",
      "Epoch: 5960 loss_train: 0.0355 loss_val: 0.1512\n",
      "Epoch: 5980 loss_train: 0.0356 loss_val: 0.1546\n",
      " total time: 453.2452s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0000 loss_train: 1.7692 loss_val: 1.7021\n",
      "Epoch: 0020 loss_train: 0.4579 loss_val: 0.3168\n",
      "Epoch: 0040 loss_train: 0.3238 loss_val: 0.2409\n",
      "Epoch: 0060 loss_train: 0.2641 loss_val: 0.2058\n",
      "Epoch: 0080 loss_train: 0.2332 loss_val: 0.1980\n",
      "Epoch: 0100 loss_train: 0.2096 loss_val: 0.1760\n",
      "Epoch: 0120 loss_train: 0.1960 loss_val: 0.1716\n",
      "Epoch: 0140 loss_train: 0.1824 loss_val: 0.1689\n",
      "Epoch: 0160 loss_train: 0.1667 loss_val: 0.1593\n",
      "Epoch: 0180 loss_train: 0.1598 loss_val: 0.1639\n",
      "Epoch: 0200 loss_train: 0.1531 loss_val: 0.1584\n",
      "Epoch: 0220 loss_train: 0.1413 loss_val: 0.1549\n",
      "Epoch: 0240 loss_train: 0.1420 loss_val: 0.1528\n",
      "Epoch: 0260 loss_train: 0.1359 loss_val: 0.1528\n",
      "Epoch: 0280 loss_train: 0.1297 loss_val: 0.1597\n",
      "Epoch: 0300 loss_train: 0.1254 loss_val: 0.1422\n",
      "Epoch: 0320 loss_train: 0.1178 loss_val: 0.1499\n",
      "Epoch: 0340 loss_train: 0.1151 loss_val: 0.1505\n",
      "Epoch: 0360 loss_train: 0.1187 loss_val: 0.1607\n",
      "Epoch: 0380 loss_train: 0.1164 loss_val: 0.1534\n",
      "Epoch: 0400 loss_train: 0.1078 loss_val: 0.1358\n",
      "Epoch: 0420 loss_train: 0.1017 loss_val: 0.1401\n",
      "Epoch: 0440 loss_train: 0.1031 loss_val: 0.1402\n",
      "Epoch: 0460 loss_train: 0.1062 loss_val: 0.1413\n",
      "Epoch: 0480 loss_train: 0.1045 loss_val: 0.1465\n",
      "Epoch: 0500 loss_train: 0.0953 loss_val: 0.1598\n",
      "Epoch: 0520 loss_train: 0.0966 loss_val: 0.1444\n",
      "Epoch: 0540 loss_train: 0.0988 loss_val: 0.1472\n",
      "Epoch: 0560 loss_train: 0.0992 loss_val: 0.1651\n",
      "Epoch: 0580 loss_train: 0.1003 loss_val: 0.1609\n",
      "Epoch: 0600 loss_train: 0.0944 loss_val: 0.1661\n",
      "Epoch: 0620 loss_train: 0.0887 loss_val: 0.1523\n",
      "Epoch: 0640 loss_train: 0.0896 loss_val: 0.1702\n",
      "Epoch: 0660 loss_train: 0.0874 loss_val: 0.1657\n",
      "Epoch: 0680 loss_train: 0.0813 loss_val: 0.1567\n",
      "Epoch: 0700 loss_train: 0.0898 loss_val: 0.1662\n",
      "Epoch: 0720 loss_train: 0.0851 loss_val: 0.1736\n",
      "Epoch: 0740 loss_train: 0.0928 loss_val: 0.1632\n",
      "Epoch: 0760 loss_train: 0.0786 loss_val: 0.1682\n",
      "Epoch: 0780 loss_train: 0.0831 loss_val: 0.1513\n",
      "Epoch: 0800 loss_train: 0.0858 loss_val: 0.1609\n",
      "Epoch: 0820 loss_train: 0.0821 loss_val: 0.1706\n",
      "Epoch: 0840 loss_train: 0.0816 loss_val: 0.1743\n",
      "Epoch: 0860 loss_train: 0.0834 loss_val: 0.1774\n",
      "Epoch: 0880 loss_train: 0.0753 loss_val: 0.1623\n",
      "Epoch: 0900 loss_train: 0.0809 loss_val: 0.1819\n",
      "Epoch: 0920 loss_train: 0.0818 loss_val: 0.1751\n",
      "Epoch: 0940 loss_train: 0.0780 loss_val: 0.1849\n",
      "Epoch: 0960 loss_train: 0.0730 loss_val: 0.1704\n",
      "Epoch: 0980 loss_train: 0.0773 loss_val: 0.1723\n",
      "Epoch: 1000 loss_train: 0.0773 loss_val: 0.1839\n",
      "Epoch: 1020 loss_train: 0.0777 loss_val: 0.1700\n",
      "Epoch: 1040 loss_train: 0.0752 loss_val: 0.1815\n",
      "Epoch: 1060 loss_train: 0.0741 loss_val: 0.1782\n",
      "Epoch: 1080 loss_train: 0.0738 loss_val: 0.1836\n",
      "Epoch: 1100 loss_train: 0.0757 loss_val: 0.1730\n",
      "Epoch: 1120 loss_train: 0.0751 loss_val: 0.1948\n",
      "Epoch: 1140 loss_train: 0.0706 loss_val: 0.1829\n",
      "Epoch: 1160 loss_train: 0.0740 loss_val: 0.1771\n",
      "Epoch: 1180 loss_train: 0.0750 loss_val: 0.1797\n",
      "Epoch: 1200 loss_train: 0.0652 loss_val: 0.1906\n",
      "Epoch: 1220 loss_train: 0.0716 loss_val: 0.1997\n",
      "Epoch: 1240 loss_train: 0.0752 loss_val: 0.1943\n",
      "Epoch: 1260 loss_train: 0.0775 loss_val: 0.1907\n",
      "Epoch: 1280 loss_train: 0.0702 loss_val: 0.1994\n",
      "Epoch: 1300 loss_train: 0.0711 loss_val: 0.1976\n",
      "Epoch: 1320 loss_train: 0.0651 loss_val: 0.1962\n",
      "Epoch: 1340 loss_train: 0.0687 loss_val: 0.1975\n",
      "Epoch: 1360 loss_train: 0.0705 loss_val: 0.1846\n",
      "Epoch: 1380 loss_train: 0.0698 loss_val: 0.1885\n",
      "Epoch: 1400 loss_train: 0.0697 loss_val: 0.2056\n",
      "Epoch: 1420 loss_train: 0.0675 loss_val: 0.2100\n",
      "Epoch: 1440 loss_train: 0.0679 loss_val: 0.1920\n",
      "Epoch: 1460 loss_train: 0.0650 loss_val: 0.1866\n",
      "Epoch: 1480 loss_train: 0.0686 loss_val: 0.1977\n",
      "Epoch: 1500 loss_train: 0.0694 loss_val: 0.1971\n",
      "Epoch: 1520 loss_train: 0.0594 loss_val: 0.1964\n",
      "Epoch: 1540 loss_train: 0.0662 loss_val: 0.1877\n",
      "Epoch: 1560 loss_train: 0.0668 loss_val: 0.2047\n",
      "Epoch: 1580 loss_train: 0.0612 loss_val: 0.1973\n",
      "Epoch: 1600 loss_train: 0.0630 loss_val: 0.1987\n",
      "Epoch: 1620 loss_train: 0.0701 loss_val: 0.2182\n",
      "Epoch: 1640 loss_train: 0.0673 loss_val: 0.2158\n",
      "Epoch: 1660 loss_train: 0.0642 loss_val: 0.2130\n",
      "Epoch: 1680 loss_train: 0.0630 loss_val: 0.2104\n",
      "Epoch: 1700 loss_train: 0.0579 loss_val: 0.1982\n",
      "Epoch: 1720 loss_train: 0.0629 loss_val: 0.2275\n",
      "Epoch: 1740 loss_train: 0.0612 loss_val: 0.2157\n",
      "Epoch: 1760 loss_train: 0.0648 loss_val: 0.2142\n",
      "Epoch: 1780 loss_train: 0.0692 loss_val: 0.2015\n",
      "Epoch: 1800 loss_train: 0.0641 loss_val: 0.1957\n",
      "Epoch: 1820 loss_train: 0.0619 loss_val: 0.2043\n",
      "Epoch: 1840 loss_train: 0.0619 loss_val: 0.2102\n",
      "Epoch: 1860 loss_train: 0.0653 loss_val: 0.2175\n",
      "Epoch: 1880 loss_train: 0.0652 loss_val: 0.2078\n",
      "Epoch: 1900 loss_train: 0.0623 loss_val: 0.2176\n",
      "Epoch: 1920 loss_train: 0.0665 loss_val: 0.2184\n",
      "Epoch: 1940 loss_train: 0.0576 loss_val: 0.2270\n",
      "Epoch: 1960 loss_train: 0.0585 loss_val: 0.2201\n",
      "Epoch: 1980 loss_train: 0.0625 loss_val: 0.2212\n",
      "Epoch: 2000 loss_train: 0.0645 loss_val: 0.2210\n",
      "Epoch: 2020 loss_train: 0.0553 loss_val: 0.2258\n",
      "Epoch: 2040 loss_train: 0.0557 loss_val: 0.2219\n",
      "Epoch: 2060 loss_train: 0.0567 loss_val: 0.2168\n",
      "Epoch: 2080 loss_train: 0.0617 loss_val: 0.2082\n",
      "Epoch: 2100 loss_train: 0.0614 loss_val: 0.2159\n",
      "Epoch: 2120 loss_train: 0.0669 loss_val: 0.2011\n",
      "Epoch: 2140 loss_train: 0.0627 loss_val: 0.2083\n",
      "Epoch: 2160 loss_train: 0.0629 loss_val: 0.2018\n",
      "Epoch: 2180 loss_train: 0.0671 loss_val: 0.2405\n",
      "Epoch: 2200 loss_train: 0.0602 loss_val: 0.2138\n",
      "Epoch: 2220 loss_train: 0.0600 loss_val: 0.2150\n",
      "Epoch: 2240 loss_train: 0.0596 loss_val: 0.2126\n",
      "Epoch: 2260 loss_train: 0.0567 loss_val: 0.2448\n",
      "Epoch: 2280 loss_train: 0.0583 loss_val: 0.2378\n",
      "Epoch: 2300 loss_train: 0.0591 loss_val: 0.2239\n",
      "Epoch: 2320 loss_train: 0.0634 loss_val: 0.2133\n",
      "Epoch: 2340 loss_train: 0.0551 loss_val: 0.2147\n",
      "Epoch: 2360 loss_train: 0.0624 loss_val: 0.2115\n",
      "Epoch: 2380 loss_train: 0.0603 loss_val: 0.2209\n",
      "Epoch: 2400 loss_train: 0.0612 loss_val: 0.2301\n",
      "Epoch: 2420 loss_train: 0.0595 loss_val: 0.2214\n",
      "Epoch: 2440 loss_train: 0.0535 loss_val: 0.2194\n",
      "Epoch: 2460 loss_train: 0.0564 loss_val: 0.2356\n",
      "Epoch: 2480 loss_train: 0.0634 loss_val: 0.2376\n",
      "Epoch: 2500 loss_train: 0.0568 loss_val: 0.2474\n",
      "Epoch: 2520 loss_train: 0.0563 loss_val: 0.2428\n",
      "Epoch: 2540 loss_train: 0.0574 loss_val: 0.2428\n",
      "Epoch: 2560 loss_train: 0.0578 loss_val: 0.2203\n",
      "Epoch: 2580 loss_train: 0.0569 loss_val: 0.2373\n",
      "Epoch: 2600 loss_train: 0.0558 loss_val: 0.2440\n",
      "Epoch: 2620 loss_train: 0.0550 loss_val: 0.2388\n",
      "Epoch: 2640 loss_train: 0.0508 loss_val: 0.2300\n",
      "Epoch: 2660 loss_train: 0.0545 loss_val: 0.2381\n",
      "Epoch: 2680 loss_train: 0.0550 loss_val: 0.2379\n",
      "Epoch: 2700 loss_train: 0.0589 loss_val: 0.2328\n",
      "Epoch: 2720 loss_train: 0.0570 loss_val: 0.2376\n",
      "Epoch: 2740 loss_train: 0.0509 loss_val: 0.2339\n",
      "Epoch: 2760 loss_train: 0.0544 loss_val: 0.2315\n",
      "Epoch: 2780 loss_train: 0.0538 loss_val: 0.2333\n",
      "Epoch: 2800 loss_train: 0.0563 loss_val: 0.2210\n",
      "Epoch: 2820 loss_train: 0.0595 loss_val: 0.2532\n",
      "Epoch: 2840 loss_train: 0.0565 loss_val: 0.2305\n",
      "Epoch: 2860 loss_train: 0.0571 loss_val: 0.2467\n",
      "Epoch: 2880 loss_train: 0.0532 loss_val: 0.2330\n",
      "Epoch: 2900 loss_train: 0.0533 loss_val: 0.2257\n",
      "Epoch: 2920 loss_train: 0.0532 loss_val: 0.2350\n",
      "Epoch: 2940 loss_train: 0.0543 loss_val: 0.2258\n",
      "Epoch: 2960 loss_train: 0.0533 loss_val: 0.2164\n",
      "Epoch: 2980 loss_train: 0.0546 loss_val: 0.2455\n",
      "Epoch: 3000 loss_train: 0.0497 loss_val: 0.2538\n",
      "Epoch: 3020 loss_train: 0.0538 loss_val: 0.2443\n",
      "Epoch: 3040 loss_train: 0.0556 loss_val: 0.2335\n",
      "Epoch: 3060 loss_train: 0.0567 loss_val: 0.2646\n",
      "Epoch: 3080 loss_train: 0.0562 loss_val: 0.2554\n",
      "Epoch: 3100 loss_train: 0.0519 loss_val: 0.2480\n",
      "Epoch: 3120 loss_train: 0.0533 loss_val: 0.2591\n",
      "Epoch: 3140 loss_train: 0.0535 loss_val: 0.2405\n",
      "Epoch: 3160 loss_train: 0.0520 loss_val: 0.2349\n",
      "Epoch: 3180 loss_train: 0.0555 loss_val: 0.2195\n",
      "Epoch: 3200 loss_train: 0.0562 loss_val: 0.2261\n",
      "Epoch: 3220 loss_train: 0.0507 loss_val: 0.2358\n",
      "Epoch: 3240 loss_train: 0.0528 loss_val: 0.2336\n",
      "Epoch: 3260 loss_train: 0.0528 loss_val: 0.2416\n",
      "Epoch: 3280 loss_train: 0.0584 loss_val: 0.2520\n",
      "Epoch: 3300 loss_train: 0.0520 loss_val: 0.2580\n",
      "Epoch: 3320 loss_train: 0.0493 loss_val: 0.2518\n",
      "Epoch: 3340 loss_train: 0.0527 loss_val: 0.2574\n",
      "Epoch: 3360 loss_train: 0.0503 loss_val: 0.2502\n",
      "Epoch: 3380 loss_train: 0.0532 loss_val: 0.2484\n",
      "Epoch: 3400 loss_train: 0.0514 loss_val: 0.2292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3420 loss_train: 0.0527 loss_val: 0.2411\n",
      "Epoch: 3440 loss_train: 0.0548 loss_val: 0.2246\n",
      "Epoch: 3460 loss_train: 0.0480 loss_val: 0.2444\n",
      "Epoch: 3480 loss_train: 0.0499 loss_val: 0.2495\n",
      "Epoch: 3500 loss_train: 0.0441 loss_val: 0.2451\n",
      "Epoch: 3520 loss_train: 0.0498 loss_val: 0.2306\n",
      "Epoch: 3540 loss_train: 0.0508 loss_val: 0.2583\n",
      "Epoch: 3560 loss_train: 0.0522 loss_val: 0.2328\n",
      "Epoch: 3580 loss_train: 0.0506 loss_val: 0.2555\n",
      "Epoch: 3600 loss_train: 0.0583 loss_val: 0.2301\n",
      "Epoch: 3620 loss_train: 0.0524 loss_val: 0.2281\n",
      "Epoch: 3640 loss_train: 0.0481 loss_val: 0.2379\n",
      "Epoch: 3660 loss_train: 0.0472 loss_val: 0.2306\n",
      "Epoch: 3680 loss_train: 0.0468 loss_val: 0.2210\n",
      "Epoch: 3700 loss_train: 0.0572 loss_val: 0.2233\n",
      "Epoch: 3720 loss_train: 0.0513 loss_val: 0.2160\n",
      "Epoch: 3740 loss_train: 0.0517 loss_val: 0.2520\n",
      "Epoch: 3760 loss_train: 0.0492 loss_val: 0.2539\n",
      "Epoch: 3780 loss_train: 0.0485 loss_val: 0.2377\n",
      "Epoch: 3800 loss_train: 0.0483 loss_val: 0.2384\n",
      "Epoch: 3820 loss_train: 0.0433 loss_val: 0.2436\n",
      "Epoch: 3840 loss_train: 0.0521 loss_val: 0.2521\n",
      "Epoch: 3860 loss_train: 0.0514 loss_val: 0.2468\n",
      "Epoch: 3880 loss_train: 0.0517 loss_val: 0.2525\n",
      "Epoch: 3900 loss_train: 0.0473 loss_val: 0.2552\n",
      "Epoch: 3920 loss_train: 0.0447 loss_val: 0.2576\n",
      "Epoch: 3940 loss_train: 0.0460 loss_val: 0.2594\n",
      "Epoch: 3960 loss_train: 0.0520 loss_val: 0.2436\n",
      "Epoch: 3980 loss_train: 0.0477 loss_val: 0.2590\n",
      "Epoch: 4000 loss_train: 0.0532 loss_val: 0.2506\n",
      "Epoch: 4020 loss_train: 0.0450 loss_val: 0.2472\n",
      "Epoch: 4040 loss_train: 0.0509 loss_val: 0.2407\n",
      "Epoch: 4060 loss_train: 0.0524 loss_val: 0.2547\n",
      "Epoch: 4080 loss_train: 0.0499 loss_val: 0.2368\n",
      "Epoch: 4100 loss_train: 0.0503 loss_val: 0.2469\n",
      "Epoch: 4120 loss_train: 0.0488 loss_val: 0.2603\n",
      "Epoch: 4140 loss_train: 0.0460 loss_val: 0.2365\n",
      "Epoch: 4160 loss_train: 0.0521 loss_val: 0.2422\n",
      "Epoch: 4180 loss_train: 0.0473 loss_val: 0.2384\n",
      "Epoch: 4200 loss_train: 0.0465 loss_val: 0.2577\n",
      "Epoch: 4220 loss_train: 0.0472 loss_val: 0.2367\n",
      "Epoch: 4240 loss_train: 0.0505 loss_val: 0.2520\n",
      "Epoch: 4260 loss_train: 0.0428 loss_val: 0.2373\n",
      "Epoch: 4280 loss_train: 0.0476 loss_val: 0.2352\n",
      "Epoch: 4300 loss_train: 0.0447 loss_val: 0.2546\n",
      "Epoch: 4320 loss_train: 0.0467 loss_val: 0.2311\n",
      "Epoch: 4340 loss_train: 0.0545 loss_val: 0.2429\n",
      "Epoch: 4360 loss_train: 0.0473 loss_val: 0.2391\n",
      "Epoch: 4380 loss_train: 0.0478 loss_val: 0.2637\n",
      "Epoch: 4400 loss_train: 0.0511 loss_val: 0.2822\n",
      "Epoch: 4420 loss_train: 0.0452 loss_val: 0.2523\n",
      "Epoch: 4440 loss_train: 0.0512 loss_val: 0.2360\n",
      "Epoch: 4460 loss_train: 0.0443 loss_val: 0.2566\n",
      "Epoch: 4480 loss_train: 0.0486 loss_val: 0.2536\n",
      "Epoch: 4500 loss_train: 0.0446 loss_val: 0.2515\n",
      "Epoch: 4520 loss_train: 0.0502 loss_val: 0.2406\n",
      "Epoch: 4540 loss_train: 0.0448 loss_val: 0.2483\n",
      "Epoch: 4560 loss_train: 0.0471 loss_val: 0.2523\n",
      "Epoch: 4580 loss_train: 0.0500 loss_val: 0.2520\n",
      "Epoch: 4600 loss_train: 0.0478 loss_val: 0.2363\n",
      "Epoch: 4620 loss_train: 0.0485 loss_val: 0.2700\n",
      "Epoch: 4640 loss_train: 0.0479 loss_val: 0.2573\n",
      "Epoch: 4660 loss_train: 0.0489 loss_val: 0.2449\n",
      "Epoch: 4680 loss_train: 0.0451 loss_val: 0.2407\n",
      "Epoch: 4700 loss_train: 0.0471 loss_val: 0.2435\n",
      "Epoch: 4720 loss_train: 0.0468 loss_val: 0.2555\n",
      "Epoch: 4740 loss_train: 0.0457 loss_val: 0.2498\n",
      "Epoch: 4760 loss_train: 0.0511 loss_val: 0.2476\n",
      "Epoch: 4780 loss_train: 0.0464 loss_val: 0.2432\n",
      "Epoch: 4800 loss_train: 0.0442 loss_val: 0.2650\n",
      "Epoch: 4820 loss_train: 0.0457 loss_val: 0.2409\n",
      "Epoch: 4840 loss_train: 0.0481 loss_val: 0.2423\n",
      "Epoch: 4860 loss_train: 0.0471 loss_val: 0.2375\n",
      "Epoch: 4880 loss_train: 0.0464 loss_val: 0.2439\n",
      "Epoch: 4900 loss_train: 0.0454 loss_val: 0.2388\n",
      "Epoch: 4920 loss_train: 0.0456 loss_val: 0.2561\n",
      "Epoch: 4940 loss_train: 0.0404 loss_val: 0.2932\n",
      "Epoch: 4960 loss_train: 0.0434 loss_val: 0.2455\n",
      "Epoch: 4980 loss_train: 0.0417 loss_val: 0.2396\n",
      "Epoch: 5000 loss_train: 0.0474 loss_val: 0.2285\n",
      "Epoch: 5020 loss_train: 0.0443 loss_val: 0.2600\n",
      "Epoch: 5040 loss_train: 0.0430 loss_val: 0.2353\n",
      "Epoch: 5060 loss_train: 0.0476 loss_val: 0.2515\n",
      "Epoch: 5080 loss_train: 0.0459 loss_val: 0.2491\n",
      "Epoch: 5100 loss_train: 0.0468 loss_val: 0.2615\n",
      "Epoch: 5120 loss_train: 0.0512 loss_val: 0.2614\n",
      "Epoch: 5140 loss_train: 0.0491 loss_val: 0.2479\n",
      "Epoch: 5160 loss_train: 0.0451 loss_val: 0.2548\n",
      "Epoch: 5180 loss_train: 0.0449 loss_val: 0.2733\n",
      "Epoch: 5200 loss_train: 0.0443 loss_val: 0.2675\n",
      "Epoch: 5220 loss_train: 0.0446 loss_val: 0.2599\n",
      "Epoch: 5240 loss_train: 0.0468 loss_val: 0.2681\n",
      "Epoch: 5260 loss_train: 0.0438 loss_val: 0.2417\n",
      "Epoch: 5280 loss_train: 0.0429 loss_val: 0.2770\n",
      "Epoch: 5300 loss_train: 0.0438 loss_val: 0.2605\n",
      "Epoch: 5320 loss_train: 0.0464 loss_val: 0.2744\n",
      "Epoch: 5340 loss_train: 0.0415 loss_val: 0.2748\n",
      "Epoch: 5360 loss_train: 0.0455 loss_val: 0.2908\n",
      "Epoch: 5380 loss_train: 0.0447 loss_val: 0.2646\n",
      "Epoch: 5400 loss_train: 0.0444 loss_val: 0.2749\n",
      "Epoch: 5420 loss_train: 0.0427 loss_val: 0.2567\n",
      "Epoch: 5440 loss_train: 0.0462 loss_val: 0.2442\n",
      "Epoch: 5460 loss_train: 0.0443 loss_val: 0.2351\n",
      "Epoch: 5480 loss_train: 0.0395 loss_val: 0.2728\n",
      "Epoch: 5500 loss_train: 0.0474 loss_val: 0.2523\n",
      "Epoch: 5520 loss_train: 0.0409 loss_val: 0.2645\n",
      "Epoch: 5540 loss_train: 0.0406 loss_val: 0.2641\n",
      "Epoch: 5560 loss_train: 0.0428 loss_val: 0.2535\n",
      "Epoch: 5580 loss_train: 0.0405 loss_val: 0.2661\n",
      "Epoch: 5600 loss_train: 0.0401 loss_val: 0.2886\n",
      "Epoch: 5620 loss_train: 0.0424 loss_val: 0.2491\n",
      "Epoch: 5640 loss_train: 0.0444 loss_val: 0.2591\n",
      "Epoch: 5660 loss_train: 0.0439 loss_val: 0.2393\n",
      "Epoch: 5680 loss_train: 0.0445 loss_val: 0.2612\n",
      "Epoch: 5700 loss_train: 0.0512 loss_val: 0.2375\n",
      "Epoch: 5720 loss_train: 0.0467 loss_val: 0.2489\n",
      "Epoch: 5740 loss_train: 0.0433 loss_val: 0.2450\n",
      "Epoch: 5760 loss_train: 0.0415 loss_val: 0.2576\n",
      "Epoch: 5780 loss_train: 0.0414 loss_val: 0.2857\n",
      "Epoch: 5800 loss_train: 0.0393 loss_val: 0.2422\n",
      "Epoch: 5820 loss_train: 0.0396 loss_val: 0.2609\n",
      "Epoch: 5840 loss_train: 0.0374 loss_val: 0.2593\n",
      "Epoch: 5860 loss_train: 0.0425 loss_val: 0.2527\n",
      "Epoch: 5880 loss_train: 0.0412 loss_val: 0.2742\n",
      "Epoch: 5900 loss_train: 0.0365 loss_val: 0.2581\n",
      "Epoch: 5920 loss_train: 0.0407 loss_val: 0.2818\n",
      "Epoch: 5940 loss_train: 0.0443 loss_val: 0.2497\n",
      "Epoch: 5960 loss_train: 0.0469 loss_val: 0.2656\n",
      "Epoch: 5980 loss_train: 0.0436 loss_val: 0.2793\n",
      " total time: 316.6227s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0000 loss_train: 1.3577 loss_val: 1.2953\n",
      "Epoch: 0020 loss_train: 0.1556 loss_val: 0.1181\n",
      "Epoch: 0040 loss_train: 0.1206 loss_val: 0.0977\n",
      "Epoch: 0060 loss_train: 0.0990 loss_val: 0.0861\n",
      "Epoch: 0080 loss_train: 0.0863 loss_val: 0.0817\n",
      "Epoch: 0100 loss_train: 0.0816 loss_val: 0.0780\n",
      "Epoch: 0120 loss_train: 0.0737 loss_val: 0.0731\n",
      "Epoch: 0140 loss_train: 0.0717 loss_val: 0.0717\n",
      "Epoch: 0160 loss_train: 0.0653 loss_val: 0.0710\n",
      "Epoch: 0180 loss_train: 0.0629 loss_val: 0.0702\n",
      "Epoch: 0200 loss_train: 0.0552 loss_val: 0.0708\n",
      "Epoch: 0220 loss_train: 0.0542 loss_val: 0.0705\n",
      "Epoch: 0240 loss_train: 0.0521 loss_val: 0.0687\n",
      "Epoch: 0260 loss_train: 0.0505 loss_val: 0.0697\n",
      "Epoch: 0280 loss_train: 0.0498 loss_val: 0.0695\n",
      "Epoch: 0300 loss_train: 0.0463 loss_val: 0.0760\n",
      "Epoch: 0320 loss_train: 0.0445 loss_val: 0.0784\n",
      "Epoch: 0340 loss_train: 0.0465 loss_val: 0.0790\n",
      "Epoch: 0360 loss_train: 0.0420 loss_val: 0.0646\n",
      "Epoch: 0380 loss_train: 0.0446 loss_val: 0.0662\n",
      "Epoch: 0400 loss_train: 0.0429 loss_val: 0.0753\n",
      "Epoch: 0420 loss_train: 0.0421 loss_val: 0.0751\n",
      "Epoch: 0440 loss_train: 0.0404 loss_val: 0.0650\n",
      "Epoch: 0460 loss_train: 0.0388 loss_val: 0.0613\n",
      "Epoch: 0480 loss_train: 0.0396 loss_val: 0.0680\n",
      "Epoch: 0500 loss_train: 0.0388 loss_val: 0.0805\n",
      "Epoch: 0520 loss_train: 0.0358 loss_val: 0.0775\n",
      "Epoch: 0540 loss_train: 0.0367 loss_val: 0.0804\n",
      "Epoch: 0560 loss_train: 0.0332 loss_val: 0.0761\n",
      "Epoch: 0580 loss_train: 0.0340 loss_val: 0.0722\n",
      "Epoch: 0600 loss_train: 0.0364 loss_val: 0.0659\n",
      "Epoch: 0620 loss_train: 0.0362 loss_val: 0.0711\n",
      "Epoch: 0640 loss_train: 0.0310 loss_val: 0.0662\n",
      "Epoch: 0660 loss_train: 0.0307 loss_val: 0.0878\n",
      "Epoch: 0680 loss_train: 0.0329 loss_val: 0.0751\n",
      "Epoch: 0700 loss_train: 0.0327 loss_val: 0.0738\n",
      "Epoch: 0720 loss_train: 0.0320 loss_val: 0.0811\n",
      "Epoch: 0740 loss_train: 0.0324 loss_val: 0.0793\n",
      "Epoch: 0760 loss_train: 0.0311 loss_val: 0.0938\n",
      "Epoch: 0780 loss_train: 0.0338 loss_val: 0.0758\n",
      "Epoch: 0800 loss_train: 0.0321 loss_val: 0.0731\n",
      "Epoch: 0820 loss_train: 0.0295 loss_val: 0.0903\n",
      "Epoch: 0840 loss_train: 0.0313 loss_val: 0.0968\n",
      "Epoch: 0860 loss_train: 0.0274 loss_val: 0.0939\n",
      "Epoch: 0880 loss_train: 0.0289 loss_val: 0.0929\n",
      "Epoch: 0900 loss_train: 0.0309 loss_val: 0.1117\n",
      "Epoch: 0920 loss_train: 0.0317 loss_val: 0.1279\n",
      "Epoch: 0940 loss_train: 0.0300 loss_val: 0.1113\n",
      "Epoch: 0960 loss_train: 0.0296 loss_val: 0.1022\n",
      "Epoch: 0980 loss_train: 0.0290 loss_val: 0.1115\n",
      "Epoch: 1000 loss_train: 0.0263 loss_val: 0.1109\n",
      "Epoch: 1020 loss_train: 0.0276 loss_val: 0.1000\n",
      "Epoch: 1040 loss_train: 0.0307 loss_val: 0.1012\n",
      "Epoch: 1060 loss_train: 0.0280 loss_val: 0.0856\n",
      "Epoch: 1080 loss_train: 0.0266 loss_val: 0.1193\n",
      "Epoch: 1100 loss_train: 0.0279 loss_val: 0.1061\n",
      "Epoch: 1120 loss_train: 0.0279 loss_val: 0.1135\n",
      "Epoch: 1140 loss_train: 0.0264 loss_val: 0.0979\n",
      "Epoch: 1160 loss_train: 0.0262 loss_val: 0.0991\n",
      "Epoch: 1180 loss_train: 0.0265 loss_val: 0.0971\n",
      "Epoch: 1200 loss_train: 0.0272 loss_val: 0.0859\n",
      "Epoch: 1220 loss_train: 0.0276 loss_val: 0.0926\n",
      "Epoch: 1240 loss_train: 0.0260 loss_val: 0.0861\n",
      "Epoch: 1260 loss_train: 0.0247 loss_val: 0.0988\n",
      "Epoch: 1280 loss_train: 0.0273 loss_val: 0.0852\n",
      "Epoch: 1300 loss_train: 0.0267 loss_val: 0.0806\n",
      "Epoch: 1320 loss_train: 0.0248 loss_val: 0.0953\n",
      "Epoch: 1340 loss_train: 0.0263 loss_val: 0.0950\n",
      "Epoch: 1360 loss_train: 0.0239 loss_val: 0.1001\n",
      "Epoch: 1380 loss_train: 0.0251 loss_val: 0.0966\n",
      "Epoch: 1400 loss_train: 0.0242 loss_val: 0.1085\n",
      "Epoch: 1420 loss_train: 0.0254 loss_val: 0.0965\n",
      "Epoch: 1440 loss_train: 0.0255 loss_val: 0.1013\n",
      "Epoch: 1460 loss_train: 0.0244 loss_val: 0.1044\n",
      "Epoch: 1480 loss_train: 0.0259 loss_val: 0.1020\n",
      "Epoch: 1500 loss_train: 0.0258 loss_val: 0.1131\n",
      "Epoch: 1520 loss_train: 0.0237 loss_val: 0.1136\n",
      "Epoch: 1540 loss_train: 0.0250 loss_val: 0.1189\n",
      "Epoch: 1560 loss_train: 0.0228 loss_val: 0.1141\n",
      "Epoch: 1580 loss_train: 0.0257 loss_val: 0.1045\n",
      "Epoch: 1600 loss_train: 0.0222 loss_val: 0.1222\n",
      "Epoch: 1620 loss_train: 0.0231 loss_val: 0.1337\n",
      "Epoch: 1640 loss_train: 0.0220 loss_val: 0.1238\n",
      "Epoch: 1660 loss_train: 0.0233 loss_val: 0.1185\n",
      "Epoch: 1680 loss_train: 0.0219 loss_val: 0.1191\n",
      "Epoch: 1700 loss_train: 0.0216 loss_val: 0.1139\n",
      "Epoch: 1720 loss_train: 0.0245 loss_val: 0.1216\n",
      "Epoch: 1740 loss_train: 0.0222 loss_val: 0.1226\n",
      "Epoch: 1760 loss_train: 0.0216 loss_val: 0.1104\n",
      "Epoch: 1780 loss_train: 0.0225 loss_val: 0.1171\n",
      "Epoch: 1800 loss_train: 0.0246 loss_val: 0.1139\n",
      "Epoch: 1820 loss_train: 0.0230 loss_val: 0.1176\n",
      "Epoch: 1840 loss_train: 0.0222 loss_val: 0.1160\n",
      "Epoch: 1860 loss_train: 0.0199 loss_val: 0.1279\n",
      "Epoch: 1880 loss_train: 0.0224 loss_val: 0.1145\n",
      "Epoch: 1900 loss_train: 0.0223 loss_val: 0.1257\n",
      "Epoch: 1920 loss_train: 0.0229 loss_val: 0.1191\n",
      "Epoch: 1940 loss_train: 0.0218 loss_val: 0.1301\n",
      "Epoch: 1960 loss_train: 0.0227 loss_val: 0.1365\n",
      "Epoch: 1980 loss_train: 0.0207 loss_val: 0.1189\n",
      "Epoch: 2000 loss_train: 0.0219 loss_val: 0.1009\n",
      "Epoch: 2020 loss_train: 0.0220 loss_val: 0.1059\n",
      "Epoch: 2040 loss_train: 0.0226 loss_val: 0.1000\n",
      "Epoch: 2060 loss_train: 0.0203 loss_val: 0.1078\n",
      "Epoch: 2080 loss_train: 0.0188 loss_val: 0.1065\n",
      "Epoch: 2100 loss_train: 0.0204 loss_val: 0.0976\n",
      "Epoch: 2120 loss_train: 0.0209 loss_val: 0.1199\n",
      "Epoch: 2140 loss_train: 0.0203 loss_val: 0.1273\n",
      "Epoch: 2160 loss_train: 0.0199 loss_val: 0.1193\n",
      "Epoch: 2180 loss_train: 0.0187 loss_val: 0.1167\n",
      "Epoch: 2200 loss_train: 0.0208 loss_val: 0.1148\n",
      "Epoch: 2220 loss_train: 0.0198 loss_val: 0.1169\n",
      "Epoch: 2240 loss_train: 0.0182 loss_val: 0.1196\n",
      "Epoch: 2260 loss_train: 0.0186 loss_val: 0.1249\n",
      "Epoch: 2280 loss_train: 0.0222 loss_val: 0.1121\n",
      "Epoch: 2300 loss_train: 0.0197 loss_val: 0.1413\n",
      "Epoch: 2320 loss_train: 0.0214 loss_val: 0.1301\n",
      "Epoch: 2340 loss_train: 0.0182 loss_val: 0.1167\n",
      "Epoch: 2360 loss_train: 0.0208 loss_val: 0.1065\n",
      "Epoch: 2380 loss_train: 0.0185 loss_val: 0.1244\n",
      "Epoch: 2400 loss_train: 0.0193 loss_val: 0.1303\n",
      "Epoch: 2420 loss_train: 0.0198 loss_val: 0.1405\n",
      "Epoch: 2440 loss_train: 0.0187 loss_val: 0.1275\n",
      "Epoch: 2460 loss_train: 0.0192 loss_val: 0.1154\n",
      "Epoch: 2480 loss_train: 0.0199 loss_val: 0.1246\n",
      "Epoch: 2500 loss_train: 0.0205 loss_val: 0.1426\n",
      "Epoch: 2520 loss_train: 0.0170 loss_val: 0.1250\n",
      "Epoch: 2540 loss_train: 0.0191 loss_val: 0.1172\n",
      "Epoch: 2560 loss_train: 0.0184 loss_val: 0.1192\n",
      "Epoch: 2580 loss_train: 0.0199 loss_val: 0.1492\n",
      "Epoch: 2600 loss_train: 0.0219 loss_val: 0.1369\n",
      "Epoch: 2620 loss_train: 0.0186 loss_val: 0.1459\n",
      "Epoch: 2640 loss_train: 0.0182 loss_val: 0.1354\n",
      "Epoch: 2660 loss_train: 0.0182 loss_val: 0.1253\n",
      "Epoch: 2680 loss_train: 0.0196 loss_val: 0.1460\n",
      "Epoch: 2700 loss_train: 0.0190 loss_val: 0.1368\n",
      "Epoch: 2720 loss_train: 0.0201 loss_val: 0.1445\n",
      "Epoch: 2740 loss_train: 0.0196 loss_val: 0.1553\n",
      "Epoch: 2760 loss_train: 0.0173 loss_val: 0.1444\n",
      "Epoch: 2780 loss_train: 0.0206 loss_val: 0.1393\n",
      "Epoch: 2800 loss_train: 0.0198 loss_val: 0.1439\n",
      "Epoch: 2820 loss_train: 0.0184 loss_val: 0.1305\n",
      "Epoch: 2840 loss_train: 0.0176 loss_val: 0.1546\n",
      "Epoch: 2860 loss_train: 0.0196 loss_val: 0.1444\n",
      "Epoch: 2880 loss_train: 0.0189 loss_val: 0.1494\n",
      "Epoch: 2900 loss_train: 0.0200 loss_val: 0.1524\n",
      "Epoch: 2920 loss_train: 0.0192 loss_val: 0.1467\n",
      "Epoch: 2940 loss_train: 0.0171 loss_val: 0.1575\n",
      "Epoch: 2960 loss_train: 0.0179 loss_val: 0.1521\n",
      "Epoch: 2980 loss_train: 0.0205 loss_val: 0.1433\n",
      "Epoch: 3000 loss_train: 0.0181 loss_val: 0.1528\n",
      "Epoch: 3020 loss_train: 0.0198 loss_val: 0.1606\n",
      "Epoch: 3040 loss_train: 0.0185 loss_val: 0.1289\n",
      "Epoch: 3060 loss_train: 0.0187 loss_val: 0.1354\n",
      "Epoch: 3080 loss_train: 0.0158 loss_val: 0.1449\n",
      "Epoch: 3100 loss_train: 0.0181 loss_val: 0.1429\n",
      "Epoch: 3120 loss_train: 0.0169 loss_val: 0.1249\n",
      "Epoch: 3140 loss_train: 0.0183 loss_val: 0.1510\n",
      "Epoch: 3160 loss_train: 0.0183 loss_val: 0.1581\n",
      "Epoch: 3180 loss_train: 0.0193 loss_val: 0.1543\n",
      "Epoch: 3200 loss_train: 0.0183 loss_val: 0.1397\n",
      "Epoch: 3220 loss_train: 0.0172 loss_val: 0.1473\n",
      "Epoch: 3240 loss_train: 0.0202 loss_val: 0.1432\n",
      "Epoch: 3260 loss_train: 0.0176 loss_val: 0.1325\n",
      "Epoch: 3280 loss_train: 0.0180 loss_val: 0.1416\n",
      "Epoch: 3300 loss_train: 0.0178 loss_val: 0.1357\n",
      "Epoch: 3320 loss_train: 0.0184 loss_val: 0.1405\n",
      "Epoch: 3340 loss_train: 0.0190 loss_val: 0.1317\n",
      "Epoch: 3360 loss_train: 0.0192 loss_val: 0.1305\n",
      "Epoch: 3380 loss_train: 0.0182 loss_val: 0.1308\n",
      "Epoch: 3400 loss_train: 0.0163 loss_val: 0.1412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3420 loss_train: 0.0179 loss_val: 0.1562\n",
      "Epoch: 3440 loss_train: 0.0178 loss_val: 0.1088\n",
      "Epoch: 3460 loss_train: 0.0176 loss_val: 0.1561\n",
      "Epoch: 3480 loss_train: 0.0163 loss_val: 0.1389\n",
      "Epoch: 3500 loss_train: 0.0173 loss_val: 0.1372\n",
      "Epoch: 3520 loss_train: 0.0175 loss_val: 0.1286\n",
      "Epoch: 3540 loss_train: 0.0171 loss_val: 0.1266\n",
      "Epoch: 3560 loss_train: 0.0160 loss_val: 0.1418\n",
      "Epoch: 3580 loss_train: 0.0173 loss_val: 0.1370\n",
      "Epoch: 3600 loss_train: 0.0171 loss_val: 0.1394\n",
      "Epoch: 3620 loss_train: 0.0180 loss_val: 0.1605\n",
      "Epoch: 3640 loss_train: 0.0158 loss_val: 0.1679\n",
      "Epoch: 3660 loss_train: 0.0158 loss_val: 0.1464\n",
      "Epoch: 3680 loss_train: 0.0162 loss_val: 0.1792\n",
      "Epoch: 3700 loss_train: 0.0173 loss_val: 0.1426\n",
      "Epoch: 3720 loss_train: 0.0163 loss_val: 0.1516\n",
      "Epoch: 3740 loss_train: 0.0167 loss_val: 0.1597\n",
      "Epoch: 3760 loss_train: 0.0166 loss_val: 0.1611\n",
      "Epoch: 3780 loss_train: 0.0167 loss_val: 0.1687\n",
      "Epoch: 3800 loss_train: 0.0172 loss_val: 0.1539\n",
      "Epoch: 3820 loss_train: 0.0169 loss_val: 0.1577\n",
      "Epoch: 3840 loss_train: 0.0158 loss_val: 0.1443\n",
      "Epoch: 3860 loss_train: 0.0171 loss_val: 0.1469\n",
      "Epoch: 3880 loss_train: 0.0157 loss_val: 0.1319\n",
      "Epoch: 3900 loss_train: 0.0197 loss_val: 0.1437\n",
      "Epoch: 3920 loss_train: 0.0168 loss_val: 0.1337\n",
      "Epoch: 3940 loss_train: 0.0176 loss_val: 0.1611\n",
      "Epoch: 3960 loss_train: 0.0175 loss_val: 0.1509\n",
      "Epoch: 3980 loss_train: 0.0175 loss_val: 0.1573\n",
      "Epoch: 4000 loss_train: 0.0156 loss_val: 0.1642\n",
      "Epoch: 4020 loss_train: 0.0162 loss_val: 0.1625\n",
      "Epoch: 4040 loss_train: 0.0188 loss_val: 0.1649\n",
      "Epoch: 4060 loss_train: 0.0159 loss_val: 0.1625\n",
      "Epoch: 4080 loss_train: 0.0162 loss_val: 0.1596\n",
      "Epoch: 4100 loss_train: 0.0158 loss_val: 0.1684\n",
      "Epoch: 4120 loss_train: 0.0144 loss_val: 0.1683\n",
      "Epoch: 4140 loss_train: 0.0168 loss_val: 0.1661\n",
      "Epoch: 4160 loss_train: 0.0179 loss_val: 0.1529\n",
      "Epoch: 4180 loss_train: 0.0143 loss_val: 0.1490\n",
      "Epoch: 4200 loss_train: 0.0154 loss_val: 0.1542\n",
      "Epoch: 4220 loss_train: 0.0164 loss_val: 0.1609\n",
      "Epoch: 4240 loss_train: 0.0171 loss_val: 0.1427\n",
      "Epoch: 4260 loss_train: 0.0174 loss_val: 0.1503\n",
      "Epoch: 4280 loss_train: 0.0165 loss_val: 0.1426\n",
      "Epoch: 4300 loss_train: 0.0161 loss_val: 0.1460\n",
      "Epoch: 4320 loss_train: 0.0173 loss_val: 0.1421\n",
      "Epoch: 4340 loss_train: 0.0184 loss_val: 0.1519\n",
      "Epoch: 4360 loss_train: 0.0161 loss_val: 0.1576\n",
      "Epoch: 4380 loss_train: 0.0157 loss_val: 0.1809\n",
      "Epoch: 4400 loss_train: 0.0144 loss_val: 0.1690\n",
      "Epoch: 4420 loss_train: 0.0158 loss_val: 0.1493\n",
      "Epoch: 4440 loss_train: 0.0147 loss_val: 0.1454\n",
      "Epoch: 4460 loss_train: 0.0137 loss_val: 0.1408\n",
      "Epoch: 4480 loss_train: 0.0146 loss_val: 0.1355\n",
      "Epoch: 4500 loss_train: 0.0137 loss_val: 0.1373\n",
      "Epoch: 4520 loss_train: 0.0169 loss_val: 0.1511\n",
      "Epoch: 4540 loss_train: 0.0147 loss_val: 0.1387\n",
      "Epoch: 4560 loss_train: 0.0144 loss_val: 0.1632\n",
      "Epoch: 4580 loss_train: 0.0171 loss_val: 0.1542\n",
      "Epoch: 4600 loss_train: 0.0165 loss_val: 0.1562\n",
      "Epoch: 4620 loss_train: 0.0152 loss_val: 0.1682\n",
      "Epoch: 4640 loss_train: 0.0138 loss_val: 0.1758\n",
      "Epoch: 4660 loss_train: 0.0147 loss_val: 0.1790\n",
      "Epoch: 4680 loss_train: 0.0150 loss_val: 0.1465\n",
      "Epoch: 4700 loss_train: 0.0150 loss_val: 0.1551\n",
      "Epoch: 4720 loss_train: 0.0135 loss_val: 0.1587\n",
      "Epoch: 4740 loss_train: 0.0161 loss_val: 0.1472\n",
      "Epoch: 4760 loss_train: 0.0149 loss_val: 0.1719\n",
      "Epoch: 4780 loss_train: 0.0164 loss_val: 0.1715\n",
      "Epoch: 4800 loss_train: 0.0152 loss_val: 0.1694\n",
      "Epoch: 4820 loss_train: 0.0155 loss_val: 0.1752\n",
      "Epoch: 4840 loss_train: 0.0154 loss_val: 0.1749\n",
      "Epoch: 4860 loss_train: 0.0164 loss_val: 0.1930\n",
      "Epoch: 4880 loss_train: 0.0148 loss_val: 0.1915\n",
      "Epoch: 4900 loss_train: 0.0146 loss_val: 0.1667\n",
      "Epoch: 4920 loss_train: 0.0133 loss_val: 0.1921\n",
      "Epoch: 4940 loss_train: 0.0148 loss_val: 0.1758\n",
      "Epoch: 4960 loss_train: 0.0143 loss_val: 0.1934\n",
      "Epoch: 4980 loss_train: 0.0154 loss_val: 0.1948\n",
      "Epoch: 5000 loss_train: 0.0132 loss_val: 0.1900\n",
      "Epoch: 5020 loss_train: 0.0171 loss_val: 0.1687\n",
      "Epoch: 5040 loss_train: 0.0145 loss_val: 0.1737\n",
      "Epoch: 5060 loss_train: 0.0156 loss_val: 0.1610\n",
      "Epoch: 5080 loss_train: 0.0132 loss_val: 0.1886\n",
      "Epoch: 5100 loss_train: 0.0138 loss_val: 0.1733\n",
      "Epoch: 5120 loss_train: 0.0148 loss_val: 0.1791\n",
      "Epoch: 5140 loss_train: 0.0152 loss_val: 0.1758\n",
      "Epoch: 5160 loss_train: 0.0152 loss_val: 0.1783\n",
      "Epoch: 5180 loss_train: 0.0137 loss_val: 0.1739\n",
      "Epoch: 5200 loss_train: 0.0148 loss_val: 0.1583\n",
      "Epoch: 5220 loss_train: 0.0147 loss_val: 0.1899\n",
      "Epoch: 5240 loss_train: 0.0153 loss_val: 0.1495\n",
      "Epoch: 5260 loss_train: 0.0157 loss_val: 0.1564\n",
      "Epoch: 5280 loss_train: 0.0158 loss_val: 0.1627\n",
      "Epoch: 5300 loss_train: 0.0152 loss_val: 0.1840\n",
      "Epoch: 5320 loss_train: 0.0128 loss_val: 0.1789\n",
      "Epoch: 5340 loss_train: 0.0142 loss_val: 0.1672\n",
      "Epoch: 5360 loss_train: 0.0160 loss_val: 0.1618\n",
      "Epoch: 5380 loss_train: 0.0136 loss_val: 0.1501\n",
      "Epoch: 5400 loss_train: 0.0146 loss_val: 0.1742\n",
      "Epoch: 5420 loss_train: 0.0149 loss_val: 0.1745\n",
      "Epoch: 5440 loss_train: 0.0132 loss_val: 0.1747\n",
      "Epoch: 5460 loss_train: 0.0162 loss_val: 0.1739\n",
      "Epoch: 5480 loss_train: 0.0140 loss_val: 0.1785\n",
      "Epoch: 5500 loss_train: 0.0165 loss_val: 0.2018\n",
      "Epoch: 5520 loss_train: 0.0149 loss_val: 0.1926\n",
      "Epoch: 5540 loss_train: 0.0158 loss_val: 0.1893\n",
      "Epoch: 5560 loss_train: 0.0148 loss_val: 0.1900\n",
      "Epoch: 5580 loss_train: 0.0137 loss_val: 0.2100\n",
      "Epoch: 5600 loss_train: 0.0153 loss_val: 0.1812\n",
      "Epoch: 5620 loss_train: 0.0134 loss_val: 0.1854\n",
      "Epoch: 5640 loss_train: 0.0151 loss_val: 0.1803\n",
      "Epoch: 5660 loss_train: 0.0155 loss_val: 0.1577\n",
      "Epoch: 5680 loss_train: 0.0162 loss_val: 0.1816\n",
      "Epoch: 5700 loss_train: 0.0132 loss_val: 0.1853\n"
     ]
    }
   ],
   "source": [
    "pctVal=0.05\n",
    "pctTest=0.1\n",
    "\n",
    "allstats=allstats.astype(float)\n",
    "allstats=scipy.stats.zscore(allstats,axis=0,nan_policy='omit')\n",
    "allstats=np.nan_to_num(allstats,nan=0)\n",
    "\n",
    "for i in np.unique(clusterRes):\n",
    "    logsavepath_sub=os.path.join(logsavepath,str(i))\n",
    "    plotsavepath_sub=os.path.join(plotsavepath,str(i))\n",
    "    modelsavepath_sub=os.path.join(modelsavepath,str(i))\n",
    "    if not os.path.exists(logsavepath_sub):\n",
    "        os.mkdir(logsavepath_sub)\n",
    "    if not os.path.exists(modelsavepath_sub):\n",
    "        os.mkdir(modelsavepath_sub)\n",
    "    if not os.path.exists(plotsavepath_sub):\n",
    "        os.mkdir(plotsavepath_sub)\n",
    "    \n",
    "    stats_sub=allstats[alllabels==i]\n",
    "    labels_sub=alllabels_sub[alllabels==i]\n",
    "    \n",
    "    #train-test split\n",
    "    np.random.seed(3)\n",
    "    allIdx=np.arange(stats_sub.shape[0])\n",
    "    np.random.shuffle(allIdx)\n",
    "    valIdx=allIdx[:int(pctVal*stats_sub.shape[0])]\n",
    "    testIdx=allIdx[int(pctVal*stats_sub.shape[0]):(int(pctVal*stats_sub.shape[0])+int(pctTest*stats_sub.shape[0]))]\n",
    "    trainIdx=allIdx[(int(pctVal*stats_sub.shape[0])+int(pctTest*stats_sub.shape[0])):]\n",
    "    \n",
    "    trainLabels,traincounts=np.unique(labels_sub[trainIdx],return_counts=True)\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.bar(trainLabels,traincounts)\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",rotation_mode=\"anchor\")\n",
    "    plt.savefig(os.path.join(plotsavepath_sub,'labelCounts.jpg'))\n",
    "    \n",
    "    weightClf=np.zeros(traincounts.size)\n",
    "    for i in range(traincounts.size):\n",
    "        weightClf[i]=np.sum(traincounts)/traincounts[i]/10\n",
    "        \n",
    "    # Create model\n",
    "    seed=3\n",
    "    torch.manual_seed(seed)\n",
    "    nclasses=np.unique(labels_sub).size\n",
    "    if use_cuda:\n",
    "        torch.cuda.manual_seed(seed)\n",
    "\n",
    "    if model_str=='fc3':\n",
    "        model = modelsCNN.FC_l3(allstats.shape[1],fc_dim1,fc_dim2,fc_dim3,nclasses,0.5,regrs=False)\n",
    "        lossCE=torch.nn.CrossEntropyLoss(torch.tensor(weightClf).cuda().float())\n",
    "    if model_str=='fc5':\n",
    "        model = modelsCNN.FC_l5(allstats.shape[1],fc_dim1,fc_dim2,fc_dim3,fc_dim4,fc_dim5,nclasses,0.5,regrs=False)\n",
    "        lossCE=torch.nn.CrossEntropyLoss(torch.tensor(weightClf).cuda().float())\n",
    "    if model_str=='fc1':\n",
    "        model = modelsCNN.FC_l1(allstats.shape[1],fc_dim1,nclasses,regrs=False)\n",
    "        lossCE=torch.nn.CrossEntropyLoss(torch.tensor(weightClf).cuda().float())\n",
    "    if model_str=='fc0':\n",
    "        model = modelsCNN.FC_l0(allstats.shape[1],nclasses,regrs=False)\n",
    "        lossCE=torch.nn.CrossEntropyLoss(torch.tensor(weightClf).cuda().float())\n",
    "\n",
    "    if use_cuda:\n",
    "        model.cuda()\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    train_loss_ep=[None]*epochs\n",
    "    val_loss_ep=[None]*epochs\n",
    "    t_ep=time.time()\n",
    "\n",
    "    for ep in range(epochs):\n",
    "    # for ep in range(10000,20000):\n",
    "\n",
    "        train_loss_ep[ep],val_loss_ep[ep]=train(ep)\n",
    "\n",
    "\n",
    "        if ep%saveFreq == 0 and ep!=0:\n",
    "            torch.save(model.cpu().state_dict(), os.path.join(modelsavepath_sub,str(ep)+'.pt'))\n",
    "        if use_cuda:\n",
    "            model.cuda()\n",
    "            torch.cuda.empty_cache()\n",
    "    print(' total time: {:.4f}s'.format(time.time() - t_ep))\n",
    "    with open(os.path.join(logsavepath_sub,'train_loss'), 'wb') as output:\n",
    "        pickle.dump(train_loss_ep, output, pickle.HIGHEST_PROTOCOL)\n",
    "    with open(os.path.join(logsavepath_sub,'val_loss'), 'wb') as output:\n",
    "        pickle.dump(val_loss_ep, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    plt.plot(np.arange(epochs),train_loss_ep)\n",
    "    plt.plot(np.arange(epochs),val_loss_ep)\n",
    "    plt.legend(['training loss','validation loss'],loc='upper right')\n",
    "    plt.savefig(os.path.join(plotsavepath_sub,'loss_seed3.jpg'))\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot confusion\n",
    "def plotCTcomp(labels,ctlist,savepath,savenamecluster,byCT,addname=''):\n",
    "    res=np.zeros((np.unique(labels).size,np.unique(ctlist).size))\n",
    "    for li in range(res.shape[0]):\n",
    "        l=np.unique(labels)[li]\n",
    "        nl=np.sum(labels==l)\n",
    "        ctlist_l=ctlist[labels==l]\n",
    "        for ci in range(res.shape[1]):\n",
    "            c=np.unique(ctlist)[ci]\n",
    "            res[li,ci]=np.sum(ctlist_l==c)\n",
    "#             res[li,ci]=np.sum(ctlist_l==c)/nl\n",
    "    if not byCT:\n",
    "        addname+=''\n",
    "        for li in range(res.shape[0]):\n",
    "            l=np.unique(labels)[li]\n",
    "            nl=np.sum(labels==l)\n",
    "            res[li]=res[li]/nl\n",
    "    else:\n",
    "        addname+='_normbyCT'\n",
    "        for ci in range(res.shape[1]):\n",
    "            c=np.unique(ctlist)[ci]\n",
    "            nc=np.sum(ctlist==c)\n",
    "            res[:,ci]=res[:,ci]/nc\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    im = ax.imshow(res,cmap='binary')\n",
    "    fig.colorbar(im)\n",
    "    ax.set_yticks(np.arange(np.unique(labels).size))\n",
    "    ax.set_yticklabels(np.unique(labels))\n",
    "    ax.set_xticks(np.arange(np.unique(ctlist).size))\n",
    "    ax.set_xticklabels(np.unique(ctlist))\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",rotation_mode=\"anchor\")\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(os.path.join(savepath,savenamecluster+addname+'.jpg'))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "test loss: 0.18815137445926666\n",
      "train loss: 0.0006257324324299892\n",
      "1\n",
      "test loss: 0.12270431220531464\n",
      "train loss: 0.008571914921049029\n",
      "2\n",
      "test loss: 0.27827978134155273\n",
      "train loss: 0.022929694736376405\n",
      "3\n",
      "test loss: 0.13980203866958618\n",
      "train loss: 0.004088625207077712\n",
      "4\n",
      "test loss: 0.16260387003421783\n",
      "train loss: 0.0024943791989547512\n",
      "5\n",
      "test loss: 0.13074420392513275\n",
      "train loss: 0.006426195241510868\n",
      "6\n",
      "test loss: 0.28670138120651245\n",
      "train loss: 0.007038193386203299\n",
      "7\n",
      "test loss: 0.1274639517068863\n",
      "train loss: 0.0012648652860661968\n"
     ]
    }
   ],
   "source": [
    "#test loss\n",
    "ep=5800\n",
    "\n",
    "for i in np.unique(clusterRes):\n",
    "    print(i)\n",
    "    logsavepath_sub=os.path.join(logsavepath,str(i))\n",
    "    plotsavepath_sub=os.path.join(plotsavepath,str(i))\n",
    "    modelsavepath_sub=os.path.join(modelsavepath,str(i))\n",
    "    \n",
    "    stats_sub=allstats[alllabels==i]\n",
    "    labels_sub=alllabels_sub[alllabels==i]\n",
    "    \n",
    "    #train-test split\n",
    "    np.random.seed(3)\n",
    "    allIdx=np.arange(stats_sub.shape[0])\n",
    "    np.random.shuffle(allIdx)\n",
    "    valIdx=allIdx[:int(pctVal*stats_sub.shape[0])]\n",
    "    testIdx=allIdx[int(pctVal*stats_sub.shape[0]):(int(pctVal*stats_sub.shape[0])+int(pctTest*stats_sub.shape[0]))]\n",
    "    trainIdx=allIdx[(int(pctVal*stats_sub.shape[0])+int(pctTest*stats_sub.shape[0])):]\n",
    "    \n",
    "    trainLabels,traincounts=np.unique(labels_sub[trainIdx],return_counts=True)\n",
    "    weightClf=np.zeros(traincounts.size)\n",
    "    for i in range(traincounts.size):\n",
    "        weightClf[i]=np.sum(traincounts)/traincounts[i]/10\n",
    "        \n",
    "    \n",
    "    # Create model\n",
    "    seed=3\n",
    "    torch.manual_seed(seed)\n",
    "    nclasses=np.unique(labels_sub).size\n",
    "    if use_cuda:\n",
    "        torch.cuda.manual_seed(seed)\n",
    "\n",
    "    if model_str=='fc3':\n",
    "        model = modelsCNN.FC_l3(allstats.shape[1],fc_dim1,fc_dim2,fc_dim3,nclasses,0.5,regrs=False)\n",
    "        lossCE=torch.nn.CrossEntropyLoss(torch.tensor(weightClf).cuda().float())\n",
    "    if model_str=='fc5':\n",
    "        model = modelsCNN.FC_l5(allstats.shape[1],fc_dim1,fc_dim2,fc_dim3,fc_dim4,fc_dim5,nclasses,0.5,regrs=False)\n",
    "        lossCE=torch.nn.CrossEntropyLoss(torch.tensor(weightClf).cuda().float())\n",
    "    if model_str=='fc1':\n",
    "        model = modelsCNN.FC_l1(allstats.shape[1],fc_dim1,nclasses,regrs=False)\n",
    "        lossCE=torch.nn.CrossEntropyLoss(torch.tensor(weightClf).cuda().float())\n",
    "    if model_str=='fc0':\n",
    "        model = modelsCNN.FC_l0(allstats.shape[1],nclasses,regrs=False)\n",
    "        lossCE=torch.nn.CrossEntropyLoss(torch.tensor(weightClf).cuda().float())\n",
    "\n",
    "    if use_cuda:\n",
    "        model.cuda()\n",
    "        \n",
    "    model.load_state_dict(torch.load(os.path.join(modelsavepath_sub,str(ep)+'.pt')))\n",
    "    predtest=np.array([])\n",
    "    with torch.no_grad():\n",
    "        model.cuda()\n",
    "        model.eval()\n",
    "        loss_test_all=0\n",
    "        ntestBatches=int(np.ceil(testIdx.shape[0]/batchsize))\n",
    "        for i in range(ntestBatches):\n",
    "            testIdx_i=testIdx[i*batchsize:min((i+1)*batchsize,testIdx.shape[0])]\n",
    "            testInput=torch.tensor(stats_sub[testIdx_i])\n",
    "            if use_cuda:\n",
    "                testInput=testInput.cuda().float()\n",
    "                labels=torch.tensor(labels_sub[testIdx_i]).cuda().long()\n",
    "            pred = model(testInput)\n",
    "            predtest=np.concatenate((predtest,np.argmax(pred.cpu().detach().numpy(),axis=1)))\n",
    "\n",
    "            loss_test=lossCE(pred,labels).item()\n",
    "\n",
    "            loss_test_all+=loss_test\n",
    "\n",
    "        loss_test_all=loss_test_all/ntestBatches\n",
    "\n",
    "    print('test loss: '+str(loss_test_all))\n",
    "    \n",
    "    plotCTcomp(labels_sub[testIdx],predtest,plotsavepath_sub,'confusion_test',False)\n",
    "    \n",
    "    predtrain=np.array([])\n",
    "    with torch.no_grad():\n",
    "        model.cuda()\n",
    "        model.eval()\n",
    "        loss_train_all=0\n",
    "        ntrainBatches=int(np.ceil(trainIdx.shape[0]/batchsize))\n",
    "        for i in range(ntrainBatches):\n",
    "            trainIdx_i=trainIdx[i*batchsize:min((i+1)*batchsize,trainIdx.shape[0])]\n",
    "            trainInput=torch.tensor(stats_sub[trainIdx_i])\n",
    "            if use_cuda:\n",
    "                trainInput=trainInput.cuda().float()\n",
    "                labels=torch.tensor(labels_sub[trainIdx_i]).cuda().long()\n",
    "            pred = model(trainInput)\n",
    "            predtrain=np.concatenate((predtrain,np.argmax(pred.cpu().detach().numpy(),axis=1)))\n",
    "\n",
    "            loss_train=lossCE(pred,labels).item()\n",
    "\n",
    "            loss_train_all+=loss_train\n",
    "\n",
    "        loss_train_all=loss_train_all/ntrainBatches\n",
    "\n",
    "    print('train loss: '+str(loss_train_all))\n",
    "    plotCTcomp(labels_sub[trainIdx],predtrain,plotsavepath_sub,'confusion_train',False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

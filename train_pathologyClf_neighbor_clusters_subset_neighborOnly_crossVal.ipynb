{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "import scanpy\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import models.loadImg as loadImg\n",
    "import models.modelsCNN as modelsCNN\n",
    "import models.optimizer as optimizer\n",
    "\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import gc\n",
    "from skimage import io\n",
    "import scipy.stats\n",
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '3'\n",
    "use_cuda=True\n",
    "datadir='/media/xinyi/dcis2idc1/data'\n",
    "name='exp0'\n",
    "plotsavepath='/media/xinyi/dcis2idc1/plots/cnnvae'+name\n",
    "sampledir=plotsavepath\n",
    "clustersavedir_alltrain=os.path.join(sampledir,'cluster_alltrain_reordered')\n",
    "ep=311\n",
    "with open(os.path.join(datadir,'processed','train_cnnvae_names'), 'rb') as input:\n",
    "    allImgNames=pickle.load(input)\n",
    "#plot by disease progression\n",
    "br1003aSpecs=pd.read_excel('/media/xinyi/dcis2idc1/data/BR1003a specs.xlsx',header=10)\n",
    "br301Specs=pd.read_excel('/media/xinyi/dcis2idc1/data/BR301 specs.xlsx',header=10)\n",
    "br8018aSpecs=pd.read_excel('/media/xinyi/dcis2idc1/data/BR8018a specs.xlsx',header=10)\n",
    "br1003aSpecs.index=br1003aSpecs.loc[:,'Position']\n",
    "br301Specs.index=br301Specs.loc[:,'Position']\n",
    "br8018aSpecs.index=br8018aSpecs.loc[:,'Position']\n",
    "\n",
    "progList=np.copy(allImgNames)\n",
    "for s in np.unique(allImgNames):\n",
    "    ssplit=s.split('_')\n",
    "    if 'br1003a'==ssplit[0]:\n",
    "        prog_s=br1003aSpecs.loc[(ssplit[-1],'Pathology diagnosis')]\n",
    "    elif 'br301'==ssplit[0]:\n",
    "        prog_s=br301Specs.loc[(ssplit[-1],'Pathology diagnosis')]\n",
    "    elif 'br8018a'==ssplit[0]:\n",
    "        prog_s=br8018aSpecs.loc[(ssplit[-1],'Pathology diagnosis')]\n",
    "    progList[allImgNames==s]=prog_s\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5]\n",
      "[0 1 2 3 4 5]\n",
      "[0 1 2 3 4 5]\n",
      "[0 1 2 3]\n",
      "[0 1 2 3 4 5 6 7]\n",
      "[0 1 2 3]\n",
      "[0 1 2 3 4 5]\n",
      "[0 1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "savenamesample='alltrain'\n",
    "\n",
    "neworder=[1, 5, 3, 7, 2, 0, 4, 6]\n",
    "#use chosen subcluster number and save plots\n",
    "scanpy.settings.verbosity = 3\n",
    "# subcluster=8\n",
    "subclusterDict={0:[4],1:[6],2:[8],3:[6],4:[6],5:[6],6:[6],7:[4]}\n",
    "ncluster=8\n",
    "\n",
    "plotepoch=311\n",
    "clusterplotdir=os.path.join(clustersavedir_alltrain,'plots')\n",
    "n_pcs=50\n",
    "savenamecluster='minibatchkmean_ncluster'+str(ncluster)+'n_pcs'+str(n_pcs)+'epoch'+str(plotepoch)\n",
    "with open(os.path.join(clustersavedir_alltrain,'minibatchkmean_ncluster'+str(ncluster)+'n_pcs'+str(n_pcs)+'epoch'+str(plotepoch)+'_all'), 'rb') as output:\n",
    "    clusterRes=pickle.load(output)\n",
    "\n",
    "kmeans_sub=(np.zeros(clusterRes.size)-1).astype(str)\n",
    "savenameAdd='_plottingIdx_progBalanced_'+str(0)\n",
    "subclusternumbers=[4,6,8,6,6,6,6,4]\n",
    "savenamecluster='minibatchkmean_ncluster'+str(ncluster)+'n_pcs'+str(n_pcs)+'epoch'+str(plotepoch)+savenameAdd\n",
    "for cnew in np.unique(clusterRes):\n",
    "#     print('cluster'+str(c))\n",
    "    c=neworder[cnew]\n",
    "    \n",
    "    subclustersavedir_alltrain=os.path.join(clustersavedir_alltrain,savenamecluster+'_subcluster'+str(c))\n",
    "    with open(os.path.join(subclustersavedir_alltrain,'minibatchkmean_ncluster'+str(subclusternumbers[c])+'n_pcs'+str(n_pcs)+'epoch'+str(plotepoch)+'_all'), 'rb') as output:\n",
    "        subclusterRes=pickle.load(output)\n",
    "    print(np.unique(subclusterRes))\n",
    "    kmeans_sub[clusterRes==cnew]=np.char.add(np.repeat(str(cnew)+'-',subclusterRes.size),subclusterRes.astype(str))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(datadir,'processed','train_cnnvae_coord'), 'rb') as output:\n",
    "    coordlist=pickle.load(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in np.unique(progList):\n",
    "    if p=='Ductal carcinoma in situ':\n",
    "        progList[progList==p]='DCIS and breast tissue'\n",
    "    elif p=='Ductal carcinoma in situ and breast tissue':\n",
    "        progList[progList==p]='DCIS and breast tissue'\n",
    "    elif p=='Ductal carcinoma in situ with early infiltratio':\n",
    "        progList[progList==p]='DCIS with early infiltration'\n",
    "    \n",
    "    elif p=='Micropapillary type ductal carcinoma in situ wi':\n",
    "        progList[progList==p]='DCIS with early infiltration'    \n",
    "#     elif p=='Atypical hyperlasia':\n",
    "#         progList[progList==p]='Hyperplasia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "progInclude=np.array(['Breast tissue','Cancer adjacent normal breast tissue','Hyperplasia','DCIS and breast tissue',  'DCIS with early infiltration','Invasive ductal carcinoma and breast tissue','Invasive ductal carcinoma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "progIncludeIdx=np.repeat(False,progList.size)\n",
    "for p in progInclude:\n",
    "    progIncludeIdx[progList==p]=True\n",
    "    \n",
    "coordlist=coordlist[progIncludeIdx]\n",
    "allImgNames=allImgNames[progIncludeIdx]\n",
    "clusterRes=clusterRes[progIncludeIdx]\n",
    "kmeans_sub=kmeans_sub[progIncludeIdx]\n",
    "progList=progList[progIncludeIdx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breast tissue\n",
      "20\n",
      "Cancer adjacent normal breast tissue\n",
      "13\n",
      "DCIS and breast tissue\n",
      "16\n",
      "DCIS with early infiltration\n",
      "30\n",
      "Hyperplasia\n",
      "41\n",
      "Invasive ductal carcinoma\n",
      "70\n",
      "Invasive ductal carcinoma and breast tissue\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "sUnique,sidx_start=np.unique(allImgNames,return_index=True)\n",
    "progUnique,labels_train,progCounts=np.unique(progList[sidx_start],return_counts=True,return_inverse=True)\n",
    "for p in range(progUnique.size):\n",
    "    print(progUnique[p])\n",
    "    print(progCounts[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHistMatrix_clusters(labels,ctlist,nrow=ncluster,ncol=ncluster):\n",
    "    res=np.zeros((nrow,ncol))\n",
    "    for li in range(res.shape[0]):\n",
    "        l=li\n",
    "        nl=np.sum(labels==l)\n",
    "        ctlist_l=ctlist[labels==l]\n",
    "        for ci in range(res.shape[1]):\n",
    "            c=ci\n",
    "            res[l,c]=np.sum(ctlist_l==c)\n",
    "#             res[li,ci]=np.sum(ctlist_l==c)/nl\n",
    "        if nl!=0:\n",
    "            res[li]=res[li]/nl\n",
    "    return res\n",
    "\n",
    "neighborhoodSize=16*9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get neighborhood composition\n",
    "\n",
    "inputNeighborhood=np.zeros((sUnique.size,ncluster*ncluster))\n",
    "for i in range(sUnique.size):\n",
    "    imgN=sUnique[i]\n",
    "    nsamples=np.sum(allImgNames==imgN)\n",
    "    cluster_i=clusterRes[allImgNames==imgN]\n",
    "    neighbor_i=np.tile(cluster_i,(nsamples,1))\n",
    "    self_i=np.tile(cluster_i.reshape((-1,1)),(1,nsamples))\n",
    "\n",
    "    dist=pairwise_distances(coordlist[allImgNames==imgN],n_jobs=-1)\n",
    "    distIn=np.logical_and(dist<neighborhoodSize,dist>0)\n",
    "    res=getHistMatrix_clusters(self_i[distIn],neighbor_i[distIn])\n",
    "    \n",
    "    inputNeighborhood[i]=res.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,inputCounts=np.unique(allImgNames,return_counts=True)\n",
    "inputAll_train=np.concatenate((inputNeighborhood,inputCounts.reshape(-1,1)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val cores (as validation cores) and val samples (as test cores)\n",
    "clustersavedir_valcores=os.path.join(sampledir,'cluster_valcores_reordered')\n",
    "clustersavedir_valsamples=os.path.join(sampledir,'cluster_valsamples_reordered')\n",
    "\n",
    "with open(os.path.join(datadir,'processed','train_cnnvae_coord_valcores'), 'rb') as output:\n",
    "    coordlist_valcores=pickle.load(output)\n",
    "with open(os.path.join(datadir,'processed','train_cnnvae_coord_valsamples'), 'rb') as output:\n",
    "    coordlist_valsamples=pickle.load(output)\n",
    "\n",
    "savenamecluster='minibatchkmean_ncluster'+str(ncluster)+'n_pcs'+str(n_pcs)+'epoch'+str(plotepoch)\n",
    "with open(os.path.join(clustersavedir_valcores,savenamecluster+'_all'), 'rb') as output:\n",
    "    clusterRes_valcores=pickle.load(output)\n",
    "with open(os.path.join(clustersavedir_valsamples,'minibatchkmean_ncluster'+str(ncluster)+'n_pcs'+str(n_pcs)+'epoch'+str(plotepoch)+'_all'), 'rb') as output:\n",
    "    clusterRes_valsamples=pickle.load(output)\n",
    "    \n",
    "kmeans_sub_valcores=(np.zeros(clusterRes_valcores.size)-1).astype(str)\n",
    "for c in np.unique(clusterRes_valcores):\n",
    "    subclustersavedir=os.path.join(clustersavedir_valcores,savenamecluster+'_plottingIdx_progBalanced_'+str(0)+'_subcluster'+str(neworder[c]))\n",
    "    with open(os.path.join(subclustersavedir,'minibatchkmean_ncluster'+str(subclusterDict[neworder[c]][0])+'n_pcs'+str(n_pcs)+'epoch'+str(plotepoch)+'_all'), 'rb') as output:\n",
    "        subclusterRes=pickle.load(output)\n",
    "    kmeans_sub_valcores[clusterRes_valcores==c]=np.char.add(np.repeat(str(c)+'-',subclusterRes.size),subclusterRes.astype(str))\n",
    "    \n",
    "kmeans_sub_valsamples=(np.zeros(clusterRes_valsamples.size)-1).astype(str)\n",
    "for c in np.unique(clusterRes_valsamples):\n",
    "    subclustersavedir=os.path.join(clustersavedir_valsamples,savenamecluster+'_plottingIdx_progBalanced_'+str(0)+'_subcluster'+str(neworder[c]))\n",
    "    with open(os.path.join(subclustersavedir,'minibatchkmean_ncluster'+str(subclusterDict[neworder[c]][0])+'n_pcs'+str(n_pcs)+'epoch'+str(plotepoch)+'_all'), 'rb') as output:\n",
    "        subclusterRes=pickle.load(output)\n",
    "    kmeans_sub_valsamples[clusterRes_valsamples==c]=np.char.add(np.repeat(str(c)+'-',subclusterRes.size),subclusterRes.astype(str))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(datadir,'processed','train_cnnvae_names_valcores'), 'rb') as input:\n",
    "    allImgNames_valcores=pickle.load(input)\n",
    "with open(os.path.join(datadir,'processed','train_cnnvae_names_valsamples'), 'rb') as input:\n",
    "    allImgNames_valsamples=pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot by disease progression\n",
    "br1003aSpecs=pd.read_excel('/media/xinyi/dcis2idc1/data/BR1003a specs.xlsx',header=10)\n",
    "br301Specs=pd.read_excel('/media/xinyi/dcis2idc1/data/BR301 specs.xlsx',header=10)\n",
    "br8018aSpecs=pd.read_excel('/media/xinyi/dcis2idc1/data/BR8018a specs.xlsx',header=10)\n",
    "br1003aSpecs.index=br1003aSpecs.loc[:,'Position']\n",
    "br301Specs.index=br301Specs.loc[:,'Position']\n",
    "br8018aSpecs.index=br8018aSpecs.loc[:,'Position']\n",
    "\n",
    "progList_valcores=np.copy(allImgNames_valcores)\n",
    "for s in np.unique(allImgNames_valcores):\n",
    "    ssplit=s.split('_')\n",
    "    if 'br1003a'==ssplit[0]:\n",
    "        prog_s=br1003aSpecs.loc[(ssplit[-1],'Pathology diagnosis')]\n",
    "    elif 'br301'==ssplit[0]:\n",
    "        prog_s=br301Specs.loc[(ssplit[-1],'Pathology diagnosis')]\n",
    "    elif 'br8018a'==ssplit[0]:\n",
    "        prog_s=br8018aSpecs.loc[(ssplit[-1],'Pathology diagnosis')]\n",
    "    progList_valcores[allImgNames_valcores==s]=prog_s\n",
    "    \n",
    "progList_valsamples=np.copy(allImgNames_valsamples)\n",
    "for s in np.unique(allImgNames_valsamples):\n",
    "    ssplit=s.split('_')\n",
    "    if 'br1003a'==ssplit[0]:\n",
    "        prog_s=br1003aSpecs.loc[(ssplit[-1],'Pathology diagnosis')]\n",
    "    elif 'br301'==ssplit[0]:\n",
    "        prog_s=br301Specs.loc[(ssplit[-1],'Pathology diagnosis')]\n",
    "    elif 'br8018a'==ssplit[0]:\n",
    "        prog_s=br8018aSpecs.loc[(ssplit[-1],'Pathology diagnosis')]\n",
    "    progList_valsamples[allImgNames_valsamples==s]=prog_s\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in np.unique(progList_valcores):\n",
    "    if p=='Ductal carcinoma in situ':\n",
    "        progList_valcores[progList_valcores==p]='DCIS and breast tissue'\n",
    "    elif p=='Ductal carcinoma in situ and breast tissue':\n",
    "        progList_valcores[progList_valcores==p]='DCIS and breast tissue'\n",
    "    elif p=='Ductal carcinoma in situ with early infiltratio':\n",
    "        progList_valcores[progList_valcores==p]='DCIS with early infiltration'\n",
    "    \n",
    "    elif p=='Micropapillary type ductal carcinoma in situ wi':\n",
    "        progList_valcores[progList_valcores==p]='DCIS with early infiltration'    \n",
    "#     elif p=='Atypical hyperlasia':\n",
    "#         progList_valcores[progList_valcores==p]='Hyperplasia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in np.unique(progList_valsamples):\n",
    "    if p=='Ductal carcinoma in situ':\n",
    "        progList_valsamples[progList_valsamples==p]='DCIS and breast tissue'\n",
    "    elif p=='Ductal carcinoma in situ and breast tissue':\n",
    "        progList_valsamples[progList_valsamples==p]='DCIS and breast tissue'\n",
    "    elif p=='Ductal carcinoma in situ with early infiltrati':\n",
    "        progList_valsamples[progList_valsamples==p]='DCIS with early infiltration'\n",
    "    \n",
    "    elif p=='Micropapillary type ductal carcinoma in situ w':\n",
    "        progList_valsamples[progList_valsamples==p]='DCIS with early infiltration'    \n",
    "#     elif p=='Atypical hyperlasia':\n",
    "#         progList_valsamples[progList_valsamples==p]='Hyperplasia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "progIncludeIdx_valcores=np.repeat(False,progList_valcores.size)\n",
    "for p in progInclude:\n",
    "    progIncludeIdx_valcores[progList_valcores==p]=True\n",
    "    \n",
    "progIncludeIdx_valsamples=np.repeat(False,progList_valsamples.size)\n",
    "for p in progInclude:\n",
    "    progIncludeIdx_valsamples[progList_valsamples==p]=True\n",
    "    \n",
    "coordlist_valcores=coordlist_valcores[progIncludeIdx_valcores]\n",
    "allImgNames_valcores=allImgNames_valcores[progIncludeIdx_valcores]\n",
    "clusterRes_valcores=clusterRes_valcores[progIncludeIdx_valcores]\n",
    "kmeans_sub_valcores=kmeans_sub_valcores[progIncludeIdx_valcores]\n",
    "progList_valcores=progList_valcores[progIncludeIdx_valcores]\n",
    "\n",
    "coordlist_valsamples=coordlist_valsamples[progIncludeIdx_valsamples]\n",
    "allImgNames_valsamples=allImgNames_valsamples[progIncludeIdx_valsamples]\n",
    "clusterRes_valsamples=clusterRes_valsamples[progIncludeIdx_valsamples]\n",
    "kmeans_sub_valsamples=kmeans_sub_valsamples[progIncludeIdx_valsamples]\n",
    "progList_valsamples=progList_valsamples[progIncludeIdx_valsamples]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breast tissue\n",
      "20\n",
      "Cancer adjacent normal breast tissue\n",
      "1\n",
      "Hyperplasia\n",
      "35\n",
      "Invasive ductal carcinoma\n",
      "97\n"
     ]
    }
   ],
   "source": [
    "sUnique_valcores,sidx_start_valcores=np.unique(allImgNames_valcores,return_index=True)\n",
    "progUnique_valcores,progCounts_valcores=np.unique(progList_valcores[sidx_start_valcores],return_counts=True)\n",
    "for p in range(progUnique_valcores.size):\n",
    "    print(progUnique_valcores[p])\n",
    "    print(progCounts_valcores[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breast tissue\n",
      "14\n",
      "Cancer adjacent normal breast tissue\n",
      "4\n",
      "DCIS and breast tissue\n",
      "16\n",
      "DCIS with early infiltration\n",
      "29\n",
      "Hyperplasia\n",
      "25\n",
      "Invasive ductal carcinoma\n",
      "66\n",
      "Invasive ductal carcinoma and breast tissue\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "sUnique_valsamples,sidx_start_valsamples=np.unique(allImgNames_valsamples,return_index=True)\n",
    "progUnique_valsamples,progCounts_valsamples=np.unique(progList_valsamples[sidx_start_valsamples],return_counts=True)\n",
    "for p in range(progUnique_valsamples.size):\n",
    "    print(progUnique_valsamples[p])\n",
    "    print(progCounts_valsamples[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct labels\n",
    "labels_valcores=np.zeros(progList_valcores[sidx_start_valcores].size)\n",
    "for i in range(progUnique.size):\n",
    "    labels_valcores[progList_valcores[sidx_start_valcores]==progUnique[i]]=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct labels\n",
    "labels_valsamples=np.zeros(progList_valsamples[sidx_start_valsamples].size)\n",
    "for i in range(progUnique.size):\n",
    "    labels_valsamples[progList_valsamples[sidx_start_valsamples]==progUnique[i]]=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputNeighborhood_valcores=np.zeros((sUnique_valcores.size,ncluster*ncluster))\n",
    "for i in range(sUnique_valcores.size):\n",
    "    imgN=sUnique_valcores[i]\n",
    "    nsamples=np.sum(allImgNames_valcores==imgN)\n",
    "    cluster_i=clusterRes_valcores[allImgNames_valcores==imgN]\n",
    "    neighbor_i=np.tile(cluster_i,(nsamples,1))\n",
    "    self_i=np.tile(cluster_i.reshape((-1,1)),(1,nsamples))\n",
    "\n",
    "    dist=pairwise_distances(coordlist_valcores[allImgNames_valcores==imgN],n_jobs=-1)\n",
    "    distIn=np.logical_and(dist<neighborhoodSize,dist>0)\n",
    "    res=getHistMatrix_clusters(self_i[distIn],neighbor_i[distIn])\n",
    "    \n",
    "    inputNeighborhood_valcores[i]=res.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputNeighborhood_valsamples=np.zeros((sUnique_valsamples.size,ncluster*ncluster))\n",
    "for i in range(sUnique_valsamples.size):\n",
    "    imgN=sUnique_valsamples[i]\n",
    "    nsamples=np.sum(allImgNames_valsamples==imgN)\n",
    "    cluster_i=clusterRes_valsamples[allImgNames_valsamples==imgN]\n",
    "    neighbor_i=np.tile(cluster_i,(nsamples,1))\n",
    "    self_i=np.tile(cluster_i.reshape((-1,1)),(1,nsamples))\n",
    "\n",
    "    dist=pairwise_distances(coordlist_valsamples[allImgNames_valsamples==imgN],n_jobs=-1)\n",
    "    distIn=np.logical_and(dist<neighborhoodSize,dist>0)\n",
    "    res=getHistMatrix_clusters(self_i[distIn],neighbor_i[distIn])\n",
    "    \n",
    "    inputNeighborhood_valsamples[i]=res.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,inputCounts_valcores=np.unique(allImgNames_valcores,return_counts=True)\n",
    "inputAll_valcores=np.concatenate((inputNeighborhood_valcores,inputCounts_valcores.reshape(-1,1)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,inputCounts_valsamples=np.unique(allImgNames_valsamples,return_counts=True)\n",
    "inputAll_valsamples=np.concatenate((inputNeighborhood_valsamples,inputCounts_valsamples.reshape(-1,1)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate cores\n",
    "inputAll=np.concatenate((inputAll_train,np.concatenate((inputAll_valcores,inputAll_valsamples),axis=0)),axis=0)\n",
    "imgNamesAll=np.concatenate((allImgNames[sidx_start],np.concatenate((allImgNames_valcores[sidx_start_valcores],allImgNames_valsamples[sidx_start_valsamples]))))\n",
    "labelsAll=np.concatenate((labels_train,np.concatenate((labels_valcores,labels_valsamples))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,progCountsAll=np.unique(labelsAll,return_counts=True)\n",
    "weights_train=np.sum(progCountsAll)/progCountsAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img sizes\n",
    "allImgNamesAll=np.concatenate((allImgNames,np.concatenate((allImgNames_valcores,allImgNames_valsamples))))\n",
    "progListAll=np.concatenate((progList,np.concatenate((progList_valcores,progList_valsamples))))\n",
    "sidxAll=np.concatenate((sidx_start,np.concatenate((sidx_start_valcores,sidx_start_valsamples))))\n",
    "coordlistAll=np.concatenate((coordlist,np.concatenate((coordlist_valcores,coordlist_valsamples),axis=0)),axis=0)\n",
    "\n",
    "imgSizeAll={}\n",
    "for p in progUnique:\n",
    "    img_cores=allImgNamesAll[sidxAll[progListAll[sidxAll]==p]]\n",
    "    pSizes=np.zeros((img_cores.size))\n",
    "    for si in range(img_cores.size):\n",
    "        scoord=coordlistAll[allImgNamesAll==img_cores[si]]\n",
    "        hsize=np.pi*np.square(np.max(scoord[:,0])-np.min(scoord[:,0]))\n",
    "        vsize=np.pi*np.square(np.max(scoord[:,1])-np.min(scoord[:,1]))\n",
    "        pSizes[si]=min(hsize,vsize)\n",
    "    imgSizeAll[p]=pSizes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgSize_median={}\n",
    "for p in progUnique:\n",
    "    imgSize_median[p]=np.median(imgSizeAll[p])\n",
    "plt.violinplot(list(imgSizeAll.values()))\n",
    "plt.scatter(np.arange(progUnique.size)+1,list(imgSize_median.values()))\n",
    "plt.xticks(np.arange(progUnique.size)+1,list(imgSizeAll),rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(datadir,'processed','imgSizeByPath'), 'wb') as output:\n",
    "    pickle.dump(imgSize_median,output,pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(datadir,'processed','imgSizeByPath'), 'rb') as output:\n",
    "    imgSize_median=pickle.load(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize count\n",
    "with open(os.path.join(datadir,'processed','imgSizeByPath'), 'rb') as output:\n",
    "    imgSize_median=pickle.load(output)\n",
    "areaAll=np.zeros(labelsAll.size)\n",
    "for s in range(labelsAll.size):\n",
    "    areaAll[s]=imgSize_median[progUnique[labelsAll.astype(int)][s]]\n",
    "inputAll[:,-1]=inputAll[:,-1]/areaAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=3\n",
    "epochs=6000\n",
    "saveFreq=200\n",
    "lr=0.001 #initial learning rate\n",
    "weight_decay=0 \n",
    "\n",
    "# batchsize=4\n",
    "batchsize=6000\n",
    "model_str='logistic'\n",
    "\n",
    "fc_dim1=64\n",
    "fc_dim2=64\n",
    "fc_dim3=64\n",
    "\n",
    "\n",
    "dropout=0.01\n",
    "\n",
    "name='exp0_pathologyClf_neighbor_clusters_exp0_subset_neighborOnly_crossVal_countAreaNorm_logistic'\n",
    "logsavepath='/media/xinyi/dcis2idc1/log/cnnvae'+name\n",
    "modelsavepath='/media/xinyi/dcis2idc1/models/cnnvae'+name\n",
    "plotsavepath='/media/xinyi/dcis2idc1/plots/cnnvae'+name\n",
    "\n",
    "\n",
    "if not os.path.exists(logsavepath):\n",
    "    os.mkdir(logsavepath)\n",
    "if not os.path.exists(modelsavepath):\n",
    "    os.mkdir(modelsavepath)\n",
    "if not os.path.exists(plotsavepath):\n",
    "    os.mkdir(plotsavepath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputAll=scipy.stats.zscore(inputAll,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch,trainInput,labels_train):\n",
    "    t = time.time()\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    pred = model(trainInput)\n",
    "\n",
    "    loss=lossCE(pred,labels_train)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch%500==0:\n",
    "        print('Epoch: {:04d}'.format(epoch),\n",
    "              'loss_train: {:.4f}'.format(loss))\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-39-efafab4f6f48>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputAll=torch.tensor(inputAll).cuda().float()\n",
      "<ipython-input-39-efafab4f6f48>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labelsAll=torch.tensor(labelsAll).cuda().long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0000 loss_train: 2.0710\n",
      "Epoch: 0500 loss_train: 0.9134\n",
      "Epoch: 1000 loss_train: 0.7261\n",
      "Epoch: 1500 loss_train: 0.6266\n",
      "Epoch: 2000 loss_train: 0.5612\n",
      "Epoch: 2500 loss_train: 0.5126\n",
      "Epoch: 3000 loss_train: 0.4734\n",
      "Epoch: 3500 loss_train: 0.4402\n",
      "Epoch: 4000 loss_train: 0.4115\n",
      "Epoch: 4500 loss_train: 0.3861\n",
      "Epoch: 5000 loss_train: 0.3633\n",
      "Epoch: 5500 loss_train: 0.3427\n",
      " total time: 9.2363s\n",
      "0.02995162457227707\n",
      "Epoch: 0000 loss_train: 2.0712\n",
      "Epoch: 0500 loss_train: 0.9127\n",
      "Epoch: 1000 loss_train: 0.7258\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4111\n",
      "Epoch: 4500 loss_train: 0.3857\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3423\n",
      " total time: 3.2104s\n",
      "0.4176146984100342\n",
      "Epoch: 0000 loss_train: 2.0696\n",
      "Epoch: 0500 loss_train: 0.9109\n",
      "Epoch: 1000 loss_train: 0.7232\n",
      "Epoch: 1500 loss_train: 0.6235\n",
      "Epoch: 2000 loss_train: 0.5578\n",
      "Epoch: 2500 loss_train: 0.5089\n",
      "Epoch: 3000 loss_train: 0.4695\n",
      "Epoch: 3500 loss_train: 0.4362\n",
      "Epoch: 4000 loss_train: 0.4075\n",
      "Epoch: 4500 loss_train: 0.3820\n",
      "Epoch: 5000 loss_train: 0.3592\n",
      "Epoch: 5500 loss_train: 0.3386\n",
      " total time: 3.0650s\n",
      "5.744052886962891\n",
      "Epoch: 0000 loss_train: 2.0695\n",
      "Epoch: 0500 loss_train: 0.9111\n",
      "Epoch: 1000 loss_train: 0.7246\n",
      "Epoch: 1500 loss_train: 0.6257\n",
      "Epoch: 2000 loss_train: 0.5607\n",
      "Epoch: 2500 loss_train: 0.5122\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4111\n",
      "Epoch: 4500 loss_train: 0.3856\n",
      "Epoch: 5000 loss_train: 0.3627\n",
      "Epoch: 5500 loss_train: 0.3420\n",
      " total time: 3.1549s\n",
      "1.8196905851364136\n",
      "Epoch: 0000 loss_train: 2.0704\n",
      "Epoch: 0500 loss_train: 0.9131\n",
      "Epoch: 1000 loss_train: 0.7262\n",
      "Epoch: 1500 loss_train: 0.6268\n",
      "Epoch: 2000 loss_train: 0.5614\n",
      "Epoch: 2500 loss_train: 0.5127\n",
      "Epoch: 3000 loss_train: 0.4734\n",
      "Epoch: 3500 loss_train: 0.4402\n",
      "Epoch: 4000 loss_train: 0.4115\n",
      "Epoch: 4500 loss_train: 0.3861\n",
      "Epoch: 5000 loss_train: 0.3633\n",
      "Epoch: 5500 loss_train: 0.3427\n",
      " total time: 3.1382s\n",
      "0.0034110713750123978\n",
      "Epoch: 0000 loss_train: 2.0704\n",
      "Epoch: 0500 loss_train: 0.9127\n",
      "Epoch: 1000 loss_train: 0.7255\n",
      "Epoch: 1500 loss_train: 0.6260\n",
      "Epoch: 2000 loss_train: 0.5605\n",
      "Epoch: 2500 loss_train: 0.5116\n",
      "Epoch: 3000 loss_train: 0.4721\n",
      "Epoch: 3500 loss_train: 0.4389\n",
      "Epoch: 4000 loss_train: 0.4101\n",
      "Epoch: 4500 loss_train: 0.3847\n",
      "Epoch: 5000 loss_train: 0.3620\n",
      "Epoch: 5500 loss_train: 0.3415\n",
      " total time: 3.2102s\n",
      "2.387011766433716\n",
      "Epoch: 0000 loss_train: 2.0710\n",
      "Epoch: 0500 loss_train: 0.9127\n",
      "Epoch: 1000 loss_train: 0.7256\n",
      "Epoch: 1500 loss_train: 0.6262\n",
      "Epoch: 2000 loss_train: 0.5609\n",
      "Epoch: 2500 loss_train: 0.5122\n",
      "Epoch: 3000 loss_train: 0.4729\n",
      "Epoch: 3500 loss_train: 0.4398\n",
      "Epoch: 4000 loss_train: 0.4111\n",
      "Epoch: 4500 loss_train: 0.3857\n",
      "Epoch: 5000 loss_train: 0.3629\n",
      "Epoch: 5500 loss_train: 0.3423\n",
      " total time: 3.0750s\n",
      "0.40982142090797424\n",
      "Epoch: 0000 loss_train: 2.0716\n",
      "Epoch: 0500 loss_train: 0.9134\n",
      "Epoch: 1000 loss_train: 0.7263\n",
      "Epoch: 1500 loss_train: 0.6268\n",
      "Epoch: 2000 loss_train: 0.5613\n",
      "Epoch: 2500 loss_train: 0.5126\n",
      "Epoch: 3000 loss_train: 0.4734\n",
      "Epoch: 3500 loss_train: 0.4402\n",
      "Epoch: 4000 loss_train: 0.4115\n",
      "Epoch: 4500 loss_train: 0.3861\n",
      "Epoch: 5000 loss_train: 0.3633\n",
      "Epoch: 5500 loss_train: 0.3426\n",
      " total time: 3.0727s\n",
      "0.043929800391197205\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9126\n",
      "Epoch: 1000 loss_train: 0.7256\n",
      "Epoch: 1500 loss_train: 0.6261\n",
      "Epoch: 2000 loss_train: 0.5607\n",
      "Epoch: 2500 loss_train: 0.5120\n",
      "Epoch: 3000 loss_train: 0.4727\n",
      "Epoch: 3500 loss_train: 0.4396\n",
      "Epoch: 4000 loss_train: 0.4109\n",
      "Epoch: 4500 loss_train: 0.3855\n",
      "Epoch: 5000 loss_train: 0.3628\n",
      "Epoch: 5500 loss_train: 0.3421\n",
      " total time: 3.1664s\n",
      "0.9417741894721985\n",
      "Epoch: 0000 loss_train: 2.0717\n",
      "Epoch: 0500 loss_train: 0.9126\n",
      "Epoch: 1000 loss_train: 0.7254\n",
      "Epoch: 1500 loss_train: 0.6258\n",
      "Epoch: 2000 loss_train: 0.5603\n",
      "Epoch: 2500 loss_train: 0.5116\n",
      "Epoch: 3000 loss_train: 0.4723\n",
      "Epoch: 3500 loss_train: 0.4393\n",
      "Epoch: 4000 loss_train: 0.4106\n",
      "Epoch: 4500 loss_train: 0.3853\n",
      "Epoch: 5000 loss_train: 0.3626\n",
      "Epoch: 5500 loss_train: 0.3421\n",
      " total time: 3.2117s\n",
      "0.7874997854232788\n",
      "Epoch: 0000 loss_train: 2.0713\n",
      "Epoch: 0500 loss_train: 0.9133\n",
      "Epoch: 1000 loss_train: 0.7262\n",
      "Epoch: 1500 loss_train: 0.6267\n",
      "Epoch: 2000 loss_train: 0.5613\n",
      "Epoch: 2500 loss_train: 0.5127\n",
      "Epoch: 3000 loss_train: 0.4734\n",
      "Epoch: 3500 loss_train: 0.4403\n",
      "Epoch: 4000 loss_train: 0.4116\n",
      "Epoch: 4500 loss_train: 0.3862\n",
      "Epoch: 5000 loss_train: 0.3634\n",
      "Epoch: 5500 loss_train: 0.3428\n",
      " total time: 2.9987s\n",
      "0.010122982785105705\n",
      "Epoch: 0000 loss_train: 2.0703\n",
      "Epoch: 0500 loss_train: 0.9130\n",
      "Epoch: 1000 loss_train: 0.7260\n",
      "Epoch: 1500 loss_train: 0.6267\n",
      "Epoch: 2000 loss_train: 0.5613\n",
      "Epoch: 2500 loss_train: 0.5127\n",
      "Epoch: 3000 loss_train: 0.4734\n",
      "Epoch: 3500 loss_train: 0.4403\n",
      "Epoch: 4000 loss_train: 0.4115\n",
      "Epoch: 4500 loss_train: 0.3861\n",
      "Epoch: 5000 loss_train: 0.3633\n",
      "Epoch: 5500 loss_train: 0.3427\n",
      " total time: 2.9900s\n",
      "0.04004815220832825\n",
      "Epoch: 0000 loss_train: 2.0714\n",
      "Epoch: 0500 loss_train: 0.9129\n",
      "Epoch: 1000 loss_train: 0.7258\n",
      "Epoch: 1500 loss_train: 0.6263\n",
      "Epoch: 2000 loss_train: 0.5608\n",
      "Epoch: 2500 loss_train: 0.5122\n",
      "Epoch: 3000 loss_train: 0.4729\n",
      "Epoch: 3500 loss_train: 0.4398\n",
      "Epoch: 4000 loss_train: 0.4111\n",
      "Epoch: 4500 loss_train: 0.3857\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3423\n",
      " total time: 3.1122s\n",
      "0.3225806653499603\n",
      "Epoch: 0000 loss_train: 2.0709\n",
      "Epoch: 0500 loss_train: 0.9122\n",
      "Epoch: 1000 loss_train: 0.7253\n",
      "Epoch: 1500 loss_train: 0.6259\n",
      "Epoch: 2000 loss_train: 0.5605\n",
      "Epoch: 2500 loss_train: 0.5118\n",
      "Epoch: 3000 loss_train: 0.4725\n",
      "Epoch: 3500 loss_train: 0.4394\n",
      "Epoch: 4000 loss_train: 0.4107\n",
      "Epoch: 4500 loss_train: 0.3853\n",
      "Epoch: 5000 loss_train: 0.3626\n",
      "Epoch: 5500 loss_train: 0.3420\n",
      " total time: 2.9612s\n",
      "0.7064573168754578\n",
      "Epoch: 0000 loss_train: 2.0730\n",
      "Epoch: 0500 loss_train: 0.9149\n",
      "Epoch: 1000 loss_train: 0.7275\n",
      "Epoch: 1500 loss_train: 0.6277\n",
      "Epoch: 2000 loss_train: 0.5620\n",
      "Epoch: 2500 loss_train: 0.5132\n",
      "Epoch: 3000 loss_train: 0.4739\n",
      "Epoch: 3500 loss_train: 0.4407\n",
      "Epoch: 4000 loss_train: 0.4119\n",
      "Epoch: 4500 loss_train: 0.3865\n",
      "Epoch: 5000 loss_train: 0.3637\n",
      "Epoch: 5500 loss_train: 0.3430\n",
      " total time: 2.9814s\n",
      "0.13997678458690643\n",
      "Epoch: 0000 loss_train: 2.0721\n",
      "Epoch: 0500 loss_train: 0.9108\n",
      "Epoch: 1000 loss_train: 0.7223\n",
      "Epoch: 1500 loss_train: 0.6216\n",
      "Epoch: 2000 loss_train: 0.5552\n",
      "Epoch: 2500 loss_train: 0.5058\n",
      "Epoch: 3000 loss_train: 0.4660\n",
      "Epoch: 3500 loss_train: 0.4324\n",
      "Epoch: 4000 loss_train: 0.4033\n",
      "Epoch: 4500 loss_train: 0.3775\n",
      "Epoch: 5000 loss_train: 0.3546\n",
      "Epoch: 5500 loss_train: 0.3338\n",
      " total time: 3.1124s\n",
      "5.88785982131958\n",
      "Epoch: 0000 loss_train: 2.0699\n",
      "Epoch: 0500 loss_train: 0.9092\n",
      "Epoch: 1000 loss_train: 0.7224\n",
      "Epoch: 1500 loss_train: 0.6233\n",
      "Epoch: 2000 loss_train: 0.5581\n",
      "Epoch: 2500 loss_train: 0.5097\n",
      "Epoch: 3000 loss_train: 0.4709\n",
      "Epoch: 3500 loss_train: 0.4381\n",
      "Epoch: 4000 loss_train: 0.4096\n",
      "Epoch: 4500 loss_train: 0.3844\n",
      "Epoch: 5000 loss_train: 0.3617\n",
      "Epoch: 5500 loss_train: 0.3411\n",
      " total time: 3.0736s\n",
      "1.7045787572860718\n",
      "Epoch: 0000 loss_train: 2.0716\n",
      "Epoch: 0500 loss_train: 0.9120\n",
      "Epoch: 1000 loss_train: 0.7249\n",
      "Epoch: 1500 loss_train: 0.6253\n",
      "Epoch: 2000 loss_train: 0.5598\n",
      "Epoch: 2500 loss_train: 0.5111\n",
      "Epoch: 3000 loss_train: 0.4719\n",
      "Epoch: 3500 loss_train: 0.4389\n",
      "Epoch: 4000 loss_train: 0.4103\n",
      "Epoch: 4500 loss_train: 0.3850\n",
      "Epoch: 5000 loss_train: 0.3624\n",
      "Epoch: 5500 loss_train: 0.3419\n",
      " total time: 3.0585s\n",
      "0.9364603757858276\n",
      "Epoch: 0000 loss_train: 2.0725\n",
      "Epoch: 0500 loss_train: 0.9143\n",
      "Epoch: 1000 loss_train: 0.7273\n",
      "Epoch: 1500 loss_train: 0.6278\n",
      "Epoch: 2000 loss_train: 0.5622\n",
      "Epoch: 2500 loss_train: 0.5135\n",
      "Epoch: 3000 loss_train: 0.4742\n",
      "Epoch: 3500 loss_train: 0.4411\n",
      "Epoch: 4000 loss_train: 0.4123\n",
      "Epoch: 4500 loss_train: 0.3869\n",
      "Epoch: 5000 loss_train: 0.3641\n",
      "Epoch: 5500 loss_train: 0.3434\n",
      " total time: 3.0585s\n",
      "0.013066384010016918\n",
      "Epoch: 0000 loss_train: 2.0707\n",
      "Epoch: 0500 loss_train: 0.9137\n",
      "Epoch: 1000 loss_train: 0.7267\n",
      "Epoch: 1500 loss_train: 0.6271\n",
      "Epoch: 2000 loss_train: 0.5616\n",
      "Epoch: 2500 loss_train: 0.5129\n",
      "Epoch: 3000 loss_train: 0.4737\n",
      "Epoch: 3500 loss_train: 0.4406\n",
      "Epoch: 4000 loss_train: 0.4119\n",
      "Epoch: 4500 loss_train: 0.3865\n",
      "Epoch: 5000 loss_train: 0.3638\n",
      "Epoch: 5500 loss_train: 0.3431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " total time: 3.0294s\n",
      "0.014234201051294804\n",
      "Epoch: 0000 loss_train: 2.0709\n",
      "Epoch: 0500 loss_train: 0.9129\n",
      "Epoch: 1000 loss_train: 0.7257\n",
      "Epoch: 1500 loss_train: 0.6263\n",
      "Epoch: 2000 loss_train: 0.5607\n",
      "Epoch: 2500 loss_train: 0.5119\n",
      "Epoch: 3000 loss_train: 0.4724\n",
      "Epoch: 3500 loss_train: 0.4391\n",
      "Epoch: 4000 loss_train: 0.4101\n",
      "Epoch: 4500 loss_train: 0.3844\n",
      "Epoch: 5000 loss_train: 0.3613\n",
      "Epoch: 5500 loss_train: 0.3403\n",
      " total time: 3.0087s\n",
      "3.4868245124816895\n",
      "Epoch: 0000 loss_train: 2.0711\n",
      "Epoch: 0500 loss_train: 0.9131\n",
      "Epoch: 1000 loss_train: 0.7262\n",
      "Epoch: 1500 loss_train: 0.6267\n",
      "Epoch: 2000 loss_train: 0.5612\n",
      "Epoch: 2500 loss_train: 0.5125\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3423\n",
      " total time: 2.9918s\n",
      "0.3474266827106476\n",
      "Epoch: 0000 loss_train: 2.0707\n",
      "Epoch: 0500 loss_train: 0.9107\n",
      "Epoch: 1000 loss_train: 0.7233\n",
      "Epoch: 1500 loss_train: 0.6235\n",
      "Epoch: 2000 loss_train: 0.5579\n",
      "Epoch: 2500 loss_train: 0.5092\n",
      "Epoch: 3000 loss_train: 0.4699\n",
      "Epoch: 3500 loss_train: 0.4368\n",
      "Epoch: 4000 loss_train: 0.4081\n",
      "Epoch: 4500 loss_train: 0.3827\n",
      "Epoch: 5000 loss_train: 0.3599\n",
      "Epoch: 5500 loss_train: 0.3392\n",
      " total time: 3.0401s\n",
      "4.071272373199463\n",
      "Epoch: 0000 loss_train: 2.0710\n",
      "Epoch: 0500 loss_train: 0.9119\n",
      "Epoch: 1000 loss_train: 0.7243\n",
      "Epoch: 1500 loss_train: 0.6246\n",
      "Epoch: 2000 loss_train: 0.5590\n",
      "Epoch: 2500 loss_train: 0.5103\n",
      "Epoch: 3000 loss_train: 0.4711\n",
      "Epoch: 3500 loss_train: 0.4380\n",
      "Epoch: 4000 loss_train: 0.4094\n",
      "Epoch: 4500 loss_train: 0.3841\n",
      "Epoch: 5000 loss_train: 0.3615\n",
      "Epoch: 5500 loss_train: 0.3411\n",
      " total time: 3.0016s\n",
      "2.2970197200775146\n",
      "Epoch: 0000 loss_train: 2.0709\n",
      "Epoch: 0500 loss_train: 0.9108\n",
      "Epoch: 1000 loss_train: 0.7236\n",
      "Epoch: 1500 loss_train: 0.6247\n",
      "Epoch: 2000 loss_train: 0.5597\n",
      "Epoch: 2500 loss_train: 0.5112\n",
      "Epoch: 3000 loss_train: 0.4720\n",
      "Epoch: 3500 loss_train: 0.4389\n",
      "Epoch: 4000 loss_train: 0.4101\n",
      "Epoch: 4500 loss_train: 0.3847\n",
      "Epoch: 5000 loss_train: 0.3619\n",
      "Epoch: 5500 loss_train: 0.3413\n",
      " total time: 3.0589s\n",
      "2.3500404357910156\n",
      "Epoch: 0000 loss_train: 2.0694\n",
      "Epoch: 0500 loss_train: 0.9091\n",
      "Epoch: 1000 loss_train: 0.7220\n",
      "Epoch: 1500 loss_train: 0.6231\n",
      "Epoch: 2000 loss_train: 0.5582\n",
      "Epoch: 2500 loss_train: 0.5101\n",
      "Epoch: 3000 loss_train: 0.4713\n",
      "Epoch: 3500 loss_train: 0.4386\n",
      "Epoch: 4000 loss_train: 0.4101\n",
      "Epoch: 4500 loss_train: 0.3849\n",
      "Epoch: 5000 loss_train: 0.3623\n",
      "Epoch: 5500 loss_train: 0.3418\n",
      " total time: 2.9595s\n",
      "2.5492868423461914\n",
      "Epoch: 0000 loss_train: 2.0690\n",
      "Epoch: 0500 loss_train: 0.9111\n",
      "Epoch: 1000 loss_train: 0.7242\n",
      "Epoch: 1500 loss_train: 0.6241\n",
      "Epoch: 2000 loss_train: 0.5578\n",
      "Epoch: 2500 loss_train: 0.5082\n",
      "Epoch: 3000 loss_train: 0.4681\n",
      "Epoch: 3500 loss_train: 0.4343\n",
      "Epoch: 4000 loss_train: 0.4048\n",
      "Epoch: 4500 loss_train: 0.3786\n",
      "Epoch: 5000 loss_train: 0.3551\n",
      "Epoch: 5500 loss_train: 0.3338\n",
      " total time: 2.9926s\n",
      "15.84640884399414\n",
      "Epoch: 0000 loss_train: 2.0698\n",
      "Epoch: 0500 loss_train: 0.9110\n",
      "Epoch: 1000 loss_train: 0.7252\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5612\n",
      "Epoch: 2500 loss_train: 0.5126\n",
      "Epoch: 3000 loss_train: 0.4734\n",
      "Epoch: 3500 loss_train: 0.4403\n",
      "Epoch: 4000 loss_train: 0.4116\n",
      "Epoch: 4500 loss_train: 0.3862\n",
      "Epoch: 5000 loss_train: 0.3634\n",
      "Epoch: 5500 loss_train: 0.3427\n",
      " total time: 3.0297s\n",
      "0.1877841204404831\n",
      "Epoch: 0000 loss_train: 2.0707\n",
      "Epoch: 0500 loss_train: 0.9133\n",
      "Epoch: 1000 loss_train: 0.7263\n",
      "Epoch: 1500 loss_train: 0.6267\n",
      "Epoch: 2000 loss_train: 0.5612\n",
      "Epoch: 2500 loss_train: 0.5125\n",
      "Epoch: 3000 loss_train: 0.4733\n",
      "Epoch: 3500 loss_train: 0.4401\n",
      "Epoch: 4000 loss_train: 0.4114\n",
      "Epoch: 4500 loss_train: 0.3860\n",
      "Epoch: 5000 loss_train: 0.3632\n",
      "Epoch: 5500 loss_train: 0.3426\n",
      " total time: 2.9282s\n",
      "0.04722350463271141\n",
      "Epoch: 0000 loss_train: 2.0714\n",
      "Epoch: 0500 loss_train: 0.9124\n",
      "Epoch: 1000 loss_train: 0.7248\n",
      "Epoch: 1500 loss_train: 0.6248\n",
      "Epoch: 2000 loss_train: 0.5590\n",
      "Epoch: 2500 loss_train: 0.5101\n",
      "Epoch: 3000 loss_train: 0.4708\n",
      "Epoch: 3500 loss_train: 0.4376\n",
      "Epoch: 4000 loss_train: 0.4088\n",
      "Epoch: 4500 loss_train: 0.3834\n",
      "Epoch: 5000 loss_train: 0.3607\n",
      "Epoch: 5500 loss_train: 0.3401\n",
      " total time: 2.9067s\n",
      "4.626437187194824\n",
      "Epoch: 0000 loss_train: 2.0713\n",
      "Epoch: 0500 loss_train: 0.9131\n",
      "Epoch: 1000 loss_train: 0.7260\n",
      "Epoch: 1500 loss_train: 0.6266\n",
      "Epoch: 2000 loss_train: 0.5612\n",
      "Epoch: 2500 loss_train: 0.5125\n",
      "Epoch: 3000 loss_train: 0.4733\n",
      "Epoch: 3500 loss_train: 0.4402\n",
      "Epoch: 4000 loss_train: 0.4115\n",
      "Epoch: 4500 loss_train: 0.3861\n",
      "Epoch: 5000 loss_train: 0.3634\n",
      "Epoch: 5500 loss_train: 0.3427\n",
      " total time: 2.9078s\n",
      "0.0618758499622345\n",
      "Epoch: 0000 loss_train: 2.0698\n",
      "Epoch: 0500 loss_train: 0.9129\n",
      "Epoch: 1000 loss_train: 0.7257\n",
      "Epoch: 1500 loss_train: 0.6262\n",
      "Epoch: 2000 loss_train: 0.5606\n",
      "Epoch: 2500 loss_train: 0.5119\n",
      "Epoch: 3000 loss_train: 0.4726\n",
      "Epoch: 3500 loss_train: 0.4395\n",
      "Epoch: 4000 loss_train: 0.4108\n",
      "Epoch: 4500 loss_train: 0.3854\n",
      "Epoch: 5000 loss_train: 0.3626\n",
      "Epoch: 5500 loss_train: 0.3420\n",
      " total time: 2.8810s\n",
      "0.9206255674362183\n",
      "Epoch: 0000 loss_train: 2.0711\n",
      "Epoch: 0500 loss_train: 0.9120\n",
      "Epoch: 1000 loss_train: 0.7251\n",
      "Epoch: 1500 loss_train: 0.6255\n",
      "Epoch: 2000 loss_train: 0.5600\n",
      "Epoch: 2500 loss_train: 0.5113\n",
      "Epoch: 3000 loss_train: 0.4721\n",
      "Epoch: 3500 loss_train: 0.4389\n",
      "Epoch: 4000 loss_train: 0.4100\n",
      "Epoch: 4500 loss_train: 0.3846\n",
      "Epoch: 5000 loss_train: 0.3617\n",
      "Epoch: 5500 loss_train: 0.3410\n",
      " total time: 2.8519s\n",
      "1.9936028718948364\n",
      "Epoch: 0000 loss_train: 2.0703\n",
      "Epoch: 0500 loss_train: 0.9114\n",
      "Epoch: 1000 loss_train: 0.7248\n",
      "Epoch: 1500 loss_train: 0.6259\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5125\n",
      "Epoch: 3000 loss_train: 0.4734\n",
      "Epoch: 3500 loss_train: 0.4402\n",
      "Epoch: 4000 loss_train: 0.4114\n",
      "Epoch: 4500 loss_train: 0.3859\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3422\n",
      " total time: 2.8824s\n",
      "0.5686203241348267\n",
      "Epoch: 0000 loss_train: 2.0720\n",
      "Epoch: 0500 loss_train: 0.9150\n",
      "Epoch: 1000 loss_train: 0.7276\n",
      "Epoch: 1500 loss_train: 0.6278\n",
      "Epoch: 2000 loss_train: 0.5622\n",
      "Epoch: 2500 loss_train: 0.5134\n",
      "Epoch: 3000 loss_train: 0.4741\n",
      "Epoch: 3500 loss_train: 0.4409\n",
      "Epoch: 4000 loss_train: 0.4121\n",
      "Epoch: 4500 loss_train: 0.3867\n",
      "Epoch: 5000 loss_train: 0.3639\n",
      "Epoch: 5500 loss_train: 0.3432\n",
      " total time: 2.9262s\n",
      "0.019855434074997902\n",
      "Epoch: 0000 loss_train: 2.0722\n",
      "Epoch: 0500 loss_train: 0.9112\n",
      "Epoch: 1000 loss_train: 0.7236\n",
      "Epoch: 1500 loss_train: 0.6243\n",
      "Epoch: 2000 loss_train: 0.5591\n",
      "Epoch: 2500 loss_train: 0.5106\n",
      "Epoch: 3000 loss_train: 0.4715\n",
      "Epoch: 3500 loss_train: 0.4384\n",
      "Epoch: 4000 loss_train: 0.4097\n",
      "Epoch: 4500 loss_train: 0.3844\n",
      "Epoch: 5000 loss_train: 0.3617\n",
      "Epoch: 5500 loss_train: 0.3411\n",
      " total time: 2.8454s\n",
      "1.6858000755310059\n",
      "Epoch: 0000 loss_train: 2.0700\n",
      "Epoch: 0500 loss_train: 0.9111\n",
      "Epoch: 1000 loss_train: 0.7245\n",
      "Epoch: 1500 loss_train: 0.6248\n",
      "Epoch: 2000 loss_train: 0.5591\n",
      "Epoch: 2500 loss_train: 0.5103\n",
      "Epoch: 3000 loss_train: 0.4710\n",
      "Epoch: 3500 loss_train: 0.4379\n",
      "Epoch: 4000 loss_train: 0.4093\n",
      "Epoch: 4500 loss_train: 0.3840\n",
      "Epoch: 5000 loss_train: 0.3613\n",
      "Epoch: 5500 loss_train: 0.3407\n",
      " total time: 2.9252s\n",
      "1.487009882926941\n",
      "Epoch: 0000 loss_train: 2.0714\n",
      "Epoch: 0500 loss_train: 0.9129\n",
      "Epoch: 1000 loss_train: 0.7260\n",
      "Epoch: 1500 loss_train: 0.6267\n",
      "Epoch: 2000 loss_train: 0.5612\n",
      "Epoch: 2500 loss_train: 0.5126\n",
      "Epoch: 3000 loss_train: 0.4734\n",
      "Epoch: 3500 loss_train: 0.4403\n",
      "Epoch: 4000 loss_train: 0.4117\n",
      "Epoch: 4500 loss_train: 0.3864\n",
      "Epoch: 5000 loss_train: 0.3637\n",
      "Epoch: 5500 loss_train: 0.3431\n",
      " total time: 2.9411s\n",
      "0.19813576340675354\n",
      "Epoch: 0000 loss_train: 2.0714\n",
      "Epoch: 0500 loss_train: 0.9138\n",
      "Epoch: 1000 loss_train: 0.7271\n",
      "Epoch: 1500 loss_train: 0.6276\n",
      "Epoch: 2000 loss_train: 0.5622\n",
      "Epoch: 2500 loss_train: 0.5134\n",
      "Epoch: 3000 loss_train: 0.4741\n",
      "Epoch: 3500 loss_train: 0.4410\n",
      "Epoch: 4000 loss_train: 0.4122\n",
      "Epoch: 4500 loss_train: 0.3868\n",
      "Epoch: 5000 loss_train: 0.3640\n",
      "Epoch: 5500 loss_train: 0.3433\n",
      " total time: 2.9023s\n",
      "0.027224645018577576\n",
      "Epoch: 0000 loss_train: 2.0699\n",
      "Epoch: 0500 loss_train: 0.9138\n",
      "Epoch: 1000 loss_train: 0.7265\n",
      "Epoch: 1500 loss_train: 0.6270\n",
      "Epoch: 2000 loss_train: 0.5615\n",
      "Epoch: 2500 loss_train: 0.5127\n",
      "Epoch: 3000 loss_train: 0.4735\n",
      "Epoch: 3500 loss_train: 0.4404\n",
      "Epoch: 4000 loss_train: 0.4117\n",
      "Epoch: 4500 loss_train: 0.3863\n",
      "Epoch: 5000 loss_train: 0.3635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5500 loss_train: 0.3429\n",
      " total time: 2.9528s\n",
      "0.0401199571788311\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9094\n",
      "Epoch: 1000 loss_train: 0.7212\n",
      "Epoch: 1500 loss_train: 0.6207\n",
      "Epoch: 2000 loss_train: 0.5543\n",
      "Epoch: 2500 loss_train: 0.5050\n",
      "Epoch: 3000 loss_train: 0.4654\n",
      "Epoch: 3500 loss_train: 0.4322\n",
      "Epoch: 4000 loss_train: 0.4036\n",
      "Epoch: 4500 loss_train: 0.3785\n",
      "Epoch: 5000 loss_train: 0.3560\n",
      "Epoch: 5500 loss_train: 0.3357\n",
      " total time: 3.0855s\n",
      "12.722186088562012\n",
      "Epoch: 0000 loss_train: 2.0707\n",
      "Epoch: 0500 loss_train: 0.9136\n",
      "Epoch: 1000 loss_train: 0.7265\n",
      "Epoch: 1500 loss_train: 0.6270\n",
      "Epoch: 2000 loss_train: 0.5615\n",
      "Epoch: 2500 loss_train: 0.5127\n",
      "Epoch: 3000 loss_train: 0.4734\n",
      "Epoch: 3500 loss_train: 0.4403\n",
      "Epoch: 4000 loss_train: 0.4115\n",
      "Epoch: 4500 loss_train: 0.3861\n",
      "Epoch: 5000 loss_train: 0.3633\n",
      "Epoch: 5500 loss_train: 0.3427\n",
      " total time: 3.1136s\n",
      "0.00014804698002990335\n",
      "Epoch: 0000 loss_train: 2.0712\n",
      "Epoch: 0500 loss_train: 0.9126\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6266\n",
      "Epoch: 2000 loss_train: 0.5613\n",
      "Epoch: 2500 loss_train: 0.5126\n",
      "Epoch: 3000 loss_train: 0.4735\n",
      "Epoch: 3500 loss_train: 0.4404\n",
      "Epoch: 4000 loss_train: 0.4117\n",
      "Epoch: 4500 loss_train: 0.3863\n",
      "Epoch: 5000 loss_train: 0.3635\n",
      "Epoch: 5500 loss_train: 0.3429\n",
      " total time: 3.0849s\n",
      "0.02630520798265934\n",
      "Epoch: 0000 loss_train: 2.0707\n",
      "Epoch: 0500 loss_train: 0.9103\n",
      "Epoch: 1000 loss_train: 0.7232\n",
      "Epoch: 1500 loss_train: 0.6237\n",
      "Epoch: 2000 loss_train: 0.5581\n",
      "Epoch: 2500 loss_train: 0.5093\n",
      "Epoch: 3000 loss_train: 0.4699\n",
      "Epoch: 3500 loss_train: 0.4366\n",
      "Epoch: 4000 loss_train: 0.4076\n",
      "Epoch: 4500 loss_train: 0.3819\n",
      "Epoch: 5000 loss_train: 0.3588\n",
      "Epoch: 5500 loss_train: 0.3378\n",
      " total time: 3.0110s\n",
      "5.76715087890625\n",
      "Epoch: 0000 loss_train: 2.0695\n",
      "Epoch: 0500 loss_train: 0.9133\n",
      "Epoch: 1000 loss_train: 0.7262\n",
      "Epoch: 1500 loss_train: 0.6266\n",
      "Epoch: 2000 loss_train: 0.5612\n",
      "Epoch: 2500 loss_train: 0.5125\n",
      "Epoch: 3000 loss_train: 0.4732\n",
      "Epoch: 3500 loss_train: 0.4401\n",
      "Epoch: 4000 loss_train: 0.4114\n",
      "Epoch: 4500 loss_train: 0.3860\n",
      "Epoch: 5000 loss_train: 0.3633\n",
      "Epoch: 5500 loss_train: 0.3426\n",
      " total time: 3.0305s\n",
      "0.0033295690082013607\n",
      "Epoch: 0000 loss_train: 2.0709\n",
      "Epoch: 0500 loss_train: 0.9117\n",
      "Epoch: 1000 loss_train: 0.7239\n",
      "Epoch: 1500 loss_train: 0.6239\n",
      "Epoch: 2000 loss_train: 0.5581\n",
      "Epoch: 2500 loss_train: 0.5093\n",
      "Epoch: 3000 loss_train: 0.4699\n",
      "Epoch: 3500 loss_train: 0.4367\n",
      "Epoch: 4000 loss_train: 0.4079\n",
      "Epoch: 4500 loss_train: 0.3825\n",
      "Epoch: 5000 loss_train: 0.3598\n",
      "Epoch: 5500 loss_train: 0.3392\n",
      " total time: 3.0310s\n",
      "4.32271146774292\n",
      "Epoch: 0000 loss_train: 2.0712\n",
      "Epoch: 0500 loss_train: 0.9095\n",
      "Epoch: 1000 loss_train: 0.7214\n",
      "Epoch: 1500 loss_train: 0.6210\n",
      "Epoch: 2000 loss_train: 0.5549\n",
      "Epoch: 2500 loss_train: 0.5060\n",
      "Epoch: 3000 loss_train: 0.4668\n",
      "Epoch: 3500 loss_train: 0.4339\n",
      "Epoch: 4000 loss_train: 0.4054\n",
      "Epoch: 4500 loss_train: 0.3803\n",
      "Epoch: 5000 loss_train: 0.3578\n",
      "Epoch: 5500 loss_train: 0.3374\n",
      " total time: 3.0986s\n",
      "9.519997596740723\n",
      "Epoch: 0000 loss_train: 2.0707\n",
      "Epoch: 0500 loss_train: 0.9124\n",
      "Epoch: 1000 loss_train: 0.7248\n",
      "Epoch: 1500 loss_train: 0.6248\n",
      "Epoch: 2000 loss_train: 0.5592\n",
      "Epoch: 2500 loss_train: 0.5104\n",
      "Epoch: 3000 loss_train: 0.4713\n",
      "Epoch: 3500 loss_train: 0.4382\n",
      "Epoch: 4000 loss_train: 0.4096\n",
      "Epoch: 4500 loss_train: 0.3843\n",
      "Epoch: 5000 loss_train: 0.3616\n",
      "Epoch: 5500 loss_train: 0.3409\n",
      " total time: 2.9268s\n",
      "3.065553903579712\n",
      "Epoch: 0000 loss_train: 2.0711\n",
      "Epoch: 0500 loss_train: 0.9131\n",
      "Epoch: 1000 loss_train: 0.7257\n",
      "Epoch: 1500 loss_train: 0.6261\n",
      "Epoch: 2000 loss_train: 0.5605\n",
      "Epoch: 2500 loss_train: 0.5118\n",
      "Epoch: 3000 loss_train: 0.4725\n",
      "Epoch: 3500 loss_train: 0.4393\n",
      "Epoch: 4000 loss_train: 0.4106\n",
      "Epoch: 4500 loss_train: 0.3852\n",
      "Epoch: 5000 loss_train: 0.3625\n",
      "Epoch: 5500 loss_train: 0.3419\n",
      " total time: 2.9970s\n",
      "1.0790627002716064\n",
      "Epoch: 0000 loss_train: 2.0714\n",
      "Epoch: 0500 loss_train: 0.9134\n",
      "Epoch: 1000 loss_train: 0.7267\n",
      "Epoch: 1500 loss_train: 0.6271\n",
      "Epoch: 2000 loss_train: 0.5614\n",
      "Epoch: 2500 loss_train: 0.5126\n",
      "Epoch: 3000 loss_train: 0.4733\n",
      "Epoch: 3500 loss_train: 0.4401\n",
      "Epoch: 4000 loss_train: 0.4113\n",
      "Epoch: 4500 loss_train: 0.3859\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 2.9570s\n",
      "1.4246022701263428\n",
      "Epoch: 0000 loss_train: 2.0706\n",
      "Epoch: 0500 loss_train: 0.9121\n",
      "Epoch: 1000 loss_train: 0.7249\n",
      "Epoch: 1500 loss_train: 0.6257\n",
      "Epoch: 2000 loss_train: 0.5605\n",
      "Epoch: 2500 loss_train: 0.5120\n",
      "Epoch: 3000 loss_train: 0.4729\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 2.9790s\n",
      "0.290034681558609\n",
      "Epoch: 0000 loss_train: 2.0716\n",
      "Epoch: 0500 loss_train: 0.9134\n",
      "Epoch: 1000 loss_train: 0.7265\n",
      "Epoch: 1500 loss_train: 0.6269\n",
      "Epoch: 2000 loss_train: 0.5613\n",
      "Epoch: 2500 loss_train: 0.5126\n",
      "Epoch: 3000 loss_train: 0.4733\n",
      "Epoch: 3500 loss_train: 0.4401\n",
      "Epoch: 4000 loss_train: 0.4114\n",
      "Epoch: 4500 loss_train: 0.3860\n",
      "Epoch: 5000 loss_train: 0.3632\n",
      "Epoch: 5500 loss_train: 0.3426\n",
      " total time: 3.0301s\n",
      "0.03872182220220566\n",
      "Epoch: 0000 loss_train: 2.0712\n",
      "Epoch: 0500 loss_train: 0.9122\n",
      "Epoch: 1000 loss_train: 0.7252\n",
      "Epoch: 1500 loss_train: 0.6258\n",
      "Epoch: 2000 loss_train: 0.5604\n",
      "Epoch: 2500 loss_train: 0.5117\n",
      "Epoch: 3000 loss_train: 0.4725\n",
      "Epoch: 3500 loss_train: 0.4394\n",
      "Epoch: 4000 loss_train: 0.4107\n",
      "Epoch: 4500 loss_train: 0.3853\n",
      "Epoch: 5000 loss_train: 0.3625\n",
      "Epoch: 5500 loss_train: 0.3419\n",
      " total time: 2.9007s\n",
      "0.7437431216239929\n",
      "Epoch: 0000 loss_train: 2.0712\n",
      "Epoch: 0500 loss_train: 0.9129\n",
      "Epoch: 1000 loss_train: 0.7258\n",
      "Epoch: 1500 loss_train: 0.6262\n",
      "Epoch: 2000 loss_train: 0.5608\n",
      "Epoch: 2500 loss_train: 0.5121\n",
      "Epoch: 3000 loss_train: 0.4729\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4113\n",
      "Epoch: 4500 loss_train: 0.3860\n",
      "Epoch: 5000 loss_train: 0.3633\n",
      "Epoch: 5500 loss_train: 0.3427\n",
      " total time: 2.8828s\n",
      "0.5289323925971985\n",
      "Epoch: 0000 loss_train: 2.0709\n",
      "Epoch: 0500 loss_train: 0.9124\n",
      "Epoch: 1000 loss_train: 0.7258\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5609\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4113\n",
      "Epoch: 4500 loss_train: 0.3859\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 2.9813s\n",
      "0.1931346207857132\n",
      "Epoch: 0000 loss_train: 2.0718\n",
      "Epoch: 0500 loss_train: 0.9148\n",
      "Epoch: 1000 loss_train: 0.7275\n",
      "Epoch: 1500 loss_train: 0.6278\n",
      "Epoch: 2000 loss_train: 0.5622\n",
      "Epoch: 2500 loss_train: 0.5134\n",
      "Epoch: 3000 loss_train: 0.4741\n",
      "Epoch: 3500 loss_train: 0.4409\n",
      "Epoch: 4000 loss_train: 0.4121\n",
      "Epoch: 4500 loss_train: 0.3867\n",
      "Epoch: 5000 loss_train: 0.3639\n",
      "Epoch: 5500 loss_train: 0.3432\n",
      " total time: 3.0840s\n",
      "7.617183291586116e-05\n",
      "Epoch: 0000 loss_train: 2.0727\n",
      "Epoch: 0500 loss_train: 0.9140\n",
      "Epoch: 1000 loss_train: 0.7268\n",
      "Epoch: 1500 loss_train: 0.6272\n",
      "Epoch: 2000 loss_train: 0.5617\n",
      "Epoch: 2500 loss_train: 0.5130\n",
      "Epoch: 3000 loss_train: 0.4737\n",
      "Epoch: 3500 loss_train: 0.4406\n",
      "Epoch: 4000 loss_train: 0.4118\n",
      "Epoch: 4500 loss_train: 0.3864\n",
      "Epoch: 5000 loss_train: 0.3636\n",
      "Epoch: 5500 loss_train: 0.3430\n",
      " total time: 3.1453s\n",
      "0.10690003633499146\n",
      "Epoch: 0000 loss_train: 2.0720\n",
      "Epoch: 0500 loss_train: 0.9142\n",
      "Epoch: 1000 loss_train: 0.7273\n",
      "Epoch: 1500 loss_train: 0.6277\n",
      "Epoch: 2000 loss_train: 0.5621\n",
      "Epoch: 2500 loss_train: 0.5133\n",
      "Epoch: 3000 loss_train: 0.4740\n",
      "Epoch: 3500 loss_train: 0.4409\n",
      "Epoch: 4000 loss_train: 0.4121\n",
      "Epoch: 4500 loss_train: 0.3867\n",
      "Epoch: 5000 loss_train: 0.3638\n",
      "Epoch: 5500 loss_train: 0.3432\n",
      " total time: 3.2126s\n",
      "0.0024412849452346563\n",
      "Epoch: 0000 loss_train: 2.0729\n",
      "Epoch: 0500 loss_train: 0.9140\n",
      "Epoch: 1000 loss_train: 0.7265\n",
      "Epoch: 1500 loss_train: 0.6267\n",
      "Epoch: 2000 loss_train: 0.5611\n",
      "Epoch: 2500 loss_train: 0.5124\n",
      "Epoch: 3000 loss_train: 0.4733\n",
      "Epoch: 3500 loss_train: 0.4403\n",
      "Epoch: 4000 loss_train: 0.4117\n",
      "Epoch: 4500 loss_train: 0.3865\n",
      "Epoch: 5000 loss_train: 0.3638\n",
      "Epoch: 5500 loss_train: 0.3432\n",
      " total time: 3.3364s\n",
      "0.31119304895401\n",
      "Epoch: 0000 loss_train: 2.0721\n",
      "Epoch: 0500 loss_train: 0.9133\n",
      "Epoch: 1000 loss_train: 0.7258\n",
      "Epoch: 1500 loss_train: 0.6259\n",
      "Epoch: 2000 loss_train: 0.5601\n",
      "Epoch: 2500 loss_train: 0.5111\n",
      "Epoch: 3000 loss_train: 0.4718\n",
      "Epoch: 3500 loss_train: 0.4386\n",
      "Epoch: 4000 loss_train: 0.4098\n",
      "Epoch: 4500 loss_train: 0.3844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 loss_train: 0.3616\n",
      "Epoch: 5500 loss_train: 0.3410\n",
      " total time: 3.1199s\n",
      "2.9257853031158447\n",
      "Epoch: 0000 loss_train: 2.0715\n",
      "Epoch: 0500 loss_train: 0.9146\n",
      "Epoch: 1000 loss_train: 0.7268\n",
      "Epoch: 1500 loss_train: 0.6268\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5121\n",
      "Epoch: 3000 loss_train: 0.4727\n",
      "Epoch: 3500 loss_train: 0.4395\n",
      "Epoch: 4000 loss_train: 0.4107\n",
      "Epoch: 4500 loss_train: 0.3853\n",
      "Epoch: 5000 loss_train: 0.3625\n",
      "Epoch: 5500 loss_train: 0.3419\n",
      " total time: 3.0540s\n",
      "2.655111312866211\n",
      "Epoch: 0000 loss_train: 2.0710\n",
      "Epoch: 0500 loss_train: 0.9112\n",
      "Epoch: 1000 loss_train: 0.7234\n",
      "Epoch: 1500 loss_train: 0.6237\n",
      "Epoch: 2000 loss_train: 0.5582\n",
      "Epoch: 2500 loss_train: 0.5096\n",
      "Epoch: 3000 loss_train: 0.4705\n",
      "Epoch: 3500 loss_train: 0.4375\n",
      "Epoch: 4000 loss_train: 0.4090\n",
      "Epoch: 4500 loss_train: 0.3837\n",
      "Epoch: 5000 loss_train: 0.3610\n",
      "Epoch: 5500 loss_train: 0.3403\n",
      " total time: 3.2504s\n",
      "1.5101361274719238\n",
      "Epoch: 0000 loss_train: 2.0700\n",
      "Epoch: 0500 loss_train: 0.9061\n",
      "Epoch: 1000 loss_train: 0.7182\n",
      "Epoch: 1500 loss_train: 0.6185\n",
      "Epoch: 2000 loss_train: 0.5531\n",
      "Epoch: 2500 loss_train: 0.5046\n",
      "Epoch: 3000 loss_train: 0.4655\n",
      "Epoch: 3500 loss_train: 0.4326\n",
      "Epoch: 4000 loss_train: 0.4040\n",
      "Epoch: 4500 loss_train: 0.3788\n",
      "Epoch: 5000 loss_train: 0.3562\n",
      "Epoch: 5500 loss_train: 0.3356\n",
      " total time: 3.2516s\n",
      "5.044517993927002\n",
      "Epoch: 0000 loss_train: 2.0715\n",
      "Epoch: 0500 loss_train: 0.9102\n",
      "Epoch: 1000 loss_train: 0.7228\n",
      "Epoch: 1500 loss_train: 0.6239\n",
      "Epoch: 2000 loss_train: 0.5591\n",
      "Epoch: 2500 loss_train: 0.5110\n",
      "Epoch: 3000 loss_train: 0.4722\n",
      "Epoch: 3500 loss_train: 0.4395\n",
      "Epoch: 4000 loss_train: 0.4110\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.1226s\n",
      "0.6111185550689697\n",
      "Epoch: 0000 loss_train: 2.0688\n",
      "Epoch: 0500 loss_train: 0.9093\n",
      "Epoch: 1000 loss_train: 0.7208\n",
      "Epoch: 1500 loss_train: 0.6205\n",
      "Epoch: 2000 loss_train: 0.5548\n",
      "Epoch: 2500 loss_train: 0.5061\n",
      "Epoch: 3000 loss_train: 0.4670\n",
      "Epoch: 3500 loss_train: 0.4341\n",
      "Epoch: 4000 loss_train: 0.4057\n",
      "Epoch: 4500 loss_train: 0.3806\n",
      "Epoch: 5000 loss_train: 0.3583\n",
      "Epoch: 5500 loss_train: 0.3380\n",
      " total time: 3.0853s\n",
      "4.091908931732178\n",
      "Epoch: 0000 loss_train: 2.0679\n",
      "Epoch: 0500 loss_train: 0.9046\n",
      "Epoch: 1000 loss_train: 0.7177\n",
      "Epoch: 1500 loss_train: 0.6189\n",
      "Epoch: 2000 loss_train: 0.5540\n",
      "Epoch: 2500 loss_train: 0.5057\n",
      "Epoch: 3000 loss_train: 0.4667\n",
      "Epoch: 3500 loss_train: 0.4338\n",
      "Epoch: 4000 loss_train: 0.4052\n",
      "Epoch: 4500 loss_train: 0.3800\n",
      "Epoch: 5000 loss_train: 0.3573\n",
      "Epoch: 5500 loss_train: 0.3368\n",
      " total time: 3.1123s\n",
      "8.323521614074707\n",
      "Epoch: 0000 loss_train: 2.0693\n",
      "Epoch: 0500 loss_train: 0.9131\n",
      "Epoch: 1000 loss_train: 0.7257\n",
      "Epoch: 1500 loss_train: 0.6261\n",
      "Epoch: 2000 loss_train: 0.5605\n",
      "Epoch: 2500 loss_train: 0.5118\n",
      "Epoch: 3000 loss_train: 0.4725\n",
      "Epoch: 3500 loss_train: 0.4394\n",
      "Epoch: 4000 loss_train: 0.4107\n",
      "Epoch: 4500 loss_train: 0.3853\n",
      "Epoch: 5000 loss_train: 0.3625\n",
      "Epoch: 5500 loss_train: 0.3418\n",
      " total time: 3.0859s\n",
      "1.3703818321228027\n",
      "Epoch: 0000 loss_train: 2.0706\n",
      "Epoch: 0500 loss_train: 0.9111\n",
      "Epoch: 1000 loss_train: 0.7239\n",
      "Epoch: 1500 loss_train: 0.6243\n",
      "Epoch: 2000 loss_train: 0.5589\n",
      "Epoch: 2500 loss_train: 0.5102\n",
      "Epoch: 3000 loss_train: 0.4710\n",
      "Epoch: 3500 loss_train: 0.4379\n",
      "Epoch: 4000 loss_train: 0.4092\n",
      "Epoch: 4500 loss_train: 0.3839\n",
      "Epoch: 5000 loss_train: 0.3612\n",
      "Epoch: 5500 loss_train: 0.3407\n",
      " total time: 3.0818s\n",
      "3.8575568199157715\n",
      "Epoch: 0000 loss_train: 2.0672\n",
      "Epoch: 0500 loss_train: 0.9100\n",
      "Epoch: 1000 loss_train: 0.7211\n",
      "Epoch: 1500 loss_train: 0.6201\n",
      "Epoch: 2000 loss_train: 0.5533\n",
      "Epoch: 2500 loss_train: 0.5035\n",
      "Epoch: 3000 loss_train: 0.4635\n",
      "Epoch: 3500 loss_train: 0.4299\n",
      "Epoch: 4000 loss_train: 0.4010\n",
      "Epoch: 4500 loss_train: 0.3757\n",
      "Epoch: 5000 loss_train: 0.3531\n",
      "Epoch: 5500 loss_train: 0.3328\n",
      " total time: 2.9769s\n",
      "5.239395618438721\n",
      "Epoch: 0000 loss_train: 2.0712\n",
      "Epoch: 0500 loss_train: 0.9145\n",
      "Epoch: 1000 loss_train: 0.7266\n",
      "Epoch: 1500 loss_train: 0.6267\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5120\n",
      "Epoch: 3000 loss_train: 0.4725\n",
      "Epoch: 3500 loss_train: 0.4392\n",
      "Epoch: 4000 loss_train: 0.4103\n",
      "Epoch: 4500 loss_train: 0.3847\n",
      "Epoch: 5000 loss_train: 0.3619\n",
      "Epoch: 5500 loss_train: 0.3411\n",
      " total time: 2.9564s\n",
      "2.3667287826538086\n",
      "Epoch: 0000 loss_train: 2.0695\n",
      "Epoch: 0500 loss_train: 0.9136\n",
      "Epoch: 1000 loss_train: 0.7263\n",
      "Epoch: 1500 loss_train: 0.6266\n",
      "Epoch: 2000 loss_train: 0.5611\n",
      "Epoch: 2500 loss_train: 0.5124\n",
      "Epoch: 3000 loss_train: 0.4732\n",
      "Epoch: 3500 loss_train: 0.4402\n",
      "Epoch: 4000 loss_train: 0.4115\n",
      "Epoch: 4500 loss_train: 0.3861\n",
      "Epoch: 5000 loss_train: 0.3633\n",
      "Epoch: 5500 loss_train: 0.3427\n",
      " total time: 2.8796s\n",
      "0.3377610743045807\n",
      "Epoch: 0000 loss_train: 2.0653\n",
      "Epoch: 0500 loss_train: 0.9180\n",
      "Epoch: 1000 loss_train: 0.7296\n",
      "Epoch: 1500 loss_train: 0.6296\n",
      "Epoch: 2000 loss_train: 0.5638\n",
      "Epoch: 2500 loss_train: 0.5149\n",
      "Epoch: 3000 loss_train: 0.4755\n",
      "Epoch: 3500 loss_train: 0.4422\n",
      "Epoch: 4000 loss_train: 0.4133\n",
      "Epoch: 4500 loss_train: 0.3878\n",
      "Epoch: 5000 loss_train: 0.3649\n",
      "Epoch: 5500 loss_train: 0.3441\n",
      " total time: 2.8895s\n",
      "0.029965275898575783\n",
      "Epoch: 0000 loss_train: 2.0659\n",
      "Epoch: 0500 loss_train: 0.9146\n",
      "Epoch: 1000 loss_train: 0.7265\n",
      "Epoch: 1500 loss_train: 0.6259\n",
      "Epoch: 2000 loss_train: 0.5596\n",
      "Epoch: 2500 loss_train: 0.5103\n",
      "Epoch: 3000 loss_train: 0.4706\n",
      "Epoch: 3500 loss_train: 0.4371\n",
      "Epoch: 4000 loss_train: 0.4082\n",
      "Epoch: 4500 loss_train: 0.3826\n",
      "Epoch: 5000 loss_train: 0.3599\n",
      "Epoch: 5500 loss_train: 0.3393\n",
      " total time: 3.0950s\n",
      "4.919899940490723\n",
      "Epoch: 0000 loss_train: 2.0715\n",
      "Epoch: 0500 loss_train: 0.9138\n",
      "Epoch: 1000 loss_train: 0.7266\n",
      "Epoch: 1500 loss_train: 0.6271\n",
      "Epoch: 2000 loss_train: 0.5617\n",
      "Epoch: 2500 loss_train: 0.5130\n",
      "Epoch: 3000 loss_train: 0.4739\n",
      "Epoch: 3500 loss_train: 0.4408\n",
      "Epoch: 4000 loss_train: 0.4121\n",
      "Epoch: 4500 loss_train: 0.3867\n",
      "Epoch: 5000 loss_train: 0.3639\n",
      "Epoch: 5500 loss_train: 0.3432\n",
      " total time: 3.0960s\n",
      "0.009713881649076939\n",
      "Epoch: 0000 loss_train: 2.0707\n",
      "Epoch: 0500 loss_train: 0.9141\n",
      "Epoch: 1000 loss_train: 0.7267\n",
      "Epoch: 1500 loss_train: 0.6270\n",
      "Epoch: 2000 loss_train: 0.5614\n",
      "Epoch: 2500 loss_train: 0.5126\n",
      "Epoch: 3000 loss_train: 0.4733\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4113\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3423\n",
      " total time: 3.0524s\n",
      "0.4224877655506134\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9124\n",
      "Epoch: 1000 loss_train: 0.7252\n",
      "Epoch: 1500 loss_train: 0.6257\n",
      "Epoch: 2000 loss_train: 0.5604\n",
      "Epoch: 2500 loss_train: 0.5118\n",
      "Epoch: 3000 loss_train: 0.4726\n",
      "Epoch: 3500 loss_train: 0.4396\n",
      "Epoch: 4000 loss_train: 0.4109\n",
      "Epoch: 4500 loss_train: 0.3855\n",
      "Epoch: 5000 loss_train: 0.3628\n",
      "Epoch: 5500 loss_train: 0.3421\n",
      " total time: 3.0558s\n",
      "0.6782441139221191\n",
      "Epoch: 0000 loss_train: 2.0712\n",
      "Epoch: 0500 loss_train: 0.9137\n",
      "Epoch: 1000 loss_train: 0.7267\n",
      "Epoch: 1500 loss_train: 0.6273\n",
      "Epoch: 2000 loss_train: 0.5619\n",
      "Epoch: 2500 loss_train: 0.5131\n",
      "Epoch: 3000 loss_train: 0.4738\n",
      "Epoch: 3500 loss_train: 0.4406\n",
      "Epoch: 4000 loss_train: 0.4118\n",
      "Epoch: 4500 loss_train: 0.3864\n",
      "Epoch: 5000 loss_train: 0.3636\n",
      "Epoch: 5500 loss_train: 0.3429\n",
      " total time: 3.0914s\n",
      "0.030793162062764168\n",
      "Epoch: 0000 loss_train: 2.0708\n",
      "Epoch: 0500 loss_train: 0.9124\n",
      "Epoch: 1000 loss_train: 0.7248\n",
      "Epoch: 1500 loss_train: 0.6251\n",
      "Epoch: 2000 loss_train: 0.5596\n",
      "Epoch: 2500 loss_train: 0.5108\n",
      "Epoch: 3000 loss_train: 0.4715\n",
      "Epoch: 3500 loss_train: 0.4383\n",
      "Epoch: 4000 loss_train: 0.4096\n",
      "Epoch: 4500 loss_train: 0.3842\n",
      "Epoch: 5000 loss_train: 0.3614\n",
      "Epoch: 5500 loss_train: 0.3407\n",
      " total time: 2.9411s\n",
      "1.346834421157837\n",
      "Epoch: 0000 loss_train: 2.0723\n",
      "Epoch: 0500 loss_train: 0.9146\n",
      "Epoch: 1000 loss_train: 0.7271\n",
      "Epoch: 1500 loss_train: 0.6274\n",
      "Epoch: 2000 loss_train: 0.5619\n",
      "Epoch: 2500 loss_train: 0.5131\n",
      "Epoch: 3000 loss_train: 0.4738\n",
      "Epoch: 3500 loss_train: 0.4406\n",
      "Epoch: 4000 loss_train: 0.4119\n",
      "Epoch: 4500 loss_train: 0.3864\n",
      "Epoch: 5000 loss_train: 0.3636\n",
      "Epoch: 5500 loss_train: 0.3429\n",
      " total time: 2.9498s\n",
      "0.0025541323702782393\n",
      "Epoch: 0000 loss_train: 2.0712\n",
      "Epoch: 0500 loss_train: 0.9143\n",
      "Epoch: 1000 loss_train: 0.7269\n",
      "Epoch: 1500 loss_train: 0.6273\n",
      "Epoch: 2000 loss_train: 0.5617\n",
      "Epoch: 2500 loss_train: 0.5130\n",
      "Epoch: 3000 loss_train: 0.4737\n",
      "Epoch: 3500 loss_train: 0.4405\n",
      "Epoch: 4000 loss_train: 0.4117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4500 loss_train: 0.3863\n",
      "Epoch: 5000 loss_train: 0.3634\n",
      "Epoch: 5500 loss_train: 0.3428\n",
      " total time: 2.9180s\n",
      "0.010241220705211163\n",
      "Epoch: 0000 loss_train: 2.0715\n",
      "Epoch: 0500 loss_train: 0.9137\n",
      "Epoch: 1000 loss_train: 0.7264\n",
      "Epoch: 1500 loss_train: 0.6268\n",
      "Epoch: 2000 loss_train: 0.5612\n",
      "Epoch: 2500 loss_train: 0.5125\n",
      "Epoch: 3000 loss_train: 0.4733\n",
      "Epoch: 3500 loss_train: 0.4402\n",
      "Epoch: 4000 loss_train: 0.4114\n",
      "Epoch: 4500 loss_train: 0.3860\n",
      "Epoch: 5000 loss_train: 0.3633\n",
      "Epoch: 5500 loss_train: 0.3426\n",
      " total time: 2.9034s\n",
      "0.3462642431259155\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.8965\n",
      "Epoch: 1000 loss_train: 0.7098\n",
      "Epoch: 1500 loss_train: 0.6129\n",
      "Epoch: 2000 loss_train: 0.5503\n",
      "Epoch: 2500 loss_train: 0.5037\n",
      "Epoch: 3000 loss_train: 0.4661\n",
      "Epoch: 3500 loss_train: 0.4341\n",
      "Epoch: 4000 loss_train: 0.4062\n",
      "Epoch: 4500 loss_train: 0.3813\n",
      "Epoch: 5000 loss_train: 0.3589\n",
      "Epoch: 5500 loss_train: 0.3386\n",
      " total time: 2.9788s\n",
      "7.873163223266602\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9128\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5611\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4113\n",
      "Epoch: 4500 loss_train: 0.3859\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.0029s\n",
      "1.823885577323381e-05\n",
      "Epoch: 0000 loss_train: 2.0718\n",
      "Epoch: 0500 loss_train: 0.9144\n",
      "Epoch: 1000 loss_train: 0.7271\n",
      "Epoch: 1500 loss_train: 0.6275\n",
      "Epoch: 2000 loss_train: 0.5620\n",
      "Epoch: 2500 loss_train: 0.5132\n",
      "Epoch: 3000 loss_train: 0.4739\n",
      "Epoch: 3500 loss_train: 0.4407\n",
      "Epoch: 4000 loss_train: 0.4120\n",
      "Epoch: 4500 loss_train: 0.3865\n",
      "Epoch: 5000 loss_train: 0.3637\n",
      "Epoch: 5500 loss_train: 0.3430\n",
      " total time: 3.1004s\n",
      "0.012566667050123215\n",
      "Epoch: 0000 loss_train: 2.0718\n",
      "Epoch: 0500 loss_train: 0.9144\n",
      "Epoch: 1000 loss_train: 0.7269\n",
      "Epoch: 1500 loss_train: 0.6273\n",
      "Epoch: 2000 loss_train: 0.5618\n",
      "Epoch: 2500 loss_train: 0.5130\n",
      "Epoch: 3000 loss_train: 0.4737\n",
      "Epoch: 3500 loss_train: 0.4406\n",
      "Epoch: 4000 loss_train: 0.4118\n",
      "Epoch: 4500 loss_train: 0.3864\n",
      "Epoch: 5000 loss_train: 0.3635\n",
      "Epoch: 5500 loss_train: 0.3428\n",
      " total time: 3.1370s\n",
      "0.07667074352502823\n",
      "Epoch: 0000 loss_train: 2.0697\n",
      "Epoch: 0500 loss_train: 0.9133\n",
      "Epoch: 1000 loss_train: 0.7265\n",
      "Epoch: 1500 loss_train: 0.6271\n",
      "Epoch: 2000 loss_train: 0.5616\n",
      "Epoch: 2500 loss_train: 0.5128\n",
      "Epoch: 3000 loss_train: 0.4735\n",
      "Epoch: 3500 loss_train: 0.4403\n",
      "Epoch: 4000 loss_train: 0.4116\n",
      "Epoch: 4500 loss_train: 0.3861\n",
      "Epoch: 5000 loss_train: 0.3633\n",
      "Epoch: 5500 loss_train: 0.3427\n",
      " total time: 3.1403s\n",
      "0.16072112321853638\n",
      "Epoch: 0000 loss_train: 2.0700\n",
      "Epoch: 0500 loss_train: 0.9110\n",
      "Epoch: 1000 loss_train: 0.7241\n",
      "Epoch: 1500 loss_train: 0.6249\n",
      "Epoch: 2000 loss_train: 0.5598\n",
      "Epoch: 2500 loss_train: 0.5113\n",
      "Epoch: 3000 loss_train: 0.4722\n",
      "Epoch: 3500 loss_train: 0.4391\n",
      "Epoch: 4000 loss_train: 0.4103\n",
      "Epoch: 4500 loss_train: 0.3849\n",
      "Epoch: 5000 loss_train: 0.3621\n",
      "Epoch: 5500 loss_train: 0.3414\n",
      " total time: 3.0807s\n",
      "2.315610408782959\n",
      "Epoch: 0000 loss_train: 2.0687\n",
      "Epoch: 0500 loss_train: 0.9154\n",
      "Epoch: 1000 loss_train: 0.7273\n",
      "Epoch: 1500 loss_train: 0.6269\n",
      "Epoch: 2000 loss_train: 0.5609\n",
      "Epoch: 2500 loss_train: 0.5119\n",
      "Epoch: 3000 loss_train: 0.4725\n",
      "Epoch: 3500 loss_train: 0.4393\n",
      "Epoch: 4000 loss_train: 0.4105\n",
      "Epoch: 4500 loss_train: 0.3851\n",
      "Epoch: 5000 loss_train: 0.3624\n",
      "Epoch: 5500 loss_train: 0.3418\n",
      " total time: 3.0666s\n",
      "0.9726532101631165\n",
      "Epoch: 0000 loss_train: 2.0703\n",
      "Epoch: 0500 loss_train: 0.9128\n",
      "Epoch: 1000 loss_train: 0.7258\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5609\n",
      "Epoch: 2500 loss_train: 0.5122\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.0771s\n",
      "5.006777428206988e-06\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9138\n",
      "Epoch: 1000 loss_train: 0.7266\n",
      "Epoch: 1500 loss_train: 0.6269\n",
      "Epoch: 2000 loss_train: 0.5612\n",
      "Epoch: 2500 loss_train: 0.5124\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4397\n",
      "Epoch: 4000 loss_train: 0.4109\n",
      "Epoch: 4500 loss_train: 0.3855\n",
      "Epoch: 5000 loss_train: 0.3627\n",
      "Epoch: 5500 loss_train: 0.3421\n",
      " total time: 3.0339s\n",
      "0.6341221928596497\n",
      "Epoch: 0000 loss_train: 2.0713\n",
      "Epoch: 0500 loss_train: 0.9132\n",
      "Epoch: 1000 loss_train: 0.7263\n",
      "Epoch: 1500 loss_train: 0.6269\n",
      "Epoch: 2000 loss_train: 0.5614\n",
      "Epoch: 2500 loss_train: 0.5127\n",
      "Epoch: 3000 loss_train: 0.4734\n",
      "Epoch: 3500 loss_train: 0.4403\n",
      "Epoch: 4000 loss_train: 0.4115\n",
      "Epoch: 4500 loss_train: 0.3861\n",
      "Epoch: 5000 loss_train: 0.3634\n",
      "Epoch: 5500 loss_train: 0.3427\n",
      " total time: 2.9088s\n",
      "0.14791464805603027\n",
      "Epoch: 0000 loss_train: 2.0693\n",
      "Epoch: 0500 loss_train: 0.9038\n",
      "Epoch: 1000 loss_train: 0.7134\n",
      "Epoch: 1500 loss_train: 0.6122\n",
      "Epoch: 2000 loss_train: 0.5460\n",
      "Epoch: 2500 loss_train: 0.4972\n",
      "Epoch: 3000 loss_train: 0.4581\n",
      "Epoch: 3500 loss_train: 0.4254\n",
      "Epoch: 4000 loss_train: 0.3972\n",
      "Epoch: 4500 loss_train: 0.3724\n",
      "Epoch: 5000 loss_train: 0.3502\n",
      "Epoch: 5500 loss_train: 0.3301\n",
      " total time: 2.8787s\n",
      "4.828334808349609\n",
      "Epoch: 0000 loss_train: 2.0697\n",
      "Epoch: 0500 loss_train: 0.9083\n",
      "Epoch: 1000 loss_train: 0.7215\n",
      "Epoch: 1500 loss_train: 0.6224\n",
      "Epoch: 2000 loss_train: 0.5573\n",
      "Epoch: 2500 loss_train: 0.5089\n",
      "Epoch: 3000 loss_train: 0.4700\n",
      "Epoch: 3500 loss_train: 0.4372\n",
      "Epoch: 4000 loss_train: 0.4087\n",
      "Epoch: 4500 loss_train: 0.3836\n",
      "Epoch: 5000 loss_train: 0.3610\n",
      "Epoch: 5500 loss_train: 0.3406\n",
      " total time: 2.9577s\n",
      "1.9702520370483398\n",
      "Epoch: 0000 loss_train: 2.0690\n",
      "Epoch: 0500 loss_train: 0.9095\n",
      "Epoch: 1000 loss_train: 0.7215\n",
      "Epoch: 1500 loss_train: 0.6222\n",
      "Epoch: 2000 loss_train: 0.5570\n",
      "Epoch: 2500 loss_train: 0.5085\n",
      "Epoch: 3000 loss_train: 0.4693\n",
      "Epoch: 3500 loss_train: 0.4362\n",
      "Epoch: 4000 loss_train: 0.4074\n",
      "Epoch: 4500 loss_train: 0.3821\n",
      "Epoch: 5000 loss_train: 0.3594\n",
      "Epoch: 5500 loss_train: 0.3389\n",
      " total time: 3.1234s\n",
      "3.232837677001953\n",
      "Epoch: 0000 loss_train: 2.0671\n",
      "Epoch: 0500 loss_train: 0.9127\n",
      "Epoch: 1000 loss_train: 0.7263\n",
      "Epoch: 1500 loss_train: 0.6274\n",
      "Epoch: 2000 loss_train: 0.5623\n",
      "Epoch: 2500 loss_train: 0.5138\n",
      "Epoch: 3000 loss_train: 0.4747\n",
      "Epoch: 3500 loss_train: 0.4415\n",
      "Epoch: 4000 loss_train: 0.4127\n",
      "Epoch: 4500 loss_train: 0.3871\n",
      "Epoch: 5000 loss_train: 0.3641\n",
      "Epoch: 5500 loss_train: 0.3433\n",
      " total time: 3.0992s\n",
      "9.536738616588991e-07\n",
      "Epoch: 0000 loss_train: 2.0694\n",
      "Epoch: 0500 loss_train: 0.9122\n",
      "Epoch: 1000 loss_train: 0.7260\n",
      "Epoch: 1500 loss_train: 0.6266\n",
      "Epoch: 2000 loss_train: 0.5609\n",
      "Epoch: 2500 loss_train: 0.5119\n",
      "Epoch: 3000 loss_train: 0.4723\n",
      "Epoch: 3500 loss_train: 0.4388\n",
      "Epoch: 4000 loss_train: 0.4098\n",
      "Epoch: 4500 loss_train: 0.3842\n",
      "Epoch: 5000 loss_train: 0.3612\n",
      "Epoch: 5500 loss_train: 0.3404\n",
      " total time: 3.2189s\n",
      "1.7693886756896973\n",
      "Epoch: 0000 loss_train: 2.0696\n",
      "Epoch: 0500 loss_train: 0.9120\n",
      "Epoch: 1000 loss_train: 0.7253\n",
      "Epoch: 1500 loss_train: 0.6262\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5125\n",
      "Epoch: 3000 loss_train: 0.4734\n",
      "Epoch: 3500 loss_train: 0.4403\n",
      "Epoch: 4000 loss_train: 0.4116\n",
      "Epoch: 4500 loss_train: 0.3861\n",
      "Epoch: 5000 loss_train: 0.3633\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.1271s\n",
      "0.5652626752853394\n",
      "Epoch: 0000 loss_train: 2.0704\n",
      "Epoch: 0500 loss_train: 0.9100\n",
      "Epoch: 1000 loss_train: 0.7230\n",
      "Epoch: 1500 loss_train: 0.6235\n",
      "Epoch: 2000 loss_train: 0.5581\n",
      "Epoch: 2500 loss_train: 0.5094\n",
      "Epoch: 3000 loss_train: 0.4703\n",
      "Epoch: 3500 loss_train: 0.4372\n",
      "Epoch: 4000 loss_train: 0.4085\n",
      "Epoch: 4500 loss_train: 0.3831\n",
      "Epoch: 5000 loss_train: 0.3603\n",
      "Epoch: 5500 loss_train: 0.3397\n",
      " total time: 3.0409s\n",
      "6.5148234367370605\n",
      "Epoch: 0000 loss_train: 2.0677\n",
      "Epoch: 0500 loss_train: 0.9131\n",
      "Epoch: 1000 loss_train: 0.7263\n",
      "Epoch: 1500 loss_train: 0.6270\n",
      "Epoch: 2000 loss_train: 0.5615\n",
      "Epoch: 2500 loss_train: 0.5127\n",
      "Epoch: 3000 loss_train: 0.4734\n",
      "Epoch: 3500 loss_train: 0.4401\n",
      "Epoch: 4000 loss_train: 0.4113\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3423\n",
      " total time: 3.0655s\n",
      "0.7194204330444336\n",
      "Epoch: 0000 loss_train: 2.0693\n",
      "Epoch: 0500 loss_train: 0.9121\n",
      "Epoch: 1000 loss_train: 0.7255\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5613\n",
      "Epoch: 2500 loss_train: 0.5127\n",
      "Epoch: 3000 loss_train: 0.4735\n",
      "Epoch: 3500 loss_train: 0.4404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4000 loss_train: 0.4115\n",
      "Epoch: 4500 loss_train: 0.3860\n",
      "Epoch: 5000 loss_train: 0.3632\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.0582s\n",
      "0.6365519762039185\n",
      "Epoch: 0000 loss_train: 2.0696\n",
      "Epoch: 0500 loss_train: 0.9119\n",
      "Epoch: 1000 loss_train: 0.7250\n",
      "Epoch: 1500 loss_train: 0.6256\n",
      "Epoch: 2000 loss_train: 0.5602\n",
      "Epoch: 2500 loss_train: 0.5114\n",
      "Epoch: 3000 loss_train: 0.4721\n",
      "Epoch: 3500 loss_train: 0.4388\n",
      "Epoch: 4000 loss_train: 0.4099\n",
      "Epoch: 4500 loss_train: 0.3843\n",
      "Epoch: 5000 loss_train: 0.3613\n",
      "Epoch: 5500 loss_train: 0.3405\n",
      " total time: 3.1174s\n",
      "1.2012877464294434\n",
      "Epoch: 0000 loss_train: 2.0663\n",
      "Epoch: 0500 loss_train: 0.9162\n",
      "Epoch: 1000 loss_train: 0.7284\n",
      "Epoch: 1500 loss_train: 0.6286\n",
      "Epoch: 2000 loss_train: 0.5630\n",
      "Epoch: 2500 loss_train: 0.5142\n",
      "Epoch: 3000 loss_train: 0.4749\n",
      "Epoch: 3500 loss_train: 0.4417\n",
      "Epoch: 4000 loss_train: 0.4129\n",
      "Epoch: 4500 loss_train: 0.3875\n",
      "Epoch: 5000 loss_train: 0.3647\n",
      "Epoch: 5500 loss_train: 0.3440\n",
      " total time: 3.1026s\n",
      "0.05064012482762337\n",
      "Epoch: 0000 loss_train: 2.0685\n",
      "Epoch: 0500 loss_train: 0.9140\n",
      "Epoch: 1000 loss_train: 0.7265\n",
      "Epoch: 1500 loss_train: 0.6270\n",
      "Epoch: 2000 loss_train: 0.5615\n",
      "Epoch: 2500 loss_train: 0.5128\n",
      "Epoch: 3000 loss_train: 0.4736\n",
      "Epoch: 3500 loss_train: 0.4405\n",
      "Epoch: 4000 loss_train: 0.4117\n",
      "Epoch: 4500 loss_train: 0.3862\n",
      "Epoch: 5000 loss_train: 0.3634\n",
      "Epoch: 5500 loss_train: 0.3427\n",
      " total time: 3.0798s\n",
      "0.483622670173645\n",
      "Epoch: 0000 loss_train: 2.0702\n",
      "Epoch: 0500 loss_train: 0.9133\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6261\n",
      "Epoch: 2000 loss_train: 0.5604\n",
      "Epoch: 2500 loss_train: 0.5113\n",
      "Epoch: 3000 loss_train: 0.4718\n",
      "Epoch: 3500 loss_train: 0.4382\n",
      "Epoch: 4000 loss_train: 0.4090\n",
      "Epoch: 4500 loss_train: 0.3831\n",
      "Epoch: 5000 loss_train: 0.3599\n",
      "Epoch: 5500 loss_train: 0.3387\n",
      " total time: 3.0227s\n",
      "2.4953551292419434\n",
      "Epoch: 0000 loss_train: 2.0684\n",
      "Epoch: 0500 loss_train: 0.9114\n",
      "Epoch: 1000 loss_train: 0.7247\n",
      "Epoch: 1500 loss_train: 0.6255\n",
      "Epoch: 2000 loss_train: 0.5604\n",
      "Epoch: 2500 loss_train: 0.5119\n",
      "Epoch: 3000 loss_train: 0.4729\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4114\n",
      "Epoch: 4500 loss_train: 0.3861\n",
      "Epoch: 5000 loss_train: 0.3634\n",
      "Epoch: 5500 loss_train: 0.3428\n",
      " total time: 3.1013s\n",
      "0.4511507451534271\n",
      "Epoch: 0000 loss_train: 2.0706\n",
      "Epoch: 0500 loss_train: 0.9130\n",
      "Epoch: 1000 loss_train: 0.7265\n",
      "Epoch: 1500 loss_train: 0.6271\n",
      "Epoch: 2000 loss_train: 0.5616\n",
      "Epoch: 2500 loss_train: 0.5129\n",
      "Epoch: 3000 loss_train: 0.4736\n",
      "Epoch: 3500 loss_train: 0.4404\n",
      "Epoch: 4000 loss_train: 0.4116\n",
      "Epoch: 4500 loss_train: 0.3862\n",
      "Epoch: 5000 loss_train: 0.3634\n",
      "Epoch: 5500 loss_train: 0.3428\n",
      " total time: 3.0772s\n",
      "0.05265026167035103\n",
      "Epoch: 0000 loss_train: 2.0704\n",
      "Epoch: 0500 loss_train: 0.9143\n",
      "Epoch: 1000 loss_train: 0.7269\n",
      "Epoch: 1500 loss_train: 0.6273\n",
      "Epoch: 2000 loss_train: 0.5618\n",
      "Epoch: 2500 loss_train: 0.5130\n",
      "Epoch: 3000 loss_train: 0.4737\n",
      "Epoch: 3500 loss_train: 0.4405\n",
      "Epoch: 4000 loss_train: 0.4118\n",
      "Epoch: 4500 loss_train: 0.3863\n",
      "Epoch: 5000 loss_train: 0.3635\n",
      "Epoch: 5500 loss_train: 0.3429\n",
      " total time: 3.1013s\n",
      "0.0039132460951805115\n",
      "Epoch: 0000 loss_train: 2.0715\n",
      "Epoch: 0500 loss_train: 0.9107\n",
      "Epoch: 1000 loss_train: 0.7222\n",
      "Epoch: 1500 loss_train: 0.6222\n",
      "Epoch: 2000 loss_train: 0.5566\n",
      "Epoch: 2500 loss_train: 0.5079\n",
      "Epoch: 3000 loss_train: 0.4688\n",
      "Epoch: 3500 loss_train: 0.4357\n",
      "Epoch: 4000 loss_train: 0.4072\n",
      "Epoch: 4500 loss_train: 0.3820\n",
      "Epoch: 5000 loss_train: 0.3595\n",
      "Epoch: 5500 loss_train: 0.3392\n",
      " total time: 3.0794s\n",
      "3.4671449661254883\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9138\n",
      "Epoch: 1000 loss_train: 0.7266\n",
      "Epoch: 1500 loss_train: 0.6271\n",
      "Epoch: 2000 loss_train: 0.5616\n",
      "Epoch: 2500 loss_train: 0.5128\n",
      "Epoch: 3000 loss_train: 0.4736\n",
      "Epoch: 3500 loss_train: 0.4405\n",
      "Epoch: 4000 loss_train: 0.4117\n",
      "Epoch: 4500 loss_train: 0.3863\n",
      "Epoch: 5000 loss_train: 0.3635\n",
      "Epoch: 5500 loss_train: 0.3429\n",
      " total time: 2.9574s\n",
      "0.03164195641875267\n",
      "Epoch: 0000 loss_train: 2.0703\n",
      "Epoch: 0500 loss_train: 0.9120\n",
      "Epoch: 1000 loss_train: 0.7245\n",
      "Epoch: 1500 loss_train: 0.6249\n",
      "Epoch: 2000 loss_train: 0.5596\n",
      "Epoch: 2500 loss_train: 0.5110\n",
      "Epoch: 3000 loss_train: 0.4718\n",
      "Epoch: 3500 loss_train: 0.4388\n",
      "Epoch: 4000 loss_train: 0.4101\n",
      "Epoch: 4500 loss_train: 0.3848\n",
      "Epoch: 5000 loss_train: 0.3621\n",
      "Epoch: 5500 loss_train: 0.3415\n",
      " total time: 3.0194s\n",
      "1.0335917472839355\n",
      "Epoch: 0000 loss_train: 2.0704\n",
      "Epoch: 0500 loss_train: 0.9057\n",
      "Epoch: 1000 loss_train: 0.7170\n",
      "Epoch: 1500 loss_train: 0.6168\n",
      "Epoch: 2000 loss_train: 0.5510\n",
      "Epoch: 2500 loss_train: 0.5022\n",
      "Epoch: 3000 loss_train: 0.4629\n",
      "Epoch: 3500 loss_train: 0.4297\n",
      "Epoch: 4000 loss_train: 0.4009\n",
      "Epoch: 4500 loss_train: 0.3755\n",
      "Epoch: 5000 loss_train: 0.3526\n",
      "Epoch: 5500 loss_train: 0.3320\n",
      " total time: 3.0267s\n",
      "8.083837509155273\n",
      "Epoch: 0000 loss_train: 2.0691\n",
      "Epoch: 0500 loss_train: 0.8956\n",
      "Epoch: 1000 loss_train: 0.7095\n",
      "Epoch: 1500 loss_train: 0.6117\n",
      "Epoch: 2000 loss_train: 0.5480\n",
      "Epoch: 2500 loss_train: 0.5009\n",
      "Epoch: 3000 loss_train: 0.4629\n",
      "Epoch: 3500 loss_train: 0.4308\n",
      "Epoch: 4000 loss_train: 0.4029\n",
      "Epoch: 4500 loss_train: 0.3782\n",
      "Epoch: 5000 loss_train: 0.3559\n",
      "Epoch: 5500 loss_train: 0.3357\n",
      " total time: 2.9449s\n",
      "5.100992202758789\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9127\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4113\n",
      "Epoch: 4500 loss_train: 0.3859\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.0718s\n",
      "0.00015937011630740017\n",
      "Epoch: 0000 loss_train: 2.0708\n",
      "Epoch: 0500 loss_train: 0.9145\n",
      "Epoch: 1000 loss_train: 0.7272\n",
      "Epoch: 1500 loss_train: 0.6275\n",
      "Epoch: 2000 loss_train: 0.5620\n",
      "Epoch: 2500 loss_train: 0.5132\n",
      "Epoch: 3000 loss_train: 0.4739\n",
      "Epoch: 3500 loss_train: 0.4408\n",
      "Epoch: 4000 loss_train: 0.4120\n",
      "Epoch: 4500 loss_train: 0.3865\n",
      "Epoch: 5000 loss_train: 0.3637\n",
      "Epoch: 5500 loss_train: 0.3431\n",
      " total time: 2.9960s\n",
      "0.04190661013126373\n",
      "Epoch: 0000 loss_train: 2.0719\n",
      "Epoch: 0500 loss_train: 0.9122\n",
      "Epoch: 1000 loss_train: 0.7235\n",
      "Epoch: 1500 loss_train: 0.6229\n",
      "Epoch: 2000 loss_train: 0.5566\n",
      "Epoch: 2500 loss_train: 0.5073\n",
      "Epoch: 3000 loss_train: 0.4676\n",
      "Epoch: 3500 loss_train: 0.4343\n",
      "Epoch: 4000 loss_train: 0.4055\n",
      "Epoch: 4500 loss_train: 0.3801\n",
      "Epoch: 5000 loss_train: 0.3574\n",
      "Epoch: 5500 loss_train: 0.3368\n",
      " total time: 2.9756s\n",
      "7.601652145385742\n",
      "Epoch: 0000 loss_train: 2.0697\n",
      "Epoch: 0500 loss_train: 0.9114\n",
      "Epoch: 1000 loss_train: 0.7246\n",
      "Epoch: 1500 loss_train: 0.6251\n",
      "Epoch: 2000 loss_train: 0.5598\n",
      "Epoch: 2500 loss_train: 0.5111\n",
      "Epoch: 3000 loss_train: 0.4719\n",
      "Epoch: 3500 loss_train: 0.4388\n",
      "Epoch: 4000 loss_train: 0.4101\n",
      "Epoch: 4500 loss_train: 0.3848\n",
      "Epoch: 5000 loss_train: 0.3621\n",
      "Epoch: 5500 loss_train: 0.3415\n",
      " total time: 3.1743s\n",
      "1.0129228830337524\n",
      "Epoch: 0000 loss_train: 2.0707\n",
      "Epoch: 0500 loss_train: 0.9125\n",
      "Epoch: 1000 loss_train: 0.7263\n",
      "Epoch: 1500 loss_train: 0.6273\n",
      "Epoch: 2000 loss_train: 0.5620\n",
      "Epoch: 2500 loss_train: 0.5134\n",
      "Epoch: 3000 loss_train: 0.4741\n",
      "Epoch: 3500 loss_train: 0.4409\n",
      "Epoch: 4000 loss_train: 0.4121\n",
      "Epoch: 4500 loss_train: 0.3867\n",
      "Epoch: 5000 loss_train: 0.3638\n",
      "Epoch: 5500 loss_train: 0.3431\n",
      " total time: 3.0619s\n",
      "0.004195341374725103\n",
      "Epoch: 0000 loss_train: 2.0664\n",
      "Epoch: 0500 loss_train: 0.9160\n",
      "Epoch: 1000 loss_train: 0.7277\n",
      "Epoch: 1500 loss_train: 0.6278\n",
      "Epoch: 2000 loss_train: 0.5623\n",
      "Epoch: 2500 loss_train: 0.5136\n",
      "Epoch: 3000 loss_train: 0.4744\n",
      "Epoch: 3500 loss_train: 0.4413\n",
      "Epoch: 4000 loss_train: 0.4126\n",
      "Epoch: 4500 loss_train: 0.3872\n",
      "Epoch: 5000 loss_train: 0.3645\n",
      "Epoch: 5500 loss_train: 0.3438\n",
      " total time: 3.0917s\n",
      "0.07932668179273605\n",
      "Epoch: 0000 loss_train: 2.0703\n",
      "Epoch: 0500 loss_train: 0.9125\n",
      "Epoch: 1000 loss_train: 0.7257\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.1039s\n",
      "1.597391747054644e-05\n",
      "Epoch: 0000 loss_train: 2.0707\n",
      "Epoch: 0500 loss_train: 0.9122\n",
      "Epoch: 1000 loss_train: 0.7258\n",
      "Epoch: 1500 loss_train: 0.6266\n",
      "Epoch: 2000 loss_train: 0.5612\n",
      "Epoch: 2500 loss_train: 0.5125\n",
      "Epoch: 3000 loss_train: 0.4733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3500 loss_train: 0.4402\n",
      "Epoch: 4000 loss_train: 0.4115\n",
      "Epoch: 4500 loss_train: 0.3861\n",
      "Epoch: 5000 loss_train: 0.3633\n",
      "Epoch: 5500 loss_train: 0.3426\n",
      " total time: 3.0193s\n",
      "0.24295607209205627\n",
      "Epoch: 0000 loss_train: 2.0707\n",
      "Epoch: 0500 loss_train: 0.9123\n",
      "Epoch: 1000 loss_train: 0.7254\n",
      "Epoch: 1500 loss_train: 0.6261\n",
      "Epoch: 2000 loss_train: 0.5608\n",
      "Epoch: 2500 loss_train: 0.5122\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4113\n",
      "Epoch: 4500 loss_train: 0.3859\n",
      "Epoch: 5000 loss_train: 0.3632\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.0158s\n",
      "0.4757787883281708\n",
      "Epoch: 0000 loss_train: 2.0706\n",
      "Epoch: 0500 loss_train: 0.9118\n",
      "Epoch: 1000 loss_train: 0.7248\n",
      "Epoch: 1500 loss_train: 0.6254\n",
      "Epoch: 2000 loss_train: 0.5601\n",
      "Epoch: 2500 loss_train: 0.5116\n",
      "Epoch: 3000 loss_train: 0.4725\n",
      "Epoch: 3500 loss_train: 0.4395\n",
      "Epoch: 4000 loss_train: 0.4108\n",
      "Epoch: 4500 loss_train: 0.3855\n",
      "Epoch: 5000 loss_train: 0.3627\n",
      "Epoch: 5500 loss_train: 0.3421\n",
      " total time: 3.0130s\n",
      "1.149227499961853\n",
      "Epoch: 0000 loss_train: 2.0708\n",
      "Epoch: 0500 loss_train: 0.9129\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5609\n",
      "Epoch: 2500 loss_train: 0.5122\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4398\n",
      "Epoch: 4000 loss_train: 0.4111\n",
      "Epoch: 4500 loss_train: 0.3857\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 2.9884s\n",
      "0.20990842580795288\n",
      "Epoch: 0000 loss_train: 2.0704\n",
      "Epoch: 0500 loss_train: 0.9129\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 2.8890s\n",
      "0.004575734958052635\n",
      "Epoch: 0000 loss_train: 2.0703\n",
      "Epoch: 0500 loss_train: 0.9121\n",
      "Epoch: 1000 loss_train: 0.7257\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5611\n",
      "Epoch: 2500 loss_train: 0.5124\n",
      "Epoch: 3000 loss_train: 0.4732\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4113\n",
      "Epoch: 4500 loss_train: 0.3859\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 2.8744s\n",
      "0.0044050803408026695\n",
      "Epoch: 0000 loss_train: 2.0704\n",
      "Epoch: 0500 loss_train: 0.9128\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3859\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 2.9189s\n",
      "0.008080529049038887\n",
      "Epoch: 0000 loss_train: 2.0706\n",
      "Epoch: 0500 loss_train: 0.9130\n",
      "Epoch: 1000 loss_train: 0.7260\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 2.9043s\n",
      "0.0003983181086368859\n",
      "Epoch: 0000 loss_train: 2.0704\n",
      "Epoch: 0500 loss_train: 0.9128\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 2.9473s\n",
      "0.010813095606863499\n",
      "Epoch: 0000 loss_train: 2.0706\n",
      "Epoch: 0500 loss_train: 0.9129\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 2.9197s\n",
      "0.027918938547372818\n",
      "Epoch: 0000 loss_train: 2.0706\n",
      "Epoch: 0500 loss_train: 0.9129\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 2.9210s\n",
      "0.028905225917696953\n",
      "Epoch: 0000 loss_train: 2.0703\n",
      "Epoch: 0500 loss_train: 0.9127\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4113\n",
      "Epoch: 4500 loss_train: 0.3859\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 2.9959s\n",
      "0.002856343751773238\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9128\n",
      "Epoch: 1000 loss_train: 0.7257\n",
      "Epoch: 1500 loss_train: 0.6263\n",
      "Epoch: 2000 loss_train: 0.5608\n",
      "Epoch: 2500 loss_train: 0.5121\n",
      "Epoch: 3000 loss_train: 0.4729\n",
      "Epoch: 3500 loss_train: 0.4398\n",
      "Epoch: 4000 loss_train: 0.4111\n",
      "Epoch: 4500 loss_train: 0.3857\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.0509s\n",
      "0.4604025185108185\n",
      "Epoch: 0000 loss_train: 2.0706\n",
      "Epoch: 0500 loss_train: 0.9131\n",
      "Epoch: 1000 loss_train: 0.7260\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 2.9330s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 2.0703\n",
      "Epoch: 0500 loss_train: 0.9128\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 2.9634s\n",
      "0.001388420001603663\n",
      "Epoch: 0000 loss_train: 2.0703\n",
      "Epoch: 0500 loss_train: 0.9120\n",
      "Epoch: 1000 loss_train: 0.7253\n",
      "Epoch: 1500 loss_train: 0.6260\n",
      "Epoch: 2000 loss_train: 0.5606\n",
      "Epoch: 2500 loss_train: 0.5119\n",
      "Epoch: 3000 loss_train: 0.4727\n",
      "Epoch: 3500 loss_train: 0.4395\n",
      "Epoch: 4000 loss_train: 0.4108\n",
      "Epoch: 4500 loss_train: 0.3854\n",
      "Epoch: 5000 loss_train: 0.3627\n",
      "Epoch: 5500 loss_train: 0.3421\n",
      " total time: 2.9237s\n",
      "0.7913868427276611\n",
      "Epoch: 0000 loss_train: 2.0704\n",
      "Epoch: 0500 loss_train: 0.9130\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 2.9210s\n",
      "3.576278118089249e-07\n",
      "Epoch: 0000 loss_train: 2.0702\n",
      "Epoch: 0500 loss_train: 0.9126\n",
      "Epoch: 1000 loss_train: 0.7257\n",
      "Epoch: 1500 loss_train: 0.6262\n",
      "Epoch: 2000 loss_train: 0.5608\n",
      "Epoch: 2500 loss_train: 0.5121\n",
      "Epoch: 3000 loss_train: 0.4729\n",
      "Epoch: 3500 loss_train: 0.4398\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.0535s\n",
      "0.08970142155885696\n",
      "Epoch: 0000 loss_train: 2.0703\n",
      "Epoch: 0500 loss_train: 0.9123\n",
      "Epoch: 1000 loss_train: 0.7254\n",
      "Epoch: 1500 loss_train: 0.6260\n",
      "Epoch: 2000 loss_train: 0.5606\n",
      "Epoch: 2500 loss_train: 0.5119\n",
      "Epoch: 3000 loss_train: 0.4727\n",
      "Epoch: 3500 loss_train: 0.4397\n",
      "Epoch: 4000 loss_train: 0.4110\n",
      "Epoch: 4500 loss_train: 0.3857\n",
      "Epoch: 5000 loss_train: 0.3629\n",
      "Epoch: 5500 loss_train: 0.3423\n",
      " total time: 3.0608s\n",
      "0.4180798828601837\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9128\n",
      "Epoch: 1000 loss_train: 0.7258\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 2.9348s\n",
      "0.05808349698781967\n",
      "Epoch: 0000 loss_train: 2.0706\n",
      "Epoch: 0500 loss_train: 0.9130\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 2.9583s\n",
      "4.768370445162873e-07\n",
      "Epoch: 0000 loss_train: 2.0702\n",
      "Epoch: 0500 loss_train: 0.9118\n",
      "Epoch: 1000 loss_train: 0.7246\n",
      "Epoch: 1500 loss_train: 0.6251\n",
      "Epoch: 2000 loss_train: 0.5598\n",
      "Epoch: 2500 loss_train: 0.5114\n",
      "Epoch: 3000 loss_train: 0.4724\n",
      "Epoch: 3500 loss_train: 0.4395\n",
      "Epoch: 4000 loss_train: 0.4109\n",
      "Epoch: 4500 loss_train: 0.3856\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.1407s\n",
      "1.141287088394165\n",
      "Epoch: 0000 loss_train: 2.0702\n",
      "Epoch: 0500 loss_train: 0.9114\n",
      "Epoch: 1000 loss_train: 0.7250\n",
      "Epoch: 1500 loss_train: 0.6259\n",
      "Epoch: 2000 loss_train: 0.5606\n",
      "Epoch: 2500 loss_train: 0.5120\n",
      "Epoch: 3000 loss_train: 0.4728\n",
      "Epoch: 3500 loss_train: 0.4398\n",
      "Epoch: 4000 loss_train: 0.4111\n",
      "Epoch: 4500 loss_train: 0.3857\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.1467s\n",
      "0.4985390901565552\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9126\n",
      "Epoch: 1000 loss_train: 0.7257\n",
      "Epoch: 1500 loss_train: 0.6262\n",
      "Epoch: 2000 loss_train: 0.5607\n",
      "Epoch: 2500 loss_train: 0.5120\n",
      "Epoch: 3000 loss_train: 0.4727\n",
      "Epoch: 3500 loss_train: 0.4396\n",
      "Epoch: 4000 loss_train: 0.4108\n",
      "Epoch: 4500 loss_train: 0.3854\n",
      "Epoch: 5000 loss_train: 0.3626\n",
      "Epoch: 5500 loss_train: 0.3420\n",
      " total time: 3.2121s\n",
      "1.1473119258880615\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9130\n",
      "Epoch: 1000 loss_train: 0.7260\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.1591s\n",
      "1.1920927533992653e-07\n",
      "Epoch: 0000 loss_train: 2.0706\n",
      "Epoch: 0500 loss_train: 0.9129\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4113\n",
      "Epoch: 4500 loss_train: 0.3859\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 2.9479s\n",
      "0.0291509497910738\n",
      "Epoch: 0000 loss_train: 2.0703\n",
      "Epoch: 0500 loss_train: 0.9112\n",
      "Epoch: 1000 loss_train: 0.7244\n",
      "Epoch: 1500 loss_train: 0.6251\n",
      "Epoch: 2000 loss_train: 0.5598\n",
      "Epoch: 2500 loss_train: 0.5113\n",
      "Epoch: 3000 loss_train: 0.4722\n",
      "Epoch: 3500 loss_train: 0.4393\n",
      "Epoch: 4000 loss_train: 0.4107\n",
      "Epoch: 4500 loss_train: 0.3855\n",
      "Epoch: 5000 loss_train: 0.3628\n",
      "Epoch: 5500 loss_train: 0.3423\n",
      " total time: 2.8834s\n",
      "1.2980268001556396\n",
      "Epoch: 0000 loss_train: 2.0702\n",
      "Epoch: 0500 loss_train: 0.9114\n",
      "Epoch: 1000 loss_train: 0.7250\n",
      "Epoch: 1500 loss_train: 0.6259\n",
      "Epoch: 2000 loss_train: 0.5606\n",
      "Epoch: 2500 loss_train: 0.5121\n",
      "Epoch: 3000 loss_train: 0.4729\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3859\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 2.8972s\n",
      "0.24578127264976501\n",
      "Epoch: 0000 loss_train: 2.0704\n",
      "Epoch: 0500 loss_train: 0.9129\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 2.9645s\n",
      "2.3841830625315197e-06\n",
      "Epoch: 0000 loss_train: 2.0703\n",
      "Epoch: 0500 loss_train: 0.9129\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 2.9494s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 2.0585\n",
      "Epoch: 0500 loss_train: 0.9165\n",
      "Epoch: 1000 loss_train: 0.7295\n",
      "Epoch: 1500 loss_train: 0.6296\n",
      "Epoch: 2000 loss_train: 0.5639\n",
      "Epoch: 2500 loss_train: 0.5149\n",
      "Epoch: 3000 loss_train: 0.4754\n",
      "Epoch: 3500 loss_train: 0.4420\n",
      "Epoch: 4000 loss_train: 0.4131\n",
      "Epoch: 4500 loss_train: 0.3874\n",
      "Epoch: 5000 loss_train: 0.3644\n",
      "Epoch: 5500 loss_train: 0.3436\n",
      " total time: 2.8946s\n",
      "3.041609764099121\n",
      "Epoch: 0000 loss_train: 2.0562\n",
      "Epoch: 0500 loss_train: 0.9035\n",
      "Epoch: 1000 loss_train: 0.7184\n",
      "Epoch: 1500 loss_train: 0.6206\n",
      "Epoch: 2000 loss_train: 0.5562\n",
      "Epoch: 2500 loss_train: 0.5081\n",
      "Epoch: 3000 loss_train: 0.4693\n",
      "Epoch: 3500 loss_train: 0.4365\n",
      "Epoch: 4000 loss_train: 0.4080\n",
      "Epoch: 4500 loss_train: 0.3828\n",
      "Epoch: 5000 loss_train: 0.3602\n",
      "Epoch: 5500 loss_train: 0.3397\n",
      " total time: 2.8896s\n",
      "2.6167802810668945\n",
      "Epoch: 0000 loss_train: 2.0587\n",
      "Epoch: 0500 loss_train: 0.9154\n",
      "Epoch: 1000 loss_train: 0.7280\n",
      "Epoch: 1500 loss_train: 0.6286\n",
      "Epoch: 2000 loss_train: 0.5632\n",
      "Epoch: 2500 loss_train: 0.5143\n",
      "Epoch: 3000 loss_train: 0.4748\n",
      "Epoch: 3500 loss_train: 0.4415\n",
      "Epoch: 4000 loss_train: 0.4126\n",
      "Epoch: 4500 loss_train: 0.3871\n",
      "Epoch: 5000 loss_train: 0.3643\n",
      "Epoch: 5500 loss_train: 0.3436\n",
      " total time: 2.9252s\n",
      "0.045872051268815994\n",
      "Epoch: 0000 loss_train: 2.0717\n",
      "Epoch: 0500 loss_train: 0.9144\n",
      "Epoch: 1000 loss_train: 0.7278\n",
      "Epoch: 1500 loss_train: 0.6281\n",
      "Epoch: 2000 loss_train: 0.5624\n",
      "Epoch: 2500 loss_train: 0.5135\n",
      "Epoch: 3000 loss_train: 0.4741\n",
      "Epoch: 3500 loss_train: 0.4408\n",
      "Epoch: 4000 loss_train: 0.4120\n",
      "Epoch: 4500 loss_train: 0.3865\n",
      "Epoch: 5000 loss_train: 0.3637\n",
      "Epoch: 5500 loss_train: 0.3431\n",
      " total time: 2.9150s\n",
      "1.5360833406448364\n",
      "Epoch: 0000 loss_train: 2.0448\n",
      "Epoch: 0500 loss_train: 0.9137\n",
      "Epoch: 1000 loss_train: 0.7263\n",
      "Epoch: 1500 loss_train: 0.6271\n",
      "Epoch: 2000 loss_train: 0.5616\n",
      "Epoch: 2500 loss_train: 0.5128\n",
      "Epoch: 3000 loss_train: 0.4735\n",
      "Epoch: 3500 loss_train: 0.4403\n",
      "Epoch: 4000 loss_train: 0.4115\n",
      "Epoch: 4500 loss_train: 0.3861\n",
      "Epoch: 5000 loss_train: 0.3633\n",
      "Epoch: 5500 loss_train: 0.3427\n",
      " total time: 2.8641s\n",
      "3.933898824470816e-06\n",
      "Epoch: 0000 loss_train: 2.0779\n",
      "Epoch: 0500 loss_train: 0.9079\n",
      "Epoch: 1000 loss_train: 0.7270\n",
      "Epoch: 1500 loss_train: 0.6293\n",
      "Epoch: 2000 loss_train: 0.5639\n",
      "Epoch: 2500 loss_train: 0.5149\n",
      "Epoch: 3000 loss_train: 0.4753\n",
      "Epoch: 3500 loss_train: 0.4419\n",
      "Epoch: 4000 loss_train: 0.4130\n",
      "Epoch: 4500 loss_train: 0.3875\n",
      "Epoch: 5000 loss_train: 0.3647\n",
      "Epoch: 5500 loss_train: 0.3440\n",
      " total time: 2.9018s\n",
      "1.5751997232437134\n",
      "Epoch: 0000 loss_train: 2.0587\n",
      "Epoch: 0500 loss_train: 0.9121\n",
      "Epoch: 1000 loss_train: 0.7278\n",
      "Epoch: 1500 loss_train: 0.6287\n",
      "Epoch: 2000 loss_train: 0.5632\n",
      "Epoch: 2500 loss_train: 0.5143\n",
      "Epoch: 3000 loss_train: 0.4748\n",
      "Epoch: 3500 loss_train: 0.4415\n",
      "Epoch: 4000 loss_train: 0.4126\n",
      "Epoch: 4500 loss_train: 0.3871\n",
      "Epoch: 5000 loss_train: 0.3643\n",
      "Epoch: 5500 loss_train: 0.3436\n",
      " total time: 2.8843s\n",
      "0.11889778822660446\n",
      "Epoch: 0000 loss_train: 2.0701\n",
      "Epoch: 0500 loss_train: 0.9098\n",
      "Epoch: 1000 loss_train: 0.7231\n",
      "Epoch: 1500 loss_train: 0.6228\n",
      "Epoch: 2000 loss_train: 0.5568\n",
      "Epoch: 2500 loss_train: 0.5080\n",
      "Epoch: 3000 loss_train: 0.4689\n",
      "Epoch: 3500 loss_train: 0.4360\n",
      "Epoch: 4000 loss_train: 0.4075\n",
      "Epoch: 4500 loss_train: 0.3825\n",
      "Epoch: 5000 loss_train: 0.3599\n",
      "Epoch: 5500 loss_train: 0.3396\n",
      " total time: 2.8966s\n",
      "3.8989973068237305\n",
      "Epoch: 0000 loss_train: 2.0704\n",
      "Epoch: 0500 loss_train: 0.9117\n",
      "Epoch: 1000 loss_train: 0.7246\n",
      "Epoch: 1500 loss_train: 0.6250\n",
      "Epoch: 2000 loss_train: 0.5595\n",
      "Epoch: 2500 loss_train: 0.5106\n",
      "Epoch: 3000 loss_train: 0.4712\n",
      "Epoch: 3500 loss_train: 0.4379\n",
      "Epoch: 4000 loss_train: 0.4089\n",
      "Epoch: 4500 loss_train: 0.3833\n",
      "Epoch: 5000 loss_train: 0.3602\n",
      "Epoch: 5500 loss_train: 0.3393\n",
      " total time: 2.8807s\n",
      "5.2746710777282715\n",
      "Epoch: 0000 loss_train: 2.0704\n",
      "Epoch: 0500 loss_train: 0.9128\n",
      "Epoch: 1000 loss_train: 0.7258\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5609\n",
      "Epoch: 2500 loss_train: 0.5122\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 2.9131s\n",
      "0.02436828799545765\n",
      "Epoch: 0000 loss_train: 2.0704\n",
      "Epoch: 0500 loss_train: 0.9116\n",
      "Epoch: 1000 loss_train: 0.7251\n",
      "Epoch: 1500 loss_train: 0.6257\n",
      "Epoch: 2000 loss_train: 0.5602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2500 loss_train: 0.5114\n",
      "Epoch: 3000 loss_train: 0.4720\n",
      "Epoch: 3500 loss_train: 0.4389\n",
      "Epoch: 4000 loss_train: 0.4101\n",
      "Epoch: 4500 loss_train: 0.3846\n",
      "Epoch: 5000 loss_train: 0.3618\n",
      "Epoch: 5500 loss_train: 0.3411\n",
      " total time: 2.9106s\n",
      "3.382819414138794\n",
      "Epoch: 0000 loss_train: 2.0702\n",
      "Epoch: 0500 loss_train: 0.9116\n",
      "Epoch: 1000 loss_train: 0.7248\n",
      "Epoch: 1500 loss_train: 0.6255\n",
      "Epoch: 2000 loss_train: 0.5602\n",
      "Epoch: 2500 loss_train: 0.5116\n",
      "Epoch: 3000 loss_train: 0.4724\n",
      "Epoch: 3500 loss_train: 0.4393\n",
      "Epoch: 4000 loss_train: 0.4107\n",
      "Epoch: 4500 loss_train: 0.3853\n",
      "Epoch: 5000 loss_train: 0.3626\n",
      "Epoch: 5500 loss_train: 0.3420\n",
      " total time: 3.6332s\n",
      "1.142520546913147\n",
      "Epoch: 0000 loss_train: 2.0704\n",
      "Epoch: 0500 loss_train: 0.9120\n",
      "Epoch: 1000 loss_train: 0.7249\n",
      "Epoch: 1500 loss_train: 0.6254\n",
      "Epoch: 2000 loss_train: 0.5601\n",
      "Epoch: 2500 loss_train: 0.5116\n",
      "Epoch: 3000 loss_train: 0.4726\n",
      "Epoch: 3500 loss_train: 0.4397\n",
      "Epoch: 4000 loss_train: 0.4111\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 2.8828s\n",
      "0.2950785756111145\n",
      "Epoch: 0000 loss_train: 2.0706\n",
      "Epoch: 0500 loss_train: 0.9126\n",
      "Epoch: 1000 loss_train: 0.7256\n",
      "Epoch: 1500 loss_train: 0.6261\n",
      "Epoch: 2000 loss_train: 0.5607\n",
      "Epoch: 2500 loss_train: 0.5120\n",
      "Epoch: 3000 loss_train: 0.4728\n",
      "Epoch: 3500 loss_train: 0.4397\n",
      "Epoch: 4000 loss_train: 0.4110\n",
      "Epoch: 4500 loss_train: 0.3855\n",
      "Epoch: 5000 loss_train: 0.3628\n",
      "Epoch: 5500 loss_train: 0.3421\n",
      " total time: 2.8779s\n",
      "0.6175796985626221\n",
      "Epoch: 0000 loss_train: 2.0706\n",
      "Epoch: 0500 loss_train: 0.9127\n",
      "Epoch: 1000 loss_train: 0.7258\n",
      "Epoch: 1500 loss_train: 0.6263\n",
      "Epoch: 2000 loss_train: 0.5608\n",
      "Epoch: 2500 loss_train: 0.5121\n",
      "Epoch: 3000 loss_train: 0.4728\n",
      "Epoch: 3500 loss_train: 0.4396\n",
      "Epoch: 4000 loss_train: 0.4108\n",
      "Epoch: 4500 loss_train: 0.3854\n",
      "Epoch: 5000 loss_train: 0.3625\n",
      "Epoch: 5500 loss_train: 0.3418\n",
      " total time: 2.8751s\n",
      "1.165421485900879\n",
      "Epoch: 0000 loss_train: 2.0701\n",
      "Epoch: 0500 loss_train: 0.9109\n",
      "Epoch: 1000 loss_train: 0.7236\n",
      "Epoch: 1500 loss_train: 0.6237\n",
      "Epoch: 2000 loss_train: 0.5580\n",
      "Epoch: 2500 loss_train: 0.5091\n",
      "Epoch: 3000 loss_train: 0.4697\n",
      "Epoch: 3500 loss_train: 0.4365\n",
      "Epoch: 4000 loss_train: 0.4077\n",
      "Epoch: 4500 loss_train: 0.3824\n",
      "Epoch: 5000 loss_train: 0.3597\n",
      "Epoch: 5500 loss_train: 0.3391\n",
      " total time: 2.8799s\n",
      "7.416097640991211\n",
      "Epoch: 0000 loss_train: 2.0706\n",
      "Epoch: 0500 loss_train: 0.9127\n",
      "Epoch: 1000 loss_train: 0.7258\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5611\n",
      "Epoch: 2500 loss_train: 0.5124\n",
      "Epoch: 3000 loss_train: 0.4732\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4113\n",
      "Epoch: 4500 loss_train: 0.3859\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.0527s\n",
      "0.00018523407925385982\n",
      "Epoch: 0000 loss_train: 2.0708\n",
      "Epoch: 0500 loss_train: 0.9131\n",
      "Epoch: 1000 loss_train: 0.7260\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.0943s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 2.0703\n",
      "Epoch: 0500 loss_train: 0.9127\n",
      "Epoch: 1000 loss_train: 0.7258\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.0876s\n",
      "0.0030107428319752216\n",
      "Epoch: 0000 loss_train: 2.0702\n",
      "Epoch: 0500 loss_train: 0.9121\n",
      "Epoch: 1000 loss_train: 0.7255\n",
      "Epoch: 1500 loss_train: 0.6262\n",
      "Epoch: 2000 loss_train: 0.5608\n",
      "Epoch: 2500 loss_train: 0.5121\n",
      "Epoch: 3000 loss_train: 0.4729\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.0962s\n",
      "0.09920994192361832\n",
      "Epoch: 0000 loss_train: 2.0703\n",
      "Epoch: 0500 loss_train: 0.9130\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.1821s\n",
      "4.768370445162873e-07\n",
      "Epoch: 0000 loss_train: 2.0702\n",
      "Epoch: 0500 loss_train: 0.9125\n",
      "Epoch: 1000 loss_train: 0.7256\n",
      "Epoch: 1500 loss_train: 0.6261\n",
      "Epoch: 2000 loss_train: 0.5607\n",
      "Epoch: 2500 loss_train: 0.5120\n",
      "Epoch: 3000 loss_train: 0.4728\n",
      "Epoch: 3500 loss_train: 0.4398\n",
      "Epoch: 4000 loss_train: 0.4111\n",
      "Epoch: 4500 loss_train: 0.3857\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.1654s\n",
      "0.17031365633010864\n",
      "Epoch: 0000 loss_train: 2.0703\n",
      "Epoch: 0500 loss_train: 0.9119\n",
      "Epoch: 1000 loss_train: 0.7249\n",
      "Epoch: 1500 loss_train: 0.6254\n",
      "Epoch: 2000 loss_train: 0.5600\n",
      "Epoch: 2500 loss_train: 0.5113\n",
      "Epoch: 3000 loss_train: 0.4720\n",
      "Epoch: 3500 loss_train: 0.4390\n",
      "Epoch: 4000 loss_train: 0.4103\n",
      "Epoch: 4500 loss_train: 0.3849\n",
      "Epoch: 5000 loss_train: 0.3622\n",
      "Epoch: 5500 loss_train: 0.3416\n",
      " total time: 3.1447s\n",
      "1.6786035299301147\n",
      "Epoch: 0000 loss_train: 2.0706\n",
      "Epoch: 0500 loss_train: 0.9128\n",
      "Epoch: 1000 loss_train: 0.7258\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4113\n",
      "Epoch: 4500 loss_train: 0.3859\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.1089s\n",
      "0.01444678008556366\n",
      "Epoch: 0000 loss_train: 2.0703\n",
      "Epoch: 0500 loss_train: 0.9119\n",
      "Epoch: 1000 loss_train: 0.7248\n",
      "Epoch: 1500 loss_train: 0.6253\n",
      "Epoch: 2000 loss_train: 0.5598\n",
      "Epoch: 2500 loss_train: 0.5111\n",
      "Epoch: 3000 loss_train: 0.4719\n",
      "Epoch: 3500 loss_train: 0.4387\n",
      "Epoch: 4000 loss_train: 0.4099\n",
      "Epoch: 4500 loss_train: 0.3845\n",
      "Epoch: 5000 loss_train: 0.3616\n",
      "Epoch: 5500 loss_train: 0.3408\n",
      " total time: 3.0749s\n",
      "3.136108636856079\n",
      "Epoch: 0000 loss_train: 2.0698\n",
      "Epoch: 0500 loss_train: 0.9098\n",
      "Epoch: 1000 loss_train: 0.7225\n",
      "Epoch: 1500 loss_train: 0.6230\n",
      "Epoch: 2000 loss_train: 0.5577\n",
      "Epoch: 2500 loss_train: 0.5092\n",
      "Epoch: 3000 loss_train: 0.4701\n",
      "Epoch: 3500 loss_train: 0.4371\n",
      "Epoch: 4000 loss_train: 0.4085\n",
      "Epoch: 4500 loss_train: 0.3831\n",
      "Epoch: 5000 loss_train: 0.3604\n",
      "Epoch: 5500 loss_train: 0.3397\n",
      " total time: 3.1183s\n",
      "6.698335647583008\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9123\n",
      "Epoch: 1000 loss_train: 0.7255\n",
      "Epoch: 1500 loss_train: 0.6262\n",
      "Epoch: 2000 loss_train: 0.5608\n",
      "Epoch: 2500 loss_train: 0.5120\n",
      "Epoch: 3000 loss_train: 0.4728\n",
      "Epoch: 3500 loss_train: 0.4396\n",
      "Epoch: 4000 loss_train: 0.4109\n",
      "Epoch: 4500 loss_train: 0.3855\n",
      "Epoch: 5000 loss_train: 0.3627\n",
      "Epoch: 5500 loss_train: 0.3421\n",
      " total time: 3.0748s\n",
      "0.7727566957473755\n",
      "Epoch: 0000 loss_train: 2.0707\n",
      "Epoch: 0500 loss_train: 0.9131\n",
      "Epoch: 1000 loss_train: 0.7260\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.0599s\n",
      "3.349725011503324e-05\n",
      "Epoch: 0000 loss_train: 2.0704\n",
      "Epoch: 0500 loss_train: 0.9115\n",
      "Epoch: 1000 loss_train: 0.7247\n",
      "Epoch: 1500 loss_train: 0.6255\n",
      "Epoch: 2000 loss_train: 0.5602\n",
      "Epoch: 2500 loss_train: 0.5116\n",
      "Epoch: 3000 loss_train: 0.4724\n",
      "Epoch: 3500 loss_train: 0.4393\n",
      "Epoch: 4000 loss_train: 0.4106\n",
      "Epoch: 4500 loss_train: 0.3852\n",
      "Epoch: 5000 loss_train: 0.3624\n",
      "Epoch: 5500 loss_train: 0.3417\n",
      " total time: 3.1630s\n",
      "1.6948198080062866\n",
      "Epoch: 0000 loss_train: 2.0703\n",
      "Epoch: 0500 loss_train: 0.9127\n",
      "Epoch: 1000 loss_train: 0.7261\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5122\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3859\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.1618s\n",
      "0.01602003537118435\n",
      "Epoch: 0000 loss_train: 2.0703\n",
      "Epoch: 0500 loss_train: 0.9128\n",
      "Epoch: 1000 loss_train: 0.7257\n",
      "Epoch: 1500 loss_train: 0.6263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 loss_train: 0.5609\n",
      "Epoch: 2500 loss_train: 0.5122\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.1079s\n",
      "0.0010189585154876113\n",
      "Epoch: 0000 loss_train: 2.0702\n",
      "Epoch: 0500 loss_train: 0.9129\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.1230s\n",
      "1.1920927533992653e-07\n",
      "Epoch: 0000 loss_train: 2.0704\n",
      "Epoch: 0500 loss_train: 0.9127\n",
      "Epoch: 1000 loss_train: 0.7257\n",
      "Epoch: 1500 loss_train: 0.6263\n",
      "Epoch: 2000 loss_train: 0.5608\n",
      "Epoch: 2500 loss_train: 0.5121\n",
      "Epoch: 3000 loss_train: 0.4729\n",
      "Epoch: 3500 loss_train: 0.4398\n",
      "Epoch: 4000 loss_train: 0.4111\n",
      "Epoch: 4500 loss_train: 0.3857\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.1726s\n",
      "0.20929120481014252\n",
      "Epoch: 0000 loss_train: 2.0703\n",
      "Epoch: 0500 loss_train: 0.9120\n",
      "Epoch: 1000 loss_train: 0.7256\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5124\n",
      "Epoch: 3000 loss_train: 0.4732\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4113\n",
      "Epoch: 4500 loss_train: 0.3859\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.1793s\n",
      "0.008227149024605751\n",
      "Epoch: 0000 loss_train: 2.0707\n",
      "Epoch: 0500 loss_train: 0.9129\n",
      "Epoch: 1000 loss_train: 0.7258\n",
      "Epoch: 1500 loss_train: 0.6263\n",
      "Epoch: 2000 loss_train: 0.5609\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3859\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.1359s\n",
      "0.019316887483000755\n",
      "Epoch: 0000 loss_train: 2.0706\n",
      "Epoch: 0500 loss_train: 0.9128\n",
      "Epoch: 1000 loss_train: 0.7258\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3859\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.0633s\n",
      "0.0009305914863944054\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9127\n",
      "Epoch: 1000 loss_train: 0.7257\n",
      "Epoch: 1500 loss_train: 0.6263\n",
      "Epoch: 2000 loss_train: 0.5609\n",
      "Epoch: 2500 loss_train: 0.5122\n",
      "Epoch: 3000 loss_train: 0.4729\n",
      "Epoch: 3500 loss_train: 0.4398\n",
      "Epoch: 4000 loss_train: 0.4111\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.1180s\n",
      "0.19532595574855804\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9130\n",
      "Epoch: 1000 loss_train: 0.7260\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.1056s\n",
      "1.4305013792181853e-05\n",
      "Epoch: 0000 loss_train: 2.0700\n",
      "Epoch: 0500 loss_train: 0.9117\n",
      "Epoch: 1000 loss_train: 0.7244\n",
      "Epoch: 1500 loss_train: 0.6247\n",
      "Epoch: 2000 loss_train: 0.5592\n",
      "Epoch: 2500 loss_train: 0.5105\n",
      "Epoch: 3000 loss_train: 0.4713\n",
      "Epoch: 3500 loss_train: 0.4382\n",
      "Epoch: 4000 loss_train: 0.4096\n",
      "Epoch: 4500 loss_train: 0.3843\n",
      "Epoch: 5000 loss_train: 0.3616\n",
      "Epoch: 5500 loss_train: 0.3410\n",
      " total time: 3.1724s\n",
      "3.2543110847473145\n",
      "Epoch: 0000 loss_train: 2.0702\n",
      "Epoch: 0500 loss_train: 0.9121\n",
      "Epoch: 1000 loss_train: 0.7252\n",
      "Epoch: 1500 loss_train: 0.6258\n",
      "Epoch: 2000 loss_train: 0.5604\n",
      "Epoch: 2500 loss_train: 0.5118\n",
      "Epoch: 3000 loss_train: 0.4726\n",
      "Epoch: 3500 loss_train: 0.4396\n",
      "Epoch: 4000 loss_train: 0.4110\n",
      "Epoch: 4500 loss_train: 0.3857\n",
      "Epoch: 5000 loss_train: 0.3629\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.1690s\n",
      "0.3887808620929718\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9126\n",
      "Epoch: 1000 loss_train: 0.7258\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5609\n",
      "Epoch: 2500 loss_train: 0.5122\n",
      "Epoch: 3000 loss_train: 0.4729\n",
      "Epoch: 3500 loss_train: 0.4398\n",
      "Epoch: 4000 loss_train: 0.4110\n",
      "Epoch: 4500 loss_train: 0.3856\n",
      "Epoch: 5000 loss_train: 0.3628\n",
      "Epoch: 5500 loss_train: 0.3422\n",
      " total time: 3.1428s\n",
      "0.5276904106140137\n",
      "Epoch: 0000 loss_train: 2.0706\n",
      "Epoch: 0500 loss_train: 0.9131\n",
      "Epoch: 1000 loss_train: 0.7260\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.0957s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 2.0703\n",
      "Epoch: 0500 loss_train: 0.9121\n",
      "Epoch: 1000 loss_train: 0.7257\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5609\n",
      "Epoch: 2500 loss_train: 0.5122\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.1817s\n",
      "0.23873955011367798\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9128\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.2944s\n",
      "0.0006098079611547291\n",
      "Epoch: 0000 loss_train: 2.0672\n",
      "Epoch: 0500 loss_train: 0.9040\n",
      "Epoch: 1000 loss_train: 0.7229\n",
      "Epoch: 1500 loss_train: 0.6272\n",
      "Epoch: 2000 loss_train: 0.5638\n",
      "Epoch: 2500 loss_train: 0.5161\n",
      "Epoch: 3000 loss_train: 0.4773\n",
      "Epoch: 3500 loss_train: 0.4444\n",
      "Epoch: 4000 loss_train: 0.4157\n",
      "Epoch: 4500 loss_train: 0.3902\n",
      "Epoch: 5000 loss_train: 0.3673\n",
      "Epoch: 5500 loss_train: 0.3465\n",
      " total time: 3.2022s\n",
      "4.166111946105957\n",
      "Epoch: 0000 loss_train: 2.0771\n",
      "Epoch: 0500 loss_train: 0.9050\n",
      "Epoch: 1000 loss_train: 0.7205\n",
      "Epoch: 1500 loss_train: 0.6230\n",
      "Epoch: 2000 loss_train: 0.5586\n",
      "Epoch: 2500 loss_train: 0.5104\n",
      "Epoch: 3000 loss_train: 0.4714\n",
      "Epoch: 3500 loss_train: 0.4384\n",
      "Epoch: 4000 loss_train: 0.4097\n",
      "Epoch: 4500 loss_train: 0.3844\n",
      "Epoch: 5000 loss_train: 0.3616\n",
      "Epoch: 5500 loss_train: 0.3410\n",
      " total time: 3.1737s\n",
      "8.13797378540039\n",
      "Epoch: 0000 loss_train: 2.0635\n",
      "Epoch: 0500 loss_train: 0.9133\n",
      "Epoch: 1000 loss_train: 0.7298\n",
      "Epoch: 1500 loss_train: 0.6305\n",
      "Epoch: 2000 loss_train: 0.5649\n",
      "Epoch: 2500 loss_train: 0.5159\n",
      "Epoch: 3000 loss_train: 0.4765\n",
      "Epoch: 3500 loss_train: 0.4432\n",
      "Epoch: 4000 loss_train: 0.4143\n",
      "Epoch: 4500 loss_train: 0.3887\n",
      "Epoch: 5000 loss_train: 0.3658\n",
      "Epoch: 5500 loss_train: 0.3450\n",
      " total time: 3.1827s\n",
      "0.168270081281662\n",
      "Epoch: 0000 loss_train: 2.0813\n",
      "Epoch: 0500 loss_train: 0.9060\n",
      "Epoch: 1000 loss_train: 0.7229\n",
      "Epoch: 1500 loss_train: 0.6255\n",
      "Epoch: 2000 loss_train: 0.5616\n",
      "Epoch: 2500 loss_train: 0.5139\n",
      "Epoch: 3000 loss_train: 0.4755\n",
      "Epoch: 3500 loss_train: 0.4428\n",
      "Epoch: 4000 loss_train: 0.4144\n",
      "Epoch: 4500 loss_train: 0.3891\n",
      "Epoch: 5000 loss_train: 0.3663\n",
      "Epoch: 5500 loss_train: 0.3456\n",
      " total time: 3.2326s\n",
      "1.5004525184631348\n",
      "Epoch: 0000 loss_train: 2.0852\n",
      "Epoch: 0500 loss_train: 0.9162\n",
      "Epoch: 1000 loss_train: 0.7290\n",
      "Epoch: 1500 loss_train: 0.6292\n",
      "Epoch: 2000 loss_train: 0.5636\n",
      "Epoch: 2500 loss_train: 0.5148\n",
      "Epoch: 3000 loss_train: 0.4756\n",
      "Epoch: 3500 loss_train: 0.4425\n",
      "Epoch: 4000 loss_train: 0.4139\n",
      "Epoch: 4500 loss_train: 0.3886\n",
      "Epoch: 5000 loss_train: 0.3658\n",
      "Epoch: 5500 loss_train: 0.3452\n",
      " total time: 3.0177s\n",
      "16.543865203857422\n",
      "Epoch: 0000 loss_train: 2.0716\n",
      "Epoch: 0500 loss_train: 0.9125\n",
      "Epoch: 1000 loss_train: 0.7251\n",
      "Epoch: 1500 loss_train: 0.6255\n",
      "Epoch: 2000 loss_train: 0.5600\n",
      "Epoch: 2500 loss_train: 0.5111\n",
      "Epoch: 3000 loss_train: 0.4718\n",
      "Epoch: 3500 loss_train: 0.4386\n",
      "Epoch: 4000 loss_train: 0.4097\n",
      "Epoch: 4500 loss_train: 0.3843\n",
      "Epoch: 5000 loss_train: 0.3615\n",
      "Epoch: 5500 loss_train: 0.3409\n",
      " total time: 3.0013s\n",
      "2.4987425804138184\n",
      "Epoch: 0000 loss_train: 2.0713\n",
      "Epoch: 0500 loss_train: 0.9122\n",
      "Epoch: 1000 loss_train: 0.7253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1500 loss_train: 0.6260\n",
      "Epoch: 2000 loss_train: 0.5608\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4732\n",
      "Epoch: 3500 loss_train: 0.4401\n",
      "Epoch: 4000 loss_train: 0.4114\n",
      "Epoch: 4500 loss_train: 0.3860\n",
      "Epoch: 5000 loss_train: 0.3633\n",
      "Epoch: 5500 loss_train: 0.3426\n",
      " total time: 3.0218s\n",
      "0.13870351016521454\n",
      "Epoch: 0000 loss_train: 2.0717\n",
      "Epoch: 0500 loss_train: 0.9128\n",
      "Epoch: 1000 loss_train: 0.7256\n",
      "Epoch: 1500 loss_train: 0.6261\n",
      "Epoch: 2000 loss_train: 0.5607\n",
      "Epoch: 2500 loss_train: 0.5120\n",
      "Epoch: 3000 loss_train: 0.4728\n",
      "Epoch: 3500 loss_train: 0.4397\n",
      "Epoch: 4000 loss_train: 0.4109\n",
      "Epoch: 4500 loss_train: 0.3856\n",
      "Epoch: 5000 loss_train: 0.3629\n",
      "Epoch: 5500 loss_train: 0.3423\n",
      " total time: 3.0214s\n",
      "0.518147349357605\n",
      "Epoch: 0000 loss_train: 2.0715\n",
      "Epoch: 0500 loss_train: 0.9117\n",
      "Epoch: 1000 loss_train: 0.7251\n",
      "Epoch: 1500 loss_train: 0.6260\n",
      "Epoch: 2000 loss_train: 0.5609\n",
      "Epoch: 2500 loss_train: 0.5124\n",
      "Epoch: 3000 loss_train: 0.4733\n",
      "Epoch: 3500 loss_train: 0.4402\n",
      "Epoch: 4000 loss_train: 0.4115\n",
      "Epoch: 4500 loss_train: 0.3862\n",
      "Epoch: 5000 loss_train: 0.3634\n",
      "Epoch: 5500 loss_train: 0.3427\n",
      " total time: 2.9971s\n",
      "0.271149218082428\n",
      "Epoch: 0000 loss_train: 2.0703\n",
      "Epoch: 0500 loss_train: 0.9026\n",
      "Epoch: 1000 loss_train: 0.7128\n",
      "Epoch: 1500 loss_train: 0.6114\n",
      "Epoch: 2000 loss_train: 0.5443\n",
      "Epoch: 2500 loss_train: 0.4939\n",
      "Epoch: 3000 loss_train: 0.4531\n",
      "Epoch: 3500 loss_train: 0.4185\n",
      "Epoch: 4000 loss_train: 0.3883\n",
      "Epoch: 4500 loss_train: 0.3616\n",
      "Epoch: 5000 loss_train: 0.3376\n",
      "Epoch: 5500 loss_train: 0.3157\n",
      " total time: 3.0526s\n",
      "22.387405395507812\n",
      "Epoch: 0000 loss_train: 2.0716\n",
      "Epoch: 0500 loss_train: 0.9130\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5611\n",
      "Epoch: 2500 loss_train: 0.5124\n",
      "Epoch: 3000 loss_train: 0.4732\n",
      "Epoch: 3500 loss_train: 0.4401\n",
      "Epoch: 4000 loss_train: 0.4114\n",
      "Epoch: 4500 loss_train: 0.3861\n",
      "Epoch: 5000 loss_train: 0.3633\n",
      "Epoch: 5500 loss_train: 0.3427\n",
      " total time: 3.0552s\n",
      "0.07500933110713959\n",
      "Epoch: 0000 loss_train: 2.0708\n",
      "Epoch: 0500 loss_train: 0.9113\n",
      "Epoch: 1000 loss_train: 0.7236\n",
      "Epoch: 1500 loss_train: 0.6236\n",
      "Epoch: 2000 loss_train: 0.5578\n",
      "Epoch: 2500 loss_train: 0.5090\n",
      "Epoch: 3000 loss_train: 0.4698\n",
      "Epoch: 3500 loss_train: 0.4369\n",
      "Epoch: 4000 loss_train: 0.4085\n",
      "Epoch: 4500 loss_train: 0.3834\n",
      "Epoch: 5000 loss_train: 0.3609\n",
      "Epoch: 5500 loss_train: 0.3404\n",
      " total time: 3.2343s\n",
      "4.883625507354736\n",
      "Epoch: 0000 loss_train: 2.0710\n",
      "Epoch: 0500 loss_train: 0.9123\n",
      "Epoch: 1000 loss_train: 0.7254\n",
      "Epoch: 1500 loss_train: 0.6261\n",
      "Epoch: 2000 loss_train: 0.5607\n",
      "Epoch: 2500 loss_train: 0.5121\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.2025s\n",
      "0.2516424059867859\n",
      "Epoch: 0000 loss_train: 2.0711\n",
      "Epoch: 0500 loss_train: 0.9123\n",
      "Epoch: 1000 loss_train: 0.7249\n",
      "Epoch: 1500 loss_train: 0.6252\n",
      "Epoch: 2000 loss_train: 0.5597\n",
      "Epoch: 0500 loss_train: 0.9139\n",
      "Epoch: 1000 loss_train: 0.7266\n",
      "Epoch: 1500 loss_train: 0.6270\n",
      "Epoch: 2000 loss_train: 0.5614\n",
      "Epoch: 2500 loss_train: 0.5127\n",
      "Epoch: 3000 loss_train: 0.4735\n",
      "Epoch: 3500 loss_train: 0.4404\n",
      "Epoch: 4000 loss_train: 0.4116\n",
      "Epoch: 4500 loss_train: 0.3862\n",
      "Epoch: 5000 loss_train: 0.3634\n",
      "Epoch: 5500 loss_train: 0.3428\n",
      " total time: 3.0425s\n",
      "0.2576466500759125\n",
      "Epoch: 0000 loss_train: 2.0719\n",
      "Epoch: 0500 loss_train: 0.9134\n",
      "Epoch: 1000 loss_train: 0.7261\n",
      "Epoch: 1500 loss_train: 0.6266\n",
      "Epoch: 2000 loss_train: 0.5612\n",
      "Epoch: 2500 loss_train: 0.5125\n",
      "Epoch: 3000 loss_train: 0.4733\n",
      "Epoch: 3500 loss_train: 0.4403\n",
      "Epoch: 4000 loss_train: 0.4116\n",
      "Epoch: 4500 loss_train: 0.3862\n",
      "Epoch: 5000 loss_train: 0.3634\n",
      "Epoch: 5500 loss_train: 0.3428\n",
      " total time: 3.1113s\n",
      "0.03093440644443035\n",
      "Epoch: 0000 loss_train: 2.0708\n",
      "Epoch: 0500 loss_train: 0.9116\n",
      "Epoch: 1000 loss_train: 0.7242\n",
      "Epoch: 1500 loss_train: 0.6248\n",
      "Epoch: 2000 loss_train: 0.5595\n",
      "Epoch: 2500 loss_train: 0.5110\n",
      "Epoch: 3000 loss_train: 0.4719\n",
      "Epoch: 3500 loss_train: 0.4390\n",
      "Epoch: 4000 loss_train: 0.4105\n",
      "Epoch: 4500 loss_train: 0.3853\n",
      "Epoch: 5000 loss_train: 0.3627\n",
      "Epoch: 5500 loss_train: 0.3422\n",
      " total time: 3.0593s\n",
      "0.8027249574661255\n",
      "Epoch: 0000 loss_train: 2.0709\n",
      "Epoch: 0500 loss_train: 0.9128\n",
      "Epoch: 1000 loss_train: 0.7257\n",
      "Epoch: 1500 loss_train: 0.6262\n",
      "Epoch: 2000 loss_train: 0.5608\n",
      "Epoch: 2500 loss_train: 0.5121\n",
      "Epoch: 3000 loss_train: 0.4728\n",
      "Epoch: 3500 loss_train: 0.4397\n",
      "Epoch: 4000 loss_train: 0.4110\n",
      "Epoch: 4500 loss_train: 0.3856\n",
      "Epoch: 5000 loss_train: 0.3629\n",
      "Epoch: 5500 loss_train: 0.3422\n",
      " total time: 3.0463s\n",
      "0.41130179166793823\n",
      "Epoch: 0000 loss_train: 2.0716\n",
      "Epoch: 0500 loss_train: 0.9134\n",
      "Epoch: 1000 loss_train: 0.7263\n",
      "Epoch: 1500 loss_train: 0.6268\n",
      "Epoch: 2000 loss_train: 0.5614\n",
      "Epoch: 2500 loss_train: 0.5127\n",
      "Epoch: 3000 loss_train: 0.4735\n",
      "Epoch: 3500 loss_train: 0.4403\n",
      "Epoch: 4000 loss_train: 0.4116\n",
      "Epoch: 4500 loss_train: 0.3862\n",
      "Epoch: 5000 loss_train: 0.3634\n",
      "Epoch: 5500 loss_train: 0.3428\n",
      " total time: 3.1375s\n",
      "0.00502774678170681\n",
      "Epoch: 0000 loss_train: 2.0717\n",
      "Epoch: 0500 loss_train: 0.9134\n",
      "Epoch: 1000 loss_train: 0.7261\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5609\n",
      "Epoch: 2500 loss_train: 0.5121\n",
      "Epoch: 3000 loss_train: 0.4728\n",
      "Epoch: 3500 loss_train: 0.4396\n",
      "Epoch: 4000 loss_train: 0.4108\n",
      "Epoch: 4500 loss_train: 0.3854\n",
      "Epoch: 5000 loss_train: 0.3626\n",
      "Epoch: 5500 loss_train: 0.3419\n",
      " total time: 3.0964s\n",
      "0.6845055222511292\n",
      "Epoch: 0000 loss_train: 2.0711\n",
      "Epoch: 0500 loss_train: 0.9131\n",
      "Epoch: 1000 loss_train: 0.7262\n",
      "Epoch: 1500 loss_train: 0.6268\n",
      "Epoch: 2000 loss_train: 0.5614\n",
      "Epoch: 2500 loss_train: 0.5126\n",
      "Epoch: 3000 loss_train: 0.4734\n",
      "Epoch: 3500 loss_train: 0.4402\n",
      "Epoch: 4000 loss_train: 0.4115\n",
      "Epoch: 4500 loss_train: 0.3860\n",
      "Epoch: 5000 loss_train: 0.3633\n",
      "Epoch: 5500 loss_train: 0.3426\n",
      " total time: 3.0493s\n",
      "0.0027083405293524265\n",
      "Epoch: 0000 loss_train: 2.0719\n",
      "Epoch: 0500 loss_train: 0.9137\n",
      "Epoch: 1000 loss_train: 0.7265\n",
      "Epoch: 1500 loss_train: 0.6269\n",
      "Epoch: 2000 loss_train: 0.5614\n",
      "Epoch: 2500 loss_train: 0.5127\n",
      "Epoch: 3000 loss_train: 0.4734\n",
      "Epoch: 3500 loss_train: 0.4403\n",
      "Epoch: 4000 loss_train: 0.4115\n",
      "Epoch: 4500 loss_train: 0.3861\n",
      "Epoch: 5000 loss_train: 0.3634\n",
      "Epoch: 5500 loss_train: 0.3427\n",
      " total time: 3.0887s\n",
      "0.013824544847011566\n",
      "Epoch: 0000 loss_train: 2.0715\n",
      "Epoch: 0500 loss_train: 0.9137\n",
      "Epoch: 1000 loss_train: 0.7264\n",
      "Epoch: 1500 loss_train: 0.6268\n",
      "Epoch: 2000 loss_train: 0.5613\n",
      "Epoch: 2500 loss_train: 0.5126\n",
      "Epoch: 3000 loss_train: 0.4733\n",
      "Epoch: 3500 loss_train: 0.4402\n",
      "Epoch: 4000 loss_train: 0.4114\n",
      "Epoch: 4500 loss_train: 0.3860\n",
      "Epoch: 5000 loss_train: 0.3632\n",
      "Epoch: 5500 loss_train: 0.3426\n",
      " total time: 3.1104s\n",
      "0.12963755428791046\n",
      "Epoch: 0000 loss_train: 2.0707\n",
      "Epoch: 0500 loss_train: 0.9099\n",
      "Epoch: 1000 loss_train: 0.7216\n",
      "Epoch: 1500 loss_train: 0.6214\n",
      "Epoch: 2000 loss_train: 0.5555\n",
      "Epoch: 2500 loss_train: 0.5065\n",
      "Epoch: 3000 loss_train: 0.4670\n",
      "Epoch: 3500 loss_train: 0.4335\n",
      "Epoch: 4000 loss_train: 0.4045\n",
      "Epoch: 4500 loss_train: 0.3789\n",
      "Epoch: 5000 loss_train: 0.3559\n",
      "Epoch: 5500 loss_train: 0.3351\n",
      " total time: 3.0861s\n",
      "6.179195404052734\n",
      "Epoch: 0000 loss_train: 2.0710\n",
      "Epoch: 0500 loss_train: 0.9123\n",
      "Epoch: 1000 loss_train: 0.7252\n",
      "Epoch: 1500 loss_train: 0.6257\n",
      "Epoch: 2000 loss_train: 0.5602\n",
      "Epoch: 2500 loss_train: 0.5116\n",
      "Epoch: 3000 loss_train: 0.4724\n",
      "Epoch: 3500 loss_train: 0.4393\n",
      "Epoch: 4000 loss_train: 0.4106\n",
      "Epoch: 4500 loss_train: 0.3853\n",
      "Epoch: 5000 loss_train: 0.3625\n",
      "Epoch: 5500 loss_train: 0.3419\n",
      " total time: 3.0576s\n",
      "0.6691580414772034\n",
      "Epoch: 0000 loss_train: 2.0713\n",
      "Epoch: 0500 loss_train: 0.9130\n",
      "Epoch: 1000 loss_train: 0.7256\n",
      "Epoch: 1500 loss_train: 0.6260\n",
      "Epoch: 2000 loss_train: 0.5605\n",
      "Epoch: 2500 loss_train: 0.5118\n",
      "Epoch: 3000 loss_train: 0.4726\n",
      "Epoch: 3500 loss_train: 0.4396\n",
      "Epoch: 4000 loss_train: 0.4109\n",
      "Epoch: 4500 loss_train: 0.3855\n",
      "Epoch: 5000 loss_train: 0.3627\n",
      "Epoch: 5500 loss_train: 0.3421\n",
      " total time: 3.0194s\n",
      "0.571951150894165\n",
      "Epoch: 0000 loss_train: 2.0699\n",
      "Epoch: 0500 loss_train: 0.9080\n",
      "Epoch: 1000 loss_train: 0.7213\n",
      "Epoch: 1500 loss_train: 0.6220\n",
      "Epoch: 2000 loss_train: 0.5563\n",
      "Epoch: 2500 loss_train: 0.5074\n",
      "Epoch: 3000 loss_train: 0.4681\n",
      "Epoch: 3500 loss_train: 0.4350\n",
      "Epoch: 4000 loss_train: 0.4063\n",
      "Epoch: 4500 loss_train: 0.3810\n",
      "Epoch: 5000 loss_train: 0.3582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5500 loss_train: 0.3376\n",
      " total time: 3.0580s\n",
      "11.373620986938477\n",
      "Epoch: 0000 loss_train: 2.0712\n",
      "Epoch: 0500 loss_train: 0.9103\n",
      "Epoch: 1000 loss_train: 0.7229\n",
      "Epoch: 1500 loss_train: 0.6234\n",
      "Epoch: 2000 loss_train: 0.5581\n",
      "Epoch: 2500 loss_train: 0.5095\n",
      "Epoch: 3000 loss_train: 0.4703\n",
      "Epoch: 3500 loss_train: 0.4371\n",
      "Epoch: 4000 loss_train: 0.4081\n",
      "Epoch: 4500 loss_train: 0.3824\n",
      "Epoch: 5000 loss_train: 0.3593\n",
      "Epoch: 5500 loss_train: 0.3382\n",
      " total time: 3.1074s\n",
      "5.129616737365723\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9129\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3859\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.0423s\n",
      "0.00273199868388474\n",
      "Epoch: 0000 loss_train: 2.0706\n",
      "Epoch: 0500 loss_train: 0.9129\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5609\n",
      "Epoch: 2500 loss_train: 0.5122\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4111\n",
      "Epoch: 4500 loss_train: 0.3857\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.1110s\n",
      "0.13569234311580658\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9126\n",
      "Epoch: 1000 loss_train: 0.7258\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.0882s\n",
      "0.05318336561322212\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9126\n",
      "Epoch: 1000 loss_train: 0.7258\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5612\n",
      "Epoch: 2500 loss_train: 0.5125\n",
      "Epoch: 3000 loss_train: 0.4732\n",
      "Epoch: 3500 loss_train: 0.4401\n",
      "Epoch: 4000 loss_train: 0.4113\n",
      "Epoch: 4500 loss_train: 0.3859\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.0795s\n",
      "0.0006255338666960597\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9130\n",
      "Epoch: 1000 loss_train: 0.7260\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.0293s\n",
      "5.483612312673358e-06\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9123\n",
      "Epoch: 1000 loss_train: 0.7255\n",
      "Epoch: 1500 loss_train: 0.6260\n",
      "Epoch: 2000 loss_train: 0.5605\n",
      "Epoch: 2500 loss_train: 0.5118\n",
      "Epoch: 3000 loss_train: 0.4725\n",
      "Epoch: 3500 loss_train: 0.4393\n",
      "Epoch: 4000 loss_train: 0.4105\n",
      "Epoch: 4500 loss_train: 0.3851\n",
      "Epoch: 5000 loss_train: 0.3624\n",
      "Epoch: 5500 loss_train: 0.3418\n",
      " total time: 3.0846s\n",
      "1.5500396490097046\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9130\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.0431s\n",
      "4.5298504119273275e-05\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9130\n",
      "Epoch: 1000 loss_train: 0.7260\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3859\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.0907s\n",
      "2.0265558760002023e-06\n",
      "Epoch: 0000 loss_train: 2.0702\n",
      "Epoch: 0500 loss_train: 0.9128\n",
      "Epoch: 1000 loss_train: 0.7258\n",
      "Epoch: 1500 loss_train: 0.6263\n",
      "Epoch: 2000 loss_train: 0.5609\n",
      "Epoch: 2500 loss_train: 0.5122\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.1022s\n",
      "0.12506982684135437\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9120\n",
      "Epoch: 1000 loss_train: 0.7249\n",
      "Epoch: 1500 loss_train: 0.6254\n",
      "Epoch: 2000 loss_train: 0.5601\n",
      "Epoch: 2500 loss_train: 0.5115\n",
      "Epoch: 3000 loss_train: 0.4723\n",
      "Epoch: 3500 loss_train: 0.4393\n",
      "Epoch: 4000 loss_train: 0.4106\n",
      "Epoch: 4500 loss_train: 0.3851\n",
      "Epoch: 5000 loss_train: 0.3623\n",
      "Epoch: 5500 loss_train: 0.3416\n",
      " total time: 3.1127s\n",
      "2.447157382965088\n",
      "Epoch: 0000 loss_train: 2.0707\n",
      "Epoch: 0500 loss_train: 0.9130\n",
      "Epoch: 1000 loss_train: 0.7260\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.0279s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 2.0706\n",
      "Epoch: 0500 loss_train: 0.9130\n",
      "Epoch: 1000 loss_train: 0.7260\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 2.9055s\n",
      "4.887569048150908e-06\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9130\n",
      "Epoch: 1000 loss_train: 0.7260\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 2.8889s\n",
      "4.9232225137529895e-05\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9125\n",
      "Epoch: 1000 loss_train: 0.7257\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4113\n",
      "Epoch: 4500 loss_train: 0.3859\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 2.9418s\n",
      "0.01083396840840578\n",
      "Epoch: 0000 loss_train: 2.0699\n",
      "Epoch: 0500 loss_train: 0.9118\n",
      "Epoch: 1000 loss_train: 0.7245\n",
      "Epoch: 1500 loss_train: 0.6250\n",
      "Epoch: 2000 loss_train: 0.5594\n",
      "Epoch: 2500 loss_train: 0.5107\n",
      "Epoch: 3000 loss_train: 0.4714\n",
      "Epoch: 3500 loss_train: 0.4383\n",
      "Epoch: 4000 loss_train: 0.4095\n",
      "Epoch: 4500 loss_train: 0.3841\n",
      "Epoch: 5000 loss_train: 0.3613\n",
      "Epoch: 5500 loss_train: 0.3406\n",
      " total time: 3.0113s\n",
      "4.119019985198975\n",
      "Epoch: 0000 loss_train: 2.0703\n",
      "Epoch: 0500 loss_train: 0.9124\n",
      "Epoch: 1000 loss_train: 0.7256\n",
      "Epoch: 1500 loss_train: 0.6262\n",
      "Epoch: 2000 loss_train: 0.5609\n",
      "Epoch: 2500 loss_train: 0.5122\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4111\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.1189s\n",
      "0.14080803096294403\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9124\n",
      "Epoch: 1000 loss_train: 0.7253\n",
      "Epoch: 1500 loss_train: 0.6258\n",
      "Epoch: 2000 loss_train: 0.5604\n",
      "Epoch: 2500 loss_train: 0.5119\n",
      "Epoch: 3000 loss_train: 0.4728\n",
      "Epoch: 3500 loss_train: 0.4397\n",
      "Epoch: 4000 loss_train: 0.4111\n",
      "Epoch: 4500 loss_train: 0.3857\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3423\n",
      " total time: 3.1053s\n",
      "0.3522144854068756\n",
      "Epoch: 0000 loss_train: 2.0700\n",
      "Epoch: 0500 loss_train: 0.9125\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.1301s\n",
      "0.0004306104383431375\n",
      "Epoch: 0000 loss_train: 2.0704\n",
      "Epoch: 0500 loss_train: 0.9130\n",
      "Epoch: 1000 loss_train: 0.7260\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.0758s\n",
      "0.001116367639042437\n",
      "Epoch: 0000 loss_train: 2.0700\n",
      "Epoch: 0500 loss_train: 0.9128\n",
      "Epoch: 1000 loss_train: 0.7258\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5609\n",
      "Epoch: 2500 loss_train: 0.5122\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.0893s\n",
      "0.0001530530134914443\n",
      "Epoch: 0000 loss_train: 2.0706\n",
      "Epoch: 0500 loss_train: 0.9129\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.1657s\n",
      "0.0029560700058937073\n",
      "Epoch: 0000 loss_train: 2.0706\n",
      "Epoch: 0500 loss_train: 0.9130\n",
      "Epoch: 1000 loss_train: 0.7260\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.1814s\n",
      "3.576272320060525e-06\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9131\n",
      "Epoch: 1000 loss_train: 0.7260\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.1517s\n",
      "3.397406908334233e-05\n",
      "Epoch: 0000 loss_train: 2.0702\n",
      "Epoch: 0500 loss_train: 0.9128\n",
      "Epoch: 1000 loss_train: 0.7258\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5609\n",
      "Epoch: 2500 loss_train: 0.5122\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 2.9967s\n",
      "0.018044129014015198\n",
      "Epoch: 0000 loss_train: 2.0706\n",
      "Epoch: 0500 loss_train: 0.9129\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.0007s\n",
      "7.152555099310121e-07\n",
      "Epoch: 0000 loss_train: 2.0700\n",
      "Epoch: 0500 loss_train: 0.9117\n",
      "Epoch: 1000 loss_train: 0.7252\n",
      "Epoch: 1500 loss_train: 0.6260\n",
      "Epoch: 2000 loss_train: 0.5608\n",
      "Epoch: 2500 loss_train: 0.5122\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4113\n",
      "Epoch: 4500 loss_train: 0.3859\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.0784s\n",
      "0.047774165868759155\n",
      "Epoch: 0000 loss_train: 2.0706\n",
      "Epoch: 0500 loss_train: 0.9125\n",
      "Epoch: 1000 loss_train: 0.7256\n",
      "Epoch: 1500 loss_train: 0.6261\n",
      "Epoch: 2000 loss_train: 0.5606\n",
      "Epoch: 2500 loss_train: 0.5119\n",
      "Epoch: 3000 loss_train: 0.4727\n",
      "Epoch: 3500 loss_train: 0.4396\n",
      "Epoch: 4000 loss_train: 0.4109\n",
      "Epoch: 4500 loss_train: 0.3855\n",
      "Epoch: 5000 loss_train: 0.3628\n",
      "Epoch: 5500 loss_train: 0.3422\n",
      " total time: 3.1988s\n",
      "0.6313045024871826\n",
      "Epoch: 0000 loss_train: 2.0707\n",
      "Epoch: 0500 loss_train: 0.9129\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4113\n",
      "Epoch: 4500 loss_train: 0.3859\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.2504s\n",
      "0.005077799782156944\n",
      "Epoch: 0000 loss_train: 2.0702\n",
      "Epoch: 0500 loss_train: 0.9122\n",
      "Epoch: 1000 loss_train: 0.7256\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5124\n",
      "Epoch: 3000 loss_train: 0.4732\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4113\n",
      "Epoch: 4500 loss_train: 0.3859\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 2.9733s\n",
      "0.0008118432597257197\n",
      "Epoch: 0000 loss_train: 2.0704\n",
      "Epoch: 0500 loss_train: 0.9128\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5124\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.2531s\n",
      "0.006272628903388977\n",
      "Epoch: 0000 loss_train: 2.0702\n",
      "Epoch: 0500 loss_train: 0.9130\n",
      "Epoch: 1000 loss_train: 0.7260\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.2452s\n",
      "5.173549288883805e-05\n",
      "Epoch: 0000 loss_train: 2.0702\n",
      "Epoch: 0500 loss_train: 0.9128\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.2698s\n",
      "0.0010832638945430517\n",
      "Epoch: 0000 loss_train: 2.0702\n",
      "Epoch: 0500 loss_train: 0.9129\n",
      "Epoch: 1000 loss_train: 0.7258\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5609\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.2783s\n",
      "3.0040289857424796e-05\n",
      "Epoch: 0000 loss_train: 2.0702\n",
      "Epoch: 0500 loss_train: 0.9129\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.2667s\n",
      "1.1920927533992653e-07\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9130\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.1333s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 2.0703\n",
      "Epoch: 0500 loss_train: 0.9128\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.1124s\n",
      "7.152555099310121e-07\n",
      "Epoch: 0000 loss_train: 2.0703\n",
      "Epoch: 0500 loss_train: 0.9121\n",
      "Epoch: 1000 loss_train: 0.7252\n",
      "Epoch: 1500 loss_train: 0.6260\n",
      "Epoch: 2000 loss_train: 0.5607\n",
      "Epoch: 2500 loss_train: 0.5121\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.1127s\n",
      "0.04846979305148125\n",
      "Epoch: 0000 loss_train: 2.0706\n",
      "Epoch: 0500 loss_train: 0.9130\n",
      "Epoch: 1000 loss_train: 0.7260\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.1482s\n",
      "6.437280717364047e-06\n",
      "Epoch: 0000 loss_train: 2.0699\n",
      "Epoch: 0500 loss_train: 0.9124\n",
      "Epoch: 1000 loss_train: 0.7256\n",
      "Epoch: 1500 loss_train: 0.6262\n",
      "Epoch: 2000 loss_train: 0.5609\n",
      "Epoch: 2500 loss_train: 0.5122\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.1859s\n",
      "0.006162925623357296\n",
      "Epoch: 0000 loss_train: 2.0542\n",
      "Epoch: 0500 loss_train: 0.9087\n",
      "Epoch: 1000 loss_train: 0.7225\n",
      "Epoch: 1500 loss_train: 0.6242\n",
      "Epoch: 2000 loss_train: 0.5593\n",
      "Epoch: 2500 loss_train: 0.5110\n",
      "Epoch: 3000 loss_train: 0.4719\n",
      "Epoch: 3500 loss_train: 0.4390\n",
      "Epoch: 4000 loss_train: 0.4105\n",
      "Epoch: 4500 loss_train: 0.3853\n",
      "Epoch: 5000 loss_train: 0.3627\n",
      "Epoch: 5500 loss_train: 0.3421\n",
      " total time: 3.0041s\n",
      "2.084806442260742\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9125\n",
      "Epoch: 1000 loss_train: 0.7256\n",
      "Epoch: 1500 loss_train: 0.6262\n",
      "Epoch: 2000 loss_train: 0.5608\n",
      "Epoch: 2500 loss_train: 0.5121\n",
      "Epoch: 3000 loss_train: 0.4729\n",
      "Epoch: 3500 loss_train: 0.4398\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 2.8894s\n",
      "0.14037643373012543\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9129\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 2.8682s\n",
      "0.007771731354296207\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9123\n",
      "Epoch: 1000 loss_train: 0.7255\n",
      "Epoch: 1500 loss_train: 0.6261\n",
      "Epoch: 2000 loss_train: 0.5607\n",
      "Epoch: 2500 loss_train: 0.5121\n",
      "Epoch: 3000 loss_train: 0.4729\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3859\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 2.8910s\n",
      "0.09398968517780304\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9130\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 2.9332s\n",
      "0.0002554328821133822\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9120\n",
      "Epoch: 1000 loss_train: 0.7248\n",
      "Epoch: 1500 loss_train: 0.6253\n",
      "Epoch: 2000 loss_train: 0.5598\n",
      "Epoch: 2500 loss_train: 0.5111\n",
      "Epoch: 3000 loss_train: 0.4719\n",
      "Epoch: 3500 loss_train: 0.4388\n",
      "Epoch: 4000 loss_train: 0.4101\n",
      "Epoch: 4500 loss_train: 0.3848\n",
      "Epoch: 5000 loss_train: 0.3620\n",
      "Epoch: 5500 loss_train: 0.3414\n",
      " total time: 2.8661s\n",
      "2.685228109359741\n",
      "Epoch: 0000 loss_train: 2.0706\n",
      "Epoch: 0500 loss_train: 0.9130\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 2.9129s\n",
      "3.2186455882765586e-06\n",
      "Epoch: 0000 loss_train: 2.0706\n",
      "Epoch: 0500 loss_train: 0.9130\n",
      "Epoch: 1000 loss_train: 0.7260\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.0273s\n",
      "1.9073468138230965e-06\n",
      "Epoch: 0000 loss_train: 2.0704\n",
      "Epoch: 0500 loss_train: 0.9129\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.0801s\n",
      "0.0039045775774866343\n",
      "Epoch: 0000 loss_train: 2.0704\n",
      "Epoch: 0500 loss_train: 0.9120\n",
      "Epoch: 1000 loss_train: 0.7250\n",
      "Epoch: 1500 loss_train: 0.6255\n",
      "Epoch: 2000 loss_train: 0.5600\n",
      "Epoch: 2500 loss_train: 0.5114\n",
      "Epoch: 3000 loss_train: 0.4722\n",
      "Epoch: 3500 loss_train: 0.4391\n",
      "Epoch: 4000 loss_train: 0.4103\n",
      "Epoch: 4500 loss_train: 0.3849\n",
      "Epoch: 5000 loss_train: 0.3620\n",
      "Epoch: 5500 loss_train: 0.3413\n",
      " total time: 3.2239s\n",
      "2.5163791179656982\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9130\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5122\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.2035s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 2.0706\n",
      "Epoch: 0500 loss_train: 0.9130\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.1778s\n",
      "3.8980677345534787e-05\n",
      "Epoch: 0000 loss_train: 2.0703\n",
      "Epoch: 0500 loss_train: 0.9126\n",
      "Epoch: 1000 loss_train: 0.7254\n",
      "Epoch: 1500 loss_train: 0.6259\n",
      "Epoch: 2000 loss_train: 0.5605\n",
      "Epoch: 2500 loss_train: 0.5119\n",
      "Epoch: 3000 loss_train: 0.4729\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4113\n",
      "Epoch: 4500 loss_train: 0.3860\n",
      "Epoch: 5000 loss_train: 0.3632\n",
      "Epoch: 5500 loss_train: 0.3426\n",
      " total time: 3.1306s\n",
      "0.05796268209815025\n",
      "Epoch: 0000 loss_train: 2.0703\n",
      "Epoch: 0500 loss_train: 0.9127\n",
      "Epoch: 1000 loss_train: 0.7260\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.0593s\n",
      "0.0002783149539027363\n",
      "Epoch: 0000 loss_train: 2.0704\n",
      "Epoch: 0500 loss_train: 0.9126\n",
      "Epoch: 1000 loss_train: 0.7257\n",
      "Epoch: 1500 loss_train: 0.6263\n",
      "Epoch: 2000 loss_train: 0.5609\n",
      "Epoch: 2500 loss_train: 0.5122\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.0781s\n",
      "0.08468650281429291\n",
      "Epoch: 0000 loss_train: 2.0703\n",
      "Epoch: 0500 loss_train: 0.9118\n",
      "Epoch: 1000 loss_train: 0.7249\n",
      "Epoch: 1500 loss_train: 0.6256\n",
      "Epoch: 2000 loss_train: 0.5603\n",
      "Epoch: 2500 loss_train: 0.5117\n",
      "Epoch: 3000 loss_train: 0.4725\n",
      "Epoch: 3500 loss_train: 0.4395\n",
      "Epoch: 4000 loss_train: 0.4108\n",
      "Epoch: 4500 loss_train: 0.3855\n",
      "Epoch: 5000 loss_train: 0.3628\n",
      "Epoch: 5500 loss_train: 0.3422\n",
      " total time: 3.1501s\n",
      "0.7433037757873535\n",
      "Epoch: 0000 loss_train: 2.0703\n",
      "Epoch: 0500 loss_train: 0.9117\n",
      "Epoch: 1000 loss_train: 0.7245\n",
      "Epoch: 1500 loss_train: 0.6252\n",
      "Epoch: 2000 loss_train: 0.5599\n",
      "Epoch: 2500 loss_train: 0.5113\n",
      "Epoch: 3000 loss_train: 0.4722\n",
      "Epoch: 3500 loss_train: 0.4392\n",
      "Epoch: 4000 loss_train: 0.4106\n",
      "Epoch: 4500 loss_train: 0.3852\n",
      "Epoch: 5000 loss_train: 0.3625\n",
      "Epoch: 5500 loss_train: 0.3420\n",
      " total time: 3.1308s\n",
      "1.2499938011169434\n",
      "Epoch: 0000 loss_train: 2.0700\n",
      "Epoch: 0500 loss_train: 0.9121\n",
      "Epoch: 1000 loss_train: 0.7256\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5611\n",
      "Epoch: 2500 loss_train: 0.5124\n",
      "Epoch: 3000 loss_train: 0.4732\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4113\n",
      "Epoch: 4500 loss_train: 0.3859\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.1986s\n",
      "0.0006631797295995057\n",
      "Epoch: 0000 loss_train: 2.0704\n",
      "Epoch: 0500 loss_train: 0.9129\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.0574s\n",
      "0.0019257586682215333\n",
      "Epoch: 0000 loss_train: 2.0699\n",
      "Epoch: 0500 loss_train: 0.9128\n",
      "Epoch: 1000 loss_train: 0.7258\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5609\n",
      "Epoch: 2500 loss_train: 0.5122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.0813s\n",
      "2.264974000354414e-06\n",
      "Epoch: 0000 loss_train: 2.0706\n",
      "Epoch: 0500 loss_train: 0.9128\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.1032s\n",
      "0.05210544541478157\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9130\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.0673s\n",
      "6.794906312279636e-06\n",
      "Epoch: 0000 loss_train: 2.0703\n",
      "Epoch: 0500 loss_train: 0.9128\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.0844s\n",
      "0.001341158407740295\n",
      "Epoch: 0000 loss_train: 2.0701\n",
      "Epoch: 0500 loss_train: 0.9129\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.1153s\n",
      "0.0004922132357023656\n",
      "Epoch: 0000 loss_train: 2.0701\n",
      "Epoch: 0500 loss_train: 0.9113\n",
      "Epoch: 1000 loss_train: 0.7245\n",
      "Epoch: 1500 loss_train: 0.6251\n",
      "Epoch: 2000 loss_train: 0.5597\n",
      "Epoch: 2500 loss_train: 0.5111\n",
      "Epoch: 3000 loss_train: 0.4719\n",
      "Epoch: 3500 loss_train: 0.4389\n",
      "Epoch: 4000 loss_train: 0.4103\n",
      "Epoch: 4500 loss_train: 0.3849\n",
      "Epoch: 5000 loss_train: 0.3623\n",
      "Epoch: 5500 loss_train: 0.3417\n",
      " total time: 3.2244s\n",
      "1.8210771083831787\n",
      "Epoch: 0000 loss_train: 2.0698\n",
      "Epoch: 0500 loss_train: 0.9122\n",
      "Epoch: 1000 loss_train: 0.7256\n",
      "Epoch: 1500 loss_train: 0.6263\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.1664s\n",
      "0.001647544908337295\n",
      "Epoch: 0000 loss_train: 2.0703\n",
      "Epoch: 0500 loss_train: 0.9127\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.1506s\n",
      "0.0078294537961483\n",
      "Epoch: 0000 loss_train: 2.0702\n",
      "Epoch: 0500 loss_train: 0.9131\n",
      "Epoch: 1000 loss_train: 0.7260\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.0844s\n",
      "1.1920927533992653e-07\n",
      "Epoch: 0000 loss_train: 2.0699\n",
      "Epoch: 0500 loss_train: 0.9116\n",
      "Epoch: 1000 loss_train: 0.7247\n",
      "Epoch: 1500 loss_train: 0.6254\n",
      "Epoch: 2000 loss_train: 0.5601\n",
      "Epoch: 2500 loss_train: 0.5116\n",
      "Epoch: 3000 loss_train: 0.4725\n",
      "Epoch: 3500 loss_train: 0.4396\n",
      "Epoch: 4000 loss_train: 0.4110\n",
      "Epoch: 4500 loss_train: 0.3857\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.0631s\n",
      "0.2964424192905426\n",
      "Epoch: 0000 loss_train: 2.0700\n",
      "Epoch: 0500 loss_train: 0.9126\n",
      "Epoch: 1000 loss_train: 0.7256\n",
      "Epoch: 1500 loss_train: 0.6262\n",
      "Epoch: 2000 loss_train: 0.5608\n",
      "Epoch: 2500 loss_train: 0.5122\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.0920s\n",
      "0.002691933885216713\n",
      "Epoch: 0000 loss_train: 2.0701\n",
      "Epoch: 0500 loss_train: 0.9129\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5609\n",
      "Epoch: 2500 loss_train: 0.5122\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.1217s\n",
      "1.1920927533992653e-07\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9130\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.0778s\n",
      "5.960462772236497e-07\n",
      "Epoch: 0000 loss_train: 2.0702\n",
      "Epoch: 0500 loss_train: 0.9128\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.0274s\n",
      "1.1920927533992653e-07\n",
      "Epoch: 0000 loss_train: 2.0702\n",
      "Epoch: 0500 loss_train: 0.9117\n",
      "Epoch: 1000 loss_train: 0.7248\n",
      "Epoch: 1500 loss_train: 0.6255\n",
      "Epoch: 2000 loss_train: 0.5602\n",
      "Epoch: 2500 loss_train: 0.5115\n",
      "Epoch: 3000 loss_train: 0.4724\n",
      "Epoch: 3500 loss_train: 0.4393\n",
      "Epoch: 4000 loss_train: 0.4106\n",
      "Epoch: 4500 loss_train: 0.3853\n",
      "Epoch: 5000 loss_train: 0.3626\n",
      "Epoch: 5500 loss_train: 0.3420\n",
      " total time: 3.0432s\n",
      "1.3060322999954224\n",
      "Epoch: 0000 loss_train: 2.0697\n",
      "Epoch: 0500 loss_train: 0.9108\n",
      "Epoch: 1000 loss_train: 0.7243\n",
      "Epoch: 1500 loss_train: 0.6251\n",
      "Epoch: 2000 loss_train: 0.5598\n",
      "Epoch: 2500 loss_train: 0.5112\n",
      "Epoch: 3000 loss_train: 0.4720\n",
      "Epoch: 3500 loss_train: 0.4389\n",
      "Epoch: 4000 loss_train: 0.4102\n",
      "Epoch: 4500 loss_train: 0.3849\n",
      "Epoch: 5000 loss_train: 0.3622\n",
      "Epoch: 5500 loss_train: 0.3416\n",
      " total time: 3.0863s\n",
      "2.679893970489502\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9128\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.0347s\n",
      "0.010674049146473408\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9126\n",
      "Epoch: 1000 loss_train: 0.7258\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.0687s\n",
      "0.01915258914232254\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9130\n",
      "Epoch: 1000 loss_train: 0.7260\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.0201s\n",
      "3.576214658096433e-05\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9126\n",
      "Epoch: 1000 loss_train: 0.7257\n",
      "Epoch: 1500 loss_train: 0.6263\n",
      "Epoch: 2000 loss_train: 0.5609\n",
      "Epoch: 2500 loss_train: 0.5122\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4113\n",
      "Epoch: 4500 loss_train: 0.3859\n",
      "Epoch: 5000 loss_train: 0.3632\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.0525s\n",
      "0.05167275667190552\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9130\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.1119s\n",
      "1.1444026313256472e-05\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9130\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.0289s\n",
      "2.0265558760002023e-06\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9123\n",
      "Epoch: 1000 loss_train: 0.7252\n",
      "Epoch: 1500 loss_train: 0.6257\n",
      "Epoch: 2000 loss_train: 0.5601\n",
      "Epoch: 2500 loss_train: 0.5113\n",
      "Epoch: 3000 loss_train: 0.4720\n",
      "Epoch: 3500 loss_train: 0.4388\n",
      "Epoch: 4000 loss_train: 0.4100\n",
      "Epoch: 4500 loss_train: 0.3846\n",
      "Epoch: 5000 loss_train: 0.3618\n",
      "Epoch: 5500 loss_train: 0.3412\n",
      " total time: 3.1409s\n",
      "2.973193645477295\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9125\n",
      "Epoch: 1000 loss_train: 0.7255\n",
      "Epoch: 1500 loss_train: 0.6262\n",
      "Epoch: 2000 loss_train: 0.5608\n",
      "Epoch: 2500 loss_train: 0.5122\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.1190s\n",
      "0.13991636037826538\n",
      "Epoch: 0000 loss_train: 2.0706\n",
      "Epoch: 0500 loss_train: 0.9130\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.1763s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 2.0706\n",
      "Epoch: 0500 loss_train: 0.9125\n",
      "Epoch: 1000 loss_train: 0.7257\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3859\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.0357s\n",
      "0.03040884993970394\n",
      "Epoch: 0000 loss_train: 2.0703\n",
      "Epoch: 0500 loss_train: 0.9122\n",
      "Epoch: 1000 loss_train: 0.7252\n",
      "Epoch: 1500 loss_train: 0.6259\n",
      "Epoch: 2000 loss_train: 0.5606\n",
      "Epoch: 2500 loss_train: 0.5120\n",
      "Epoch: 3000 loss_train: 0.4729\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 2.9387s\n",
      "0.17793183028697968\n",
      "Epoch: 0000 loss_train: 2.0706\n",
      "Epoch: 0500 loss_train: 0.9129\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 2.9647s\n",
      "1.8954096958623268e-05\n",
      "Epoch: 0000 loss_train: 2.0701\n",
      "Epoch: 0500 loss_train: 0.9129\n",
      "Epoch: 1000 loss_train: 0.7258\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5609\n",
      "Epoch: 2500 loss_train: 0.5122\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 2.9421s\n",
      "2.52720492426306e-05\n",
      "Epoch: 0000 loss_train: 2.0706\n",
      "Epoch: 0500 loss_train: 0.9129\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.1420s\n",
      "0.006478616502135992\n",
      "Epoch: 0000 loss_train: 2.0702\n",
      "Epoch: 0500 loss_train: 0.9128\n",
      "Epoch: 1000 loss_train: 0.7258\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5609\n",
      "Epoch: 2500 loss_train: 0.5122\n",
      "Epoch: 3000 loss_train: 0.4729\n",
      "Epoch: 3500 loss_train: 0.4398\n",
      "Epoch: 4000 loss_train: 0.4111\n",
      "Epoch: 4500 loss_train: 0.3857\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.2075s\n",
      "0.1688346117734909\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9123\n",
      "Epoch: 1000 loss_train: 0.7251\n",
      "Epoch: 1500 loss_train: 0.6255\n",
      "Epoch: 2000 loss_train: 0.5599\n",
      "Epoch: 2500 loss_train: 0.5111\n",
      "Epoch: 3000 loss_train: 0.4717\n",
      "Epoch: 3500 loss_train: 0.4385\n",
      "Epoch: 4000 loss_train: 0.4097\n",
      "Epoch: 4500 loss_train: 0.3842\n",
      "Epoch: 5000 loss_train: 0.3615\n",
      "Epoch: 5500 loss_train: 0.3409\n",
      " total time: 3.1606s\n",
      "2.918243408203125\n",
      "Epoch: 0000 loss_train: 2.0707\n",
      "Epoch: 0500 loss_train: 0.9128\n",
      "Epoch: 1000 loss_train: 0.7258\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5609\n",
      "Epoch: 2500 loss_train: 0.5122\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4398\n",
      "Epoch: 4000 loss_train: 0.4111\n",
      "Epoch: 4500 loss_train: 0.3857\n",
      "Epoch: 5000 loss_train: 0.3629\n",
      "Epoch: 5500 loss_train: 0.3423\n",
      " total time: 3.2554s\n",
      "0.5124326348304749\n",
      "Epoch: 0000 loss_train: 2.0700\n",
      "Epoch: 0500 loss_train: 0.9121\n",
      "Epoch: 1000 loss_train: 0.7254\n",
      "Epoch: 1500 loss_train: 0.6261\n",
      "Epoch: 2000 loss_train: 0.5608\n",
      "Epoch: 2500 loss_train: 0.5122\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4113\n",
      "Epoch: 4500 loss_train: 0.3859\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 2.9645s\n",
      "0.013815727084875107\n",
      "Epoch: 0000 loss_train: 2.0704\n",
      "Epoch: 0500 loss_train: 0.9128\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.0865s\n",
      "0.019451813772320747\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9130\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.1162s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 2.0704\n",
      "Epoch: 0500 loss_train: 0.9129\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.1016s\n",
      "4.768370445162873e-07\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9125\n",
      "Epoch: 1000 loss_train: 0.7256\n",
      "Epoch: 1500 loss_train: 0.6263\n",
      "Epoch: 2000 loss_train: 0.5609\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3859\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.0370s\n",
      "0.021937213838100433\n",
      "Epoch: 0000 loss_train: 2.0706\n",
      "Epoch: 0500 loss_train: 0.9130\n",
      "Epoch: 1000 loss_train: 0.7260\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3859\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.0815s\n",
      "0.00018988236843142658\n",
      "Epoch: 0000 loss_train: 2.0699\n",
      "Epoch: 0500 loss_train: 0.9118\n",
      "Epoch: 1000 loss_train: 0.7255\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5611\n",
      "Epoch: 2500 loss_train: 0.5125\n",
      "Epoch: 3000 loss_train: 0.4732\n",
      "Epoch: 3500 loss_train: 0.4401\n",
      "Epoch: 4000 loss_train: 0.4113\n",
      "Epoch: 4500 loss_train: 0.3859\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.0558s\n",
      "0.003148719435557723\n",
      "Epoch: 0000 loss_train: 2.0702\n",
      "Epoch: 0500 loss_train: 0.9129\n",
      "Epoch: 1000 loss_train: 0.7256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1500 loss_train: 0.6262\n",
      "Epoch: 2000 loss_train: 0.5608\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4732\n",
      "Epoch: 3500 loss_train: 0.4402\n",
      "Epoch: 4000 loss_train: 0.4115\n",
      "Epoch: 4500 loss_train: 0.3861\n",
      "Epoch: 5000 loss_train: 0.3633\n",
      "Epoch: 5500 loss_train: 0.3426\n",
      " total time: 3.0298s\n",
      "0.17439743876457214\n",
      "Epoch: 0000 loss_train: 2.0689\n",
      "Epoch: 0500 loss_train: 0.9104\n",
      "Epoch: 1000 loss_train: 0.7226\n",
      "Epoch: 1500 loss_train: 0.6226\n",
      "Epoch: 2000 loss_train: 0.5567\n",
      "Epoch: 2500 loss_train: 0.5079\n",
      "Epoch: 3000 loss_train: 0.4686\n",
      "Epoch: 3500 loss_train: 0.4355\n",
      "Epoch: 4000 loss_train: 0.4069\n",
      "Epoch: 4500 loss_train: 0.3817\n",
      "Epoch: 5000 loss_train: 0.3591\n",
      "Epoch: 5500 loss_train: 0.3386\n",
      " total time: 3.1154s\n",
      "7.961686134338379\n",
      "Epoch: 0000 loss_train: 2.0701\n",
      "Epoch: 0500 loss_train: 0.9114\n",
      "Epoch: 1000 loss_train: 0.7244\n",
      "Epoch: 1500 loss_train: 0.6246\n",
      "Epoch: 2000 loss_train: 0.5589\n",
      "Epoch: 2500 loss_train: 0.5100\n",
      "Epoch: 3000 loss_train: 0.4706\n",
      "Epoch: 3500 loss_train: 0.4373\n",
      "Epoch: 4000 loss_train: 0.4085\n",
      "Epoch: 4500 loss_train: 0.3829\n",
      "Epoch: 5000 loss_train: 0.3600\n",
      "Epoch: 5500 loss_train: 0.3392\n",
      " total time: 3.0167s\n",
      "8.513741493225098\n",
      "Epoch: 0000 loss_train: 2.0712\n",
      "Epoch: 0500 loss_train: 0.9129\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5609\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4113\n",
      "Epoch: 4500 loss_train: 0.3859\n",
      "Epoch: 5000 loss_train: 0.3632\n",
      "Epoch: 5500 loss_train: 0.3426\n",
      " total time: 2.9870s\n",
      "0.20135554671287537\n",
      "Epoch: 0000 loss_train: 2.0690\n",
      "Epoch: 0500 loss_train: 0.9103\n",
      "Epoch: 1000 loss_train: 0.7226\n",
      "Epoch: 1500 loss_train: 0.6229\n",
      "Epoch: 2000 loss_train: 0.5575\n",
      "Epoch: 2500 loss_train: 0.5091\n",
      "Epoch: 3000 loss_train: 0.4702\n",
      "Epoch: 3500 loss_train: 0.4374\n",
      "Epoch: 4000 loss_train: 0.4091\n",
      "Epoch: 4500 loss_train: 0.3841\n",
      "Epoch: 5000 loss_train: 0.3616\n",
      "Epoch: 5500 loss_train: 0.3413\n",
      " total time: 3.0060s\n",
      "3.0076851844787598\n",
      "Epoch: 0000 loss_train: 2.0706\n",
      "Epoch: 0500 loss_train: 0.9124\n",
      "Epoch: 1000 loss_train: 0.7253\n",
      "Epoch: 1500 loss_train: 0.6261\n",
      "Epoch: 2000 loss_train: 0.5608\n",
      "Epoch: 2500 loss_train: 0.5122\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3859\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.0297s\n",
      "0.26086941361427307\n",
      "Epoch: 0000 loss_train: 2.0690\n",
      "Epoch: 0500 loss_train: 0.9106\n",
      "Epoch: 1000 loss_train: 0.7228\n",
      "Epoch: 1500 loss_train: 0.6229\n",
      "Epoch: 2000 loss_train: 0.5572\n",
      "Epoch: 2500 loss_train: 0.5083\n",
      "Epoch: 3000 loss_train: 0.4688\n",
      "Epoch: 3500 loss_train: 0.4353\n",
      "Epoch: 4000 loss_train: 0.4061\n",
      "Epoch: 4500 loss_train: 0.3802\n",
      "Epoch: 5000 loss_train: 0.3569\n",
      "Epoch: 5500 loss_train: 0.3357\n",
      " total time: 3.0872s\n",
      "7.085609436035156\n",
      "Epoch: 0000 loss_train: 2.0718\n",
      "Epoch: 0500 loss_train: 0.9112\n",
      "Epoch: 1000 loss_train: 0.7239\n",
      "Epoch: 1500 loss_train: 0.6244\n",
      "Epoch: 2000 loss_train: 0.5588\n",
      "Epoch: 2500 loss_train: 0.5099\n",
      "Epoch: 3000 loss_train: 0.4706\n",
      "Epoch: 3500 loss_train: 0.4374\n",
      "Epoch: 4000 loss_train: 0.4086\n",
      "Epoch: 4500 loss_train: 0.3832\n",
      "Epoch: 5000 loss_train: 0.3605\n",
      "Epoch: 5500 loss_train: 0.3399\n",
      " total time: 3.1072s\n",
      "3.6017136573791504\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9106\n",
      "Epoch: 1000 loss_train: 0.7231\n",
      "Epoch: 1500 loss_train: 0.6233\n",
      "Epoch: 2000 loss_train: 0.5576\n",
      "Epoch: 2500 loss_train: 0.5087\n",
      "Epoch: 3000 loss_train: 0.4693\n",
      "Epoch: 3500 loss_train: 0.4361\n",
      "Epoch: 4000 loss_train: 0.4073\n",
      "Epoch: 4500 loss_train: 0.3818\n",
      "Epoch: 5000 loss_train: 0.3589\n",
      "Epoch: 5500 loss_train: 0.3382\n",
      " total time: 3.2005s\n",
      "3.8372178077697754\n",
      "Epoch: 0000 loss_train: 2.0715\n",
      "Epoch: 0500 loss_train: 0.9130\n",
      "Epoch: 1000 loss_train: 0.7262\n",
      "Epoch: 1500 loss_train: 0.6268\n",
      "Epoch: 2000 loss_train: 0.5614\n",
      "Epoch: 2500 loss_train: 0.5127\n",
      "Epoch: 3000 loss_train: 0.4734\n",
      "Epoch: 3500 loss_train: 0.4403\n",
      "Epoch: 4000 loss_train: 0.4115\n",
      "Epoch: 4500 loss_train: 0.3861\n",
      "Epoch: 5000 loss_train: 0.3634\n",
      "Epoch: 5500 loss_train: 0.3427\n",
      " total time: 3.2152s\n",
      "0.013566674664616585\n",
      "Epoch: 0000 loss_train: 2.0715\n",
      "Epoch: 0500 loss_train: 0.9116\n",
      "Epoch: 1000 loss_train: 0.7247\n",
      "Epoch: 1500 loss_train: 0.6252\n",
      "Epoch: 2000 loss_train: 0.5597\n",
      "Epoch: 2500 loss_train: 0.5110\n",
      "Epoch: 3000 loss_train: 0.4717\n",
      "Epoch: 3500 loss_train: 0.4387\n",
      "Epoch: 4000 loss_train: 0.4101\n",
      "Epoch: 4500 loss_train: 0.3848\n",
      "Epoch: 5000 loss_train: 0.3622\n",
      "Epoch: 5500 loss_train: 0.3417\n",
      " total time: 2.8918s\n",
      "1.3894766569137573\n",
      "Epoch: 0000 loss_train: 2.0713\n",
      "Epoch: 0500 loss_train: 0.9125\n",
      "Epoch: 1000 loss_train: 0.7251\n",
      "Epoch: 1500 loss_train: 0.6253\n",
      "Epoch: 2000 loss_train: 0.5598\n",
      "Epoch: 2500 loss_train: 0.5111\n",
      "Epoch: 3000 loss_train: 0.4719\n",
      "Epoch: 3500 loss_train: 0.4390\n",
      "Epoch: 4000 loss_train: 0.4104\n",
      "Epoch: 4500 loss_train: 0.3851\n",
      "Epoch: 5000 loss_train: 0.3625\n",
      "Epoch: 5500 loss_train: 0.3420\n",
      " total time: 2.8765s\n",
      "1.1147112846374512\n",
      "Epoch: 0000 loss_train: 2.0710\n",
      "Epoch: 0500 loss_train: 0.9135\n",
      "Epoch: 1000 loss_train: 0.7265\n",
      "Epoch: 1500 loss_train: 0.6269\n",
      "Epoch: 2000 loss_train: 0.5614\n",
      "Epoch: 2500 loss_train: 0.5126\n",
      "Epoch: 3000 loss_train: 0.4733\n",
      "Epoch: 3500 loss_train: 0.4402\n",
      "Epoch: 4000 loss_train: 0.4114\n",
      "Epoch: 4500 loss_train: 0.3860\n",
      "Epoch: 5000 loss_train: 0.3633\n",
      "Epoch: 5500 loss_train: 0.3426\n",
      " total time: 2.8850s\n",
      "0.02429790049791336\n",
      "Epoch: 0000 loss_train: 2.0714\n",
      "Epoch: 0500 loss_train: 0.9132\n",
      "Epoch: 1000 loss_train: 0.7262\n",
      "Epoch: 1500 loss_train: 0.6268\n",
      "Epoch: 2000 loss_train: 0.5613\n",
      "Epoch: 2500 loss_train: 0.5126\n",
      "Epoch: 3000 loss_train: 0.4733\n",
      "Epoch: 3500 loss_train: 0.4402\n",
      "Epoch: 4000 loss_train: 0.4114\n",
      "Epoch: 4500 loss_train: 0.3860\n",
      "Epoch: 5000 loss_train: 0.3632\n",
      "Epoch: 5500 loss_train: 0.3426\n",
      " total time: 2.8700s\n",
      "0.08243323862552643\n",
      "Epoch: 0000 loss_train: 2.0695\n",
      "Epoch: 0500 loss_train: 0.9108\n",
      "Epoch: 1000 loss_train: 0.7252\n",
      "Epoch: 1500 loss_train: 0.6261\n",
      "Epoch: 2000 loss_train: 0.5607\n",
      "Epoch: 2500 loss_train: 0.5120\n",
      "Epoch: 3000 loss_train: 0.4727\n",
      "Epoch: 3500 loss_train: 0.4395\n",
      "Epoch: 4000 loss_train: 0.4107\n",
      "Epoch: 4500 loss_train: 0.3852\n",
      "Epoch: 5000 loss_train: 0.3624\n",
      "Epoch: 5500 loss_train: 0.3418\n",
      " total time: 3.0973s\n",
      "2.524731397628784\n",
      "Epoch: 0000 loss_train: 2.0708\n",
      "Epoch: 0500 loss_train: 0.9115\n",
      "Epoch: 1000 loss_train: 0.7239\n",
      "Epoch: 1500 loss_train: 0.6239\n",
      "Epoch: 2000 loss_train: 0.5581\n",
      "Epoch: 2500 loss_train: 0.5092\n",
      "Epoch: 3000 loss_train: 0.4698\n",
      "Epoch: 3500 loss_train: 0.4365\n",
      "Epoch: 4000 loss_train: 0.4076\n",
      "Epoch: 4500 loss_train: 0.3820\n",
      "Epoch: 5000 loss_train: 0.3590\n",
      "Epoch: 5500 loss_train: 0.3380\n",
      " total time: 3.2638s\n",
      "4.369405269622803\n",
      "Epoch: 0000 loss_train: 2.0709\n",
      "Epoch: 0500 loss_train: 0.9124\n",
      "Epoch: 1000 loss_train: 0.7258\n",
      "Epoch: 1500 loss_train: 0.6266\n",
      "Epoch: 2000 loss_train: 0.5613\n",
      "Epoch: 2500 loss_train: 0.5126\n",
      "Epoch: 3000 loss_train: 0.4734\n",
      "Epoch: 3500 loss_train: 0.4403\n",
      "Epoch: 4000 loss_train: 0.4116\n",
      "Epoch: 4500 loss_train: 0.3862\n",
      "Epoch: 5000 loss_train: 0.3634\n",
      "Epoch: 5500 loss_train: 0.3428\n",
      " total time: 3.2068s\n",
      "0.026429209858179092\n",
      "Epoch: 0000 loss_train: 2.0718\n",
      "Epoch: 0500 loss_train: 0.9129\n",
      "Epoch: 1000 loss_train: 0.7258\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5612\n",
      "Epoch: 2500 loss_train: 0.5125\n",
      "Epoch: 3000 loss_train: 0.4733\n",
      "Epoch: 3500 loss_train: 0.4402\n",
      "Epoch: 4000 loss_train: 0.4114\n",
      "Epoch: 4500 loss_train: 0.3861\n",
      "Epoch: 5000 loss_train: 0.3633\n",
      "Epoch: 5500 loss_train: 0.3427\n",
      " total time: 3.1259s\n",
      "0.05369539558887482\n",
      "Epoch: 0000 loss_train: 2.0702\n",
      "Epoch: 0500 loss_train: 0.9114\n",
      "Epoch: 1000 loss_train: 0.7247\n",
      "Epoch: 1500 loss_train: 0.6253\n",
      "Epoch: 2000 loss_train: 0.5599\n",
      "Epoch: 2500 loss_train: 0.5113\n",
      "Epoch: 3000 loss_train: 0.4720\n",
      "Epoch: 3500 loss_train: 0.4389\n",
      "Epoch: 4000 loss_train: 0.4102\n",
      "Epoch: 4500 loss_train: 0.3849\n",
      "Epoch: 5000 loss_train: 0.3621\n",
      "Epoch: 5500 loss_train: 0.3416\n",
      " total time: 3.2247s\n",
      "1.22282075881958\n",
      "Epoch: 0000 loss_train: 2.0706\n",
      "Epoch: 0500 loss_train: 0.9133\n",
      "Epoch: 1000 loss_train: 0.7263\n",
      "Epoch: 1500 loss_train: 0.6267\n",
      "Epoch: 2000 loss_train: 0.5612\n",
      "Epoch: 2500 loss_train: 0.5125\n",
      "Epoch: 3000 loss_train: 0.4733\n",
      "Epoch: 3500 loss_train: 0.4401\n",
      "Epoch: 4000 loss_train: 0.4114\n",
      "Epoch: 4500 loss_train: 0.3860\n",
      "Epoch: 5000 loss_train: 0.3633\n",
      "Epoch: 5500 loss_train: 0.3426\n",
      " total time: 3.2458s\n",
      "0.041187986731529236\n",
      "Epoch: 0000 loss_train: 2.0709\n",
      "Epoch: 0500 loss_train: 0.9126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1000 loss_train: 0.7255\n",
      "Epoch: 1500 loss_train: 0.6260\n",
      "Epoch: 2000 loss_train: 0.5605\n",
      "Epoch: 2500 loss_train: 0.5118\n",
      "Epoch: 3000 loss_train: 0.4726\n",
      "Epoch: 3500 loss_train: 0.4395\n",
      "Epoch: 4000 loss_train: 0.4108\n",
      "Epoch: 4500 loss_train: 0.3854\n",
      "Epoch: 5000 loss_train: 0.3627\n",
      "Epoch: 5500 loss_train: 0.3420\n",
      " total time: 3.2345s\n",
      "0.5404962301254272\n",
      "Epoch: 0000 loss_train: 2.0710\n",
      "Epoch: 0500 loss_train: 0.9121\n",
      "Epoch: 1000 loss_train: 0.7249\n",
      "Epoch: 1500 loss_train: 0.6254\n",
      "Epoch: 2000 loss_train: 0.5600\n",
      "Epoch: 2500 loss_train: 0.5113\n",
      "Epoch: 3000 loss_train: 0.4721\n",
      "Epoch: 3500 loss_train: 0.4390\n",
      "Epoch: 4000 loss_train: 0.4103\n",
      "Epoch: 4500 loss_train: 0.3849\n",
      "Epoch: 5000 loss_train: 0.3622\n",
      "Epoch: 5500 loss_train: 0.3416\n",
      " total time: 3.1945s\n",
      "0.9555199146270752\n",
      "Epoch: 0000 loss_train: 2.0713\n",
      "Epoch: 0500 loss_train: 0.9127\n",
      "Epoch: 1000 loss_train: 0.7257\n",
      "Epoch: 1500 loss_train: 0.6262\n",
      "Epoch: 2000 loss_train: 0.5607\n",
      "Epoch: 2500 loss_train: 0.5120\n",
      "Epoch: 3000 loss_train: 0.4728\n",
      "Epoch: 3500 loss_train: 0.4397\n",
      "Epoch: 4000 loss_train: 0.4110\n",
      "Epoch: 4500 loss_train: 0.3856\n",
      "Epoch: 5000 loss_train: 0.3628\n",
      "Epoch: 5500 loss_train: 0.3421\n",
      " total time: 2.9443s\n",
      "0.4630681872367859\n",
      "Epoch: 0000 loss_train: 2.0714\n",
      "Epoch: 0500 loss_train: 0.9132\n",
      "Epoch: 1000 loss_train: 0.7262\n",
      "Epoch: 1500 loss_train: 0.6267\n",
      "Epoch: 2000 loss_train: 0.5612\n",
      "Epoch: 2500 loss_train: 0.5124\n",
      "Epoch: 3000 loss_train: 0.4732\n",
      "Epoch: 3500 loss_train: 0.4401\n",
      "Epoch: 4000 loss_train: 0.4114\n",
      "Epoch: 4500 loss_train: 0.3860\n",
      "Epoch: 5000 loss_train: 0.3632\n",
      "Epoch: 5500 loss_train: 0.3426\n",
      " total time: 2.8759s\n",
      "0.011867751367390156\n",
      "Epoch: 0000 loss_train: 2.0715\n",
      "Epoch: 0500 loss_train: 0.9115\n",
      "Epoch: 1000 loss_train: 0.7242\n",
      "Epoch: 1500 loss_train: 0.6245\n",
      "Epoch: 2000 loss_train: 0.5589\n",
      "Epoch: 2500 loss_train: 0.5102\n",
      "Epoch: 3000 loss_train: 0.4711\n",
      "Epoch: 3500 loss_train: 0.4382\n",
      "Epoch: 4000 loss_train: 0.4097\n",
      "Epoch: 4500 loss_train: 0.3846\n",
      "Epoch: 5000 loss_train: 0.3620\n",
      "Epoch: 5500 loss_train: 0.3416\n",
      " total time: 2.9463s\n",
      "2.251004934310913\n",
      "Epoch: 0000 loss_train: 2.0717\n",
      "Epoch: 0500 loss_train: 0.9129\n",
      "Epoch: 1000 loss_train: 0.7258\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5124\n",
      "Epoch: 3000 loss_train: 0.4733\n",
      "Epoch: 3500 loss_train: 0.4402\n",
      "Epoch: 4000 loss_train: 0.4115\n",
      "Epoch: 4500 loss_train: 0.3862\n",
      "Epoch: 5000 loss_train: 0.3635\n",
      "Epoch: 5500 loss_train: 0.3429\n",
      " total time: 3.1109s\n",
      "0.20828068256378174\n",
      "Epoch: 0000 loss_train: 2.0727\n",
      "Epoch: 0500 loss_train: 0.9148\n",
      "Epoch: 1000 loss_train: 0.7273\n",
      "Epoch: 1500 loss_train: 0.6277\n",
      "Epoch: 2000 loss_train: 0.5623\n",
      "Epoch: 2500 loss_train: 0.5135\n",
      "Epoch: 3000 loss_train: 0.4742\n",
      "Epoch: 3500 loss_train: 0.4411\n",
      "Epoch: 4000 loss_train: 0.4123\n",
      "Epoch: 4500 loss_train: 0.3868\n",
      "Epoch: 5000 loss_train: 0.3640\n",
      "Epoch: 5500 loss_train: 0.3433\n",
      " total time: 3.1252s\n",
      "0.0028765511233359575\n",
      "Epoch: 0000 loss_train: 2.0722\n",
      "Epoch: 0500 loss_train: 0.9141\n",
      "Epoch: 1000 loss_train: 0.7272\n",
      "Epoch: 1500 loss_train: 0.6277\n",
      "Epoch: 2000 loss_train: 0.5622\n",
      "Epoch: 2500 loss_train: 0.5135\n",
      "Epoch: 3000 loss_train: 0.4742\n",
      "Epoch: 3500 loss_train: 0.4411\n",
      "Epoch: 4000 loss_train: 0.4123\n",
      "Epoch: 4500 loss_train: 0.3869\n",
      "Epoch: 5000 loss_train: 0.3640\n",
      "Epoch: 5500 loss_train: 0.3433\n",
      " total time: 3.1814s\n",
      "0.016727661713957787\n",
      "Epoch: 0000 loss_train: 2.0712\n",
      "Epoch: 0500 loss_train: 0.9097\n",
      "Epoch: 1000 loss_train: 0.7231\n",
      "Epoch: 1500 loss_train: 0.6241\n",
      "Epoch: 2000 loss_train: 0.5590\n",
      "Epoch: 2500 loss_train: 0.5105\n",
      "Epoch: 3000 loss_train: 0.4715\n",
      "Epoch: 3500 loss_train: 0.4385\n",
      "Epoch: 4000 loss_train: 0.4099\n",
      "Epoch: 4500 loss_train: 0.3847\n",
      "Epoch: 5000 loss_train: 0.3621\n",
      "Epoch: 5500 loss_train: 0.3416\n",
      " total time: 3.2272s\n",
      "1.0731348991394043\n",
      "Epoch: 0000 loss_train: 2.0664\n",
      "Epoch: 0500 loss_train: 0.9082\n",
      "Epoch: 1000 loss_train: 0.7212\n",
      "Epoch: 1500 loss_train: 0.6216\n",
      "Epoch: 2000 loss_train: 0.5562\n",
      "Epoch: 2500 loss_train: 0.5075\n",
      "Epoch: 3000 loss_train: 0.4683\n",
      "Epoch: 3500 loss_train: 0.4351\n",
      "Epoch: 4000 loss_train: 0.4063\n",
      "Epoch: 4500 loss_train: 0.3809\n",
      "Epoch: 5000 loss_train: 0.3581\n",
      "Epoch: 5500 loss_train: 0.3375\n",
      " total time: 3.1219s\n",
      "8.629243850708008\n",
      "Epoch: 0000 loss_train: 2.0674\n",
      "Epoch: 0500 loss_train: 0.9077\n",
      "Epoch: 1000 loss_train: 0.7200\n",
      "Epoch: 1500 loss_train: 0.6201\n",
      "Epoch: 2000 loss_train: 0.5542\n",
      "Epoch: 2500 loss_train: 0.5049\n",
      "Epoch: 3000 loss_train: 0.4652\n",
      "Epoch: 3500 loss_train: 0.4317\n",
      "Epoch: 4000 loss_train: 0.4025\n",
      "Epoch: 4500 loss_train: 0.3768\n",
      "Epoch: 5000 loss_train: 0.3537\n",
      "Epoch: 5500 loss_train: 0.3330\n",
      " total time: 3.1038s\n",
      "25.379297256469727\n",
      "Epoch: 0000 loss_train: 2.0726\n",
      "Epoch: 0500 loss_train: 0.9134\n",
      "Epoch: 1000 loss_train: 0.7261\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5606\n",
      "Epoch: 2500 loss_train: 0.5116\n",
      "Epoch: 3000 loss_train: 0.4721\n",
      "Epoch: 3500 loss_train: 0.4388\n",
      "Epoch: 4000 loss_train: 0.4099\n",
      "Epoch: 4500 loss_train: 0.3844\n",
      "Epoch: 5000 loss_train: 0.3616\n",
      "Epoch: 5500 loss_train: 0.3409\n",
      " total time: 3.1539s\n",
      "1.4155521392822266\n",
      "Epoch: 0000 loss_train: 2.0723\n",
      "Epoch: 0500 loss_train: 0.9147\n",
      "Epoch: 1000 loss_train: 0.7276\n",
      "Epoch: 1500 loss_train: 0.6280\n",
      "Epoch: 2000 loss_train: 0.5624\n",
      "Epoch: 2500 loss_train: 0.5136\n",
      "Epoch: 3000 loss_train: 0.4743\n",
      "Epoch: 3500 loss_train: 0.4411\n",
      "Epoch: 4000 loss_train: 0.4124\n",
      "Epoch: 4500 loss_train: 0.3869\n",
      "Epoch: 5000 loss_train: 0.3640\n",
      "Epoch: 5500 loss_train: 0.3433\n",
      " total time: 3.1411s\n",
      "0.0024695871397852898\n",
      "Epoch: 0000 loss_train: 2.0711\n",
      "Epoch: 0500 loss_train: 0.9128\n",
      "Epoch: 1000 loss_train: 0.7255\n",
      "Epoch: 1500 loss_train: 0.6258\n",
      "Epoch: 2000 loss_train: 0.5602\n",
      "Epoch: 2500 loss_train: 0.5115\n",
      "Epoch: 3000 loss_train: 0.4724\n",
      "Epoch: 3500 loss_train: 0.4394\n",
      "Epoch: 4000 loss_train: 0.4108\n",
      "Epoch: 4500 loss_train: 0.3855\n",
      "Epoch: 5000 loss_train: 0.3628\n",
      "Epoch: 5500 loss_train: 0.3423\n",
      " total time: 3.2190s\n",
      "0.616313636302948\n",
      "Epoch: 0000 loss_train: 2.0719\n",
      "Epoch: 0500 loss_train: 0.9141\n",
      "Epoch: 1000 loss_train: 0.7269\n",
      "Epoch: 1500 loss_train: 0.6271\n",
      "Epoch: 2000 loss_train: 0.5614\n",
      "Epoch: 2500 loss_train: 0.5124\n",
      "Epoch: 3000 loss_train: 0.4728\n",
      "Epoch: 3500 loss_train: 0.4393\n",
      "Epoch: 4000 loss_train: 0.4102\n",
      "Epoch: 4500 loss_train: 0.3845\n",
      "Epoch: 5000 loss_train: 0.3615\n",
      "Epoch: 5500 loss_train: 0.3407\n",
      " total time: 3.1410s\n",
      "3.1075384616851807\n",
      "Epoch: 0000 loss_train: 2.0723\n",
      "Epoch: 0500 loss_train: 0.9138\n",
      "Epoch: 1000 loss_train: 0.7265\n",
      "Epoch: 1500 loss_train: 0.6272\n",
      "Epoch: 2000 loss_train: 0.5619\n",
      "Epoch: 2500 loss_train: 0.5132\n",
      "Epoch: 3000 loss_train: 0.4740\n",
      "Epoch: 3500 loss_train: 0.4409\n",
      "Epoch: 4000 loss_train: 0.4121\n",
      "Epoch: 4500 loss_train: 0.3866\n",
      "Epoch: 5000 loss_train: 0.3637\n",
      "Epoch: 5500 loss_train: 0.3430\n",
      " total time: 2.9122s\n",
      "0.18790879845619202\n",
      "Epoch: 0000 loss_train: 2.0721\n",
      "Epoch: 0500 loss_train: 0.9130\n",
      "Epoch: 1000 loss_train: 0.7260\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5609\n",
      "Epoch: 2500 loss_train: 0.5122\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4402\n",
      "Epoch: 4000 loss_train: 0.4116\n",
      "Epoch: 4500 loss_train: 0.3863\n",
      "Epoch: 5000 loss_train: 0.3636\n",
      "Epoch: 5500 loss_train: 0.3429\n",
      " total time: 2.9029s\n",
      "0.24203622341156006\n",
      "Epoch: 0000 loss_train: 2.0725\n",
      "Epoch: 0500 loss_train: 0.9128\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5609\n",
      "Epoch: 2500 loss_train: 0.5121\n",
      "Epoch: 3000 loss_train: 0.4729\n",
      "Epoch: 3500 loss_train: 0.4398\n",
      "Epoch: 4000 loss_train: 0.4111\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 2.8787s\n",
      "0.4584203064441681\n",
      "Epoch: 0000 loss_train: 2.0707\n",
      "Epoch: 0500 loss_train: 0.9119\n",
      "Epoch: 1000 loss_train: 0.7233\n",
      "Epoch: 1500 loss_train: 0.6234\n",
      "Epoch: 2000 loss_train: 0.5580\n",
      "Epoch: 2500 loss_train: 0.5095\n",
      "Epoch: 3000 loss_train: 0.4705\n",
      "Epoch: 3500 loss_train: 0.4377\n",
      "Epoch: 4000 loss_train: 0.4092\n",
      "Epoch: 4500 loss_train: 0.3840\n",
      "Epoch: 5000 loss_train: 0.3614\n",
      "Epoch: 5500 loss_train: 0.3409\n",
      " total time: 2.8897s\n",
      "13.17434024810791\n",
      "Epoch: 0000 loss_train: 2.0710\n",
      "Epoch: 0500 loss_train: 0.9067\n",
      "Epoch: 1000 loss_train: 0.7192\n",
      "Epoch: 1500 loss_train: 0.6202\n",
      "Epoch: 2000 loss_train: 0.5552\n",
      "Epoch: 2500 loss_train: 0.5070\n",
      "Epoch: 3000 loss_train: 0.4682\n",
      "Epoch: 3500 loss_train: 0.4356\n",
      "Epoch: 4000 loss_train: 0.4073\n",
      "Epoch: 4500 loss_train: 0.3823\n",
      "Epoch: 5000 loss_train: 0.3600\n",
      "Epoch: 5500 loss_train: 0.3398\n",
      " total time: 2.8873s\n",
      "1.831437349319458\n",
      "Epoch: 0000 loss_train: 2.0700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0500 loss_train: 0.9078\n",
      "Epoch: 1000 loss_train: 0.7205\n",
      "Epoch: 1500 loss_train: 0.6207\n",
      "Epoch: 2000 loss_train: 0.5549\n",
      "Epoch: 2500 loss_train: 0.5059\n",
      "Epoch: 3000 loss_train: 0.4664\n",
      "Epoch: 3500 loss_train: 0.4331\n",
      "Epoch: 4000 loss_train: 0.4041\n",
      "Epoch: 4500 loss_train: 0.3785\n",
      "Epoch: 5000 loss_train: 0.3556\n",
      "Epoch: 5500 loss_train: 0.3348\n",
      " total time: 2.8996s\n",
      "5.008342266082764\n",
      "Epoch: 0000 loss_train: 2.0708\n",
      "Epoch: 0500 loss_train: 0.9130\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6263\n",
      "Epoch: 2000 loss_train: 0.5608\n",
      "Epoch: 2500 loss_train: 0.5121\n",
      "Epoch: 3000 loss_train: 0.4728\n",
      "Epoch: 3500 loss_train: 0.4397\n",
      "Epoch: 4000 loss_train: 0.4110\n",
      "Epoch: 4500 loss_train: 0.3856\n",
      "Epoch: 5000 loss_train: 0.3629\n",
      "Epoch: 5500 loss_train: 0.3423\n",
      " total time: 2.9292s\n",
      "0.6478436589241028\n",
      "Epoch: 0000 loss_train: 2.0720\n",
      "Epoch: 0500 loss_train: 0.9025\n",
      "Epoch: 1000 loss_train: 0.7127\n",
      "Epoch: 1500 loss_train: 0.6123\n",
      "Epoch: 2000 loss_train: 0.5466\n",
      "Epoch: 2500 loss_train: 0.4979\n",
      "Epoch: 3000 loss_train: 0.4587\n",
      "Epoch: 3500 loss_train: 0.4259\n",
      "Epoch: 4000 loss_train: 0.3976\n",
      "Epoch: 4500 loss_train: 0.3728\n",
      "Epoch: 5000 loss_train: 0.3507\n",
      "Epoch: 5500 loss_train: 0.3309\n",
      " total time: 2.9317s\n",
      "9.984374046325684\n",
      "Epoch: 0000 loss_train: 2.0702\n",
      "Epoch: 0500 loss_train: 0.9122\n",
      "Epoch: 1000 loss_train: 0.7258\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5608\n",
      "Epoch: 2500 loss_train: 0.5120\n",
      "Epoch: 3000 loss_train: 0.4726\n",
      "Epoch: 3500 loss_train: 0.4393\n",
      "Epoch: 4000 loss_train: 0.4104\n",
      "Epoch: 4500 loss_train: 0.3847\n",
      "Epoch: 5000 loss_train: 0.3617\n",
      "Epoch: 5500 loss_train: 0.3408\n",
      " total time: 2.9048s\n",
      "4.863956928253174\n",
      "Epoch: 0000 loss_train: 2.0714\n",
      "Epoch: 0500 loss_train: 0.9149\n",
      "Epoch: 1000 loss_train: 0.7273\n",
      "Epoch: 1500 loss_train: 0.6273\n",
      "Epoch: 2000 loss_train: 0.5616\n",
      "Epoch: 2500 loss_train: 0.5127\n",
      "Epoch: 3000 loss_train: 0.4733\n",
      "Epoch: 3500 loss_train: 0.4401\n",
      "Epoch: 4000 loss_train: 0.4114\n",
      "Epoch: 4500 loss_train: 0.3860\n",
      "Epoch: 5000 loss_train: 0.3632\n",
      "Epoch: 5500 loss_train: 0.3427\n",
      " total time: 2.9006s\n",
      "0.6560567617416382\n",
      "Epoch: 0000 loss_train: 2.0707\n",
      "Epoch: 0500 loss_train: 0.9115\n",
      "Epoch: 1000 loss_train: 0.7250\n",
      "Epoch: 1500 loss_train: 0.6259\n",
      "Epoch: 2000 loss_train: 0.5607\n",
      "Epoch: 2500 loss_train: 0.5122\n",
      "Epoch: 3000 loss_train: 0.4732\n",
      "Epoch: 3500 loss_train: 0.4402\n",
      "Epoch: 4000 loss_train: 0.4115\n",
      "Epoch: 4500 loss_train: 0.3861\n",
      "Epoch: 5000 loss_train: 0.3633\n",
      "Epoch: 5500 loss_train: 0.3427\n",
      " total time: 2.9290s\n",
      "0.028080761432647705\n",
      "Epoch: 0000 loss_train: 2.0667\n",
      "Epoch: 0500 loss_train: 0.9083\n",
      "Epoch: 1000 loss_train: 0.7205\n",
      "Epoch: 1500 loss_train: 0.6212\n",
      "Epoch: 2000 loss_train: 0.5562\n",
      "Epoch: 2500 loss_train: 0.5080\n",
      "Epoch: 3000 loss_train: 0.4693\n",
      "Epoch: 3500 loss_train: 0.4368\n",
      "Epoch: 4000 loss_train: 0.4087\n",
      "Epoch: 4500 loss_train: 0.3837\n",
      "Epoch: 5000 loss_train: 0.3614\n",
      "Epoch: 5500 loss_train: 0.3411\n",
      " total time: 2.8889s\n",
      "2.953526020050049\n",
      "Epoch: 0000 loss_train: 2.0709\n",
      "Epoch: 0500 loss_train: 0.9121\n",
      "Epoch: 1000 loss_train: 0.7248\n",
      "Epoch: 1500 loss_train: 0.6248\n",
      "Epoch: 2000 loss_train: 0.5588\n",
      "Epoch: 2500 loss_train: 0.5096\n",
      "Epoch: 3000 loss_train: 0.4699\n",
      "Epoch: 3500 loss_train: 0.4365\n",
      "Epoch: 4000 loss_train: 0.4075\n",
      "Epoch: 4500 loss_train: 0.3820\n",
      "Epoch: 5000 loss_train: 0.3591\n",
      "Epoch: 5500 loss_train: 0.3385\n",
      " total time: 3.0523s\n",
      "2.5465121269226074\n",
      "Epoch: 0000 loss_train: 2.0697\n",
      "Epoch: 0500 loss_train: 0.9141\n",
      "Epoch: 1000 loss_train: 0.7266\n",
      "Epoch: 1500 loss_train: 0.6268\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5120\n",
      "Epoch: 3000 loss_train: 0.4725\n",
      "Epoch: 3500 loss_train: 0.4391\n",
      "Epoch: 4000 loss_train: 0.4102\n",
      "Epoch: 4500 loss_train: 0.3847\n",
      "Epoch: 5000 loss_train: 0.3619\n",
      "Epoch: 5500 loss_train: 0.3413\n",
      " total time: 3.1643s\n",
      "1.1127575635910034\n",
      "Epoch: 0000 loss_train: 2.0668\n",
      "Epoch: 0500 loss_train: 0.9153\n",
      "Epoch: 1000 loss_train: 0.7265\n",
      "Epoch: 1500 loss_train: 0.6263\n",
      "Epoch: 2000 loss_train: 0.5605\n",
      "Epoch: 2500 loss_train: 0.5116\n",
      "Epoch: 3000 loss_train: 0.4723\n",
      "Epoch: 3500 loss_train: 0.4390\n",
      "Epoch: 4000 loss_train: 0.4102\n",
      "Epoch: 4500 loss_train: 0.3848\n",
      "Epoch: 5000 loss_train: 0.3620\n",
      "Epoch: 5500 loss_train: 0.3414\n",
      " total time: 3.1268s\n",
      "1.9783234596252441\n",
      "Epoch: 0000 loss_train: 2.0680\n",
      "Epoch: 0500 loss_train: 0.9162\n",
      "Epoch: 1000 loss_train: 0.7285\n",
      "Epoch: 1500 loss_train: 0.6288\n",
      "Epoch: 2000 loss_train: 0.5633\n",
      "Epoch: 2500 loss_train: 0.5145\n",
      "Epoch: 3000 loss_train: 0.4752\n",
      "Epoch: 3500 loss_train: 0.4419\n",
      "Epoch: 4000 loss_train: 0.4131\n",
      "Epoch: 4500 loss_train: 0.3875\n",
      "Epoch: 5000 loss_train: 0.3646\n",
      "Epoch: 5500 loss_train: 0.3439\n",
      " total time: 3.1540s\n",
      "0.17582769691944122\n",
      "Epoch: 0000 loss_train: 2.0707\n",
      "Epoch: 0500 loss_train: 0.9117\n",
      "Epoch: 1000 loss_train: 0.7243\n",
      "Epoch: 1500 loss_train: 0.6245\n",
      "Epoch: 2000 loss_train: 0.5587\n",
      "Epoch: 2500 loss_train: 0.5098\n",
      "Epoch: 3000 loss_train: 0.4704\n",
      "Epoch: 3500 loss_train: 0.4372\n",
      "Epoch: 4000 loss_train: 0.4084\n",
      "Epoch: 4500 loss_train: 0.3830\n",
      "Epoch: 5000 loss_train: 0.3603\n",
      "Epoch: 5500 loss_train: 0.3397\n",
      " total time: 3.1859s\n",
      "2.8222434520721436\n",
      "Epoch: 0000 loss_train: 2.0699\n",
      "Epoch: 0500 loss_train: 0.9139\n",
      "Epoch: 1000 loss_train: 0.7268\n",
      "Epoch: 1500 loss_train: 0.6272\n",
      "Epoch: 2000 loss_train: 0.5617\n",
      "Epoch: 2500 loss_train: 0.5129\n",
      "Epoch: 3000 loss_train: 0.4735\n",
      "Epoch: 3500 loss_train: 0.4403\n",
      "Epoch: 4000 loss_train: 0.4115\n",
      "Epoch: 4500 loss_train: 0.3860\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.1021s\n",
      "0.2856883108615875\n",
      "Epoch: 0000 loss_train: 2.0717\n",
      "Epoch: 0500 loss_train: 0.9137\n",
      "Epoch: 1000 loss_train: 0.7265\n",
      "Epoch: 1500 loss_train: 0.6269\n",
      "Epoch: 2000 loss_train: 0.5614\n",
      "Epoch: 2500 loss_train: 0.5126\n",
      "Epoch: 3000 loss_train: 0.4734\n",
      "Epoch: 3500 loss_train: 0.4402\n",
      "Epoch: 4000 loss_train: 0.4114\n",
      "Epoch: 4500 loss_train: 0.3860\n",
      "Epoch: 5000 loss_train: 0.3632\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.1045s\n",
      "0.2894646227359772\n",
      "Epoch: 0000 loss_train: 2.0714\n",
      "Epoch: 0500 loss_train: 0.9143\n",
      "Epoch: 1000 loss_train: 0.7271\n",
      "Epoch: 1500 loss_train: 0.6275\n",
      "Epoch: 2000 loss_train: 0.5619\n",
      "Epoch: 2500 loss_train: 0.5131\n",
      "Epoch: 3000 loss_train: 0.4738\n",
      "Epoch: 3500 loss_train: 0.4407\n",
      "Epoch: 4000 loss_train: 0.4119\n",
      "Epoch: 4500 loss_train: 0.3865\n",
      "Epoch: 5000 loss_train: 0.3637\n",
      "Epoch: 5500 loss_train: 0.3430\n",
      " total time: 3.2568s\n",
      "0.004733665846288204\n",
      "Epoch: 0000 loss_train: 2.0709\n",
      "Epoch: 0500 loss_train: 0.9121\n",
      "Epoch: 1000 loss_train: 0.7250\n",
      "Epoch: 1500 loss_train: 0.6257\n",
      "Epoch: 2000 loss_train: 0.5603\n",
      "Epoch: 2500 loss_train: 0.5117\n",
      "Epoch: 3000 loss_train: 0.4725\n",
      "Epoch: 3500 loss_train: 0.4395\n",
      "Epoch: 4000 loss_train: 0.4108\n",
      "Epoch: 4500 loss_train: 0.3855\n",
      "Epoch: 5000 loss_train: 0.3628\n",
      "Epoch: 5500 loss_train: 0.3422\n",
      " total time: 3.1895s\n",
      "0.574341893196106\n",
      "Epoch: 0000 loss_train: 2.0712\n",
      "Epoch: 0500 loss_train: 0.9128\n",
      "Epoch: 1000 loss_train: 0.7254\n",
      "Epoch: 1500 loss_train: 0.6256\n",
      "Epoch: 2000 loss_train: 0.5599\n",
      "Epoch: 2500 loss_train: 0.5110\n",
      "Epoch: 3000 loss_train: 0.4716\n",
      "Epoch: 3500 loss_train: 0.4383\n",
      "Epoch: 4000 loss_train: 0.4095\n",
      "Epoch: 4500 loss_train: 0.3841\n",
      "Epoch: 5000 loss_train: 0.3613\n",
      "Epoch: 5500 loss_train: 0.3407\n",
      " total time: 3.1164s\n",
      "1.547309160232544\n",
      "Epoch: 0000 loss_train: 2.0707\n",
      "Epoch: 0500 loss_train: 0.9138\n",
      "Epoch: 1000 loss_train: 0.7267\n",
      "Epoch: 1500 loss_train: 0.6272\n",
      "Epoch: 2000 loss_train: 0.5616\n",
      "Epoch: 2500 loss_train: 0.5129\n",
      "Epoch: 3000 loss_train: 0.4736\n",
      "Epoch: 3500 loss_train: 0.4404\n",
      "Epoch: 4000 loss_train: 0.4116\n",
      "Epoch: 4500 loss_train: 0.3862\n",
      "Epoch: 5000 loss_train: 0.3634\n",
      "Epoch: 5500 loss_train: 0.3427\n",
      " total time: 2.9662s\n",
      "0.09960366785526276\n",
      "Epoch: 0000 loss_train: 2.0716\n",
      "Epoch: 0500 loss_train: 0.9126\n",
      "Epoch: 1000 loss_train: 0.7253\n",
      "Epoch: 1500 loss_train: 0.6258\n",
      "Epoch: 2000 loss_train: 0.5603\n",
      "Epoch: 2500 loss_train: 0.5116\n",
      "Epoch: 3000 loss_train: 0.4723\n",
      "Epoch: 3500 loss_train: 0.4392\n",
      "Epoch: 4000 loss_train: 0.4105\n",
      "Epoch: 4500 loss_train: 0.3851\n",
      "Epoch: 5000 loss_train: 0.3625\n",
      "Epoch: 5500 loss_train: 0.3419\n",
      " total time: 3.0432s\n",
      "1.355041265487671\n",
      "Epoch: 0000 loss_train: 2.0718\n",
      "Epoch: 0500 loss_train: 0.9014\n",
      "Epoch: 1000 loss_train: 0.7140\n",
      "Epoch: 1500 loss_train: 0.6138\n",
      "Epoch: 2000 loss_train: 0.5477\n",
      "Epoch: 2500 loss_train: 0.4985\n",
      "Epoch: 3000 loss_train: 0.4590\n",
      "Epoch: 3500 loss_train: 0.4258\n",
      "Epoch: 4000 loss_train: 0.3971\n",
      "Epoch: 4500 loss_train: 0.3719\n",
      "Epoch: 5000 loss_train: 0.3494\n",
      "Epoch: 5500 loss_train: 0.3291\n",
      " total time: 3.0226s\n",
      "5.8155741691589355\n",
      "Epoch: 0000 loss_train: 2.0706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0500 loss_train: 0.9129\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3859\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 2.9654s\n",
      "0.00015639036428183317\n",
      "Epoch: 0000 loss_train: 2.0713\n",
      "Epoch: 0500 loss_train: 0.9143\n",
      "Epoch: 1000 loss_train: 0.7272\n",
      "Epoch: 1500 loss_train: 0.6276\n",
      "Epoch: 2000 loss_train: 0.5621\n",
      "Epoch: 2500 loss_train: 0.5133\n",
      "Epoch: 3000 loss_train: 0.4740\n",
      "Epoch: 3500 loss_train: 0.4408\n",
      "Epoch: 4000 loss_train: 0.4121\n",
      "Epoch: 4500 loss_train: 0.3866\n",
      "Epoch: 5000 loss_train: 0.3638\n",
      "Epoch: 5500 loss_train: 0.3431\n",
      " total time: 2.9249s\n",
      "0.011585456319153309\n",
      "Epoch: 0000 loss_train: 2.0722\n",
      "Epoch: 0500 loss_train: 0.9146\n",
      "Epoch: 1000 loss_train: 0.7271\n",
      "Epoch: 1500 loss_train: 0.6275\n",
      "Epoch: 2000 loss_train: 0.5619\n",
      "Epoch: 2500 loss_train: 0.5131\n",
      "Epoch: 3000 loss_train: 0.4738\n",
      "Epoch: 3500 loss_train: 0.4407\n",
      "Epoch: 4000 loss_train: 0.4119\n",
      "Epoch: 4500 loss_train: 0.3864\n",
      "Epoch: 5000 loss_train: 0.3636\n",
      "Epoch: 5500 loss_train: 0.3430\n",
      " total time: 2.9441s\n",
      "0.0018970841774716973\n",
      "Epoch: 0000 loss_train: 2.0706\n",
      "Epoch: 0500 loss_train: 0.9137\n",
      "Epoch: 1000 loss_train: 0.7265\n",
      "Epoch: 1500 loss_train: 0.6269\n",
      "Epoch: 2000 loss_train: 0.5614\n",
      "Epoch: 2500 loss_train: 0.5126\n",
      "Epoch: 3000 loss_train: 0.4733\n",
      "Epoch: 3500 loss_train: 0.4401\n",
      "Epoch: 4000 loss_train: 0.4113\n",
      "Epoch: 4500 loss_train: 0.3859\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.0363s\n",
      "0.23855222761631012\n",
      "Epoch: 0000 loss_train: 2.0704\n",
      "Epoch: 0500 loss_train: 0.9139\n",
      "Epoch: 1000 loss_train: 0.7266\n",
      "Epoch: 1500 loss_train: 0.6270\n",
      "Epoch: 2000 loss_train: 0.5616\n",
      "Epoch: 2500 loss_train: 0.5129\n",
      "Epoch: 3000 loss_train: 0.4737\n",
      "Epoch: 3500 loss_train: 0.4406\n",
      "Epoch: 4000 loss_train: 0.4119\n",
      "Epoch: 4500 loss_train: 0.3865\n",
      "Epoch: 5000 loss_train: 0.3637\n",
      "Epoch: 5500 loss_train: 0.3430\n",
      " total time: 2.9456s\n",
      "0.007889064960181713\n",
      "Epoch: 0000 loss_train: 2.0672\n",
      "Epoch: 0500 loss_train: 0.9164\n",
      "Epoch: 1000 loss_train: 0.7288\n",
      "Epoch: 1500 loss_train: 0.6289\n",
      "Epoch: 2000 loss_train: 0.5631\n",
      "Epoch: 2500 loss_train: 0.5142\n",
      "Epoch: 3000 loss_train: 0.4747\n",
      "Epoch: 3500 loss_train: 0.4415\n",
      "Epoch: 4000 loss_train: 0.4126\n",
      "Epoch: 4500 loss_train: 0.3871\n",
      "Epoch: 5000 loss_train: 0.3643\n",
      "Epoch: 5500 loss_train: 0.3436\n",
      " total time: 3.0688s\n",
      "0.17677932977676392\n",
      "Epoch: 0000 loss_train: 2.0702\n",
      "Epoch: 0500 loss_train: 0.9127\n",
      "Epoch: 1000 loss_train: 0.7258\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 2.9803s\n",
      "1.6093124941107817e-05\n",
      "Epoch: 0000 loss_train: 2.0709\n",
      "Epoch: 0500 loss_train: 0.9142\n",
      "Epoch: 1000 loss_train: 0.7270\n",
      "Epoch: 1500 loss_train: 0.6273\n",
      "Epoch: 2000 loss_train: 0.5618\n",
      "Epoch: 2500 loss_train: 0.5130\n",
      "Epoch: 3000 loss_train: 0.4736\n",
      "Epoch: 3500 loss_train: 0.4404\n",
      "Epoch: 4000 loss_train: 0.4116\n",
      "Epoch: 4500 loss_train: 0.3862\n",
      "Epoch: 5000 loss_train: 0.3634\n",
      "Epoch: 5500 loss_train: 0.3427\n",
      " total time: 3.0752s\n",
      "0.11541809886693954\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9139\n",
      "Epoch: 1000 loss_train: 0.7267\n",
      "Epoch: 1500 loss_train: 0.6272\n",
      "Epoch: 2000 loss_train: 0.5617\n",
      "Epoch: 2500 loss_train: 0.5129\n",
      "Epoch: 3000 loss_train: 0.4737\n",
      "Epoch: 3500 loss_train: 0.4405\n",
      "Epoch: 4000 loss_train: 0.4118\n",
      "Epoch: 4500 loss_train: 0.3863\n",
      "Epoch: 5000 loss_train: 0.3635\n",
      "Epoch: 5500 loss_train: 0.3429\n",
      " total time: 3.1353s\n",
      "0.02016870118677616\n",
      "Epoch: 0000 loss_train: 2.0696\n",
      "Epoch: 0500 loss_train: 0.9053\n",
      "Epoch: 1000 loss_train: 0.7159\n",
      "Epoch: 1500 loss_train: 0.6154\n",
      "Epoch: 2000 loss_train: 0.5495\n",
      "Epoch: 2500 loss_train: 0.5007\n",
      "Epoch: 3000 loss_train: 0.4616\n",
      "Epoch: 3500 loss_train: 0.4287\n",
      "Epoch: 4000 loss_train: 0.4003\n",
      "Epoch: 4500 loss_train: 0.3752\n",
      "Epoch: 5000 loss_train: 0.3529\n",
      "Epoch: 5500 loss_train: 0.3326\n",
      " total time: 3.1452s\n",
      "3.961503028869629\n",
      "Epoch: 0000 loss_train: 2.0698\n",
      "Epoch: 0500 loss_train: 0.9087\n",
      "Epoch: 1000 loss_train: 0.7222\n",
      "Epoch: 1500 loss_train: 0.6233\n",
      "Epoch: 2000 loss_train: 0.5584\n",
      "Epoch: 2500 loss_train: 0.5102\n",
      "Epoch: 3000 loss_train: 0.4714\n",
      "Epoch: 3500 loss_train: 0.4387\n",
      "Epoch: 4000 loss_train: 0.4103\n",
      "Epoch: 4500 loss_train: 0.3851\n",
      "Epoch: 5000 loss_train: 0.3626\n",
      "Epoch: 5500 loss_train: 0.3421\n",
      " total time: 3.1443s\n",
      "1.0380128622055054\n",
      "Epoch: 0000 loss_train: 2.0694\n",
      "Epoch: 0500 loss_train: 0.9127\n",
      "Epoch: 1000 loss_train: 0.7255\n",
      "Epoch: 1500 loss_train: 0.6258\n",
      "Epoch: 2000 loss_train: 0.5602\n",
      "Epoch: 2500 loss_train: 0.5114\n",
      "Epoch: 3000 loss_train: 0.4720\n",
      "Epoch: 3500 loss_train: 0.4387\n",
      "Epoch: 4000 loss_train: 0.4098\n",
      "Epoch: 4500 loss_train: 0.3843\n",
      "Epoch: 5000 loss_train: 0.3614\n",
      "Epoch: 5500 loss_train: 0.3406\n",
      " total time: 3.1825s\n",
      "4.497711658477783\n",
      "Epoch: 0000 loss_train: 2.0707\n",
      "Epoch: 0500 loss_train: 0.9128\n",
      "Epoch: 1000 loss_train: 0.7258\n",
      "Epoch: 1500 loss_train: 0.6261\n",
      "Epoch: 2000 loss_train: 0.5605\n",
      "Epoch: 2500 loss_train: 0.5117\n",
      "Epoch: 3000 loss_train: 0.4724\n",
      "Epoch: 3500 loss_train: 0.4393\n",
      "Epoch: 4000 loss_train: 0.4106\n",
      "Epoch: 4500 loss_train: 0.3853\n",
      "Epoch: 5000 loss_train: 0.3626\n",
      "Epoch: 5500 loss_train: 0.3419\n",
      " total time: 3.1351s\n",
      "3.887047529220581\n",
      "Epoch: 0000 loss_train: 2.0706\n",
      "Epoch: 0500 loss_train: 0.9137\n",
      "Epoch: 1000 loss_train: 0.7278\n",
      "Epoch: 1500 loss_train: 0.6288\n",
      "Epoch: 2000 loss_train: 0.5633\n",
      "Epoch: 2500 loss_train: 0.5144\n",
      "Epoch: 3000 loss_train: 0.4750\n",
      "Epoch: 3500 loss_train: 0.4417\n",
      "Epoch: 4000 loss_train: 0.4129\n",
      "Epoch: 4500 loss_train: 0.3874\n",
      "Epoch: 5000 loss_train: 0.3645\n",
      "Epoch: 5500 loss_train: 0.3438\n",
      " total time: 2.8965s\n",
      "0.017949290573596954\n",
      "Epoch: 0000 loss_train: 2.0715\n",
      "Epoch: 0500 loss_train: 0.9144\n",
      "Epoch: 1000 loss_train: 0.7270\n",
      "Epoch: 1500 loss_train: 0.6270\n",
      "Epoch: 2000 loss_train: 0.5611\n",
      "Epoch: 2500 loss_train: 0.5120\n",
      "Epoch: 3000 loss_train: 0.4724\n",
      "Epoch: 3500 loss_train: 0.4388\n",
      "Epoch: 4000 loss_train: 0.4097\n",
      "Epoch: 4500 loss_train: 0.3840\n",
      "Epoch: 5000 loss_train: 0.3608\n",
      "Epoch: 5500 loss_train: 0.3399\n",
      " total time: 2.8901s\n",
      "2.5899884700775146\n",
      "Epoch: 0000 loss_train: 2.0704\n",
      "Epoch: 0500 loss_train: 0.9120\n",
      "Epoch: 1000 loss_train: 0.7255\n",
      "Epoch: 1500 loss_train: 0.6263\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4113\n",
      "Epoch: 4500 loss_train: 0.3859\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 2.8995s\n",
      "0.12287717312574387\n",
      "Epoch: 0000 loss_train: 2.0680\n",
      "Epoch: 0500 loss_train: 0.9095\n",
      "Epoch: 1000 loss_train: 0.7229\n",
      "Epoch: 1500 loss_train: 0.6241\n",
      "Epoch: 2000 loss_train: 0.5589\n",
      "Epoch: 2500 loss_train: 0.5102\n",
      "Epoch: 3000 loss_train: 0.4709\n",
      "Epoch: 3500 loss_train: 0.4378\n",
      "Epoch: 4000 loss_train: 0.4089\n",
      "Epoch: 4500 loss_train: 0.3835\n",
      "Epoch: 5000 loss_train: 0.3607\n",
      "Epoch: 5500 loss_train: 0.3400\n",
      " total time: 2.9134s\n",
      "2.266251564025879\n",
      "Epoch: 0000 loss_train: 2.0699\n",
      "Epoch: 0500 loss_train: 0.9147\n",
      "Epoch: 1000 loss_train: 0.7275\n",
      "Epoch: 1500 loss_train: 0.6279\n",
      "Epoch: 2000 loss_train: 0.5624\n",
      "Epoch: 2500 loss_train: 0.5137\n",
      "Epoch: 3000 loss_train: 0.4744\n",
      "Epoch: 3500 loss_train: 0.4412\n",
      "Epoch: 4000 loss_train: 0.4124\n",
      "Epoch: 4500 loss_train: 0.3869\n",
      "Epoch: 5000 loss_train: 0.3641\n",
      "Epoch: 5500 loss_train: 0.3434\n",
      " total time: 2.8941s\n",
      "0.02382727898657322\n",
      "Epoch: 0000 loss_train: 2.0697\n",
      "Epoch: 0500 loss_train: 0.9141\n",
      "Epoch: 1000 loss_train: 0.7271\n",
      "Epoch: 1500 loss_train: 0.6276\n",
      "Epoch: 2000 loss_train: 0.5621\n",
      "Epoch: 2500 loss_train: 0.5133\n",
      "Epoch: 3000 loss_train: 0.4740\n",
      "Epoch: 3500 loss_train: 0.4408\n",
      "Epoch: 4000 loss_train: 0.4120\n",
      "Epoch: 4500 loss_train: 0.3866\n",
      "Epoch: 5000 loss_train: 0.3638\n",
      "Epoch: 5500 loss_train: 0.3431\n",
      " total time: 2.9697s\n",
      "0.09788516163825989\n",
      "Epoch: 0000 loss_train: 2.0647\n",
      "Epoch: 0500 loss_train: 0.9167\n",
      "Epoch: 1000 loss_train: 0.7288\n",
      "Epoch: 1500 loss_train: 0.6290\n",
      "Epoch: 2000 loss_train: 0.5634\n",
      "Epoch: 2500 loss_train: 0.5146\n",
      "Epoch: 3000 loss_train: 0.4752\n",
      "Epoch: 3500 loss_train: 0.4420\n",
      "Epoch: 4000 loss_train: 0.4131\n",
      "Epoch: 4500 loss_train: 0.3876\n",
      "Epoch: 5000 loss_train: 0.3647\n",
      "Epoch: 5500 loss_train: 0.3441\n",
      " total time: 3.3061s\n",
      "0.03826918452978134\n",
      "Epoch: 0000 loss_train: 2.0664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0500 loss_train: 0.9157\n",
      "Epoch: 1000 loss_train: 0.7290\n",
      "Epoch: 1500 loss_train: 0.6294\n",
      "Epoch: 2000 loss_train: 0.5639\n",
      "Epoch: 2500 loss_train: 0.5151\n",
      "Epoch: 3000 loss_train: 0.4758\n",
      "Epoch: 3500 loss_train: 0.4425\n",
      "Epoch: 4000 loss_train: 0.4137\n",
      "Epoch: 4500 loss_train: 0.3882\n",
      "Epoch: 5000 loss_train: 0.3653\n",
      "Epoch: 5500 loss_train: 0.3446\n",
      " total time: 3.2601s\n",
      "0.013173097744584084\n",
      "Epoch: 0000 loss_train: 2.0700\n",
      "Epoch: 0500 loss_train: 0.9124\n",
      "Epoch: 1000 loss_train: 0.7254\n",
      "Epoch: 1500 loss_train: 0.6261\n",
      "Epoch: 2000 loss_train: 0.5607\n",
      "Epoch: 2500 loss_train: 0.5121\n",
      "Epoch: 3000 loss_train: 0.4729\n",
      "Epoch: 3500 loss_train: 0.4398\n",
      "Epoch: 4000 loss_train: 0.4110\n",
      "Epoch: 4500 loss_train: 0.3856\n",
      "Epoch: 5000 loss_train: 0.3629\n",
      "Epoch: 5500 loss_train: 0.3422\n",
      " total time: 3.2389s\n",
      "0.5204038619995117\n",
      "Epoch: 0000 loss_train: 2.0694\n",
      "Epoch: 0500 loss_train: 0.9142\n",
      "Epoch: 1000 loss_train: 0.7269\n",
      "Epoch: 1500 loss_train: 0.6272\n",
      "Epoch: 2000 loss_train: 0.5617\n",
      "Epoch: 2500 loss_train: 0.5129\n",
      "Epoch: 3000 loss_train: 0.4736\n",
      "Epoch: 3500 loss_train: 0.4404\n",
      "Epoch: 4000 loss_train: 0.4116\n",
      "Epoch: 4500 loss_train: 0.3862\n",
      "Epoch: 5000 loss_train: 0.3634\n",
      "Epoch: 5500 loss_train: 0.3428\n",
      " total time: 3.1688s\n",
      "0.10953640192747116\n",
      "Epoch: 0000 loss_train: 2.0719\n",
      "Epoch: 0500 loss_train: 0.9141\n",
      "Epoch: 1000 loss_train: 0.7270\n",
      "Epoch: 1500 loss_train: 0.6275\n",
      "Epoch: 2000 loss_train: 0.5620\n",
      "Epoch: 2500 loss_train: 0.5132\n",
      "Epoch: 3000 loss_train: 0.4739\n",
      "Epoch: 3500 loss_train: 0.4407\n",
      "Epoch: 4000 loss_train: 0.4119\n",
      "Epoch: 4500 loss_train: 0.3865\n",
      "Epoch: 5000 loss_train: 0.3637\n",
      "Epoch: 5500 loss_train: 0.3430\n",
      " total time: 3.1303s\n",
      "0.010585233569145203\n",
      "Epoch: 0000 loss_train: 2.0712\n",
      "Epoch: 0500 loss_train: 0.9143\n",
      "Epoch: 1000 loss_train: 0.7270\n",
      "Epoch: 1500 loss_train: 0.6275\n",
      "Epoch: 2000 loss_train: 0.5620\n",
      "Epoch: 2500 loss_train: 0.5132\n",
      "Epoch: 3000 loss_train: 0.4739\n",
      "Epoch: 3500 loss_train: 0.4407\n",
      "Epoch: 4000 loss_train: 0.4119\n",
      "Epoch: 4500 loss_train: 0.3865\n",
      "Epoch: 5000 loss_train: 0.3637\n",
      "Epoch: 5500 loss_train: 0.3430\n",
      " total time: 3.1831s\n",
      "0.010084275156259537\n",
      "Epoch: 0000 loss_train: 2.0711\n",
      "Epoch: 0500 loss_train: 0.9114\n",
      "Epoch: 1000 loss_train: 0.7244\n",
      "Epoch: 1500 loss_train: 0.6253\n",
      "Epoch: 2000 loss_train: 0.5601\n",
      "Epoch: 2500 loss_train: 0.5115\n",
      "Epoch: 3000 loss_train: 0.4724\n",
      "Epoch: 3500 loss_train: 0.4393\n",
      "Epoch: 4000 loss_train: 0.4106\n",
      "Epoch: 4500 loss_train: 0.3852\n",
      "Epoch: 5000 loss_train: 0.3623\n",
      "Epoch: 5500 loss_train: 0.3416\n",
      " total time: 3.1150s\n",
      "0.9761680960655212\n",
      "Epoch: 0000 loss_train: 2.0710\n",
      "Epoch: 0500 loss_train: 0.9135\n",
      "Epoch: 1000 loss_train: 0.7261\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5124\n",
      "Epoch: 3000 loss_train: 0.4733\n",
      "Epoch: 3500 loss_train: 0.4403\n",
      "Epoch: 4000 loss_train: 0.4116\n",
      "Epoch: 4500 loss_train: 0.3863\n",
      "Epoch: 5000 loss_train: 0.3635\n",
      "Epoch: 5500 loss_train: 0.3429\n",
      " total time: 3.1092s\n",
      "0.16856694221496582\n",
      "Epoch: 0000 loss_train: 2.0707\n",
      "Epoch: 0500 loss_train: 0.9140\n",
      "Epoch: 1000 loss_train: 0.7268\n",
      "Epoch: 1500 loss_train: 0.6273\n",
      "Epoch: 2000 loss_train: 0.5618\n",
      "Epoch: 2500 loss_train: 0.5130\n",
      "Epoch: 3000 loss_train: 0.4737\n",
      "Epoch: 3500 loss_train: 0.4406\n",
      "Epoch: 4000 loss_train: 0.4118\n",
      "Epoch: 4500 loss_train: 0.3864\n",
      "Epoch: 5000 loss_train: 0.3636\n",
      "Epoch: 5500 loss_train: 0.3429\n",
      " total time: 3.0570s\n",
      "0.04100939258933067\n",
      "Epoch: 0000 loss_train: 2.0710\n",
      "Epoch: 0500 loss_train: 0.9126\n",
      "Epoch: 1000 loss_train: 0.7260\n",
      "Epoch: 1500 loss_train: 0.6268\n",
      "Epoch: 2000 loss_train: 0.5615\n",
      "Epoch: 2500 loss_train: 0.5129\n",
      "Epoch: 3000 loss_train: 0.4737\n",
      "Epoch: 3500 loss_train: 0.4405\n",
      "Epoch: 4000 loss_train: 0.4118\n",
      "Epoch: 4500 loss_train: 0.3864\n",
      "Epoch: 5000 loss_train: 0.3636\n",
      "Epoch: 5500 loss_train: 0.3429\n",
      " total time: 3.0886s\n",
      "0.10840709507465363\n",
      "Epoch: 0000 loss_train: 2.0700\n",
      "Epoch: 0500 loss_train: 0.9060\n",
      "Epoch: 1000 loss_train: 0.7222\n",
      "Epoch: 1500 loss_train: 0.6241\n",
      "Epoch: 2000 loss_train: 0.5590\n",
      "Epoch: 2500 loss_train: 0.5102\n",
      "Epoch: 3000 loss_train: 0.4707\n",
      "Epoch: 3500 loss_train: 0.4372\n",
      "Epoch: 4000 loss_train: 0.4082\n",
      "Epoch: 4500 loss_train: 0.3826\n",
      "Epoch: 5000 loss_train: 0.3597\n",
      "Epoch: 5500 loss_train: 0.3390\n",
      " total time: 3.1467s\n",
      "1.6964671611785889\n",
      "Epoch: 0000 loss_train: 2.0706\n",
      "Epoch: 0500 loss_train: 0.9129\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 2.9433s\n",
      "0.00021610308613162488\n",
      "Epoch: 0000 loss_train: 2.0711\n",
      "Epoch: 0500 loss_train: 0.9132\n",
      "Epoch: 1000 loss_train: 0.7267\n",
      "Epoch: 1500 loss_train: 0.6274\n",
      "Epoch: 2000 loss_train: 0.5619\n",
      "Epoch: 2500 loss_train: 0.5131\n",
      "Epoch: 3000 loss_train: 0.4737\n",
      "Epoch: 3500 loss_train: 0.4405\n",
      "Epoch: 4000 loss_train: 0.4116\n",
      "Epoch: 4500 loss_train: 0.3861\n",
      "Epoch: 5000 loss_train: 0.3633\n",
      "Epoch: 5500 loss_train: 0.3426\n",
      " total time: 3.1216s\n",
      "0.523401141166687\n",
      "Epoch: 0000 loss_train: 2.0699\n",
      "Epoch: 0500 loss_train: 0.9130\n",
      "Epoch: 1000 loss_train: 0.7255\n",
      "Epoch: 1500 loss_train: 0.6258\n",
      "Epoch: 2000 loss_train: 0.5604\n",
      "Epoch: 2500 loss_train: 0.5117\n",
      "Epoch: 3000 loss_train: 0.4725\n",
      "Epoch: 3500 loss_train: 0.4395\n",
      "Epoch: 4000 loss_train: 0.4108\n",
      "Epoch: 4500 loss_train: 0.3855\n",
      "Epoch: 5000 loss_train: 0.3628\n",
      "Epoch: 5500 loss_train: 0.3422\n",
      " total time: 3.1292s\n",
      "0.6032837629318237\n",
      "Epoch: 0000 loss_train: 2.0700\n",
      "Epoch: 0500 loss_train: 0.9126\n",
      "Epoch: 1000 loss_train: 0.7258\n",
      "Epoch: 1500 loss_train: 0.6263\n",
      "Epoch: 2000 loss_train: 0.5609\n",
      "Epoch: 2500 loss_train: 0.5122\n",
      "Epoch: 3000 loss_train: 0.4729\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3859\n",
      "Epoch: 5000 loss_train: 0.3632\n",
      "Epoch: 5500 loss_train: 0.3426\n",
      " total time: 3.1242s\n",
      "0.3386381268501282\n",
      "Epoch: 0000 loss_train: 2.0664\n",
      "Epoch: 0500 loss_train: 0.9174\n",
      "Epoch: 1000 loss_train: 0.7298\n",
      "Epoch: 1500 loss_train: 0.6297\n",
      "Epoch: 2000 loss_train: 0.5637\n",
      "Epoch: 2500 loss_train: 0.5147\n",
      "Epoch: 3000 loss_train: 0.4753\n",
      "Epoch: 3500 loss_train: 0.4419\n",
      "Epoch: 4000 loss_train: 0.4131\n",
      "Epoch: 4500 loss_train: 0.3875\n",
      "Epoch: 5000 loss_train: 0.3646\n",
      "Epoch: 5500 loss_train: 0.3439\n",
      " total time: 3.1518s\n",
      "0.05584687367081642\n",
      "Epoch: 0000 loss_train: 2.0703\n",
      "Epoch: 0500 loss_train: 0.9127\n",
      "Epoch: 1000 loss_train: 0.7258\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5122\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.0810s\n",
      "4.768370445162873e-07\n",
      "Epoch: 0000 loss_train: 2.0712\n",
      "Epoch: 0500 loss_train: 0.9140\n",
      "Epoch: 1000 loss_train: 0.7269\n",
      "Epoch: 1500 loss_train: 0.6273\n",
      "Epoch: 2000 loss_train: 0.5617\n",
      "Epoch: 2500 loss_train: 0.5129\n",
      "Epoch: 3000 loss_train: 0.4736\n",
      "Epoch: 3500 loss_train: 0.4405\n",
      "Epoch: 4000 loss_train: 0.4117\n",
      "Epoch: 4500 loss_train: 0.3863\n",
      "Epoch: 5000 loss_train: 0.3635\n",
      "Epoch: 5500 loss_train: 0.3429\n",
      " total time: 3.0343s\n",
      "0.08744961023330688\n",
      "Epoch: 0000 loss_train: 2.0708\n",
      "Epoch: 0500 loss_train: 0.9128\n",
      "Epoch: 1000 loss_train: 0.7258\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5124\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4113\n",
      "Epoch: 4500 loss_train: 0.3859\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.0989s\n",
      "0.31634092330932617\n",
      "Epoch: 0000 loss_train: 2.0706\n",
      "Epoch: 0500 loss_train: 0.9121\n",
      "Epoch: 1000 loss_train: 0.7247\n",
      "Epoch: 1500 loss_train: 0.6250\n",
      "Epoch: 2000 loss_train: 0.5595\n",
      "Epoch: 2500 loss_train: 0.5108\n",
      "Epoch: 3000 loss_train: 0.4716\n",
      "Epoch: 3500 loss_train: 0.4384\n",
      "Epoch: 4000 loss_train: 0.4096\n",
      "Epoch: 4500 loss_train: 0.3842\n",
      "Epoch: 5000 loss_train: 0.3613\n",
      "Epoch: 5500 loss_train: 0.3406\n",
      " total time: 3.0990s\n",
      "3.9263579845428467\n",
      "Epoch: 0000 loss_train: 2.0709\n",
      "Epoch: 0500 loss_train: 0.9129\n",
      "Epoch: 1000 loss_train: 0.7257\n",
      "Epoch: 1500 loss_train: 0.6262\n",
      "Epoch: 2000 loss_train: 0.5607\n",
      "Epoch: 2500 loss_train: 0.5120\n",
      "Epoch: 3000 loss_train: 0.4728\n",
      "Epoch: 3500 loss_train: 0.4396\n",
      "Epoch: 4000 loss_train: 0.4109\n",
      "Epoch: 4500 loss_train: 0.3855\n",
      "Epoch: 5000 loss_train: 0.3627\n",
      "Epoch: 5500 loss_train: 0.3421\n",
      " total time: 3.0544s\n",
      "1.2278366088867188\n",
      "Epoch: 0000 loss_train: 2.0706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0500 loss_train: 0.9129\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5609\n",
      "Epoch: 2500 loss_train: 0.5122\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.1191s\n",
      "0.017283186316490173\n",
      "Epoch: 0000 loss_train: 2.0701\n",
      "Epoch: 0500 loss_train: 0.9100\n",
      "Epoch: 1000 loss_train: 0.7233\n",
      "Epoch: 1500 loss_train: 0.6240\n",
      "Epoch: 2000 loss_train: 0.5588\n",
      "Epoch: 2500 loss_train: 0.5104\n",
      "Epoch: 3000 loss_train: 0.4715\n",
      "Epoch: 3500 loss_train: 0.4387\n",
      "Epoch: 4000 loss_train: 0.4103\n",
      "Epoch: 4500 loss_train: 0.3851\n",
      "Epoch: 5000 loss_train: 0.3626\n",
      "Epoch: 5500 loss_train: 0.3421\n",
      " total time: 3.0650s\n",
      "2.1359643936157227\n",
      "Epoch: 0000 loss_train: 2.0706\n",
      "Epoch: 0500 loss_train: 0.9127\n",
      "Epoch: 1000 loss_train: 0.7258\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3859\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.0506s\n",
      "0.032447103410959244\n",
      "Epoch: 0000 loss_train: 2.0706\n",
      "Epoch: 0500 loss_train: 0.9130\n",
      "Epoch: 1000 loss_train: 0.7260\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5611\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.0973s\n",
      "0.0020214139949530363\n",
      "Epoch: 0000 loss_train: 2.0700\n",
      "Epoch: 0500 loss_train: 0.9111\n",
      "Epoch: 1000 loss_train: 0.7238\n",
      "Epoch: 1500 loss_train: 0.6242\n",
      "Epoch: 2000 loss_train: 0.5586\n",
      "Epoch: 2500 loss_train: 0.5099\n",
      "Epoch: 3000 loss_train: 0.4707\n",
      "Epoch: 3500 loss_train: 0.4377\n",
      "Epoch: 4000 loss_train: 0.4090\n",
      "Epoch: 4500 loss_train: 0.3838\n",
      "Epoch: 5000 loss_train: 0.3612\n",
      "Epoch: 5500 loss_train: 0.3407\n",
      " total time: 3.0728s\n",
      "4.1991167068481445\n",
      "Epoch: 0000 loss_train: 2.0707\n",
      "Epoch: 0500 loss_train: 0.9130\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.1066s\n",
      "0.002110279630869627\n",
      "Epoch: 0000 loss_train: 2.0706\n",
      "Epoch: 0500 loss_train: 0.9126\n",
      "Epoch: 1000 loss_train: 0.7256\n",
      "Epoch: 1500 loss_train: 0.6262\n",
      "Epoch: 2000 loss_train: 0.5608\n",
      "Epoch: 2500 loss_train: 0.5122\n",
      "Epoch: 3000 loss_train: 0.4729\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4111\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.0604s\n",
      "0.1524074822664261\n",
      "Epoch: 0000 loss_train: 2.0700\n",
      "Epoch: 0500 loss_train: 0.9101\n",
      "Epoch: 1000 loss_train: 0.7222\n",
      "Epoch: 1500 loss_train: 0.6221\n",
      "Epoch: 2000 loss_train: 0.5563\n",
      "Epoch: 2500 loss_train: 0.5072\n",
      "Epoch: 3000 loss_train: 0.4676\n",
      "Epoch: 3500 loss_train: 0.4343\n",
      "Epoch: 4000 loss_train: 0.4053\n",
      "Epoch: 4500 loss_train: 0.3796\n",
      "Epoch: 5000 loss_train: 0.3567\n",
      "Epoch: 5500 loss_train: 0.3358\n",
      " total time: 3.0338s\n",
      "12.989012718200684\n",
      "Epoch: 0000 loss_train: 2.0704\n",
      "Epoch: 0500 loss_train: 0.9129\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 2.9743s\n",
      "9.846202738117427e-05\n",
      "Epoch: 0000 loss_train: 2.0706\n",
      "Epoch: 0500 loss_train: 0.9130\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.0394s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 2.0703\n",
      "Epoch: 0500 loss_train: 0.9129\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.0562s\n",
      "0.0014459164813160896\n",
      "Epoch: 0000 loss_train: 2.0704\n",
      "Epoch: 0500 loss_train: 0.9127\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.0347s\n",
      "0.06403027474880219\n",
      "Epoch: 0000 loss_train: 2.0701\n",
      "Epoch: 0500 loss_train: 0.9126\n",
      "Epoch: 1000 loss_train: 0.7257\n",
      "Epoch: 1500 loss_train: 0.6263\n",
      "Epoch: 2000 loss_train: 0.5609\n",
      "Epoch: 2500 loss_train: 0.5122\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.0752s\n",
      "0.0072348034009337425\n",
      "Epoch: 0000 loss_train: 2.0703\n",
      "Epoch: 0500 loss_train: 0.9125\n",
      "Epoch: 1000 loss_train: 0.7256\n",
      "Epoch: 1500 loss_train: 0.6261\n",
      "Epoch: 2000 loss_train: 0.5607\n",
      "Epoch: 2500 loss_train: 0.5119\n",
      "Epoch: 3000 loss_train: 0.4726\n",
      "Epoch: 3500 loss_train: 0.4395\n",
      "Epoch: 4000 loss_train: 0.4108\n",
      "Epoch: 4500 loss_train: 0.3853\n",
      "Epoch: 5000 loss_train: 0.3626\n",
      "Epoch: 5500 loss_train: 0.3419\n",
      " total time: 3.0794s\n",
      "0.9994780421257019\n",
      "Epoch: 0000 loss_train: 2.0703\n",
      "Epoch: 0500 loss_train: 0.9127\n",
      "Epoch: 1000 loss_train: 0.7256\n",
      "Epoch: 1500 loss_train: 0.6261\n",
      "Epoch: 2000 loss_train: 0.5606\n",
      "Epoch: 2500 loss_train: 0.5120\n",
      "Epoch: 3000 loss_train: 0.4728\n",
      "Epoch: 3500 loss_train: 0.4398\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3859\n",
      "Epoch: 5000 loss_train: 0.3632\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.0695s\n",
      "0.1408504843711853\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9127\n",
      "Epoch: 1000 loss_train: 0.7258\n",
      "Epoch: 1500 loss_train: 0.6263\n",
      "Epoch: 2000 loss_train: 0.5609\n",
      "Epoch: 2500 loss_train: 0.5122\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4398\n",
      "Epoch: 4000 loss_train: 0.4111\n",
      "Epoch: 4500 loss_train: 0.3857\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3423\n",
      " total time: 3.0912s\n",
      "0.2700946033000946\n",
      "Epoch: 0000 loss_train: 2.0706\n",
      "Epoch: 0500 loss_train: 0.9128\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3859\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.1027s\n",
      "0.02652394399046898\n",
      "Epoch: 0000 loss_train: 2.0706\n",
      "Epoch: 0500 loss_train: 0.9127\n",
      "Epoch: 1000 loss_train: 0.7258\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4113\n",
      "Epoch: 4500 loss_train: 0.3859\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.1174s\n",
      "0.0026802828069776297\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9127\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.0271s\n",
      "0.008602348156273365\n",
      "Epoch: 0000 loss_train: 2.0704\n",
      "Epoch: 0500 loss_train: 0.9127\n",
      "Epoch: 1000 loss_train: 0.7257\n",
      "Epoch: 1500 loss_train: 0.6262\n",
      "Epoch: 2000 loss_train: 0.5607\n",
      "Epoch: 2500 loss_train: 0.5119\n",
      "Epoch: 3000 loss_train: 0.4725\n",
      "Epoch: 3500 loss_train: 0.4393\n",
      "Epoch: 4000 loss_train: 0.4105\n",
      "Epoch: 4500 loss_train: 0.3849\n",
      "Epoch: 5000 loss_train: 0.3621\n",
      "Epoch: 5500 loss_train: 0.3413\n",
      " total time: 2.9859s\n",
      "2.6218369007110596\n",
      "Epoch: 0000 loss_train: 2.0706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0500 loss_train: 0.9130\n",
      "Epoch: 1000 loss_train: 0.7260\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.1856s\n",
      "6.437280717364047e-06\n",
      "Epoch: 0000 loss_train: 2.0703\n",
      "Epoch: 0500 loss_train: 0.9119\n",
      "Epoch: 1000 loss_train: 0.7248\n",
      "Epoch: 1500 loss_train: 0.6252\n",
      "Epoch: 2000 loss_train: 0.5597\n",
      "Epoch: 2500 loss_train: 0.5110\n",
      "Epoch: 3000 loss_train: 0.4717\n",
      "Epoch: 3500 loss_train: 0.4386\n",
      "Epoch: 4000 loss_train: 0.4098\n",
      "Epoch: 4500 loss_train: 0.3843\n",
      "Epoch: 5000 loss_train: 0.3615\n",
      "Epoch: 5500 loss_train: 0.3408\n",
      " total time: 3.1580s\n",
      "3.139277696609497\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9130\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.2745s\n",
      "9.500529267825186e-05\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9130\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 2.9746s\n",
      "9.53673918502318e-07\n",
      "Epoch: 0000 loss_train: 2.0703\n",
      "Epoch: 0500 loss_train: 0.9127\n",
      "Epoch: 1000 loss_train: 0.7257\n",
      "Epoch: 1500 loss_train: 0.6263\n",
      "Epoch: 2000 loss_train: 0.5609\n",
      "Epoch: 2500 loss_train: 0.5122\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.0452s\n",
      "0.13000807166099548\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9111\n",
      "Epoch: 1000 loss_train: 0.7239\n",
      "Epoch: 1500 loss_train: 0.6245\n",
      "Epoch: 2000 loss_train: 0.5593\n",
      "Epoch: 2500 loss_train: 0.5110\n",
      "Epoch: 3000 loss_train: 0.4721\n",
      "Epoch: 3500 loss_train: 0.4394\n",
      "Epoch: 4000 loss_train: 0.4109\n",
      "Epoch: 4500 loss_train: 0.3857\n",
      "Epoch: 5000 loss_train: 0.3630\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 2.8823s\n",
      "1.128614068031311\n",
      "Epoch: 0000 loss_train: 2.0707\n",
      "Epoch: 0500 loss_train: 0.9131\n",
      "Epoch: 1000 loss_train: 0.7260\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 2.9779s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9130\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 2.8733s\n",
      "1.3947389561508317e-05\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9122\n",
      "Epoch: 1000 loss_train: 0.7255\n",
      "Epoch: 1500 loss_train: 0.6262\n",
      "Epoch: 2000 loss_train: 0.5609\n",
      "Epoch: 2500 loss_train: 0.5122\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.1336s\n",
      "0.08115912973880768\n",
      "Epoch: 0000 loss_train: 2.0701\n",
      "Epoch: 0500 loss_train: 0.9117\n",
      "Epoch: 1000 loss_train: 0.7246\n",
      "Epoch: 1500 loss_train: 0.6251\n",
      "Epoch: 2000 loss_train: 0.5595\n",
      "Epoch: 2500 loss_train: 0.5107\n",
      "Epoch: 3000 loss_train: 0.4713\n",
      "Epoch: 3500 loss_train: 0.4380\n",
      "Epoch: 4000 loss_train: 0.4092\n",
      "Epoch: 4500 loss_train: 0.3837\n",
      "Epoch: 5000 loss_train: 0.3609\n",
      "Epoch: 5500 loss_train: 0.3401\n",
      " total time: 3.1000s\n",
      "4.320333003997803\n",
      "Epoch: 0000 loss_train: 2.0704\n",
      "Epoch: 0500 loss_train: 0.9120\n",
      "Epoch: 1000 loss_train: 0.7252\n",
      "Epoch: 1500 loss_train: 0.6259\n",
      "Epoch: 2000 loss_train: 0.5606\n",
      "Epoch: 2500 loss_train: 0.5120\n",
      "Epoch: 3000 loss_train: 0.4728\n",
      "Epoch: 3500 loss_train: 0.4397\n",
      "Epoch: 4000 loss_train: 0.4109\n",
      "Epoch: 4500 loss_train: 0.3856\n",
      "Epoch: 5000 loss_train: 0.3628\n",
      "Epoch: 5500 loss_train: 0.3422\n",
      " total time: 3.0897s\n",
      "0.6018033623695374\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9121\n",
      "Epoch: 1000 loss_train: 0.7249\n",
      "Epoch: 1500 loss_train: 0.6254\n",
      "Epoch: 2000 loss_train: 0.5600\n",
      "Epoch: 2500 loss_train: 0.5114\n",
      "Epoch: 3000 loss_train: 0.4723\n",
      "Epoch: 3500 loss_train: 0.4393\n",
      "Epoch: 4000 loss_train: 0.4106\n",
      "Epoch: 4500 loss_train: 0.3853\n",
      "Epoch: 5000 loss_train: 0.3625\n",
      "Epoch: 5500 loss_train: 0.3419\n",
      " total time: 3.0760s\n",
      "1.1537597179412842\n",
      "Epoch: 0000 loss_train: 2.0701\n",
      "Epoch: 0500 loss_train: 0.9125\n",
      "Epoch: 1000 loss_train: 0.7258\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.1084s\n",
      "0.00019703354337252676\n",
      "Epoch: 0000 loss_train: 2.0706\n",
      "Epoch: 0500 loss_train: 0.9129\n",
      "Epoch: 1000 loss_train: 0.7260\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3859\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 3.0996s\n",
      "0.0021020714193582535\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9130\n",
      "Epoch: 1000 loss_train: 0.7260\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.0662s\n",
      "2.264974000354414e-06\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9129\n",
      "Epoch: 1000 loss_train: 0.7260\n",
      "Epoch: 1500 loss_train: 0.6265\n",
      "Epoch: 2000 loss_train: 0.5611\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4731\n",
      "Epoch: 3500 loss_train: 0.4400\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3859\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.1171s\n",
      "2.9205850296420977e-05\n",
      "Epoch: 0000 loss_train: 2.0702\n",
      "Epoch: 0500 loss_train: 0.9130\n",
      "Epoch: 1000 loss_train: 0.7259\n",
      "Epoch: 1500 loss_train: 0.6264\n",
      "Epoch: 2000 loss_train: 0.5610\n",
      "Epoch: 2500 loss_train: 0.5123\n",
      "Epoch: 3000 loss_train: 0.4730\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3424\n",
      " total time: 3.0352s\n",
      "2.753696753643453e-05\n",
      "Epoch: 0000 loss_train: 2.0705\n",
      "Epoch: 0500 loss_train: 0.9124\n",
      "Epoch: 1000 loss_train: 0.7255\n",
      "Epoch: 1500 loss_train: 0.6261\n",
      "Epoch: 2000 loss_train: 0.5608\n",
      "Epoch: 2500 loss_train: 0.5121\n",
      "Epoch: 3000 loss_train: 0.4729\n",
      "Epoch: 3500 loss_train: 0.4399\n",
      "Epoch: 4000 loss_train: 0.4112\n",
      "Epoch: 4500 loss_train: 0.3858\n",
      "Epoch: 5000 loss_train: 0.3631\n",
      "Epoch: 5500 loss_train: 0.3425\n",
      " total time: 2.9913s\n",
      "0.12652309238910675\n",
      "Epoch: 0000 loss_train: 2.0704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputAll=torch.tensor(inputAll).cuda().float()\n",
    "labelsAll=torch.tensor(labelsAll).cuda().long()\n",
    "\n",
    "testepoch=5800\n",
    "predtest=np.zeros((inputAll.shape[0],np.unique(labels_train).size))\n",
    "for sampleIdx in range(inputAll.shape[0]):\n",
    "\n",
    "    trainIdx=np.arange(inputAll.shape[0])!=sampleIdx\n",
    "    \n",
    "    seed=3\n",
    "    torch.manual_seed(seed)\n",
    "    nclasses=np.unique(labels_train).size\n",
    "    if use_cuda:\n",
    "        torch.cuda.manual_seed(seed)\n",
    "\n",
    "    nfeatures=inputAll.shape[1]\n",
    "    if model_str=='fc3':\n",
    "        model = modelsCNN.FC_l3(nfeatures,fc_dim1,fc_dim2,fc_dim3,nclasses,0.5,regrs=False)\n",
    "        lossCE=torch.nn.CrossEntropyLoss(torch.tensor(weights_train).cuda().float())\n",
    "    if model_str=='logistic':\n",
    "        model = modelsCNN.LogisticReg(nfeatures,nclasses)\n",
    "        lossCE=torch.nn.CrossEntropyLoss(torch.tensor(weights_train).cuda().float())\n",
    "    if model_str=='fc5':\n",
    "        model = modelsCNN.FC_l5(nfeatures,fc_dim1,fc_dim2,fc_dim3,fc_dim4,fc_dim5,nclasses,0.5,regrs=False)\n",
    "        lossCE=torch.nn.CrossEntropyLoss(torch.tensor(weights_train).cuda().float())\n",
    "    if model_str=='fc1':\n",
    "        model = modelsCNN.FC_l1(nfeatures,fc_dim1,nclasses,regrs=False)\n",
    "        lossCE=torch.nn.CrossEntropyLoss(torch.tensor(weights_train).cuda().float())\n",
    "    if model_str=='fc0':\n",
    "        model = modelsCNN.FC_l0(nfeatures,nclasses,regrs=False)\n",
    "        lossCE=torch.nn.CrossEntropyLoss(torch.tensor(weights_train).cuda().float())\n",
    "\n",
    "    if use_cuda:\n",
    "        model.cuda()\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    train_loss_ep=[None]*epochs\n",
    "    val_loss_ep=[None]*epochs\n",
    "    t_ep=time.time()\n",
    "\n",
    "    for ep in range(epochs):\n",
    "        train_loss_ep[ep]=train(ep,inputAll[trainIdx],labelsAll[trainIdx])\n",
    "\n",
    "\n",
    "        if ep%saveFreq == 0 and ep!=0:\n",
    "            torch.save(model.cpu().state_dict(), os.path.join(modelsavepath,imgNamesAll[sampleIdx]+'_'+str(ep)+'.pt'))\n",
    "        if use_cuda:\n",
    "            model.cuda()\n",
    "            torch.cuda.empty_cache()\n",
    "    print(' total time: {:.4f}s'.format(time.time() - t_ep))\n",
    "\n",
    "    with open(os.path.join(logsavepath,imgNamesAll[sampleIdx]+'_train_loss'), 'wb') as output:\n",
    "        pickle.dump(train_loss_ep, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    model.load_state_dict(torch.load(os.path.join(modelsavepath,imgNamesAll[sampleIdx]+'_'+str(testepoch)+'.pt')))\n",
    "    with torch.no_grad():\n",
    "        model.cuda()\n",
    "        model.eval()\n",
    "        pred = model(inputAll[[sampleIdx]])\n",
    "        predtest[sampleIdx]=pred.cpu().detach().numpy()\n",
    "\n",
    "        loss_test=lossCE(pred,labelsAll[[sampleIdx]]).item()\n",
    "\n",
    "    print(loss_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(logsavepath,'crossVal_loss'), 'wb') as output:\n",
    "    pickle.dump(predtest, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "predtest_label=np.argmax(predtest,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=pd.DataFrame({'sampleName':imgNamesAll,'true':progUnique[labelsAll.cpu().numpy()],'predicted':progUnique[predtest_label]})\n",
    "res.to_csv(os.path.join(plotsavepath,'predictions.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progInclude=np.array(['Hyperplasia','Atypical hyperplasia','DCIS and breast tissue',  'DCIS with early infiltration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot confusion\n",
    "def plotCTcomp(labels,ctlist,savepath,savenamecluster,byCT,addname='',order=progInclude):\n",
    "    res=np.zeros((order.size,order.size))\n",
    "    for li in range(res.shape[0]):\n",
    "        l=order[li]\n",
    "        nl=np.sum(labels==l)\n",
    "        ctlist_l=ctlist[labels==l]\n",
    "        for ci in range(res.shape[1]):\n",
    "            c=order[ci]\n",
    "            res[li,ci]=np.sum(ctlist_l==c)\n",
    "#             res[li,ci]=np.sum(ctlist_l==c)/nl\n",
    "    if not byCT:\n",
    "        addname+=''\n",
    "        for li in range(res.shape[0]):\n",
    "            l=order[li]\n",
    "            nl=np.sum(labels==l)\n",
    "            res[li]=res[li]/nl\n",
    "    else:\n",
    "        addname+='_normbyCT'\n",
    "        for ci in range(res.shape[1]):\n",
    "            c=order[ci]\n",
    "            nc=np.sum(ctlist==c)\n",
    "            res[:,ci]=res[:,ci]/nc\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    im = ax.imshow(res,cmap='binary',vmin=0,vmax=1)\n",
    "    fig.colorbar(im)\n",
    "    ax.set_yticks(np.arange(order.size))\n",
    "    ax.set_yticklabels(order)\n",
    "    ax.set_xticks(np.arange(order.size))\n",
    "    ax.set_xticklabels(order)\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",rotation_mode=\"anchor\")\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(os.path.join(savepath,savenamecluster+addname+'.pdf'))\n",
    "    plt.close()\n",
    "    \n",
    "plotCTcomp(progUnique[labelsAll.cpu().numpy()],progUnique[predtest_label],plotsavepath,'confusion'+str(testepoch),False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCTcomp(progUnique[labelsAll.cpu().numpy()][:sidx_start.size],progUnique[predtest_label][:sidx_start.size],plotsavepath,'confusion_excludeValSamples'+str(testepoch),False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sampleName</th>\n",
       "      <th>true</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>br1003a_1_cytokeratin_555_aSMA_647_hoechst_I1</td>\n",
       "      <td>Breast tissue</td>\n",
       "      <td>Breast tissue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>br1003a_1_cytokeratin_555_aSMA_647_hoechst_I10</td>\n",
       "      <td>Breast tissue</td>\n",
       "      <td>Breast tissue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>br1003a_1_cytokeratin_555_aSMA_647_hoechst_I2</td>\n",
       "      <td>Breast tissue</td>\n",
       "      <td>DCIS with early infiltration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>br1003a_1_cytokeratin_555_aSMA_647_hoechst_I3</td>\n",
       "      <td>Breast tissue</td>\n",
       "      <td>Breast tissue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>br1003a_1_cytokeratin_555_aSMA_647_hoechst_I7</td>\n",
       "      <td>Breast tissue</td>\n",
       "      <td>Breast tissue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>br8018a_2_cytokeratin_555_ki67_647_hoechst_G6</td>\n",
       "      <td>Invasive ductal carcinoma</td>\n",
       "      <td>Invasive ductal carcinoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>br8018a_2_cytokeratin_555_ki67_647_hoechst_H2</td>\n",
       "      <td>Cancer adjacent normal breast tissue</td>\n",
       "      <td>Invasive ductal carcinoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>br8018a_2_cytokeratin_555_ki67_647_hoechst_H3</td>\n",
       "      <td>Cancer adjacent normal breast tissue</td>\n",
       "      <td>Cancer adjacent normal breast tissue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>br8018a_2_cytokeratin_555_ki67_647_hoechst_H4</td>\n",
       "      <td>Cancer adjacent normal breast tissue</td>\n",
       "      <td>Cancer adjacent normal breast tissue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>br8018a_2_cytokeratin_555_ki67_647_hoechst_H5</td>\n",
       "      <td>Cancer adjacent normal breast tissue</td>\n",
       "      <td>Breast tissue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>412 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         sampleName  \\\n",
       "0     br1003a_1_cytokeratin_555_aSMA_647_hoechst_I1   \n",
       "1    br1003a_1_cytokeratin_555_aSMA_647_hoechst_I10   \n",
       "2     br1003a_1_cytokeratin_555_aSMA_647_hoechst_I2   \n",
       "3     br1003a_1_cytokeratin_555_aSMA_647_hoechst_I3   \n",
       "4     br1003a_1_cytokeratin_555_aSMA_647_hoechst_I7   \n",
       "..                                              ...   \n",
       "407   br8018a_2_cytokeratin_555_ki67_647_hoechst_G6   \n",
       "408   br8018a_2_cytokeratin_555_ki67_647_hoechst_H2   \n",
       "409   br8018a_2_cytokeratin_555_ki67_647_hoechst_H3   \n",
       "410   br8018a_2_cytokeratin_555_ki67_647_hoechst_H4   \n",
       "411   br8018a_2_cytokeratin_555_ki67_647_hoechst_H5   \n",
       "\n",
       "                                     true  \\\n",
       "0                           Breast tissue   \n",
       "1                           Breast tissue   \n",
       "2                           Breast tissue   \n",
       "3                           Breast tissue   \n",
       "4                           Breast tissue   \n",
       "..                                    ...   \n",
       "407             Invasive ductal carcinoma   \n",
       "408  Cancer adjacent normal breast tissue   \n",
       "409  Cancer adjacent normal breast tissue   \n",
       "410  Cancer adjacent normal breast tissue   \n",
       "411  Cancer adjacent normal breast tissue   \n",
       "\n",
       "                                predicted  \n",
       "0                           Breast tissue  \n",
       "1                           Breast tissue  \n",
       "2            DCIS with early infiltration  \n",
       "3                           Breast tissue  \n",
       "4                           Breast tissue  \n",
       "..                                    ...  \n",
       "407             Invasive ductal carcinoma  \n",
       "408             Invasive ductal carcinoma  \n",
       "409  Cancer adjacent normal breast tissue  \n",
       "410  Cancer adjacent normal breast tissue  \n",
       "411                         Breast tissue  \n",
       "\n",
       "[412 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "import scanpy\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import models.loadImg as loadImg\n",
    "import models.modelsCNN as modelsCNN\n",
    "import models.optimizer as optimizer\n",
    "\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import gc\n",
    "from skimage import io\n",
    "import scipy.stats\n",
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0,1,2,3'\n",
    "use_cuda=True\n",
    "datadir='/media/xinyi/dcis2idc/data'\n",
    "name='exp0'\n",
    "plotsavepath='/media/xinyi/dcis2idc/plots/cnnvae'+name\n",
    "sampledir=plotsavepath\n",
    "clustersavedir_alltrain=os.path.join(sampledir,'cluster_alltrain_reordered')\n",
    "ep=311\n",
    "with open(os.path.join(datadir,'processed','train_cnnvae_names'), 'rb') as input:\n",
    "    allImgNames=pickle.load(input)\n",
    "#plot by disease progression\n",
    "br1003aSpecs=pd.read_excel('/media/xinyi/dcis2idc/data/BR1003a specs.xlsx',header=10)\n",
    "br301Specs=pd.read_excel('/media/xinyi/dcis2idc/data/BR301 specs.xlsx',header=10)\n",
    "br8018aSpecs=pd.read_excel('/media/xinyi/dcis2idc/data/BR8018a specs.xlsx',header=10)\n",
    "br1003aSpecs.index=br1003aSpecs.loc[:,'Position']\n",
    "br301Specs.index=br301Specs.loc[:,'Position']\n",
    "br8018aSpecs.index=br8018aSpecs.loc[:,'Position']\n",
    "\n",
    "progList=np.copy(allImgNames)\n",
    "for s in np.unique(allImgNames):\n",
    "    ssplit=s.split('_')\n",
    "    if 'br1003a'==ssplit[0]:\n",
    "        prog_s=br1003aSpecs.loc[(ssplit[-1],'Pathology diagnosis')]\n",
    "    elif 'br301'==ssplit[0]:\n",
    "        prog_s=br301Specs.loc[(ssplit[-1],'Pathology diagnosis')]\n",
    "    elif 'br8018a'==ssplit[0]:\n",
    "        prog_s=br8018aSpecs.loc[(ssplit[-1],'Pathology diagnosis')]\n",
    "    progList[allImgNames==s]=prog_s\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5]\n",
      "[0 1 2 3 4 5]\n",
      "[0 1 2 3 4 5]\n",
      "[0 1 2 3]\n",
      "[0 1 2 3 4 5 6 7]\n",
      "[0 1 2 3]\n",
      "[0 1 2 3 4 5]\n",
      "[0 1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "savenamesample='alltrain'\n",
    "\n",
    "neworder=[1, 5, 3, 7, 2, 0, 4, 6]\n",
    "#use chosen subcluster number and save plots\n",
    "scanpy.settings.verbosity = 3\n",
    "# subcluster=8\n",
    "subclusterDict={0:[4],1:[6],2:[8],3:[6],4:[6],5:[6],6:[6],7:[4]}\n",
    "ncluster=8\n",
    "\n",
    "plotepoch=311\n",
    "clusterplotdir=os.path.join(clustersavedir_alltrain,'plots')\n",
    "n_pcs=50\n",
    "savenamecluster='minibatchkmean_ncluster'+str(ncluster)+'n_pcs'+str(n_pcs)+'epoch'+str(plotepoch)\n",
    "with open(os.path.join(clustersavedir_alltrain,'minibatchkmean_ncluster'+str(ncluster)+'n_pcs'+str(n_pcs)+'epoch'+str(plotepoch)+'_all'), 'rb') as output:\n",
    "    clusterRes=pickle.load(output)\n",
    "\n",
    "kmeans_sub=(np.zeros(clusterRes.size)-1).astype(str)\n",
    "savenameAdd='_plottingIdx_progBalanced_'+str(0)\n",
    "subclusternumbers=[4,6,8,6,6,6,6,4]\n",
    "savenamecluster='minibatchkmean_ncluster'+str(ncluster)+'n_pcs'+str(n_pcs)+'epoch'+str(plotepoch)+savenameAdd\n",
    "for cnew in np.unique(clusterRes):\n",
    "#     print('cluster'+str(c))\n",
    "    c=neworder[cnew]\n",
    "    \n",
    "    subclustersavedir_alltrain=os.path.join(clustersavedir_alltrain,savenamecluster+'_subcluster'+str(c))\n",
    "    with open(os.path.join(subclustersavedir_alltrain,'minibatchkmean_ncluster'+str(subclusternumbers[c])+'n_pcs'+str(n_pcs)+'epoch'+str(plotepoch)+'_all'), 'rb') as output:\n",
    "        subclusterRes=pickle.load(output)\n",
    "    print(np.unique(subclusterRes))\n",
    "    kmeans_sub[clusterRes==cnew]=np.char.add(np.repeat(str(cnew)+'-',subclusterRes.size),subclusterRes.astype(str))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(datadir,'processed','train_cnnvae_coord'), 'rb') as output:\n",
    "    coordlist=pickle.load(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in np.unique(progList):\n",
    "    if p=='Ductal carcinoma in situ':\n",
    "        progList[progList==p]='DCIS and breast tissue'\n",
    "    elif p=='Ductal carcinoma in situ and breast tissue':\n",
    "        progList[progList==p]='DCIS and breast tissue'\n",
    "    elif p=='Ductal carcinoma in situ with early infiltratio':\n",
    "        progList[progList==p]='DCIS with early infiltration'\n",
    "    \n",
    "    elif p=='Micropapillary type ductal carcinoma in situ wi':\n",
    "        progList[progList==p]='DCIS with early infiltration'    \n",
    "#     elif p=='Atypical hyperlasia':\n",
    "#         progList[progList==p]='Hyperplasia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "progInclude=np.array(['DCIS and breast tissue','DCIS with early infiltration', 'Hyperplasia','Atypical hyperplasia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "progIncludeIdx=np.repeat(False,progList.size)\n",
    "for p in progInclude:\n",
    "    progIncludeIdx[progList==p]=True\n",
    "    \n",
    "coordlist=coordlist[progIncludeIdx]\n",
    "allImgNames=allImgNames[progIncludeIdx]\n",
    "clusterRes=clusterRes[progIncludeIdx]\n",
    "kmeans_sub=kmeans_sub[progIncludeIdx]\n",
    "progList=progList[progIncludeIdx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atypical hyperplasia\n",
      "14\n",
      "DCIS and breast tissue\n",
      "16\n",
      "DCIS with early infiltration\n",
      "30\n",
      "Hyperplasia\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "sUnique,sidx_start=np.unique(allImgNames,return_index=True)\n",
    "progUnique,labels_train,progCounts=np.unique(progList[sidx_start],return_counts=True,return_inverse=True)\n",
    "for p in range(progUnique.size):\n",
    "    print(progUnique[p])\n",
    "    print(progCounts[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHistMatrix_clusters(labels,ctlist,nrow=ncluster,ncol=ncluster):\n",
    "    res=np.zeros((nrow,ncol))\n",
    "    for li in range(res.shape[0]):\n",
    "        l=li\n",
    "        nl=np.sum(labels==l)\n",
    "        ctlist_l=ctlist[labels==l]\n",
    "        for ci in range(res.shape[1]):\n",
    "            c=ci\n",
    "            res[l,c]=np.sum(ctlist_l==c)\n",
    "#             res[li,ci]=np.sum(ctlist_l==c)/nl\n",
    "        if nl!=0:\n",
    "            res[li]=res[li]/nl\n",
    "    return res\n",
    "\n",
    "neighborhoodSize=16*9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get neighborhood composition\n",
    "\n",
    "inputNeighborhood=np.zeros((sUnique.size,ncluster*ncluster))\n",
    "for i in range(sUnique.size):\n",
    "    imgN=sUnique[i]\n",
    "    nsamples=np.sum(allImgNames==imgN)\n",
    "    cluster_i=clusterRes[allImgNames==imgN]\n",
    "    neighbor_i=np.tile(cluster_i,(nsamples,1))\n",
    "    self_i=np.tile(cluster_i.reshape((-1,1)),(1,nsamples))\n",
    "\n",
    "    dist=pairwise_distances(coordlist[allImgNames==imgN],n_jobs=-1)\n",
    "    distIn=np.logical_and(dist<neighborhoodSize,dist>0)\n",
    "    res=getHistMatrix_clusters(self_i[distIn],neighbor_i[distIn])\n",
    "    \n",
    "    inputNeighborhood[i]=res.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,inputCounts=np.unique(allImgNames,return_counts=True)\n",
    "inputAll_train=np.concatenate((inputNeighborhood,inputCounts.reshape(-1,1)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val cores (as validation cores) and val samples (as test cores)\n",
    "clustersavedir_valcores=os.path.join(sampledir,'cluster_valcores_reordered')\n",
    "clustersavedir_valsamples=os.path.join(sampledir,'cluster_valsamples_reordered')\n",
    "\n",
    "with open(os.path.join(datadir,'processed','train_cnnvae_coord_valcores'), 'rb') as output:\n",
    "    coordlist_valcores=pickle.load(output)\n",
    "with open(os.path.join(datadir,'processed','train_cnnvae_coord_valsamples'), 'rb') as output:\n",
    "    coordlist_valsamples=pickle.load(output)\n",
    "\n",
    "savenamecluster='minibatchkmean_ncluster'+str(ncluster)+'n_pcs'+str(n_pcs)+'epoch'+str(plotepoch)\n",
    "with open(os.path.join(clustersavedir_valcores,savenamecluster+'_all'), 'rb') as output:\n",
    "    clusterRes_valcores=pickle.load(output)\n",
    "with open(os.path.join(clustersavedir_valsamples,'minibatchkmean_ncluster'+str(ncluster)+'n_pcs'+str(n_pcs)+'epoch'+str(plotepoch)+'_all'), 'rb') as output:\n",
    "    clusterRes_valsamples=pickle.load(output)\n",
    "    \n",
    "kmeans_sub_valcores=(np.zeros(clusterRes_valcores.size)-1).astype(str)\n",
    "for c in np.unique(clusterRes_valcores):\n",
    "    subclustersavedir=os.path.join(clustersavedir_valcores,savenamecluster+'_plottingIdx_progBalanced_'+str(0)+'_subcluster'+str(neworder[c]))\n",
    "    with open(os.path.join(subclustersavedir,'minibatchkmean_ncluster'+str(subclusterDict[neworder[c]][0])+'n_pcs'+str(n_pcs)+'epoch'+str(plotepoch)+'_all'), 'rb') as output:\n",
    "        subclusterRes=pickle.load(output)\n",
    "    kmeans_sub_valcores[clusterRes_valcores==c]=np.char.add(np.repeat(str(c)+'-',subclusterRes.size),subclusterRes.astype(str))\n",
    "    \n",
    "kmeans_sub_valsamples=(np.zeros(clusterRes_valsamples.size)-1).astype(str)\n",
    "for c in np.unique(clusterRes_valsamples):\n",
    "    subclustersavedir=os.path.join(clustersavedir_valsamples,savenamecluster+'_plottingIdx_progBalanced_'+str(0)+'_subcluster'+str(neworder[c]))\n",
    "    with open(os.path.join(subclustersavedir,'minibatchkmean_ncluster'+str(subclusterDict[neworder[c]][0])+'n_pcs'+str(n_pcs)+'epoch'+str(plotepoch)+'_all'), 'rb') as output:\n",
    "        subclusterRes=pickle.load(output)\n",
    "    kmeans_sub_valsamples[clusterRes_valsamples==c]=np.char.add(np.repeat(str(c)+'-',subclusterRes.size),subclusterRes.astype(str))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(datadir,'processed','train_cnnvae_names_valcores'), 'rb') as input:\n",
    "    allImgNames_valcores=pickle.load(input)\n",
    "with open(os.path.join(datadir,'processed','train_cnnvae_names_valsamples'), 'rb') as input:\n",
    "    allImgNames_valsamples=pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot by disease progression\n",
    "br1003aSpecs=pd.read_excel('/media/xinyi/dcis2idc/data/BR1003a specs.xlsx',header=10)\n",
    "br301Specs=pd.read_excel('/media/xinyi/dcis2idc/data/BR301 specs.xlsx',header=10)\n",
    "br8018aSpecs=pd.read_excel('/media/xinyi/dcis2idc/data/BR8018a specs.xlsx',header=10)\n",
    "br1003aSpecs.index=br1003aSpecs.loc[:,'Position']\n",
    "br301Specs.index=br301Specs.loc[:,'Position']\n",
    "br8018aSpecs.index=br8018aSpecs.loc[:,'Position']\n",
    "\n",
    "progList_valcores=np.copy(allImgNames_valcores)\n",
    "for s in np.unique(allImgNames_valcores):\n",
    "    ssplit=s.split('_')\n",
    "    if 'br1003a'==ssplit[0]:\n",
    "        prog_s=br1003aSpecs.loc[(ssplit[-1],'Pathology diagnosis')]\n",
    "    elif 'br301'==ssplit[0]:\n",
    "        prog_s=br301Specs.loc[(ssplit[-1],'Pathology diagnosis')]\n",
    "    elif 'br8018a'==ssplit[0]:\n",
    "        prog_s=br8018aSpecs.loc[(ssplit[-1],'Pathology diagnosis')]\n",
    "    progList_valcores[allImgNames_valcores==s]=prog_s\n",
    "    \n",
    "progList_valsamples=np.copy(allImgNames_valsamples)\n",
    "for s in np.unique(allImgNames_valsamples):\n",
    "    ssplit=s.split('_')\n",
    "    if 'br1003a'==ssplit[0]:\n",
    "        prog_s=br1003aSpecs.loc[(ssplit[-1],'Pathology diagnosis')]\n",
    "    elif 'br301'==ssplit[0]:\n",
    "        prog_s=br301Specs.loc[(ssplit[-1],'Pathology diagnosis')]\n",
    "    elif 'br8018a'==ssplit[0]:\n",
    "        prog_s=br8018aSpecs.loc[(ssplit[-1],'Pathology diagnosis')]\n",
    "    progList_valsamples[allImgNames_valsamples==s]=prog_s\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in np.unique(progList_valcores):\n",
    "    if p=='Ductal carcinoma in situ':\n",
    "        progList_valcores[progList_valcores==p]='DCIS and breast tissue'\n",
    "    elif p=='Ductal carcinoma in situ and breast tissue':\n",
    "        progList_valcores[progList_valcores==p]='DCIS and breast tissue'\n",
    "    elif p=='Ductal carcinoma in situ with early infiltratio':\n",
    "        progList_valcores[progList_valcores==p]='DCIS with early infiltration'\n",
    "    \n",
    "    elif p=='Micropapillary type ductal carcinoma in situ wi':\n",
    "        progList_valcores[progList_valcores==p]='DCIS with early infiltration'    \n",
    "#     elif p=='Atypical hyperlasia':\n",
    "#         progList_valcores[progList_valcores==p]='Hyperplasia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in np.unique(progList_valsamples):\n",
    "    if p=='Ductal carcinoma in situ':\n",
    "        progList_valsamples[progList_valsamples==p]='DCIS and breast tissue'\n",
    "    elif p=='Ductal carcinoma in situ and breast tissue':\n",
    "        progList_valsamples[progList_valsamples==p]='DCIS and breast tissue'\n",
    "    elif p=='Ductal carcinoma in situ with early infiltrati':\n",
    "        progList_valsamples[progList_valsamples==p]='DCIS with early infiltration'\n",
    "    \n",
    "    elif p=='Micropapillary type ductal carcinoma in situ w':\n",
    "        progList_valsamples[progList_valsamples==p]='DCIS with early infiltration'    \n",
    "#     elif p=='Atypical hyperlasia':\n",
    "#         progList_valsamples[progList_valsamples==p]='Hyperplasia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "progIncludeIdx_valcores=np.repeat(False,progList_valcores.size)\n",
    "for p in progInclude:\n",
    "    progIncludeIdx_valcores[progList_valcores==p]=True\n",
    "    \n",
    "progIncludeIdx_valsamples=np.repeat(False,progList_valsamples.size)\n",
    "for p in progInclude:\n",
    "    progIncludeIdx_valsamples[progList_valsamples==p]=True\n",
    "    \n",
    "coordlist_valcores=coordlist_valcores[progIncludeIdx_valcores]\n",
    "allImgNames_valcores=allImgNames_valcores[progIncludeIdx_valcores]\n",
    "clusterRes_valcores=clusterRes_valcores[progIncludeIdx_valcores]\n",
    "kmeans_sub_valcores=kmeans_sub_valcores[progIncludeIdx_valcores]\n",
    "progList_valcores=progList_valcores[progIncludeIdx_valcores]\n",
    "\n",
    "coordlist_valsamples=coordlist_valsamples[progIncludeIdx_valsamples]\n",
    "allImgNames_valsamples=allImgNames_valsamples[progIncludeIdx_valsamples]\n",
    "clusterRes_valsamples=clusterRes_valsamples[progIncludeIdx_valsamples]\n",
    "kmeans_sub_valsamples=kmeans_sub_valsamples[progIncludeIdx_valsamples]\n",
    "progList_valsamples=progList_valsamples[progIncludeIdx_valsamples]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atypical hyperplasia\n",
      "15\n",
      "Hyperplasia\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "sUnique_valcores,sidx_start_valcores=np.unique(allImgNames_valcores,return_index=True)\n",
    "progUnique_valcores,progCounts_valcores=np.unique(progList_valcores[sidx_start_valcores],return_counts=True)\n",
    "for p in range(progUnique_valcores.size):\n",
    "    print(progUnique_valcores[p])\n",
    "    print(progCounts_valcores[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atypical hyperplasia\n",
      "10\n",
      "DCIS and breast tissue\n",
      "16\n",
      "DCIS with early infiltration\n",
      "29\n",
      "Hyperplasia\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "sUnique_valsamples,sidx_start_valsamples=np.unique(allImgNames_valsamples,return_index=True)\n",
    "progUnique_valsamples,progCounts_valsamples=np.unique(progList_valsamples[sidx_start_valsamples],return_counts=True)\n",
    "for p in range(progUnique_valsamples.size):\n",
    "    print(progUnique_valsamples[p])\n",
    "    print(progCounts_valsamples[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct labels\n",
    "labels_valcores=np.zeros(progList_valcores[sidx_start_valcores].size)\n",
    "for i in range(progUnique.size):\n",
    "    labels_valcores[progList_valcores[sidx_start_valcores]==progUnique[i]]=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct labels\n",
    "labels_valsamples=np.zeros(progList_valsamples[sidx_start_valsamples].size)\n",
    "for i in range(progUnique.size):\n",
    "    labels_valsamples[progList_valsamples[sidx_start_valsamples]==progUnique[i]]=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputNeighborhood_valcores=np.zeros((sUnique_valcores.size,ncluster*ncluster))\n",
    "for i in range(sUnique_valcores.size):\n",
    "    imgN=sUnique_valcores[i]\n",
    "    nsamples=np.sum(allImgNames_valcores==imgN)\n",
    "    cluster_i=clusterRes_valcores[allImgNames_valcores==imgN]\n",
    "    neighbor_i=np.tile(cluster_i,(nsamples,1))\n",
    "    self_i=np.tile(cluster_i.reshape((-1,1)),(1,nsamples))\n",
    "\n",
    "    dist=pairwise_distances(coordlist_valcores[allImgNames_valcores==imgN],n_jobs=-1)\n",
    "    distIn=np.logical_and(dist<neighborhoodSize,dist>0)\n",
    "    res=getHistMatrix_clusters(self_i[distIn],neighbor_i[distIn])\n",
    "    \n",
    "    inputNeighborhood_valcores[i]=res.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputNeighborhood_valsamples=np.zeros((sUnique_valsamples.size,ncluster*ncluster))\n",
    "for i in range(sUnique_valsamples.size):\n",
    "    imgN=sUnique_valsamples[i]\n",
    "    nsamples=np.sum(allImgNames_valsamples==imgN)\n",
    "    cluster_i=clusterRes_valsamples[allImgNames_valsamples==imgN]\n",
    "    neighbor_i=np.tile(cluster_i,(nsamples,1))\n",
    "    self_i=np.tile(cluster_i.reshape((-1,1)),(1,nsamples))\n",
    "\n",
    "    dist=pairwise_distances(coordlist_valsamples[allImgNames_valsamples==imgN],n_jobs=-1)\n",
    "    distIn=np.logical_and(dist<neighborhoodSize,dist>0)\n",
    "    res=getHistMatrix_clusters(self_i[distIn],neighbor_i[distIn])\n",
    "    \n",
    "    inputNeighborhood_valsamples[i]=res.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,inputCounts_valcores=np.unique(allImgNames_valcores,return_counts=True)\n",
    "inputAll_valcores=np.concatenate((inputNeighborhood_valcores,inputCounts_valcores.reshape(-1,1)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,inputCounts_valsamples=np.unique(allImgNames_valsamples,return_counts=True)\n",
    "inputAll_valsamples=np.concatenate((inputNeighborhood_valsamples,inputCounts_valsamples.reshape(-1,1)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate cores\n",
    "inputAll=np.concatenate((inputAll_train,np.concatenate((inputAll_valcores,inputAll_valsamples),axis=0)),axis=0)\n",
    "imgNamesAll=np.concatenate((allImgNames[sidx_start],np.concatenate((allImgNames_valcores[sidx_start_valcores],allImgNames_valsamples[sidx_start_valsamples]))))\n",
    "labelsAll=np.concatenate((labels_train,np.concatenate((labels_valcores,labels_valsamples))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,progCountsAll=np.unique(labelsAll,return_counts=True)\n",
    "weights_train=np.sum(progCountsAll)/progCountsAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img sizes\n",
    "allImgNamesAll=np.concatenate((allImgNames,np.concatenate((allImgNames_valcores,allImgNames_valsamples))))\n",
    "progListAll=np.concatenate((progList,np.concatenate((progList_valcores,progList_valsamples))))\n",
    "sidxAll=np.concatenate((sidx_start,np.concatenate((sidx_start_valcores,sidx_start_valsamples))))\n",
    "coordlistAll=np.concatenate((coordlist,np.concatenate((coordlist_valcores,coordlist_valsamples),axis=0)),axis=0)\n",
    "\n",
    "imgSizeAll={}\n",
    "for p in progUnique:\n",
    "    img_cores=allImgNamesAll[sidxAll[progListAll[sidxAll]==p]]\n",
    "    pSizes=np.zeros((img_cores.size))\n",
    "    for si in range(img_cores.size):\n",
    "        scoord=coordlistAll[allImgNamesAll==img_cores[si]]\n",
    "        hsize=np.pi*np.square(np.max(scoord[:,0])-np.min(scoord[:,0]))\n",
    "        vsize=np.pi*np.square(np.max(scoord[:,1])-np.min(scoord[:,1]))\n",
    "        pSizes[si]=min(hsize,vsize)\n",
    "    imgSizeAll[p]=pSizes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x7f9bc7d76910>,\n",
       "  <matplotlib.axis.XTick at 0x7f9bc7d76c40>,\n",
       "  <matplotlib.axis.XTick at 0x7f9bc4c7d580>,\n",
       "  <matplotlib.axis.XTick at 0x7f9bc4bd7eb0>,\n",
       "  <matplotlib.axis.XTick at 0x7f9bc4bf0f40>,\n",
       "  <matplotlib.axis.XTick at 0x7f9bc4bf09d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f9bc4d2dfd0>,\n",
       "  <matplotlib.axis.XTick at 0x7f9bc4d2d0d0>],\n",
       " [Text(1, 0, 'Atypical hyperplasia'),\n",
       "  Text(2, 0, 'Breast tissue'),\n",
       "  Text(3, 0, 'Cancer adjacent normal breast tissue'),\n",
       "  Text(4, 0, 'DCIS and breast tissue'),\n",
       "  Text(5, 0, 'DCIS with early infiltration'),\n",
       "  Text(6, 0, 'Hyperplasia'),\n",
       "  Text(7, 0, 'Invasive ductal carcinoma'),\n",
       "  Text(8, 0, 'Invasive ductal carcinoma and breast tissue')])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imgSize_median={}\n",
    "for p in progUnique:\n",
    "    imgSize_median[p]=np.median(imgSizeAll[p])\n",
    "plt.violinplot(list(imgSizeAll.values()))\n",
    "plt.scatter(np.arange(progUnique.size)+1,list(imgSize_median.values()))\n",
    "plt.xticks(np.arange(progUnique.size)+1,list(imgSizeAll),rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(datadir,'processed','imgSizeByPath'), 'wb') as output:\n",
    "    pickle.dump(imgSize_median,output,pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(datadir,'processed','imgSizeByPath'), 'rb') as output:\n",
    "    imgSize_median=pickle.load(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize count\n",
    "with open(os.path.join(datadir,'processed','imgSizeByPath'), 'rb') as output:\n",
    "    imgSize_median=pickle.load(output)\n",
    "areaAll=np.zeros(labelsAll.size)\n",
    "for s in range(labelsAll.size):\n",
    "    areaAll[s]=imgSize_median[progUnique[labelsAll.astype(int)][s]]\n",
    "inputAll[:,-1]=inputAll[:,-1]/areaAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=3\n",
    "epochs=6000\n",
    "saveFreq=200\n",
    "lr=0.001 #initial learning rate\n",
    "weight_decay=0 \n",
    "\n",
    "# batchsize=4\n",
    "batchsize=6000\n",
    "model_str='fc3'\n",
    "\n",
    "fc_dim1=64\n",
    "fc_dim2=64\n",
    "fc_dim3=64\n",
    "\n",
    "\n",
    "dropout=0.01\n",
    "\n",
    "name='exp0_pathologyClf_neighbor_clusters_exp0_subset_neighborOnly_crossVal_countAreaNorm_DCIS_AH_H'\n",
    "logsavepath='/media/xinyi/dcis2idc/log/cnnvae'+name\n",
    "modelsavepath='/media/xinyi/dcis2idc/models/cnnvae'+name\n",
    "plotsavepath='/media/xinyi/dcis2idc/plots/cnnvae'+name\n",
    "\n",
    "\n",
    "if not os.path.exists(logsavepath):\n",
    "    os.mkdir(logsavepath)\n",
    "if not os.path.exists(modelsavepath):\n",
    "    os.mkdir(modelsavepath)\n",
    "if not os.path.exists(plotsavepath):\n",
    "    os.mkdir(plotsavepath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputAll=scipy.stats.zscore(inputAll,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch,trainInput,labels_train):\n",
    "    t = time.time()\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    pred = model(trainInput)\n",
    "\n",
    "    loss=lossCE(pred,labels_train)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch%500==0:\n",
    "        print('Epoch: {:04d}'.format(epoch),\n",
    "              'loss_train: {:.4f}'.format(loss))\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0000 loss_train: 1.3864\n",
      "Epoch: 0500 loss_train: 0.1225\n",
      "Epoch: 1000 loss_train: 0.0898\n",
      "Epoch: 1500 loss_train: 0.0178\n",
      "Epoch: 2000 loss_train: 0.0043\n",
      "Epoch: 2500 loss_train: 0.0053\n",
      "Epoch: 3000 loss_train: 0.0199\n",
      "Epoch: 3500 loss_train: 0.0044\n",
      "Epoch: 4000 loss_train: 0.0089\n",
      "Epoch: 4500 loss_train: 0.0489\n",
      "Epoch: 5000 loss_train: 0.0034\n",
      "Epoch: 5500 loss_train: 0.0141\n",
      " total time: 7.7013s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3864\n",
      "Epoch: 0500 loss_train: 0.1258\n",
      "Epoch: 1000 loss_train: 0.1043\n",
      "Epoch: 1500 loss_train: 0.0863\n",
      "Epoch: 2000 loss_train: 0.0070\n",
      "Epoch: 2500 loss_train: 0.0039\n",
      "Epoch: 3000 loss_train: 0.0144\n",
      "Epoch: 3500 loss_train: 0.0032\n",
      "Epoch: 4000 loss_train: 0.0114\n",
      "Epoch: 4500 loss_train: 0.0237\n",
      "Epoch: 5000 loss_train: 0.0035\n",
      "Epoch: 5500 loss_train: 0.0091\n",
      " total time: 7.7724s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3864\n",
      "Epoch: 0500 loss_train: 0.1165\n",
      "Epoch: 1000 loss_train: 0.0986\n",
      "Epoch: 1500 loss_train: 0.0687\n",
      "Epoch: 2000 loss_train: 0.0067\n",
      "Epoch: 2500 loss_train: 0.0073\n",
      "Epoch: 3000 loss_train: 0.0180\n",
      "Epoch: 3500 loss_train: 0.0037\n",
      "Epoch: 4000 loss_train: 0.0089\n",
      "Epoch: 4500 loss_train: 0.0456\n",
      "Epoch: 5000 loss_train: 0.0009\n",
      "Epoch: 5500 loss_train: 0.0059\n",
      " total time: 7.7667s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3864\n",
      "Epoch: 0500 loss_train: 0.1147\n",
      "Epoch: 1000 loss_train: 0.0877\n",
      "Epoch: 1500 loss_train: 0.0340\n",
      "Epoch: 2000 loss_train: 0.0101\n",
      "Epoch: 2500 loss_train: 0.0039\n",
      "Epoch: 3000 loss_train: 0.0294\n",
      "Epoch: 3500 loss_train: 0.0047\n",
      "Epoch: 4000 loss_train: 0.0219\n",
      "Epoch: 4500 loss_train: 0.0155\n",
      "Epoch: 5000 loss_train: 0.0010\n",
      "Epoch: 5500 loss_train: 0.0281\n",
      " total time: 7.7550s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3865\n",
      "Epoch: 0500 loss_train: 0.1113\n",
      "Epoch: 1000 loss_train: 0.0839\n",
      "Epoch: 1500 loss_train: 0.0328\n",
      "Epoch: 2000 loss_train: 0.0083\n",
      "Epoch: 2500 loss_train: 0.0075\n",
      "Epoch: 3000 loss_train: 0.0259\n",
      "Epoch: 3500 loss_train: 0.0041\n",
      "Epoch: 4000 loss_train: 0.0073\n",
      "Epoch: 4500 loss_train: 0.0029\n",
      "Epoch: 5000 loss_train: 0.0102\n",
      "Epoch: 5500 loss_train: 0.0121\n",
      " total time: 7.7640s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3866\n",
      "Epoch: 0500 loss_train: 0.1106\n",
      "Epoch: 1000 loss_train: 0.1057\n",
      "Epoch: 1500 loss_train: 0.0392\n",
      "Epoch: 2000 loss_train: 0.0054\n",
      "Epoch: 2500 loss_train: 0.0120\n",
      "Epoch: 3000 loss_train: 0.0140\n",
      "Epoch: 3500 loss_train: 0.0059\n",
      "Epoch: 4000 loss_train: 0.0237\n",
      "Epoch: 4500 loss_train: 0.0321\n",
      "Epoch: 5000 loss_train: 0.0297\n",
      "Epoch: 5500 loss_train: 0.0072\n",
      " total time: 7.7597s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3866\n",
      "Epoch: 0500 loss_train: 0.1149\n",
      "Epoch: 1000 loss_train: 0.0824\n",
      "Epoch: 1500 loss_train: 0.0273\n",
      "Epoch: 2000 loss_train: 0.0100\n",
      "Epoch: 2500 loss_train: 0.0071\n",
      "Epoch: 3000 loss_train: 0.0146\n",
      "Epoch: 3500 loss_train: 0.0053\n",
      "Epoch: 4000 loss_train: 0.0329\n",
      "Epoch: 4500 loss_train: 0.0042\n",
      "Epoch: 5000 loss_train: 0.0078\n",
      "Epoch: 5500 loss_train: 0.0199\n",
      " total time: 7.7784s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3865\n",
      "Epoch: 0500 loss_train: 0.1090\n",
      "Epoch: 1000 loss_train: 0.1102\n",
      "Epoch: 1500 loss_train: 0.0302\n",
      "Epoch: 2000 loss_train: 0.0054\n",
      "Epoch: 2500 loss_train: 0.0096\n",
      "Epoch: 3000 loss_train: 0.0223\n",
      "Epoch: 3500 loss_train: 0.0079\n",
      "Epoch: 4000 loss_train: 0.0109\n",
      "Epoch: 4500 loss_train: 0.0112\n",
      "Epoch: 5000 loss_train: 0.0040\n",
      "Epoch: 5500 loss_train: 0.0134\n",
      " total time: 7.7683s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3856\n",
      "Epoch: 0500 loss_train: 0.1062\n",
      "Epoch: 1000 loss_train: 0.0710\n",
      "Epoch: 1500 loss_train: 0.0316\n",
      "Epoch: 2000 loss_train: 0.0086\n",
      "Epoch: 2500 loss_train: 0.0058\n",
      "Epoch: 3000 loss_train: 0.0114\n",
      "Epoch: 3500 loss_train: 0.0056\n",
      "Epoch: 4000 loss_train: 0.0202\n",
      "Epoch: 4500 loss_train: 0.0231\n",
      "Epoch: 5000 loss_train: 0.0051\n",
      "Epoch: 5500 loss_train: 0.0242\n",
      " total time: 7.7620s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3864\n",
      "Epoch: 0500 loss_train: 0.1155\n",
      "Epoch: 1000 loss_train: 0.0887\n",
      "Epoch: 1500 loss_train: 0.0549\n",
      "Epoch: 2000 loss_train: 0.0083\n",
      "Epoch: 2500 loss_train: 0.0033\n",
      "Epoch: 3000 loss_train: 0.0147\n",
      "Epoch: 3500 loss_train: 0.0064\n",
      "Epoch: 4000 loss_train: 0.0180\n",
      "Epoch: 4500 loss_train: 0.0025\n",
      "Epoch: 5000 loss_train: 0.0022\n",
      "Epoch: 5500 loss_train: 0.0063\n",
      " total time: 7.7505s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3865\n",
      "Epoch: 0500 loss_train: 0.1091\n",
      "Epoch: 1000 loss_train: 0.0794\n",
      "Epoch: 1500 loss_train: 0.0569\n",
      "Epoch: 2000 loss_train: 0.0088\n",
      "Epoch: 2500 loss_train: 0.0050\n",
      "Epoch: 3000 loss_train: 0.0264\n",
      "Epoch: 3500 loss_train: 0.0054\n",
      "Epoch: 4000 loss_train: 0.0145\n",
      "Epoch: 4500 loss_train: 0.0029\n",
      "Epoch: 5000 loss_train: 0.0084\n",
      "Epoch: 5500 loss_train: 0.0256\n",
      " total time: 7.7464s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3868\n",
      "Epoch: 0500 loss_train: 0.1040\n",
      "Epoch: 1000 loss_train: 0.0702\n",
      "Epoch: 1500 loss_train: 0.0616\n",
      "Epoch: 2000 loss_train: 0.0070\n",
      "Epoch: 2500 loss_train: 0.0057\n",
      "Epoch: 3000 loss_train: 0.0153\n",
      "Epoch: 3500 loss_train: 0.0056\n",
      "Epoch: 4000 loss_train: 0.0227\n",
      "Epoch: 4500 loss_train: 0.0471\n",
      "Epoch: 5000 loss_train: 0.0084\n",
      "Epoch: 5500 loss_train: 0.0093\n",
      " total time: 7.7480s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3867\n",
      "Epoch: 0500 loss_train: 0.1259\n",
      "Epoch: 1000 loss_train: 0.1139\n",
      "Epoch: 1500 loss_train: 0.0636\n",
      "Epoch: 2000 loss_train: 0.0097\n",
      "Epoch: 2500 loss_train: 0.0068\n",
      "Epoch: 3000 loss_train: 0.0134\n",
      "Epoch: 3500 loss_train: 0.0051\n",
      "Epoch: 4000 loss_train: 0.0153\n",
      "Epoch: 4500 loss_train: 0.0277\n",
      "Epoch: 5000 loss_train: 0.0015\n",
      "Epoch: 5500 loss_train: 0.0079\n",
      " total time: 7.7655s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3869\n",
      "Epoch: 0500 loss_train: 0.0995\n",
      "Epoch: 1000 loss_train: 0.0692\n",
      "Epoch: 1500 loss_train: 0.0457\n",
      "Epoch: 2000 loss_train: 0.0072\n",
      "Epoch: 2500 loss_train: 0.0172\n",
      "Epoch: 3000 loss_train: 0.0137\n",
      "Epoch: 3500 loss_train: 0.0042\n",
      "Epoch: 4000 loss_train: 0.0078\n",
      "Epoch: 4500 loss_train: 0.0267\n",
      "Epoch: 5000 loss_train: 0.0104\n",
      "Epoch: 5500 loss_train: 0.0287\n",
      " total time: 7.7790s\n",
      "4.768370445162873e-07\n",
      "Epoch: 0000 loss_train: 1.3864\n",
      "Epoch: 0500 loss_train: 0.1063\n",
      "Epoch: 1000 loss_train: 0.1036\n",
      "Epoch: 1500 loss_train: 0.0310\n",
      "Epoch: 2000 loss_train: 0.0132\n",
      "Epoch: 2500 loss_train: 0.0161\n",
      "Epoch: 3000 loss_train: 0.0145\n",
      "Epoch: 3500 loss_train: 0.0059\n",
      "Epoch: 4000 loss_train: 0.0282\n",
      "Epoch: 4500 loss_train: 0.0189\n",
      "Epoch: 5000 loss_train: 0.0039\n",
      "Epoch: 5500 loss_train: 0.0179\n",
      " total time: 7.7924s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3874\n",
      "Epoch: 0500 loss_train: 0.1205\n",
      "Epoch: 1000 loss_train: 0.1348\n",
      "Epoch: 1500 loss_train: 0.0272\n",
      "Epoch: 2000 loss_train: 0.0062\n",
      "Epoch: 2500 loss_train: 0.0084\n",
      "Epoch: 3000 loss_train: 0.0162\n",
      "Epoch: 3500 loss_train: 0.0025\n",
      "Epoch: 4000 loss_train: 0.0146\n",
      "Epoch: 4500 loss_train: 0.0014\n",
      "Epoch: 5000 loss_train: 0.0064\n",
      "Epoch: 5500 loss_train: 0.0072\n",
      " total time: 7.7529s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3874\n",
      "Epoch: 0500 loss_train: 0.1167\n",
      "Epoch: 1000 loss_train: 0.1381\n",
      "Epoch: 1500 loss_train: 0.0406\n",
      "Epoch: 2000 loss_train: 0.0085\n",
      "Epoch: 2500 loss_train: 0.0065\n",
      "Epoch: 3000 loss_train: 0.0234\n",
      "Epoch: 3500 loss_train: 0.0013\n",
      "Epoch: 4000 loss_train: 0.0162\n",
      "Epoch: 4500 loss_train: 0.0017\n",
      "Epoch: 5000 loss_train: 0.0051\n",
      "Epoch: 5500 loss_train: 0.0272\n",
      " total time: 7.7603s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3874\n",
      "Epoch: 0500 loss_train: 0.1180\n",
      "Epoch: 1000 loss_train: 0.1143\n",
      "Epoch: 1500 loss_train: 0.0293\n",
      "Epoch: 2000 loss_train: 0.0118\n",
      "Epoch: 2500 loss_train: 0.0032\n",
      "Epoch: 3000 loss_train: 0.0235\n",
      "Epoch: 3500 loss_train: 0.0030\n",
      "Epoch: 4000 loss_train: 0.0049\n",
      "Epoch: 4500 loss_train: 0.0055\n",
      "Epoch: 5000 loss_train: 0.0016\n",
      "Epoch: 5500 loss_train: 0.0242\n",
      " total time: 7.7868s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3874\n",
      "Epoch: 0500 loss_train: 0.1143\n",
      "Epoch: 1000 loss_train: 0.1177\n",
      "Epoch: 1500 loss_train: 0.0359\n",
      "Epoch: 2000 loss_train: 0.0110\n",
      "Epoch: 2500 loss_train: 0.0074\n",
      "Epoch: 3000 loss_train: 0.0243\n",
      "Epoch: 3500 loss_train: 0.0031\n",
      "Epoch: 4000 loss_train: 0.0119\n",
      "Epoch: 4500 loss_train: 0.0209\n",
      "Epoch: 5000 loss_train: 0.0208\n",
      "Epoch: 5500 loss_train: 0.0039\n",
      " total time: 7.7461s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3874\n",
      "Epoch: 0500 loss_train: 0.1164\n",
      "Epoch: 1000 loss_train: 0.1152\n",
      "Epoch: 1500 loss_train: 0.0632\n",
      "Epoch: 2000 loss_train: 0.0082\n",
      "Epoch: 2500 loss_train: 0.0111\n",
      "Epoch: 3000 loss_train: 0.0403\n",
      "Epoch: 3500 loss_train: 0.0037\n",
      "Epoch: 4000 loss_train: 0.0107\n",
      "Epoch: 4500 loss_train: 0.0016\n",
      "Epoch: 5000 loss_train: 0.0037\n",
      "Epoch: 5500 loss_train: 0.0061\n",
      " total time: 7.7976s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3874\n",
      "Epoch: 0500 loss_train: 0.1184\n",
      "Epoch: 1000 loss_train: 0.1034\n",
      "Epoch: 1500 loss_train: 0.0362\n",
      "Epoch: 2000 loss_train: 0.0098\n",
      "Epoch: 2500 loss_train: 0.0059\n",
      "Epoch: 3000 loss_train: 0.0153\n",
      "Epoch: 3500 loss_train: 0.0033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4000 loss_train: 0.0110\n",
      "Epoch: 4500 loss_train: 0.0081\n",
      "Epoch: 5000 loss_train: 0.0060\n",
      "Epoch: 5500 loss_train: 0.0066\n",
      " total time: 7.7800s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3875\n",
      "Epoch: 0500 loss_train: 0.1087\n",
      "Epoch: 1000 loss_train: 0.1045\n",
      "Epoch: 1500 loss_train: 0.0350\n",
      "Epoch: 2000 loss_train: 0.0074\n",
      "Epoch: 2500 loss_train: 0.0071\n",
      "Epoch: 3000 loss_train: 0.0208\n",
      "Epoch: 3500 loss_train: 0.0038\n",
      "Epoch: 4000 loss_train: 0.0122\n",
      "Epoch: 4500 loss_train: 0.0022\n",
      "Epoch: 5000 loss_train: 0.0026\n",
      "Epoch: 5500 loss_train: 0.0040\n",
      " total time: 7.7954s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3874\n",
      "Epoch: 0500 loss_train: 0.1125\n",
      "Epoch: 1000 loss_train: 0.1243\n",
      "Epoch: 1500 loss_train: 0.0364\n",
      "Epoch: 2000 loss_train: 0.0073\n",
      "Epoch: 2500 loss_train: 0.0050\n",
      "Epoch: 3000 loss_train: 0.0134\n",
      "Epoch: 3500 loss_train: 0.0025\n",
      "Epoch: 4000 loss_train: 0.0156\n",
      "Epoch: 4500 loss_train: 0.0069\n",
      "Epoch: 5000 loss_train: 0.0022\n",
      "Epoch: 5500 loss_train: 0.0276\n",
      " total time: 7.8090s\n",
      "0.3532223403453827\n",
      "Epoch: 0000 loss_train: 1.3872\n",
      "Epoch: 0500 loss_train: 0.1135\n",
      "Epoch: 1000 loss_train: 0.0791\n",
      "Epoch: 1500 loss_train: 0.0493\n",
      "Epoch: 2000 loss_train: 0.0150\n",
      "Epoch: 2500 loss_train: 0.0065\n",
      "Epoch: 3000 loss_train: 0.0159\n",
      "Epoch: 3500 loss_train: 0.0066\n",
      "Epoch: 4000 loss_train: 0.0113\n",
      "Epoch: 4500 loss_train: 0.0034\n",
      "Epoch: 5000 loss_train: 0.0279\n",
      "Epoch: 5500 loss_train: 0.0195\n",
      " total time: 7.7282s\n",
      "0.5747236609458923\n",
      "Epoch: 0000 loss_train: 1.3871\n",
      "Epoch: 0500 loss_train: 0.1188\n",
      "Epoch: 1000 loss_train: 0.0869\n",
      "Epoch: 1500 loss_train: 0.0276\n",
      "Epoch: 2000 loss_train: 0.0066\n",
      "Epoch: 2500 loss_train: 0.0054\n",
      "Epoch: 3000 loss_train: 0.0193\n",
      "Epoch: 3500 loss_train: 0.0030\n",
      "Epoch: 4000 loss_train: 0.0189\n",
      "Epoch: 4500 loss_train: 0.0018\n",
      "Epoch: 5000 loss_train: 0.0065\n",
      "Epoch: 5500 loss_train: 0.0119\n",
      " total time: 7.5346s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3870\n",
      "Epoch: 0500 loss_train: 0.1159\n",
      "Epoch: 1000 loss_train: 0.1017\n",
      "Epoch: 1500 loss_train: 0.0346\n",
      "Epoch: 2000 loss_train: 0.0082\n",
      "Epoch: 2500 loss_train: 0.0076\n",
      "Epoch: 3000 loss_train: 0.0272\n",
      "Epoch: 3500 loss_train: 0.0021\n",
      "Epoch: 4000 loss_train: 0.0134\n",
      "Epoch: 4500 loss_train: 0.0185\n",
      "Epoch: 5000 loss_train: 0.0061\n",
      "Epoch: 5500 loss_train: 0.0232\n",
      " total time: 7.5409s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3862\n",
      "Epoch: 0500 loss_train: 0.0995\n",
      "Epoch: 1000 loss_train: 0.0738\n",
      "Epoch: 1500 loss_train: 0.0323\n",
      "Epoch: 2000 loss_train: 0.0041\n",
      "Epoch: 2500 loss_train: 0.0043\n",
      "Epoch: 3000 loss_train: 0.0264\n",
      "Epoch: 3500 loss_train: 0.0067\n",
      "Epoch: 4000 loss_train: 0.0204\n",
      "Epoch: 4500 loss_train: 0.0051\n",
      "Epoch: 5000 loss_train: 0.0032\n",
      "Epoch: 5500 loss_train: 0.0106\n",
      " total time: 7.5415s\n",
      "10.664131164550781\n",
      "Epoch: 0000 loss_train: 1.3874\n",
      "Epoch: 0500 loss_train: 0.1281\n",
      "Epoch: 1000 loss_train: 0.1090\n",
      "Epoch: 1500 loss_train: 0.0530\n",
      "Epoch: 2000 loss_train: 0.0084\n",
      "Epoch: 2500 loss_train: 0.0052\n",
      "Epoch: 3000 loss_train: 0.0252\n",
      "Epoch: 3500 loss_train: 0.0040\n",
      "Epoch: 4000 loss_train: 0.0126\n",
      "Epoch: 4500 loss_train: 0.0326\n",
      "Epoch: 5000 loss_train: 0.0033\n",
      "Epoch: 5500 loss_train: 0.0053\n",
      " total time: 7.2700s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3874\n",
      "Epoch: 0500 loss_train: 0.1219\n",
      "Epoch: 1000 loss_train: 0.1043\n",
      "Epoch: 1500 loss_train: 0.0480\n",
      "Epoch: 2000 loss_train: 0.0126\n",
      "Epoch: 2500 loss_train: 0.0070\n",
      "Epoch: 3000 loss_train: 0.0165\n",
      "Epoch: 3500 loss_train: 0.0046\n",
      "Epoch: 4000 loss_train: 0.0161\n",
      "Epoch: 4500 loss_train: 0.0627\n",
      "Epoch: 5000 loss_train: 0.0236\n",
      "Epoch: 5500 loss_train: 0.0454\n",
      " total time: 7.5403s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3873\n",
      "Epoch: 0500 loss_train: 0.1169\n",
      "Epoch: 1000 loss_train: 0.0667\n",
      "Epoch: 1500 loss_train: 0.0294\n",
      "Epoch: 2000 loss_train: 0.0148\n",
      "Epoch: 2500 loss_train: 0.0050\n",
      "Epoch: 3000 loss_train: 0.0248\n",
      "Epoch: 3500 loss_train: 0.0073\n",
      "Epoch: 4000 loss_train: 0.0156\n",
      "Epoch: 4500 loss_train: 0.0289\n",
      "Epoch: 5000 loss_train: 0.0036\n",
      "Epoch: 5500 loss_train: 0.0164\n",
      " total time: 7.5291s\n",
      "5.105722427368164\n",
      "Epoch: 0000 loss_train: 1.3870\n",
      "Epoch: 0500 loss_train: 0.1206\n",
      "Epoch: 1000 loss_train: 0.0663\n",
      "Epoch: 1500 loss_train: 0.0242\n",
      "Epoch: 2000 loss_train: 0.0118\n",
      "Epoch: 2500 loss_train: 0.0051\n",
      "Epoch: 3000 loss_train: 0.0138\n",
      "Epoch: 3500 loss_train: 0.0026\n",
      "Epoch: 4000 loss_train: 0.0150\n",
      "Epoch: 4500 loss_train: 0.0663\n",
      "Epoch: 5000 loss_train: 0.0276\n",
      "Epoch: 5500 loss_train: 0.0143\n",
      " total time: 7.5390s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3867\n",
      "Epoch: 0500 loss_train: 0.1175\n",
      "Epoch: 1000 loss_train: 0.0703\n",
      "Epoch: 1500 loss_train: 0.0358\n",
      "Epoch: 2000 loss_train: 0.0126\n",
      "Epoch: 2500 loss_train: 0.0059\n",
      "Epoch: 3000 loss_train: 0.0215\n",
      "Epoch: 3500 loss_train: 0.0040\n",
      "Epoch: 4000 loss_train: 0.0075\n",
      "Epoch: 4500 loss_train: 0.0138\n",
      "Epoch: 5000 loss_train: 0.0028\n",
      "Epoch: 5500 loss_train: 0.0139\n",
      " total time: 7.7291s\n",
      "0.0029633203521370888\n",
      "Epoch: 0000 loss_train: 1.3870\n",
      "Epoch: 0500 loss_train: 0.1268\n",
      "Epoch: 1000 loss_train: 0.0924\n",
      "Epoch: 1500 loss_train: 0.0343\n",
      "Epoch: 2000 loss_train: 0.0164\n",
      "Epoch: 2500 loss_train: 0.0055\n",
      "Epoch: 3000 loss_train: 0.0122\n",
      "Epoch: 3500 loss_train: 0.0024\n",
      "Epoch: 4000 loss_train: 0.0054\n",
      "Epoch: 4500 loss_train: 0.0026\n",
      "Epoch: 5000 loss_train: 0.0025\n",
      "Epoch: 5500 loss_train: 0.0083\n",
      " total time: 7.7345s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3879\n",
      "Epoch: 0500 loss_train: 0.1303\n",
      "Epoch: 1000 loss_train: 0.0804\n",
      "Epoch: 1500 loss_train: 0.0296\n",
      "Epoch: 2000 loss_train: 0.0184\n",
      "Epoch: 2500 loss_train: 0.0068\n",
      "Epoch: 3000 loss_train: 0.0137\n",
      "Epoch: 3500 loss_train: 0.0047\n",
      "Epoch: 4000 loss_train: 0.0093\n",
      "Epoch: 4500 loss_train: 0.0276\n",
      "Epoch: 5000 loss_train: 0.0050\n",
      "Epoch: 5500 loss_train: 0.0141\n",
      " total time: 7.7023s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3879\n",
      "Epoch: 0500 loss_train: 0.1230\n",
      "Epoch: 1000 loss_train: 0.0948\n",
      "Epoch: 1500 loss_train: 0.0439\n",
      "Epoch: 2000 loss_train: 0.0072\n",
      "Epoch: 2500 loss_train: 0.0071\n",
      "Epoch: 3000 loss_train: 0.0360\n",
      "Epoch: 3500 loss_train: 0.0045\n",
      "Epoch: 4000 loss_train: 0.0082\n",
      "Epoch: 4500 loss_train: 0.0271\n",
      "Epoch: 5000 loss_train: 0.0031\n",
      "Epoch: 5500 loss_train: 0.0176\n",
      " total time: 7.4518s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3879\n",
      "Epoch: 0500 loss_train: 0.1285\n",
      "Epoch: 1000 loss_train: 0.0986\n",
      "Epoch: 1500 loss_train: 0.0536\n",
      "Epoch: 2000 loss_train: 0.0176\n",
      "Epoch: 2500 loss_train: 0.0061\n",
      "Epoch: 3000 loss_train: 0.0180\n",
      "Epoch: 3500 loss_train: 0.0029\n",
      "Epoch: 4000 loss_train: 0.0112\n",
      "Epoch: 4500 loss_train: 0.0027\n",
      "Epoch: 5000 loss_train: 0.0012\n",
      "Epoch: 5500 loss_train: 0.0095\n",
      " total time: 7.4728s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3881\n",
      "Epoch: 0500 loss_train: 0.1110\n",
      "Epoch: 1000 loss_train: 0.0849\n",
      "Epoch: 1500 loss_train: 0.0245\n",
      "Epoch: 2000 loss_train: 0.0078\n",
      "Epoch: 2500 loss_train: 0.0083\n",
      "Epoch: 3000 loss_train: 0.0190\n",
      "Epoch: 3500 loss_train: 0.0015\n",
      "Epoch: 4000 loss_train: 0.0030\n",
      "Epoch: 4500 loss_train: 0.0039\n",
      "Epoch: 5000 loss_train: 0.0010\n",
      "Epoch: 5500 loss_train: 0.0099\n",
      " total time: 7.4519s\n",
      "27.552824020385742\n",
      "Epoch: 0000 loss_train: 1.3883\n",
      "Epoch: 0500 loss_train: 0.1280\n",
      "Epoch: 1000 loss_train: 0.0638\n",
      "Epoch: 1500 loss_train: 0.0457\n",
      "Epoch: 2000 loss_train: 0.0076\n",
      "Epoch: 2500 loss_train: 0.0091\n",
      "Epoch: 3000 loss_train: 0.0164\n",
      "Epoch: 3500 loss_train: 0.0045\n",
      "Epoch: 4000 loss_train: 0.0107\n",
      "Epoch: 4500 loss_train: 0.0009\n",
      "Epoch: 5000 loss_train: 0.0104\n",
      "Epoch: 5500 loss_train: 0.0075\n",
      " total time: 7.4543s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3882\n",
      "Epoch: 0500 loss_train: 0.1043\n",
      "Epoch: 1000 loss_train: 0.1073\n",
      "Epoch: 1500 loss_train: 0.0431\n",
      "Epoch: 2000 loss_train: 0.0045\n",
      "Epoch: 2500 loss_train: 0.0096\n",
      "Epoch: 3000 loss_train: 0.0302\n",
      "Epoch: 3500 loss_train: 0.0047\n",
      "Epoch: 4000 loss_train: 0.0080\n",
      "Epoch: 4500 loss_train: 0.0050\n",
      "Epoch: 5000 loss_train: 0.0249\n",
      "Epoch: 5500 loss_train: 0.0125\n",
      " total time: 7.4486s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3882\n",
      "Epoch: 0500 loss_train: 0.1061\n",
      "Epoch: 1000 loss_train: 0.0556\n",
      "Epoch: 1500 loss_train: 0.0573\n",
      "Epoch: 2000 loss_train: 0.0065\n",
      "Epoch: 2500 loss_train: 0.0085\n",
      "Epoch: 3000 loss_train: 0.0134\n",
      "Epoch: 3500 loss_train: 0.0023\n",
      "Epoch: 4000 loss_train: 0.0077\n",
      "Epoch: 4500 loss_train: 0.0045\n",
      "Epoch: 5000 loss_train: 0.0200\n",
      "Epoch: 5500 loss_train: 0.0038\n",
      " total time: 7.4508s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3879\n",
      "Epoch: 0500 loss_train: 0.1102\n",
      "Epoch: 1000 loss_train: 0.0871\n",
      "Epoch: 1500 loss_train: 0.0420\n",
      "Epoch: 2000 loss_train: 0.0072\n",
      "Epoch: 2500 loss_train: 0.0084\n",
      "Epoch: 3000 loss_train: 0.0267\n",
      "Epoch: 3500 loss_train: 0.0043\n",
      "Epoch: 4000 loss_train: 0.0096\n",
      "Epoch: 4500 loss_train: 0.0113\n",
      "Epoch: 5000 loss_train: 0.0029\n",
      "Epoch: 5500 loss_train: 0.0273\n",
      " total time: 7.4513s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0500 loss_train: 0.1151\n",
      "Epoch: 1000 loss_train: 0.0703\n",
      "Epoch: 1500 loss_train: 0.0499\n",
      "Epoch: 2000 loss_train: 0.0060\n",
      "Epoch: 2500 loss_train: 0.0065\n",
      "Epoch: 3000 loss_train: 0.0193\n",
      "Epoch: 3500 loss_train: 0.0081\n",
      "Epoch: 4000 loss_train: 0.0101\n",
      "Epoch: 4500 loss_train: 0.0008\n",
      "Epoch: 5000 loss_train: 0.0019\n",
      "Epoch: 5500 loss_train: 0.0156\n",
      " total time: 7.4662s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3879\n",
      "Epoch: 0500 loss_train: 0.0977\n",
      "Epoch: 1000 loss_train: 0.0850\n",
      "Epoch: 1500 loss_train: 0.0382\n",
      "Epoch: 2000 loss_train: 0.0050\n",
      "Epoch: 2500 loss_train: 0.0148\n",
      "Epoch: 3000 loss_train: 0.0276\n",
      "Epoch: 3500 loss_train: 0.0038\n",
      "Epoch: 4000 loss_train: 0.0150\n",
      "Epoch: 4500 loss_train: 0.0091\n",
      "Epoch: 5000 loss_train: 0.0011\n",
      "Epoch: 5500 loss_train: 0.0168\n",
      " total time: 7.4616s\n",
      "6.661959648132324\n",
      "Epoch: 0000 loss_train: 1.3879\n",
      "Epoch: 0500 loss_train: 0.1147\n",
      "Epoch: 1000 loss_train: 0.0628\n",
      "Epoch: 1500 loss_train: 0.0454\n",
      "Epoch: 2000 loss_train: 0.0100\n",
      "Epoch: 2500 loss_train: 0.0098\n",
      "Epoch: 3000 loss_train: 0.0118\n",
      "Epoch: 3500 loss_train: 0.0030\n",
      "Epoch: 4000 loss_train: 0.0130\n",
      "Epoch: 4500 loss_train: 0.0136\n",
      "Epoch: 5000 loss_train: 0.0029\n",
      "Epoch: 5500 loss_train: 0.0046\n",
      " total time: 7.4443s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3878\n",
      "Epoch: 0500 loss_train: 0.1093\n",
      "Epoch: 1000 loss_train: 0.0832\n",
      "Epoch: 1500 loss_train: 0.0357\n",
      "Epoch: 2000 loss_train: 0.0045\n",
      "Epoch: 2500 loss_train: 0.0108\n",
      "Epoch: 3000 loss_train: 0.0194\n",
      "Epoch: 3500 loss_train: 0.0021\n",
      "Epoch: 4000 loss_train: 0.0098\n",
      "Epoch: 4500 loss_train: 0.0016\n",
      "Epoch: 5000 loss_train: 0.0017\n",
      "Epoch: 5500 loss_train: 0.0029\n",
      " total time: 7.4626s\n",
      "2.3841855067985307e-07\n",
      "Epoch: 0000 loss_train: 1.3879\n",
      "Epoch: 0500 loss_train: 0.1165\n",
      "Epoch: 1000 loss_train: 0.0719\n",
      "Epoch: 1500 loss_train: 0.0297\n",
      "Epoch: 2000 loss_train: 0.0057\n",
      "Epoch: 2500 loss_train: 0.0089\n",
      "Epoch: 3000 loss_train: 0.0123\n",
      "Epoch: 3500 loss_train: 0.0018\n",
      "Epoch: 4000 loss_train: 0.0101\n",
      "Epoch: 4500 loss_train: 0.0036\n",
      "Epoch: 5000 loss_train: 0.0015\n",
      "Epoch: 5500 loss_train: 0.0219\n",
      " total time: 7.4407s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3869\n",
      "Epoch: 0500 loss_train: 0.1022\n",
      "Epoch: 1000 loss_train: 0.0807\n",
      "Epoch: 1500 loss_train: 0.0386\n",
      "Epoch: 2000 loss_train: 0.0131\n",
      "Epoch: 2500 loss_train: 0.0169\n",
      "Epoch: 3000 loss_train: 0.0168\n",
      "Epoch: 3500 loss_train: 0.0042\n",
      "Epoch: 4000 loss_train: 0.0085\n",
      "Epoch: 4500 loss_train: 0.0043\n",
      "Epoch: 5000 loss_train: 0.0013\n",
      "Epoch: 5500 loss_train: 0.0085\n",
      " total time: 7.4514s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3871\n",
      "Epoch: 0500 loss_train: 0.1082\n",
      "Epoch: 1000 loss_train: 0.0671\n",
      "Epoch: 1500 loss_train: 0.0318\n",
      "Epoch: 2000 loss_train: 0.0258\n",
      "Epoch: 2500 loss_train: 0.0240\n",
      "Epoch: 3000 loss_train: 0.0167\n",
      "Epoch: 3500 loss_train: 0.0027\n",
      "Epoch: 4000 loss_train: 0.0203\n",
      "Epoch: 4500 loss_train: 0.0014\n",
      "Epoch: 5000 loss_train: 0.0024\n",
      "Epoch: 5500 loss_train: 0.0059\n",
      " total time: 7.4541s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3872\n",
      "Epoch: 0500 loss_train: 0.1021\n",
      "Epoch: 1000 loss_train: 0.0759\n",
      "Epoch: 1500 loss_train: 0.0426\n",
      "Epoch: 2000 loss_train: 0.0130\n",
      "Epoch: 2500 loss_train: 0.0155\n",
      "Epoch: 3000 loss_train: 0.0213\n",
      "Epoch: 3500 loss_train: 0.0029\n",
      "Epoch: 4000 loss_train: 0.0063\n",
      "Epoch: 4500 loss_train: 0.0041\n",
      "Epoch: 5000 loss_train: 0.0049\n",
      "Epoch: 5500 loss_train: 0.0054\n",
      " total time: 7.4542s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3869\n",
      "Epoch: 0500 loss_train: 0.0962\n",
      "Epoch: 1000 loss_train: 0.0517\n",
      "Epoch: 1500 loss_train: 0.0498\n",
      "Epoch: 2000 loss_train: 0.0084\n",
      "Epoch: 2500 loss_train: 0.0084\n",
      "Epoch: 3000 loss_train: 0.0201\n",
      "Epoch: 3500 loss_train: 0.0038\n",
      "Epoch: 4000 loss_train: 0.0054\n",
      "Epoch: 4500 loss_train: 0.0122\n",
      "Epoch: 5000 loss_train: 0.0052\n",
      "Epoch: 5500 loss_train: 0.0134\n",
      " total time: 7.4517s\n",
      "1.9311717551317997e-05\n",
      "Epoch: 0000 loss_train: 1.3865\n",
      "Epoch: 0500 loss_train: 0.0970\n",
      "Epoch: 1000 loss_train: 0.0856\n",
      "Epoch: 1500 loss_train: 0.0368\n",
      "Epoch: 2000 loss_train: 0.0126\n",
      "Epoch: 2500 loss_train: 0.0084\n",
      "Epoch: 3000 loss_train: 0.0182\n",
      "Epoch: 3500 loss_train: 0.0036\n",
      "Epoch: 4000 loss_train: 0.0070\n",
      "Epoch: 4500 loss_train: 0.0034\n",
      "Epoch: 5000 loss_train: 0.0075\n",
      "Epoch: 5500 loss_train: 0.0180\n",
      " total time: 7.4591s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3858\n",
      "Epoch: 0500 loss_train: 0.1035\n",
      "Epoch: 1000 loss_train: 0.0743\n",
      "Epoch: 1500 loss_train: 0.0508\n",
      "Epoch: 2000 loss_train: 0.0049\n",
      "Epoch: 2500 loss_train: 0.0136\n",
      "Epoch: 3000 loss_train: 0.0178\n",
      "Epoch: 3500 loss_train: 0.0055\n",
      "Epoch: 4000 loss_train: 0.0129\n",
      "Epoch: 4500 loss_train: 0.0072\n",
      "Epoch: 5000 loss_train: 0.0024\n",
      "Epoch: 5500 loss_train: 0.0174\n",
      " total time: 7.4674s\n",
      "1.2993727978027891e-05\n",
      "Epoch: 0000 loss_train: 1.3866\n",
      "Epoch: 0500 loss_train: 0.1130\n",
      "Epoch: 1000 loss_train: 0.1063\n",
      "Epoch: 1500 loss_train: 0.0362\n",
      "Epoch: 2000 loss_train: 0.0081\n",
      "Epoch: 2500 loss_train: 0.0074\n",
      "Epoch: 3000 loss_train: 0.0173\n",
      "Epoch: 3500 loss_train: 0.0132\n",
      "Epoch: 4000 loss_train: 0.0147\n",
      "Epoch: 4500 loss_train: 0.0064\n",
      "Epoch: 5000 loss_train: 0.0135\n",
      "Epoch: 5500 loss_train: 0.0073\n",
      " total time: 7.4434s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3865\n",
      "Epoch: 0500 loss_train: 0.1110\n",
      "Epoch: 1000 loss_train: 0.0597\n",
      "Epoch: 1500 loss_train: 0.0693\n",
      "Epoch: 2000 loss_train: 0.0092\n",
      "Epoch: 2500 loss_train: 0.0188\n",
      "Epoch: 3000 loss_train: 0.0237\n",
      "Epoch: 3500 loss_train: 0.0092\n",
      "Epoch: 4000 loss_train: 0.0144\n",
      "Epoch: 4500 loss_train: 0.0020\n",
      "Epoch: 5000 loss_train: 0.0131\n",
      "Epoch: 5500 loss_train: 0.0035\n",
      " total time: 7.4523s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3865\n",
      "Epoch: 0500 loss_train: 0.1033\n",
      "Epoch: 1000 loss_train: 0.0606\n",
      "Epoch: 1500 loss_train: 0.0444\n",
      "Epoch: 2000 loss_train: 0.0080\n",
      "Epoch: 2500 loss_train: 0.0102\n",
      "Epoch: 3000 loss_train: 0.0112\n",
      "Epoch: 3500 loss_train: 0.0299\n",
      "Epoch: 4000 loss_train: 0.0090\n",
      "Epoch: 4500 loss_train: 0.0350\n",
      "Epoch: 5000 loss_train: 0.0053\n",
      "Epoch: 5500 loss_train: 0.0054\n",
      " total time: 7.4410s\n",
      "4.6491513785440475e-06\n",
      "Epoch: 0000 loss_train: 1.3866\n",
      "Epoch: 0500 loss_train: 0.1029\n",
      "Epoch: 1000 loss_train: 0.0767\n",
      "Epoch: 1500 loss_train: 0.0357\n",
      "Epoch: 2000 loss_train: 0.0051\n",
      "Epoch: 2500 loss_train: 0.0142\n",
      "Epoch: 3000 loss_train: 0.0204\n",
      "Epoch: 3500 loss_train: 0.0052\n",
      "Epoch: 4000 loss_train: 0.0051\n",
      "Epoch: 4500 loss_train: 0.0229\n",
      "Epoch: 5000 loss_train: 0.0073\n",
      "Epoch: 5500 loss_train: 0.0028\n",
      " total time: 7.4391s\n",
      "5.637872219085693\n",
      "Epoch: 0000 loss_train: 1.3870\n",
      "Epoch: 0500 loss_train: 0.0959\n",
      "Epoch: 1000 loss_train: 0.0645\n",
      "Epoch: 1500 loss_train: 0.0275\n",
      "Epoch: 2000 loss_train: 0.0041\n",
      "Epoch: 2500 loss_train: 0.0089\n",
      "Epoch: 3000 loss_train: 0.0269\n",
      "Epoch: 3500 loss_train: 0.0033\n",
      "Epoch: 4000 loss_train: 0.0215\n",
      "Epoch: 4500 loss_train: 0.0758\n",
      "Epoch: 5000 loss_train: 0.0023\n",
      "Epoch: 5500 loss_train: 0.0054\n",
      " total time: 7.4619s\n",
      "13.436302185058594\n",
      "Epoch: 0000 loss_train: 1.3872\n",
      "Epoch: 0500 loss_train: 0.1140\n",
      "Epoch: 1000 loss_train: 0.0526\n",
      "Epoch: 1500 loss_train: 0.0658\n",
      "Epoch: 2000 loss_train: 0.0102\n",
      "Epoch: 2500 loss_train: 0.0235\n",
      "Epoch: 3000 loss_train: 0.0152\n",
      "Epoch: 3500 loss_train: 0.0275\n",
      "Epoch: 4000 loss_train: 0.0071\n",
      "Epoch: 4500 loss_train: 0.0061\n",
      "Epoch: 5000 loss_train: 0.0017\n",
      "Epoch: 5500 loss_train: 0.0073\n",
      " total time: 7.3642s\n",
      "0.0006403064471669495\n",
      "Epoch: 0000 loss_train: 1.3870\n",
      "Epoch: 0500 loss_train: 0.1107\n",
      "Epoch: 1000 loss_train: 0.0356\n",
      "Epoch: 1500 loss_train: 0.0601\n",
      "Epoch: 2000 loss_train: 0.0126\n",
      "Epoch: 2500 loss_train: 0.0121\n",
      "Epoch: 3000 loss_train: 0.0140\n",
      "Epoch: 3500 loss_train: 0.0142\n",
      "Epoch: 4000 loss_train: 0.0321\n",
      "Epoch: 4500 loss_train: 0.0016\n",
      "Epoch: 5000 loss_train: 0.0032\n",
      "Epoch: 5500 loss_train: 0.0043\n",
      " total time: 7.4615s\n",
      "18.01263427734375\n",
      "Epoch: 0000 loss_train: 1.3870\n",
      "Epoch: 0500 loss_train: 0.1101\n",
      "Epoch: 1000 loss_train: 0.0610\n",
      "Epoch: 1500 loss_train: 0.0353\n",
      "Epoch: 2000 loss_train: 0.0165\n",
      "Epoch: 2500 loss_train: 0.0075\n",
      "Epoch: 3000 loss_train: 0.0110\n",
      "Epoch: 3500 loss_train: 0.0024\n",
      "Epoch: 4000 loss_train: 0.0167\n",
      "Epoch: 4500 loss_train: 0.0222\n",
      "Epoch: 5000 loss_train: 0.0044\n",
      "Epoch: 5500 loss_train: 0.0020\n",
      " total time: 7.4587s\n",
      "48.833580017089844\n",
      "Epoch: 0000 loss_train: 1.3883\n",
      "Epoch: 0500 loss_train: 0.1090\n",
      "Epoch: 1000 loss_train: 0.0537\n",
      "Epoch: 1500 loss_train: 0.0671\n",
      "Epoch: 2000 loss_train: 0.0090\n",
      "Epoch: 2500 loss_train: 0.0107\n",
      "Epoch: 3000 loss_train: 0.0358\n",
      "Epoch: 3500 loss_train: 0.0043\n",
      "Epoch: 4000 loss_train: 0.0107\n",
      "Epoch: 4500 loss_train: 0.0091\n",
      "Epoch: 5000 loss_train: 0.0044\n",
      "Epoch: 5500 loss_train: 0.0046\n",
      " total time: 7.4724s\n",
      "11.160202026367188\n",
      "Epoch: 0000 loss_train: 1.3885\n",
      "Epoch: 0500 loss_train: 0.1087\n",
      "Epoch: 1000 loss_train: 0.0754\n",
      "Epoch: 1500 loss_train: 0.0351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 loss_train: 0.0192\n",
      "Epoch: 2500 loss_train: 0.0145\n",
      "Epoch: 3000 loss_train: 0.0160\n",
      "Epoch: 3500 loss_train: 0.0045\n",
      "Epoch: 4000 loss_train: 0.0113\n",
      "Epoch: 4500 loss_train: 0.0057\n",
      "Epoch: 5000 loss_train: 0.0017\n",
      "Epoch: 5500 loss_train: 0.0023\n",
      " total time: 7.4447s\n",
      "0.0006560318870469928\n",
      "Epoch: 0000 loss_train: 1.3889\n",
      "Epoch: 0500 loss_train: 0.0886\n",
      "Epoch: 1000 loss_train: 0.0301\n",
      "Epoch: 1500 loss_train: 0.0748\n",
      "Epoch: 2000 loss_train: 0.0089\n",
      "Epoch: 2500 loss_train: 0.0073\n",
      "Epoch: 3000 loss_train: 0.0207\n",
      "Epoch: 3500 loss_train: 0.0052\n",
      "Epoch: 4000 loss_train: 0.0131\n",
      "Epoch: 4500 loss_train: 0.0614\n",
      "Epoch: 5000 loss_train: 0.0022\n",
      "Epoch: 5500 loss_train: 0.0122\n",
      " total time: 7.4541s\n",
      "3.4927710657939315e-05\n",
      "Epoch: 0000 loss_train: 1.3888\n",
      "Epoch: 0500 loss_train: 0.1017\n",
      "Epoch: 1000 loss_train: 0.0525\n",
      "Epoch: 1500 loss_train: 0.0664\n",
      "Epoch: 2000 loss_train: 0.0054\n",
      "Epoch: 2500 loss_train: 0.0082\n",
      "Epoch: 3000 loss_train: 0.0198\n",
      "Epoch: 3500 loss_train: 0.0039\n",
      "Epoch: 4000 loss_train: 0.0051\n",
      "Epoch: 4500 loss_train: 0.0119\n",
      "Epoch: 5000 loss_train: 0.0066\n",
      "Epoch: 5500 loss_train: 0.0172\n",
      " total time: 7.4444s\n",
      "1.072882923836005e-06\n",
      "Epoch: 0000 loss_train: 1.3889\n",
      "Epoch: 0500 loss_train: 0.0999\n",
      "Epoch: 1000 loss_train: 0.0396\n",
      "Epoch: 1500 loss_train: 0.0459\n",
      "Epoch: 2000 loss_train: 0.0113\n",
      "Epoch: 2500 loss_train: 0.0054\n",
      "Epoch: 3000 loss_train: 0.0208\n",
      "Epoch: 3500 loss_train: 0.0071\n",
      "Epoch: 4000 loss_train: 0.0050\n",
      "Epoch: 4500 loss_train: 0.0070\n",
      "Epoch: 5000 loss_train: 0.0011\n",
      "Epoch: 5500 loss_train: 0.0065\n",
      " total time: 7.4797s\n",
      "3.4570634852570947e-06\n",
      "Epoch: 0000 loss_train: 1.3890\n",
      "Epoch: 0500 loss_train: 0.1129\n",
      "Epoch: 1000 loss_train: 0.0351\n",
      "Epoch: 1500 loss_train: 0.0886\n",
      "Epoch: 2000 loss_train: 0.0218\n",
      "Epoch: 2500 loss_train: 0.0146\n",
      "Epoch: 3000 loss_train: 0.0132\n",
      "Epoch: 3500 loss_train: 0.0069\n",
      "Epoch: 4000 loss_train: 0.0074\n",
      "Epoch: 4500 loss_train: 0.0023\n",
      "Epoch: 5000 loss_train: 0.0022\n",
      "Epoch: 5500 loss_train: 0.0046\n",
      " total time: 7.4504s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3890\n",
      "Epoch: 0500 loss_train: 0.1025\n",
      "Epoch: 1000 loss_train: 0.0331\n",
      "Epoch: 1500 loss_train: 0.0637\n",
      "Epoch: 2000 loss_train: 0.0092\n",
      "Epoch: 2500 loss_train: 0.0071\n",
      "Epoch: 3000 loss_train: 0.0233\n",
      "Epoch: 3500 loss_train: 0.0078\n",
      "Epoch: 4000 loss_train: 0.0054\n",
      "Epoch: 4500 loss_train: 0.0136\n",
      "Epoch: 5000 loss_train: 0.0212\n",
      "Epoch: 5500 loss_train: 0.0101\n",
      " total time: 7.4534s\n",
      "3.862306402879767e-05\n",
      "Epoch: 0000 loss_train: 1.3891\n",
      "Epoch: 0500 loss_train: 0.1042\n",
      "Epoch: 1000 loss_train: 0.0273\n",
      "Epoch: 1500 loss_train: 0.0921\n",
      "Epoch: 2000 loss_train: 0.0113\n",
      "Epoch: 2500 loss_train: 0.0066\n",
      "Epoch: 3000 loss_train: 0.0237\n",
      "Epoch: 3500 loss_train: 0.0040\n",
      "Epoch: 4000 loss_train: 0.0040\n",
      "Epoch: 4500 loss_train: 0.0268\n",
      "Epoch: 5000 loss_train: 0.0077\n",
      "Epoch: 5500 loss_train: 0.0297\n",
      " total time: 7.4482s\n",
      "5.471556869451888e-05\n",
      "Epoch: 0000 loss_train: 1.3890\n",
      "Epoch: 0500 loss_train: 0.0964\n",
      "Epoch: 1000 loss_train: 0.0281\n",
      "Epoch: 1500 loss_train: 0.0578\n",
      "Epoch: 2000 loss_train: 0.0048\n",
      "Epoch: 2500 loss_train: 0.0084\n",
      "Epoch: 3000 loss_train: 0.0241\n",
      "Epoch: 3500 loss_train: 0.0087\n",
      "Epoch: 4000 loss_train: 0.0096\n",
      "Epoch: 4500 loss_train: 0.0023\n",
      "Epoch: 5000 loss_train: 0.0109\n",
      "Epoch: 5500 loss_train: 0.0082\n",
      " total time: 7.3870s\n",
      "12.485962867736816\n",
      "Epoch: 0000 loss_train: 1.3891\n",
      "Epoch: 0500 loss_train: 0.1077\n",
      "Epoch: 1000 loss_train: 0.0423\n",
      "Epoch: 1500 loss_train: 0.0650\n",
      "Epoch: 2000 loss_train: 0.0065\n",
      "Epoch: 2500 loss_train: 0.0158\n",
      "Epoch: 3000 loss_train: 0.0208\n",
      "Epoch: 3500 loss_train: 0.0041\n",
      "Epoch: 4000 loss_train: 0.0185\n",
      "Epoch: 4500 loss_train: 0.0032\n",
      "Epoch: 5000 loss_train: 0.0037\n",
      "Epoch: 5500 loss_train: 0.0029\n",
      " total time: 7.4527s\n",
      "3.218599158572033e-05\n",
      "Epoch: 0000 loss_train: 1.3896\n",
      "Epoch: 0500 loss_train: 0.0919\n",
      "Epoch: 1000 loss_train: 0.0345\n",
      "Epoch: 1500 loss_train: 0.0478\n",
      "Epoch: 2000 loss_train: 0.0049\n",
      "Epoch: 2500 loss_train: 0.0039\n",
      "Epoch: 3000 loss_train: 0.0322\n",
      "Epoch: 3500 loss_train: 0.0049\n",
      "Epoch: 4000 loss_train: 0.0157\n",
      "Epoch: 4500 loss_train: 0.0173\n",
      "Epoch: 5000 loss_train: 0.0017\n",
      "Epoch: 5500 loss_train: 0.0203\n",
      " total time: 7.4599s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3894\n",
      "Epoch: 0500 loss_train: 0.0984\n",
      "Epoch: 1000 loss_train: 0.0462\n",
      "Epoch: 1500 loss_train: 0.0477\n",
      "Epoch: 2000 loss_train: 0.0058\n",
      "Epoch: 2500 loss_train: 0.0125\n",
      "Epoch: 3000 loss_train: 0.0481\n",
      "Epoch: 3500 loss_train: 0.0066\n",
      "Epoch: 4000 loss_train: 0.0332\n",
      "Epoch: 4500 loss_train: 0.0021\n",
      "Epoch: 5000 loss_train: 0.0025\n",
      "Epoch: 5500 loss_train: 0.0029\n",
      " total time: 7.4300s\n",
      "0.002042114268988371\n",
      "Epoch: 0000 loss_train: 1.3895\n",
      "Epoch: 0500 loss_train: 0.0945\n",
      "Epoch: 1000 loss_train: 0.0445\n",
      "Epoch: 1500 loss_train: 0.0757\n",
      "Epoch: 2000 loss_train: 0.0064\n",
      "Epoch: 2500 loss_train: 0.0093\n",
      "Epoch: 3000 loss_train: 0.0287\n",
      "Epoch: 3500 loss_train: 0.0057\n",
      "Epoch: 4000 loss_train: 0.0084\n",
      "Epoch: 4500 loss_train: 0.0044\n",
      "Epoch: 5000 loss_train: 0.0027\n",
      "Epoch: 5500 loss_train: 0.0063\n",
      " total time: 7.4544s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3897\n",
      "Epoch: 0500 loss_train: 0.0849\n",
      "Epoch: 1000 loss_train: 0.0290\n",
      "Epoch: 1500 loss_train: 0.0767\n",
      "Epoch: 2000 loss_train: 0.0054\n",
      "Epoch: 2500 loss_train: 0.0105\n",
      "Epoch: 3000 loss_train: 0.0295\n",
      "Epoch: 3500 loss_train: 0.0072\n",
      "Epoch: 4000 loss_train: 0.0081\n",
      "Epoch: 4500 loss_train: 0.0017\n",
      "Epoch: 5000 loss_train: 0.0235\n",
      "Epoch: 5500 loss_train: 0.0222\n",
      " total time: 7.4397s\n",
      "19.390459060668945\n",
      "Epoch: 0000 loss_train: 1.3897\n",
      "Epoch: 0500 loss_train: 0.0919\n",
      "Epoch: 1000 loss_train: 0.0401\n",
      "Epoch: 1500 loss_train: 0.0654\n",
      "Epoch: 2000 loss_train: 0.0058\n",
      "Epoch: 2500 loss_train: 0.0047\n",
      "Epoch: 3000 loss_train: 0.0338\n",
      "Epoch: 3500 loss_train: 0.0059\n",
      "Epoch: 4000 loss_train: 0.0117\n",
      "Epoch: 4500 loss_train: 0.0012\n",
      "Epoch: 5000 loss_train: 0.0011\n",
      "Epoch: 5500 loss_train: 0.0176\n",
      " total time: 7.4522s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3896\n",
      "Epoch: 0500 loss_train: 0.0927\n",
      "Epoch: 1000 loss_train: 0.0439\n",
      "Epoch: 1500 loss_train: 0.0795\n",
      "Epoch: 2000 loss_train: 0.0064\n",
      "Epoch: 2500 loss_train: 0.0085\n",
      "Epoch: 3000 loss_train: 0.0208\n",
      "Epoch: 3500 loss_train: 0.0073\n",
      "Epoch: 4000 loss_train: 0.0095\n",
      "Epoch: 4500 loss_train: 0.0010\n",
      "Epoch: 5000 loss_train: 0.0085\n",
      "Epoch: 5500 loss_train: 0.0028\n",
      " total time: 7.2833s\n",
      "30.11089324951172\n",
      "Epoch: 0000 loss_train: 1.3894\n",
      "Epoch: 0500 loss_train: 0.0843\n",
      "Epoch: 1000 loss_train: 0.0412\n",
      "Epoch: 1500 loss_train: 0.0679\n",
      "Epoch: 2000 loss_train: 0.0050\n",
      "Epoch: 2500 loss_train: 0.0083\n",
      "Epoch: 3000 loss_train: 0.0268\n",
      "Epoch: 3500 loss_train: 0.0050\n",
      "Epoch: 4000 loss_train: 0.0071\n",
      "Epoch: 4500 loss_train: 0.0028\n",
      "Epoch: 5000 loss_train: 0.0044\n",
      "Epoch: 5500 loss_train: 0.0113\n",
      " total time: 7.4367s\n",
      "1.1920928244535389e-07\n",
      "Epoch: 0000 loss_train: 1.3894\n",
      "Epoch: 0500 loss_train: 0.0850\n",
      "Epoch: 1000 loss_train: 0.0547\n",
      "Epoch: 1500 loss_train: 0.0670\n",
      "Epoch: 2000 loss_train: 0.0036\n",
      "Epoch: 2500 loss_train: 0.0084\n",
      "Epoch: 3000 loss_train: 0.0268\n",
      "Epoch: 3500 loss_train: 0.0041\n",
      "Epoch: 4000 loss_train: 0.0263\n",
      "Epoch: 4500 loss_train: 0.0014\n",
      "Epoch: 5000 loss_train: 0.0228\n",
      "Epoch: 5500 loss_train: 0.0188\n",
      " total time: 7.4453s\n",
      "0.0001726001501083374\n",
      "Epoch: 0000 loss_train: 1.3891\n",
      "Epoch: 0500 loss_train: 0.0974\n",
      "Epoch: 1000 loss_train: 0.0765\n",
      "Epoch: 1500 loss_train: 0.0672\n",
      "Epoch: 2000 loss_train: 0.0058\n",
      "Epoch: 2500 loss_train: 0.0057\n",
      "Epoch: 3000 loss_train: 0.0383\n",
      "Epoch: 3500 loss_train: 0.0139\n",
      "Epoch: 4000 loss_train: 0.0114\n",
      "Epoch: 4500 loss_train: 0.0014\n",
      "Epoch: 5000 loss_train: 0.0030\n",
      "Epoch: 5500 loss_train: 0.0350\n",
      " total time: 7.4420s\n",
      "1.1230390071868896\n",
      "Epoch: 0000 loss_train: 1.3892\n",
      "Epoch: 0500 loss_train: 0.0922\n",
      "Epoch: 1000 loss_train: 0.0606\n",
      "Epoch: 1500 loss_train: 0.0604\n",
      "Epoch: 2000 loss_train: 0.0090\n",
      "Epoch: 2500 loss_train: 0.0081\n",
      "Epoch: 3000 loss_train: 0.0129\n",
      "Epoch: 3500 loss_train: 0.0072\n",
      "Epoch: 4000 loss_train: 0.0203\n",
      "Epoch: 4500 loss_train: 0.0069\n",
      "Epoch: 5000 loss_train: 0.0094\n",
      "Epoch: 5500 loss_train: 0.0194\n",
      " total time: 7.4459s\n",
      "0.10428828746080399\n",
      "Epoch: 0000 loss_train: 1.3888\n",
      "Epoch: 0500 loss_train: 0.0806\n",
      "Epoch: 1000 loss_train: 0.0378\n",
      "Epoch: 1500 loss_train: 0.0713\n",
      "Epoch: 2000 loss_train: 0.0079\n",
      "Epoch: 2500 loss_train: 0.0061\n",
      "Epoch: 3000 loss_train: 0.0244\n",
      "Epoch: 3500 loss_train: 0.0104\n",
      "Epoch: 4000 loss_train: 0.0169\n",
      "Epoch: 4500 loss_train: 0.0306\n",
      "Epoch: 5000 loss_train: 0.0065\n",
      "Epoch: 5500 loss_train: 0.0028\n",
      " total time: 7.4419s\n",
      "0.0006213641609065235\n",
      "Epoch: 0000 loss_train: 1.3890\n",
      "Epoch: 0500 loss_train: 0.0738\n",
      "Epoch: 1000 loss_train: 0.0440\n",
      "Epoch: 1500 loss_train: 0.0326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 loss_train: 0.0300\n",
      "Epoch: 2500 loss_train: 0.0097\n",
      "Epoch: 3000 loss_train: 0.0166\n",
      "Epoch: 3500 loss_train: 0.0049\n",
      "Epoch: 4000 loss_train: 0.0025\n",
      "Epoch: 4500 loss_train: 0.0109\n",
      "Epoch: 5000 loss_train: 0.0017\n",
      "Epoch: 5500 loss_train: 0.0423\n",
      " total time: 7.4494s\n",
      "37.705745697021484\n",
      "Epoch: 0000 loss_train: 1.3900\n",
      "Epoch: 0500 loss_train: 0.0806\n",
      "Epoch: 1000 loss_train: 0.0554\n",
      "Epoch: 1500 loss_train: 0.0400\n",
      "Epoch: 2000 loss_train: 0.0114\n",
      "Epoch: 2500 loss_train: 0.0077\n",
      "Epoch: 3000 loss_train: 0.0172\n",
      "Epoch: 3500 loss_train: 0.0187\n",
      "Epoch: 4000 loss_train: 0.0090\n",
      "Epoch: 4500 loss_train: 0.0367\n",
      "Epoch: 5000 loss_train: 0.0029\n",
      "Epoch: 5500 loss_train: 0.0150\n",
      " total time: 7.4599s\n",
      "0.0005133026279509068\n",
      "Epoch: 0000 loss_train: 1.3899\n",
      "Epoch: 0500 loss_train: 0.0968\n",
      "Epoch: 1000 loss_train: 0.0760\n",
      "Epoch: 1500 loss_train: 0.0229\n",
      "Epoch: 2000 loss_train: 0.0065\n",
      "Epoch: 2500 loss_train: 0.0107\n",
      "Epoch: 3000 loss_train: 0.0162\n",
      "Epoch: 3500 loss_train: 0.0056\n",
      "Epoch: 4000 loss_train: 0.0129\n",
      "Epoch: 4500 loss_train: 0.0358\n",
      "Epoch: 5000 loss_train: 0.0053\n",
      "Epoch: 5500 loss_train: 0.0039\n",
      " total time: 7.4594s\n",
      "3.0920965671539307\n",
      "Epoch: 0000 loss_train: 1.3892\n",
      "Epoch: 0500 loss_train: 0.0976\n",
      "Epoch: 1000 loss_train: 0.0574\n",
      "Epoch: 1500 loss_train: 0.0541\n",
      "Epoch: 2000 loss_train: 0.0049\n",
      "Epoch: 2500 loss_train: 0.0064\n",
      "Epoch: 3000 loss_train: 0.0180\n",
      "Epoch: 3500 loss_train: 0.0116\n",
      "Epoch: 4000 loss_train: 0.0532\n",
      "Epoch: 4500 loss_train: 0.0256\n",
      "Epoch: 5000 loss_train: 0.0033\n",
      "Epoch: 5500 loss_train: 0.0236\n",
      " total time: 7.4659s\n",
      "1.4305104514278355e-06\n",
      "Epoch: 0000 loss_train: 1.3895\n",
      "Epoch: 0500 loss_train: 0.0844\n",
      "Epoch: 1000 loss_train: 0.0907\n",
      "Epoch: 1500 loss_train: 0.0314\n",
      "Epoch: 2000 loss_train: 0.0103\n",
      "Epoch: 2500 loss_train: 0.0061\n",
      "Epoch: 3000 loss_train: 0.0163\n",
      "Epoch: 3500 loss_train: 0.0127\n",
      "Epoch: 4000 loss_train: 0.0265\n",
      "Epoch: 4500 loss_train: 0.0098\n",
      "Epoch: 5000 loss_train: 0.0296\n",
      "Epoch: 5500 loss_train: 0.0285\n",
      " total time: 7.4512s\n",
      "6.053462505340576\n",
      "Epoch: 0000 loss_train: 1.3901\n",
      "Epoch: 0500 loss_train: 0.0826\n",
      "Epoch: 1000 loss_train: 0.0837\n",
      "Epoch: 1500 loss_train: 0.0564\n",
      "Epoch: 2000 loss_train: 0.0077\n",
      "Epoch: 2500 loss_train: 0.0206\n",
      "Epoch: 3000 loss_train: 0.0116\n",
      "Epoch: 3500 loss_train: 0.0424\n",
      "Epoch: 4000 loss_train: 0.0236\n",
      "Epoch: 4500 loss_train: 0.0023\n",
      "Epoch: 5000 loss_train: 0.0036\n",
      "Epoch: 5500 loss_train: 0.0393\n",
      " total time: 7.4063s\n",
      "3.8622336387634277\n",
      "Epoch: 0000 loss_train: 1.3907\n",
      "Epoch: 0500 loss_train: 0.0911\n",
      "Epoch: 1000 loss_train: 0.0614\n",
      "Epoch: 1500 loss_train: 0.0501\n",
      "Epoch: 2000 loss_train: 0.0044\n",
      "Epoch: 2500 loss_train: 0.0125\n",
      "Epoch: 3000 loss_train: 0.0097\n",
      "Epoch: 3500 loss_train: 0.0264\n",
      "Epoch: 4000 loss_train: 0.0160\n",
      "Epoch: 4500 loss_train: 0.0024\n",
      "Epoch: 5000 loss_train: 0.0020\n",
      "Epoch: 5500 loss_train: 0.0336\n",
      " total time: 7.4488s\n",
      "3.0278701160568744e-05\n",
      "Epoch: 0000 loss_train: 1.3907\n",
      "Epoch: 0500 loss_train: 0.0971\n",
      "Epoch: 1000 loss_train: 0.0731\n",
      "Epoch: 1500 loss_train: 0.0483\n",
      "Epoch: 2000 loss_train: 0.0181\n",
      "Epoch: 2500 loss_train: 0.0117\n",
      "Epoch: 3000 loss_train: 0.0236\n",
      "Epoch: 3500 loss_train: 0.0204\n",
      "Epoch: 4000 loss_train: 0.0472\n",
      "Epoch: 4500 loss_train: 0.0023\n",
      "Epoch: 5000 loss_train: 0.0055\n",
      "Epoch: 5500 loss_train: 0.0272\n",
      " total time: 7.4381s\n",
      "5.960462772236497e-07\n",
      "Epoch: 0000 loss_train: 1.3909\n",
      "Epoch: 0500 loss_train: 0.0964\n",
      "Epoch: 1000 loss_train: 0.0883\n",
      "Epoch: 1500 loss_train: 0.0422\n",
      "Epoch: 2000 loss_train: 0.0128\n",
      "Epoch: 2500 loss_train: 0.0055\n",
      "Epoch: 3000 loss_train: 0.0176\n",
      "Epoch: 3500 loss_train: 0.0037\n",
      "Epoch: 4000 loss_train: 0.0451\n",
      "Epoch: 4500 loss_train: 0.0108\n",
      "Epoch: 5000 loss_train: 0.0026\n",
      "Epoch: 5500 loss_train: 0.0261\n",
      " total time: 7.4485s\n",
      "1.1920923270736239e-06\n",
      "Epoch: 0000 loss_train: 1.3906\n",
      "Epoch: 0500 loss_train: 0.0806\n",
      "Epoch: 1000 loss_train: 0.0724\n",
      "Epoch: 1500 loss_train: 0.0485\n",
      "Epoch: 2000 loss_train: 0.0075\n",
      "Epoch: 2500 loss_train: 0.0201\n",
      "Epoch: 3000 loss_train: 0.0204\n",
      "Epoch: 3500 loss_train: 0.0110\n",
      "Epoch: 4000 loss_train: 0.0147\n",
      "Epoch: 4500 loss_train: 0.0082\n",
      "Epoch: 5000 loss_train: 0.0012\n",
      "Epoch: 5500 loss_train: 0.0203\n",
      " total time: 7.4497s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3905\n",
      "Epoch: 0500 loss_train: 0.0859\n",
      "Epoch: 1000 loss_train: 0.0775\n",
      "Epoch: 1500 loss_train: 0.0361\n",
      "Epoch: 2000 loss_train: 0.0068\n",
      "Epoch: 2500 loss_train: 0.0097\n",
      "Epoch: 3000 loss_train: 0.0185\n",
      "Epoch: 3500 loss_train: 0.0048\n",
      "Epoch: 4000 loss_train: 0.0045\n",
      "Epoch: 4500 loss_train: 0.0287\n",
      "Epoch: 5000 loss_train: 0.0279\n",
      "Epoch: 5500 loss_train: 0.0062\n",
      " total time: 7.4498s\n",
      "18.328275680541992\n",
      "Epoch: 0000 loss_train: 1.3905\n",
      "Epoch: 0500 loss_train: 0.0887\n",
      "Epoch: 1000 loss_train: 0.0809\n",
      "Epoch: 1500 loss_train: 0.0536\n",
      "Epoch: 2000 loss_train: 0.0109\n",
      "Epoch: 2500 loss_train: 0.0065\n",
      "Epoch: 3000 loss_train: 0.0208\n",
      "Epoch: 3500 loss_train: 0.0074\n",
      "Epoch: 4000 loss_train: 0.0165\n",
      "Epoch: 4500 loss_train: 0.0073\n",
      "Epoch: 5000 loss_train: 0.0047\n",
      "Epoch: 5500 loss_train: 0.0479\n",
      " total time: 7.4466s\n",
      "2.861018856492592e-06\n",
      "Epoch: 0000 loss_train: 1.3903\n",
      "Epoch: 0500 loss_train: 0.1021\n",
      "Epoch: 1000 loss_train: 0.0634\n",
      "Epoch: 1500 loss_train: 0.0365\n",
      "Epoch: 2000 loss_train: 0.0127\n",
      "Epoch: 2500 loss_train: 0.0092\n",
      "Epoch: 3000 loss_train: 0.0099\n",
      "Epoch: 3500 loss_train: 0.0203\n",
      "Epoch: 4000 loss_train: 0.0408\n",
      "Epoch: 4500 loss_train: 0.0075\n",
      "Epoch: 5000 loss_train: 0.0017\n",
      "Epoch: 5500 loss_train: 0.0164\n",
      " total time: 7.4423s\n",
      "0.004311908036470413\n",
      "Epoch: 0000 loss_train: 1.3902\n",
      "Epoch: 0500 loss_train: 0.0895\n",
      "Epoch: 1000 loss_train: 0.0631\n",
      "Epoch: 1500 loss_train: 0.0373\n",
      "Epoch: 2000 loss_train: 0.0172\n",
      "Epoch: 2500 loss_train: 0.0124\n",
      "Epoch: 3000 loss_train: 0.0173\n",
      "Epoch: 3500 loss_train: 0.0067\n",
      "Epoch: 4000 loss_train: 0.0261\n",
      "Epoch: 4500 loss_train: 0.0022\n",
      "Epoch: 5000 loss_train: 0.0040\n",
      "Epoch: 5500 loss_train: 0.0334\n",
      " total time: 7.4353s\n",
      "26.090164184570312\n",
      "Epoch: 0000 loss_train: 1.3903\n",
      "Epoch: 0500 loss_train: 0.0991\n",
      "Epoch: 1000 loss_train: 0.0861\n",
      "Epoch: 1500 loss_train: 0.0484\n",
      "Epoch: 2000 loss_train: 0.0229\n",
      "Epoch: 2500 loss_train: 0.0171\n",
      "Epoch: 3000 loss_train: 0.0159\n",
      "Epoch: 3500 loss_train: 0.0155\n",
      "Epoch: 4000 loss_train: 0.0269\n",
      "Epoch: 4500 loss_train: 0.0154\n",
      "Epoch: 5000 loss_train: 0.0255\n",
      "Epoch: 5500 loss_train: 0.0259\n",
      " total time: 7.4770s\n",
      "1.1920928244535389e-07\n",
      "Epoch: 0000 loss_train: 1.3901\n",
      "Epoch: 0500 loss_train: 0.0952\n",
      "Epoch: 1000 loss_train: 0.0797\n",
      "Epoch: 1500 loss_train: 0.0381\n",
      "Epoch: 2000 loss_train: 0.0130\n",
      "Epoch: 2500 loss_train: 0.0122\n",
      "Epoch: 3000 loss_train: 0.0074\n",
      "Epoch: 3500 loss_train: 0.0268\n",
      "Epoch: 4000 loss_train: 0.0041\n",
      "Epoch: 4500 loss_train: 0.0016\n",
      "Epoch: 5000 loss_train: 0.0121\n",
      "Epoch: 5500 loss_train: 0.0321\n",
      " total time: 7.4434s\n",
      "9.205677032470703\n",
      "Epoch: 0000 loss_train: 1.3903\n",
      "Epoch: 0500 loss_train: 0.0803\n",
      "Epoch: 1000 loss_train: 0.0589\n",
      "Epoch: 1500 loss_train: 0.0474\n",
      "Epoch: 2000 loss_train: 0.0209\n",
      "Epoch: 2500 loss_train: 0.0124\n",
      "Epoch: 3000 loss_train: 0.0145\n",
      "Epoch: 3500 loss_train: 0.0080\n",
      "Epoch: 4000 loss_train: 0.0179\n",
      "Epoch: 4500 loss_train: 0.0012\n",
      "Epoch: 5000 loss_train: 0.0036\n",
      "Epoch: 5500 loss_train: 0.0441\n",
      " total time: 7.4517s\n",
      "4.887569048150908e-06\n",
      "Epoch: 0000 loss_train: 1.3901\n",
      "Epoch: 0500 loss_train: 0.0830\n",
      "Epoch: 1000 loss_train: 0.0615\n",
      "Epoch: 1500 loss_train: 0.0381\n",
      "Epoch: 2000 loss_train: 0.0121\n",
      "Epoch: 2500 loss_train: 0.0099\n",
      "Epoch: 3000 loss_train: 0.0194\n",
      "Epoch: 3500 loss_train: 0.0407\n",
      "Epoch: 4000 loss_train: 0.0153\n",
      "Epoch: 4500 loss_train: 0.0143\n",
      "Epoch: 5000 loss_train: 0.0065\n",
      "Epoch: 5500 loss_train: 0.0191\n",
      " total time: 7.4342s\n",
      "2.3841855067985307e-07\n",
      "Epoch: 0000 loss_train: 1.3901\n",
      "Epoch: 0500 loss_train: 0.0870\n",
      "Epoch: 1000 loss_train: 0.0508\n",
      "Epoch: 1500 loss_train: 0.0396\n",
      "Epoch: 2000 loss_train: 0.0089\n",
      "Epoch: 2500 loss_train: 0.0077\n",
      "Epoch: 3000 loss_train: 0.0195\n",
      "Epoch: 3500 loss_train: 0.0211\n",
      "Epoch: 4000 loss_train: 0.0117\n",
      "Epoch: 4500 loss_train: 0.0055\n",
      "Epoch: 5000 loss_train: 0.0176\n",
      "Epoch: 5500 loss_train: 0.0224\n",
      " total time: 7.4022s\n",
      "1.6689286894688848e-06\n",
      "Epoch: 0000 loss_train: 1.3900\n",
      "Epoch: 0500 loss_train: 0.1031\n",
      "Epoch: 1000 loss_train: 0.0354\n",
      "Epoch: 1500 loss_train: 0.0393\n",
      "Epoch: 2000 loss_train: 0.0090\n",
      "Epoch: 2500 loss_train: 0.0117\n",
      "Epoch: 3000 loss_train: 0.0163\n",
      "Epoch: 3500 loss_train: 0.0124\n",
      "Epoch: 4000 loss_train: 0.0227\n",
      "Epoch: 4500 loss_train: 0.0196\n",
      "Epoch: 5000 loss_train: 0.0011\n",
      "Epoch: 5500 loss_train: 0.0259\n",
      " total time: 7.4457s\n",
      "0.012380886822938919\n",
      "Epoch: 0000 loss_train: 1.3899\n",
      "Epoch: 0500 loss_train: 0.0816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1000 loss_train: 0.0512\n",
      "Epoch: 1500 loss_train: 0.0294\n",
      "Epoch: 2000 loss_train: 0.0096\n",
      "Epoch: 2500 loss_train: 0.0054\n",
      "Epoch: 3000 loss_train: 0.0201\n",
      "Epoch: 3500 loss_train: 0.0167\n",
      "Epoch: 4000 loss_train: 0.0312\n",
      "Epoch: 4500 loss_train: 0.0518\n",
      "Epoch: 5000 loss_train: 0.0015\n",
      "Epoch: 5500 loss_train: 0.0201\n",
      " total time: 7.4652s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3900\n",
      "Epoch: 0500 loss_train: 0.0871\n",
      "Epoch: 1000 loss_train: 0.0610\n",
      "Epoch: 1500 loss_train: 0.0302\n",
      "Epoch: 2000 loss_train: 0.0240\n",
      "Epoch: 2500 loss_train: 0.0156\n",
      "Epoch: 3000 loss_train: 0.0189\n",
      "Epoch: 3500 loss_train: 0.0139\n",
      "Epoch: 4000 loss_train: 0.0242\n",
      "Epoch: 4500 loss_train: 0.0020\n",
      "Epoch: 5000 loss_train: 0.0017\n",
      "Epoch: 5500 loss_train: 0.0287\n",
      " total time: 7.4525s\n",
      "3.421248038648628e-05\n",
      "Epoch: 0000 loss_train: 1.3899\n",
      "Epoch: 0500 loss_train: 0.0845\n",
      "Epoch: 1000 loss_train: 0.0673\n",
      "Epoch: 1500 loss_train: 0.0286\n",
      "Epoch: 2000 loss_train: 0.0070\n",
      "Epoch: 2500 loss_train: 0.0068\n",
      "Epoch: 3000 loss_train: 0.0227\n",
      "Epoch: 3500 loss_train: 0.0070\n",
      "Epoch: 4000 loss_train: 0.0978\n",
      "Epoch: 4500 loss_train: 0.0068\n",
      "Epoch: 5000 loss_train: 0.0025\n",
      "Epoch: 5500 loss_train: 0.0183\n",
      " total time: 7.4574s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3898\n",
      "Epoch: 0500 loss_train: 0.0748\n",
      "Epoch: 1000 loss_train: 0.0654\n",
      "Epoch: 1500 loss_train: 0.0233\n",
      "Epoch: 2000 loss_train: 0.0092\n",
      "Epoch: 2500 loss_train: 0.0195\n",
      "Epoch: 3000 loss_train: 0.0196\n",
      "Epoch: 3500 loss_train: 0.0219\n",
      "Epoch: 4000 loss_train: 0.0416\n",
      "Epoch: 4500 loss_train: 0.0077\n",
      "Epoch: 5000 loss_train: 0.0027\n",
      "Epoch: 5500 loss_train: 0.0256\n",
      " total time: 7.3391s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3899\n",
      "Epoch: 0500 loss_train: 0.0552\n",
      "Epoch: 1000 loss_train: 0.0587\n",
      "Epoch: 1500 loss_train: 0.0338\n",
      "Epoch: 2000 loss_train: 0.0170\n",
      "Epoch: 2500 loss_train: 0.0067\n",
      "Epoch: 3000 loss_train: 0.0114\n",
      "Epoch: 3500 loss_train: 0.0107\n",
      "Epoch: 4000 loss_train: 0.0106\n",
      "Epoch: 4500 loss_train: 0.0599\n",
      "Epoch: 5000 loss_train: 0.0122\n",
      "Epoch: 5500 loss_train: 0.0194\n",
      " total time: 7.4554s\n",
      "61.29343032836914\n",
      "Epoch: 0000 loss_train: 1.3900\n",
      "Epoch: 0500 loss_train: 0.0808\n",
      "Epoch: 1000 loss_train: 0.0681\n",
      "Epoch: 1500 loss_train: 0.0449\n",
      "Epoch: 2000 loss_train: 0.0094\n",
      "Epoch: 2500 loss_train: 0.0060\n",
      "Epoch: 3000 loss_train: 0.0209\n",
      "Epoch: 3500 loss_train: 0.0291\n",
      "Epoch: 4000 loss_train: 0.0354\n",
      "Epoch: 4500 loss_train: 0.0025\n",
      "Epoch: 5000 loss_train: 0.0054\n",
      "Epoch: 5500 loss_train: 0.0197\n",
      " total time: 7.4623s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3901\n",
      "Epoch: 0500 loss_train: 0.1009\n",
      "Epoch: 1000 loss_train: 0.0764\n",
      "Epoch: 1500 loss_train: 0.0476\n",
      "Epoch: 2000 loss_train: 0.0095\n",
      "Epoch: 2500 loss_train: 0.0074\n",
      "Epoch: 3000 loss_train: 0.0190\n",
      "Epoch: 3500 loss_train: 0.0332\n",
      "Epoch: 4000 loss_train: 0.0051\n",
      "Epoch: 4500 loss_train: 0.0018\n",
      "Epoch: 5000 loss_train: 0.0029\n",
      "Epoch: 5500 loss_train: 0.0204\n",
      " total time: 7.4499s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3898\n",
      "Epoch: 0500 loss_train: 0.0881\n",
      "Epoch: 1000 loss_train: 0.0749\n",
      "Epoch: 1500 loss_train: 0.0262\n",
      "Epoch: 2000 loss_train: 0.0106\n",
      "Epoch: 2500 loss_train: 0.0097\n",
      "Epoch: 3000 loss_train: 0.0147\n",
      "Epoch: 3500 loss_train: 0.0129\n",
      "Epoch: 4000 loss_train: 0.0180\n",
      "Epoch: 4500 loss_train: 0.0080\n",
      "Epoch: 5000 loss_train: 0.0041\n",
      "Epoch: 5500 loss_train: 0.0057\n",
      " total time: 7.4469s\n",
      "0.0006556744920089841\n",
      "Epoch: 0000 loss_train: 1.3898\n",
      "Epoch: 0500 loss_train: 0.0847\n",
      "Epoch: 1000 loss_train: 0.0752\n",
      "Epoch: 1500 loss_train: 0.0309\n",
      "Epoch: 2000 loss_train: 0.0103\n",
      "Epoch: 2500 loss_train: 0.0093\n",
      "Epoch: 3000 loss_train: 0.0237\n",
      "Epoch: 3500 loss_train: 0.0060\n",
      "Epoch: 4000 loss_train: 0.0204\n",
      "Epoch: 4500 loss_train: 0.0130\n",
      "Epoch: 5000 loss_train: 0.0107\n",
      "Epoch: 5500 loss_train: 0.0363\n",
      " total time: 7.4597s\n",
      "0.5254855155944824\n",
      "Epoch: 0000 loss_train: 1.3897\n",
      "Epoch: 0500 loss_train: 0.0822\n",
      "Epoch: 1000 loss_train: 0.0903\n",
      "Epoch: 1500 loss_train: 0.0357\n",
      "Epoch: 2000 loss_train: 0.0111\n",
      "Epoch: 2500 loss_train: 0.0048\n",
      "Epoch: 3000 loss_train: 0.0066\n",
      "Epoch: 3500 loss_train: 0.0186\n",
      "Epoch: 4000 loss_train: 0.0202\n",
      "Epoch: 4500 loss_train: 0.0017\n",
      "Epoch: 5000 loss_train: 0.0136\n",
      "Epoch: 5500 loss_train: 0.0279\n",
      " total time: 7.4453s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3894\n",
      "Epoch: 0500 loss_train: 0.0564\n",
      "Epoch: 1000 loss_train: 0.0404\n",
      "Epoch: 1500 loss_train: 0.0441\n",
      "Epoch: 2000 loss_train: 0.0101\n",
      "Epoch: 2500 loss_train: 0.0049\n",
      "Epoch: 3000 loss_train: 0.0064\n",
      "Epoch: 3500 loss_train: 0.0031\n",
      "Epoch: 4000 loss_train: 0.0581\n",
      "Epoch: 4500 loss_train: 0.0072\n",
      "Epoch: 5000 loss_train: 0.0028\n",
      "Epoch: 5500 loss_train: 0.0519\n",
      " total time: 7.3888s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3888\n",
      "Epoch: 0500 loss_train: 0.0842\n",
      "Epoch: 1000 loss_train: 0.0303\n",
      "Epoch: 1500 loss_train: 0.0381\n",
      "Epoch: 2000 loss_train: 0.0127\n",
      "Epoch: 2500 loss_train: 0.0082\n",
      "Epoch: 3000 loss_train: 0.0087\n",
      "Epoch: 3500 loss_train: 0.0053\n",
      "Epoch: 4000 loss_train: 0.0101\n",
      "Epoch: 4500 loss_train: 0.0029\n",
      "Epoch: 5000 loss_train: 0.0032\n",
      "Epoch: 5500 loss_train: 0.0252\n",
      " total time: 7.4500s\n",
      "0.0006877202540636063\n",
      "Epoch: 0000 loss_train: 1.3880\n",
      "Epoch: 0500 loss_train: 0.0616\n",
      "Epoch: 1000 loss_train: 0.0413\n",
      "Epoch: 1500 loss_train: 0.0259\n",
      "Epoch: 2000 loss_train: 0.0201\n",
      "Epoch: 2500 loss_train: 0.0115\n",
      "Epoch: 3000 loss_train: 0.0154\n",
      "Epoch: 3500 loss_train: 0.0103\n",
      "Epoch: 4000 loss_train: 0.0220\n",
      "Epoch: 4500 loss_train: 0.0233\n",
      "Epoch: 5000 loss_train: 0.0031\n",
      "Epoch: 5500 loss_train: 0.0421\n",
      " total time: 7.4573s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3890\n",
      "Epoch: 0500 loss_train: 0.0649\n",
      "Epoch: 1000 loss_train: 0.0427\n",
      "Epoch: 1500 loss_train: 0.0321\n",
      "Epoch: 2000 loss_train: 0.0133\n",
      "Epoch: 2500 loss_train: 0.0077\n",
      "Epoch: 3000 loss_train: 0.0105\n",
      "Epoch: 3500 loss_train: 0.0074\n",
      "Epoch: 4000 loss_train: 0.0376\n",
      "Epoch: 4500 loss_train: 0.0048\n",
      "Epoch: 5000 loss_train: 0.0098\n",
      "Epoch: 5500 loss_train: 0.0278\n",
      " total time: 7.4350s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3890\n",
      "Epoch: 0500 loss_train: 0.0649\n",
      "Epoch: 1000 loss_train: 0.0427\n",
      "Epoch: 1500 loss_train: 0.0321\n",
      "Epoch: 2000 loss_train: 0.0133\n",
      "Epoch: 2500 loss_train: 0.0077\n",
      "Epoch: 3000 loss_train: 0.0105\n",
      "Epoch: 3500 loss_train: 0.0074\n",
      "Epoch: 4000 loss_train: 0.0376\n",
      "Epoch: 4500 loss_train: 0.0048\n",
      "Epoch: 5000 loss_train: 0.0098\n",
      "Epoch: 5500 loss_train: 0.0278\n",
      " total time: 7.4521s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3889\n",
      "Epoch: 0500 loss_train: 0.0916\n",
      "Epoch: 1000 loss_train: 0.0353\n",
      "Epoch: 1500 loss_train: 0.0221\n",
      "Epoch: 2000 loss_train: 0.0153\n",
      "Epoch: 2500 loss_train: 0.0227\n",
      "Epoch: 3000 loss_train: 0.0123\n",
      "Epoch: 3500 loss_train: 0.0131\n",
      "Epoch: 4000 loss_train: 0.0271\n",
      "Epoch: 4500 loss_train: 0.0017\n",
      "Epoch: 5000 loss_train: 0.0123\n",
      "Epoch: 5500 loss_train: 0.0192\n",
      " total time: 7.4602s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3889\n",
      "Epoch: 0500 loss_train: 0.0765\n",
      "Epoch: 1000 loss_train: 0.0359\n",
      "Epoch: 1500 loss_train: 0.0389\n",
      "Epoch: 2000 loss_train: 0.0106\n",
      "Epoch: 2500 loss_train: 0.0123\n",
      "Epoch: 3000 loss_train: 0.0182\n",
      "Epoch: 3500 loss_train: 0.0095\n",
      "Epoch: 4000 loss_train: 0.0532\n",
      "Epoch: 4500 loss_train: 0.0076\n",
      "Epoch: 5000 loss_train: 0.0240\n",
      "Epoch: 5500 loss_train: 0.0201\n",
      " total time: 7.4545s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3889\n",
      "Epoch: 0500 loss_train: 0.0861\n",
      "Epoch: 1000 loss_train: 0.0316\n",
      "Epoch: 1500 loss_train: 0.0259\n",
      "Epoch: 2000 loss_train: 0.0148\n",
      "Epoch: 2500 loss_train: 0.0103\n",
      "Epoch: 3000 loss_train: 0.0069\n",
      "Epoch: 3500 loss_train: 0.0176\n",
      "Epoch: 4000 loss_train: 0.0146\n",
      "Epoch: 4500 loss_train: 0.0027\n",
      "Epoch: 5000 loss_train: 0.0023\n",
      "Epoch: 5500 loss_train: 0.0219\n",
      " total time: 7.4476s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3889\n",
      "Epoch: 0500 loss_train: 0.0618\n",
      "Epoch: 1000 loss_train: 0.0360\n",
      "Epoch: 1500 loss_train: 0.0442\n",
      "Epoch: 2000 loss_train: 0.0198\n",
      "Epoch: 2500 loss_train: 0.0141\n",
      "Epoch: 3000 loss_train: 0.0182\n",
      "Epoch: 3500 loss_train: 0.0151\n",
      "Epoch: 4000 loss_train: 0.0386\n",
      "Epoch: 4500 loss_train: 0.0018\n",
      "Epoch: 5000 loss_train: 0.0013\n",
      "Epoch: 5500 loss_train: 0.0279\n",
      " total time: 7.4347s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3891\n",
      "Epoch: 0500 loss_train: 0.0799\n",
      "Epoch: 1000 loss_train: 0.0396\n",
      "Epoch: 1500 loss_train: 0.0488\n",
      "Epoch: 2000 loss_train: 0.0194\n",
      "Epoch: 2500 loss_train: 0.0129\n",
      "Epoch: 3000 loss_train: 0.0166\n",
      "Epoch: 3500 loss_train: 0.0237\n",
      "Epoch: 4000 loss_train: 0.0273\n",
      "Epoch: 4500 loss_train: 0.0029\n",
      "Epoch: 5000 loss_train: 0.0077\n",
      "Epoch: 5500 loss_train: 0.0254\n",
      " total time: 7.4552s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3890\n",
      "Epoch: 0500 loss_train: 0.1002\n",
      "Epoch: 1000 loss_train: 0.0379\n",
      "Epoch: 1500 loss_train: 0.0288\n",
      "Epoch: 2000 loss_train: 0.0156\n",
      "Epoch: 2500 loss_train: 0.0112\n",
      "Epoch: 3000 loss_train: 0.0117\n",
      "Epoch: 3500 loss_train: 0.0131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4000 loss_train: 0.0369\n",
      "Epoch: 4500 loss_train: 0.0009\n",
      "Epoch: 5000 loss_train: 0.0030\n",
      "Epoch: 5500 loss_train: 0.0395\n",
      " total time: 7.4488s\n",
      "0.00014232576359063387\n",
      "Epoch: 0000 loss_train: 1.3889\n",
      "Epoch: 0500 loss_train: 0.0848\n",
      "Epoch: 1000 loss_train: 0.0431\n",
      "Epoch: 1500 loss_train: 0.0403\n",
      "Epoch: 2000 loss_train: 0.0130\n",
      "Epoch: 2500 loss_train: 0.0113\n",
      "Epoch: 3000 loss_train: 0.0128\n",
      "Epoch: 3500 loss_train: 0.0039\n",
      "Epoch: 4000 loss_train: 0.0461\n",
      "Epoch: 4500 loss_train: 0.0050\n",
      "Epoch: 5000 loss_train: 0.0035\n",
      "Epoch: 5500 loss_train: 0.0221\n",
      " total time: 7.4663s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3886\n",
      "Epoch: 0500 loss_train: 0.0584\n",
      "Epoch: 1000 loss_train: 0.0334\n",
      "Epoch: 1500 loss_train: 0.0302\n",
      "Epoch: 2000 loss_train: 0.0184\n",
      "Epoch: 2500 loss_train: 0.0118\n",
      "Epoch: 3000 loss_train: 0.0166\n",
      "Epoch: 3500 loss_train: 0.0042\n",
      "Epoch: 4000 loss_train: 0.0582\n",
      "Epoch: 4500 loss_train: 0.0038\n",
      "Epoch: 5000 loss_train: 0.0111\n",
      "Epoch: 5500 loss_train: 0.0472\n",
      " total time: 7.4661s\n",
      "3.325251340866089\n",
      "Epoch: 0000 loss_train: 1.3898\n",
      "Epoch: 0500 loss_train: 0.0703\n",
      "Epoch: 1000 loss_train: 0.0223\n",
      "Epoch: 1500 loss_train: 0.0239\n",
      "Epoch: 2000 loss_train: 0.0237\n",
      "Epoch: 2500 loss_train: 0.0066\n",
      "Epoch: 3000 loss_train: 0.0051\n",
      "Epoch: 3500 loss_train: 0.0101\n",
      "Epoch: 4000 loss_train: 0.0279\n",
      "Epoch: 4500 loss_train: 0.0015\n",
      "Epoch: 5000 loss_train: 0.0118\n",
      "Epoch: 5500 loss_train: 0.0138\n",
      " total time: 7.3445s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3895\n",
      "Epoch: 0500 loss_train: 0.0518\n",
      "Epoch: 1000 loss_train: 0.0335\n",
      "Epoch: 1500 loss_train: 0.0206\n",
      "Epoch: 2000 loss_train: 0.0190\n",
      "Epoch: 2500 loss_train: 0.0069\n",
      "Epoch: 3000 loss_train: 0.0180\n",
      "Epoch: 3500 loss_train: 0.0094\n",
      "Epoch: 4000 loss_train: 0.0393\n",
      "Epoch: 4500 loss_train: 0.0020\n",
      "Epoch: 5000 loss_train: 0.0052\n",
      "Epoch: 5500 loss_train: 0.0106\n",
      " total time: 7.4791s\n",
      "4.613293276634067e-05\n",
      "Epoch: 0000 loss_train: 1.3897\n",
      "Epoch: 0500 loss_train: 0.0677\n",
      "Epoch: 1000 loss_train: 0.0313\n",
      "Epoch: 1500 loss_train: 0.0205\n",
      "Epoch: 2000 loss_train: 0.0272\n",
      "Epoch: 2500 loss_train: 0.0154\n",
      "Epoch: 3000 loss_train: 0.0040\n",
      "Epoch: 3500 loss_train: 0.0196\n",
      "Epoch: 4000 loss_train: 0.0404\n",
      "Epoch: 4500 loss_train: 0.0034\n",
      "Epoch: 5000 loss_train: 0.0109\n",
      "Epoch: 5500 loss_train: 0.0358\n",
      " total time: 7.4681s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3903\n",
      "Epoch: 0500 loss_train: 0.0730\n",
      "Epoch: 1000 loss_train: 0.0299\n",
      "Epoch: 1500 loss_train: 0.0170\n",
      "Epoch: 2000 loss_train: 0.0213\n",
      "Epoch: 2500 loss_train: 0.0063\n",
      "Epoch: 3000 loss_train: 0.0035\n",
      "Epoch: 3500 loss_train: 0.0178\n",
      "Epoch: 4000 loss_train: 0.0432\n",
      "Epoch: 4500 loss_train: 0.0071\n",
      "Epoch: 5000 loss_train: 0.0031\n",
      "Epoch: 5500 loss_train: 0.0422\n",
      " total time: 7.5003s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3901\n",
      "Epoch: 0500 loss_train: 0.0521\n",
      "Epoch: 1000 loss_train: 0.0337\n",
      "Epoch: 1500 loss_train: 0.0247\n",
      "Epoch: 2000 loss_train: 0.0144\n",
      "Epoch: 2500 loss_train: 0.0168\n",
      "Epoch: 3000 loss_train: 0.0108\n",
      "Epoch: 3500 loss_train: 0.0130\n",
      "Epoch: 4000 loss_train: 0.0151\n",
      "Epoch: 4500 loss_train: 0.0018\n",
      "Epoch: 5000 loss_train: 0.0034\n",
      "Epoch: 5500 loss_train: 0.0297\n",
      " total time: 7.7365s\n",
      "1.4653321504592896\n",
      "Epoch: 0000 loss_train: 1.3892\n",
      "Epoch: 0500 loss_train: 0.0712\n",
      "Epoch: 1000 loss_train: 0.0324\n",
      "Epoch: 1500 loss_train: 0.0240\n",
      "Epoch: 2000 loss_train: 0.0076\n",
      "Epoch: 2500 loss_train: 0.0066\n",
      "Epoch: 3000 loss_train: 0.0251\n",
      "Epoch: 3500 loss_train: 0.0203\n",
      "Epoch: 4000 loss_train: 0.0133\n",
      "Epoch: 4500 loss_train: 0.0065\n",
      "Epoch: 5000 loss_train: 0.0062\n",
      "Epoch: 5500 loss_train: 0.0569\n",
      " total time: 7.7377s\n",
      "5.960462772236497e-07\n",
      "Epoch: 0000 loss_train: 1.3895\n",
      "Epoch: 0500 loss_train: 0.0603\n",
      "Epoch: 1000 loss_train: 0.0257\n",
      "Epoch: 1500 loss_train: 0.0219\n",
      "Epoch: 2000 loss_train: 0.0150\n",
      "Epoch: 2500 loss_train: 0.0103\n",
      "Epoch: 3000 loss_train: 0.0417\n",
      "Epoch: 3500 loss_train: 0.0102\n",
      "Epoch: 4000 loss_train: 0.0186\n",
      "Epoch: 4500 loss_train: 0.0300\n",
      "Epoch: 5000 loss_train: 0.0043\n",
      "Epoch: 5500 loss_train: 0.0332\n",
      " total time: 7.7328s\n",
      "0.5184165239334106\n",
      "Epoch: 0000 loss_train: 1.3899\n",
      "Epoch: 0500 loss_train: 0.0619\n",
      "Epoch: 1000 loss_train: 0.0363\n",
      "Epoch: 1500 loss_train: 0.0142\n",
      "Epoch: 2000 loss_train: 0.0169\n",
      "Epoch: 2500 loss_train: 0.0244\n",
      "Epoch: 3000 loss_train: 0.0227\n",
      "Epoch: 3500 loss_train: 0.0600\n",
      "Epoch: 4000 loss_train: 0.0208\n",
      "Epoch: 4500 loss_train: 0.0069\n",
      "Epoch: 5000 loss_train: 0.0156\n",
      "Epoch: 5500 loss_train: 0.0107\n",
      " total time: 7.5972s\n",
      "20.79175567626953\n",
      "Epoch: 0000 loss_train: 1.3907\n",
      "Epoch: 0500 loss_train: 0.0722\n",
      "Epoch: 1000 loss_train: 0.0263\n",
      "Epoch: 1500 loss_train: 0.0292\n",
      "Epoch: 2000 loss_train: 0.0179\n",
      "Epoch: 2500 loss_train: 0.0301\n",
      "Epoch: 3000 loss_train: 0.0181\n",
      "Epoch: 3500 loss_train: 0.0342\n",
      "Epoch: 4000 loss_train: 0.0432\n",
      "Epoch: 4500 loss_train: 0.0027\n",
      "Epoch: 5000 loss_train: 0.0068\n",
      "Epoch: 5500 loss_train: 0.0290\n",
      " total time: 7.3458s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3907\n",
      "Epoch: 0500 loss_train: 0.0602\n",
      "Epoch: 1000 loss_train: 0.0263\n",
      "Epoch: 1500 loss_train: 0.0228\n",
      "Epoch: 2000 loss_train: 0.0176\n",
      "Epoch: 2500 loss_train: 0.0328\n",
      "Epoch: 3000 loss_train: 0.0232\n",
      "Epoch: 3500 loss_train: 0.0262\n",
      "Epoch: 4000 loss_train: 0.0173\n",
      "Epoch: 4500 loss_train: 0.0069\n",
      "Epoch: 5000 loss_train: 0.0078\n",
      "Epoch: 5500 loss_train: 0.0026\n",
      " total time: 7.4496s\n",
      "0.0011511372867971659\n",
      "Epoch: 0000 loss_train: 1.3907\n",
      "Epoch: 0500 loss_train: 0.0650\n",
      "Epoch: 1000 loss_train: 0.0421\n",
      "Epoch: 1500 loss_train: 0.0256\n",
      "Epoch: 2000 loss_train: 0.0182\n",
      "Epoch: 2500 loss_train: 0.0511\n",
      "Epoch: 3000 loss_train: 0.0160\n",
      "Epoch: 3500 loss_train: 0.0125\n",
      "Epoch: 4000 loss_train: 0.0515\n",
      "Epoch: 4500 loss_train: 0.0039\n",
      "Epoch: 5000 loss_train: 0.0115\n",
      "Epoch: 5500 loss_train: 0.0172\n",
      " total time: 7.4418s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3907\n",
      "Epoch: 0500 loss_train: 0.0739\n",
      "Epoch: 1000 loss_train: 0.0376\n",
      "Epoch: 1500 loss_train: 0.0333\n",
      "Epoch: 2000 loss_train: 0.0120\n",
      "Epoch: 2500 loss_train: 0.0486\n",
      "Epoch: 3000 loss_train: 0.0125\n",
      "Epoch: 3500 loss_train: 0.0417\n",
      "Epoch: 4000 loss_train: 0.0158\n",
      "Epoch: 4500 loss_train: 0.0084\n",
      "Epoch: 5000 loss_train: 0.0050\n",
      "Epoch: 5500 loss_train: 0.0371\n",
      " total time: 7.4397s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3907\n",
      "Epoch: 0500 loss_train: 0.0679\n",
      "Epoch: 1000 loss_train: 0.0342\n",
      "Epoch: 1500 loss_train: 0.0260\n",
      "Epoch: 2000 loss_train: 0.0124\n",
      "Epoch: 2500 loss_train: 0.0567\n",
      "Epoch: 3000 loss_train: 0.0176\n",
      "Epoch: 3500 loss_train: 0.0112\n",
      "Epoch: 4000 loss_train: 0.0319\n",
      "Epoch: 4500 loss_train: 0.0038\n",
      "Epoch: 5000 loss_train: 0.0173\n",
      "Epoch: 5500 loss_train: 0.0359\n",
      " total time: 7.4685s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3908\n",
      "Epoch: 0500 loss_train: 0.0673\n",
      "Epoch: 1000 loss_train: 0.0437\n",
      "Epoch: 1500 loss_train: 0.0340\n",
      "Epoch: 2000 loss_train: 0.0159\n",
      "Epoch: 2500 loss_train: 0.0395\n",
      "Epoch: 3000 loss_train: 0.0139\n",
      "Epoch: 3500 loss_train: 0.0158\n",
      "Epoch: 4000 loss_train: 0.0331\n",
      "Epoch: 4500 loss_train: 0.0035\n",
      "Epoch: 5000 loss_train: 0.0112\n",
      "Epoch: 5500 loss_train: 0.0317\n",
      " total time: 7.4476s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3908\n",
      "Epoch: 0500 loss_train: 0.0688\n",
      "Epoch: 1000 loss_train: 0.0660\n",
      "Epoch: 1500 loss_train: 0.0197\n",
      "Epoch: 2000 loss_train: 0.0075\n",
      "Epoch: 2500 loss_train: 0.0100\n",
      "Epoch: 3000 loss_train: 0.0194\n",
      "Epoch: 3500 loss_train: 0.0287\n",
      "Epoch: 4000 loss_train: 0.0095\n",
      "Epoch: 4500 loss_train: 0.0048\n",
      "Epoch: 5000 loss_train: 0.0103\n",
      "Epoch: 5500 loss_train: 0.0581\n",
      " total time: 7.4422s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3908\n",
      "Epoch: 0500 loss_train: 0.0633\n",
      "Epoch: 1000 loss_train: 0.0356\n",
      "Epoch: 1500 loss_train: 0.0257\n",
      "Epoch: 2000 loss_train: 0.0172\n",
      "Epoch: 2500 loss_train: 0.0254\n",
      "Epoch: 3000 loss_train: 0.0173\n",
      "Epoch: 3500 loss_train: 0.0250\n",
      "Epoch: 4000 loss_train: 0.0214\n",
      "Epoch: 4500 loss_train: 0.0141\n",
      "Epoch: 5000 loss_train: 0.0065\n",
      "Epoch: 5500 loss_train: 0.0437\n",
      " total time: 7.4386s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3908\n",
      "Epoch: 0500 loss_train: 0.0706\n",
      "Epoch: 1000 loss_train: 0.0334\n",
      "Epoch: 1500 loss_train: 0.0247\n",
      "Epoch: 2000 loss_train: 0.0160\n",
      "Epoch: 2500 loss_train: 0.0163\n",
      "Epoch: 3000 loss_train: 0.0054\n",
      "Epoch: 3500 loss_train: 0.0084\n",
      "Epoch: 4000 loss_train: 0.0176\n",
      "Epoch: 4500 loss_train: 0.0029\n",
      "Epoch: 5000 loss_train: 0.0201\n",
      "Epoch: 5500 loss_train: 0.0338\n",
      " total time: 7.4460s\n",
      "11.680277824401855\n",
      "Epoch: 0000 loss_train: 1.3908\n",
      "Epoch: 0500 loss_train: 0.0786\n",
      "Epoch: 1000 loss_train: 0.0578\n",
      "Epoch: 3000 loss_train: 0.0094\n",
      "Epoch: 3500 loss_train: 0.0028\n",
      "Epoch: 4000 loss_train: 0.0117\n",
      "Epoch: 4500 loss_train: 0.0034\n",
      "Epoch: 5000 loss_train: 0.0028\n",
      "Epoch: 5500 loss_train: 0.0386\n",
      " total time: 7.4609s\n",
      "0.08154288679361343\n",
      "Epoch: 0000 loss_train: 1.3900\n",
      "Epoch: 0500 loss_train: 0.0887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1000 loss_train: 0.0998\n",
      "Epoch: 1500 loss_train: 0.0213\n",
      "Epoch: 2000 loss_train: 0.0174\n",
      "Epoch: 2500 loss_train: 0.0279\n",
      "Epoch: 3000 loss_train: 0.0053\n",
      "Epoch: 3500 loss_train: 0.0093\n",
      "Epoch: 4000 loss_train: 0.0176\n",
      "Epoch: 4500 loss_train: 0.0021\n",
      "Epoch: 5000 loss_train: 0.0047\n",
      "Epoch: 5500 loss_train: 0.0357\n",
      " total time: 7.4557s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3896\n",
      "Epoch: 0500 loss_train: 0.1117\n",
      "Epoch: 1000 loss_train: 0.0692\n",
      "Epoch: 1500 loss_train: 0.0243\n",
      "Epoch: 2000 loss_train: 0.0127\n",
      "Epoch: 2500 loss_train: 0.0223\n",
      "Epoch: 3000 loss_train: 0.0086\n",
      "Epoch: 3500 loss_train: 0.0021\n",
      "Epoch: 4000 loss_train: 0.1252\n",
      "Epoch: 4500 loss_train: 0.0057\n",
      "Epoch: 5000 loss_train: 0.0074\n",
      "Epoch: 5500 loss_train: 0.0435\n",
      " total time: 7.4534s\n",
      "0.0008045773720368743\n",
      "Epoch: 0000 loss_train: 1.3894\n",
      "Epoch: 0500 loss_train: 0.0891\n",
      "Epoch: 1000 loss_train: 0.0698\n",
      "Epoch: 1500 loss_train: 0.0343\n",
      "Epoch: 2000 loss_train: 0.0201\n",
      "Epoch: 2500 loss_train: 0.0408\n",
      "Epoch: 3000 loss_train: 0.0194\n",
      "Epoch: 3500 loss_train: 0.0053\n",
      "Epoch: 4000 loss_train: 0.0138\n",
      "Epoch: 4500 loss_train: 0.0032\n",
      "Epoch: 5000 loss_train: 0.0017\n",
      "Epoch: 5500 loss_train: 0.0331\n",
      " total time: 7.4586s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3896\n",
      "Epoch: 0500 loss_train: 0.0898\n",
      "Epoch: 1000 loss_train: 0.0664\n",
      "Epoch: 1500 loss_train: 0.0326\n",
      "Epoch: 2000 loss_train: 0.0108\n",
      "Epoch: 2500 loss_train: 0.0128\n",
      "Epoch: 3000 loss_train: 0.0054\n",
      "Epoch: 3500 loss_train: 0.0023\n",
      "Epoch: 4000 loss_train: 0.0204\n",
      "Epoch: 4500 loss_train: 0.0060\n",
      "Epoch: 5000 loss_train: 0.0070\n",
      "Epoch: 5500 loss_train: 0.0667\n",
      " total time: 7.4593s\n",
      "4.623847484588623\n",
      "Epoch: 0000 loss_train: 1.3896\n",
      "Epoch: 0500 loss_train: 0.1098\n",
      "Epoch: 1000 loss_train: 0.0869\n",
      "Epoch: 1500 loss_train: 0.0319\n",
      "Epoch: 2000 loss_train: 0.0167\n",
      "Epoch: 2500 loss_train: 0.0196\n",
      "Epoch: 3000 loss_train: 0.0084\n",
      "Epoch: 3500 loss_train: 0.0071\n",
      "Epoch: 4000 loss_train: 0.0351\n",
      "Epoch: 4500 loss_train: 0.0057\n",
      "Epoch: 5000 loss_train: 0.0062\n",
      "Epoch: 5500 loss_train: 0.0264\n",
      " total time: 7.4572s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3897\n",
      "Epoch: 0500 loss_train: 0.0919\n",
      "Epoch: 1000 loss_train: 0.1042\n",
      "Epoch: 1500 loss_train: 0.0466\n",
      "Epoch: 2000 loss_train: 0.0113\n",
      "Epoch: 2500 loss_train: 0.0320\n",
      "Epoch: 3000 loss_train: 0.0067\n",
      "Epoch: 3500 loss_train: 0.0021\n",
      "Epoch: 4000 loss_train: 0.0352\n",
      "Epoch: 4500 loss_train: 0.0047\n",
      "Epoch: 5000 loss_train: 0.0513\n",
      "Epoch: 5500 loss_train: 0.0457\n",
      " total time: 7.4336s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3897\n",
      "Epoch: 0500 loss_train: 0.0942\n",
      "Epoch: 1000 loss_train: 0.0957\n",
      "Epoch: 1500 loss_train: 0.0551\n",
      "Epoch: 2000 loss_train: 0.0081\n",
      "Epoch: 2500 loss_train: 0.0133\n",
      "Epoch: 3000 loss_train: 0.0102\n",
      "Epoch: 3500 loss_train: 0.0121\n",
      "Epoch: 4000 loss_train: 0.0362\n",
      "Epoch: 4500 loss_train: 0.0054\n",
      "Epoch: 5000 loss_train: 0.0129\n",
      "Epoch: 5500 loss_train: 0.0496\n",
      " total time: 7.4025s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3896\n",
      "Epoch: 0500 loss_train: 0.1241\n",
      "Epoch: 1000 loss_train: 0.1050\n",
      "Epoch: 1500 loss_train: 0.0297\n",
      "Epoch: 2000 loss_train: 0.0164\n",
      "Epoch: 2500 loss_train: 0.0254\n",
      "Epoch: 3000 loss_train: 0.0044\n",
      "Epoch: 3500 loss_train: 0.0071\n",
      "Epoch: 4000 loss_train: 0.0252\n",
      "Epoch: 4500 loss_train: 0.0038\n",
      "Epoch: 5000 loss_train: 0.0066\n",
      "Epoch: 5500 loss_train: 0.0243\n",
      " total time: 7.4594s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3897\n",
      "Epoch: 0500 loss_train: 0.1017\n",
      "Epoch: 1000 loss_train: 0.0971\n",
      "Epoch: 1500 loss_train: 0.0416\n",
      "Epoch: 2000 loss_train: 0.0162\n",
      "Epoch: 2500 loss_train: 0.0608\n",
      "Epoch: 3000 loss_train: 0.0060\n",
      "Epoch: 3500 loss_train: 0.0261\n",
      "Epoch: 4000 loss_train: 0.0557\n",
      "Epoch: 4500 loss_train: 0.0026\n",
      "Epoch: 5000 loss_train: 0.0033\n",
      "Epoch: 5500 loss_train: 0.0494\n",
      " total time: 7.4534s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3899\n",
      "Epoch: 0500 loss_train: 0.1106\n",
      "Epoch: 1000 loss_train: 0.0786\n",
      "Epoch: 1500 loss_train: 0.0311\n",
      "Epoch: 2000 loss_train: 0.0054\n",
      "Epoch: 2500 loss_train: 0.0367\n",
      "Epoch: 3000 loss_train: 0.0034\n",
      "Epoch: 3500 loss_train: 0.0049\n",
      "Epoch: 4000 loss_train: 0.0137\n",
      "Epoch: 4500 loss_train: 0.0025\n",
      "Epoch: 5000 loss_train: 0.0037\n",
      "Epoch: 5500 loss_train: 0.0360\n",
      " total time: 7.4531s\n",
      "9.847234725952148\n",
      "Epoch: 0000 loss_train: 1.3902\n",
      "Epoch: 0500 loss_train: 0.0989\n",
      "Epoch: 1000 loss_train: 0.0823\n",
      "Epoch: 1500 loss_train: 0.0431\n",
      "Epoch: 2000 loss_train: 0.0062\n",
      "Epoch: 2500 loss_train: 0.0153\n",
      "Epoch: 3000 loss_train: 0.0118\n",
      "Epoch: 3500 loss_train: 0.0069\n",
      "Epoch: 4000 loss_train: 0.0284\n",
      "Epoch: 4500 loss_train: 0.0029\n",
      "Epoch: 5000 loss_train: 0.0018\n",
      "Epoch: 5500 loss_train: 0.0578\n",
      " total time: 7.4525s\n",
      "0.008558617904782295\n",
      "Epoch: 0000 loss_train: 1.3890\n",
      "Epoch: 0500 loss_train: 0.1183\n",
      "Epoch: 1000 loss_train: 0.1058\n",
      "Epoch: 1500 loss_train: 0.0301\n",
      "Epoch: 2000 loss_train: 0.0115\n",
      "Epoch: 2500 loss_train: 0.0082\n",
      "Epoch: 3000 loss_train: 0.0025\n",
      "Epoch: 3500 loss_train: 0.0103\n",
      "Epoch: 4000 loss_train: 0.0443\n",
      "Epoch: 4500 loss_train: 0.0039\n",
      "Epoch: 5000 loss_train: 0.0038\n",
      "Epoch: 5500 loss_train: 0.0358\n",
      " total time: 7.4503s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3906\n",
      "Epoch: 0500 loss_train: 0.1102\n",
      "Epoch: 1000 loss_train: 0.0810\n",
      "Epoch: 1500 loss_train: 0.0268\n",
      "Epoch: 2000 loss_train: 0.0380\n",
      "Epoch: 2500 loss_train: 0.0416\n",
      "Epoch: 3000 loss_train: 0.0160\n",
      "Epoch: 3500 loss_train: 0.0059\n",
      "Epoch: 4000 loss_train: 0.0193\n",
      "Epoch: 4500 loss_train: 0.0056\n",
      "Epoch: 5000 loss_train: 0.0080\n",
      "Epoch: 5500 loss_train: 0.0421\n",
      " total time: 7.4607s\n",
      "0.07224462926387787\n",
      "Epoch: 0000 loss_train: 1.3907\n",
      "Epoch: 0500 loss_train: 0.0880\n",
      "Epoch: 1000 loss_train: 0.0830\n",
      "Epoch: 1500 loss_train: 0.0255\n",
      "Epoch: 2000 loss_train: 0.0083\n",
      "Epoch: 2500 loss_train: 0.0263\n",
      "Epoch: 3000 loss_train: 0.0031\n",
      "Epoch: 3500 loss_train: 0.0203\n",
      "Epoch: 4000 loss_train: 0.0348\n",
      "Epoch: 4500 loss_train: 0.0050\n",
      "Epoch: 5000 loss_train: 0.0047\n",
      "Epoch: 5500 loss_train: 0.0145\n",
      " total time: 7.4466s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3909\n",
      "Epoch: 0500 loss_train: 0.1054\n",
      "Epoch: 1000 loss_train: 0.1041\n",
      "Epoch: 1500 loss_train: 0.0329\n",
      "Epoch: 2000 loss_train: 0.0109\n",
      "Epoch: 2500 loss_train: 0.0190\n",
      "Epoch: 3000 loss_train: 0.0064\n",
      "Epoch: 3500 loss_train: 0.0156\n",
      "Epoch: 4000 loss_train: 0.0106\n",
      "Epoch: 4500 loss_train: 0.0082\n",
      "Epoch: 5000 loss_train: 0.0055\n",
      "Epoch: 5500 loss_train: 0.0146\n",
      " total time: 7.4457s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3909\n",
      "Epoch: 0500 loss_train: 0.0864\n",
      "Epoch: 1000 loss_train: 0.0771\n",
      "Epoch: 1500 loss_train: 0.0379\n",
      "Epoch: 2000 loss_train: 0.0155\n",
      "Epoch: 2500 loss_train: 0.0419\n",
      "Epoch: 3000 loss_train: 0.0038\n",
      "Epoch: 3500 loss_train: 0.0066\n",
      "Epoch: 4000 loss_train: 0.0071\n",
      "Epoch: 4500 loss_train: 0.0172\n",
      "Epoch: 5000 loss_train: 0.0078\n",
      "Epoch: 5500 loss_train: 0.0322\n",
      " total time: 7.4514s\n",
      "1.1920928244535389e-07\n",
      "Epoch: 0000 loss_train: 1.3903\n",
      "Epoch: 0500 loss_train: 0.0964\n",
      "Epoch: 1000 loss_train: 0.0834\n",
      "Epoch: 1500 loss_train: 0.0256\n",
      "Epoch: 2000 loss_train: 0.0083\n",
      "Epoch: 2500 loss_train: 0.0594\n",
      "Epoch: 3000 loss_train: 0.0036\n",
      "Epoch: 3500 loss_train: 0.0214\n",
      "Epoch: 4000 loss_train: 0.0778\n",
      "Epoch: 4500 loss_train: 0.0111\n",
      "Epoch: 5000 loss_train: 0.0167\n",
      "Epoch: 5500 loss_train: 0.0119\n",
      " total time: 7.4496s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3913\n",
      "Epoch: 0500 loss_train: 0.1051\n",
      "Epoch: 1000 loss_train: 0.0848\n",
      "Epoch: 1500 loss_train: 0.0364\n",
      "Epoch: 2000 loss_train: 0.0225\n",
      "Epoch: 2500 loss_train: 0.0087\n",
      "Epoch: 3000 loss_train: 0.0048\n",
      "Epoch: 3500 loss_train: 0.0047\n",
      "Epoch: 4000 loss_train: 0.0318\n",
      "Epoch: 4500 loss_train: 0.0056\n",
      "Epoch: 5000 loss_train: 0.0050\n",
      "Epoch: 5500 loss_train: 0.0078\n",
      " total time: 7.4563s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3910\n",
      "Epoch: 0500 loss_train: 0.0953\n",
      "Epoch: 1000 loss_train: 0.0811\n",
      "Epoch: 1500 loss_train: 0.0501\n",
      "Epoch: 2000 loss_train: 0.0107\n",
      "Epoch: 2500 loss_train: 0.0259\n",
      "Epoch: 3000 loss_train: 0.0051\n",
      "Epoch: 3500 loss_train: 0.0075\n",
      "Epoch: 4000 loss_train: 0.0583\n",
      "Epoch: 4500 loss_train: 0.0143\n",
      "Epoch: 5000 loss_train: 0.0173\n",
      "Epoch: 5500 loss_train: 0.0595\n",
      " total time: 7.4587s\n",
      "3.0418927669525146\n",
      "Epoch: 0000 loss_train: 1.3910\n",
      "Epoch: 0500 loss_train: 0.0985\n",
      "Epoch: 1000 loss_train: 0.0726\n",
      "Epoch: 1500 loss_train: 0.0569\n",
      "Epoch: 2000 loss_train: 0.0062\n",
      "Epoch: 2500 loss_train: 0.0837\n",
      "Epoch: 3000 loss_train: 0.0056\n",
      "Epoch: 3500 loss_train: 0.0035\n",
      "Epoch: 4000 loss_train: 0.0142\n",
      "Epoch: 4500 loss_train: 0.0012\n",
      "Epoch: 5000 loss_train: 0.0032\n",
      "Epoch: 5500 loss_train: 0.0512\n",
      " total time: 7.4585s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3908\n",
      "Epoch: 0500 loss_train: 0.0960\n",
      "Epoch: 1000 loss_train: 0.0977\n",
      "Epoch: 1500 loss_train: 0.0581\n",
      "Epoch: 2000 loss_train: 0.0122\n",
      "Epoch: 2500 loss_train: 0.0180\n",
      "Epoch: 3000 loss_train: 0.0107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3500 loss_train: 0.0115\n",
      "Epoch: 4000 loss_train: 0.0375\n",
      "Epoch: 4500 loss_train: 0.0064\n",
      "Epoch: 5000 loss_train: 0.0141\n",
      "Epoch: 5500 loss_train: 0.0226\n",
      " total time: 7.4670s\n",
      "2.3841855067985307e-07\n",
      "Epoch: 0000 loss_train: 1.3908\n",
      "Epoch: 0500 loss_train: 0.0929\n",
      "Epoch: 1000 loss_train: 0.0753\n",
      "Epoch: 1500 loss_train: 0.0460\n",
      "Epoch: 2000 loss_train: 0.0052\n",
      "Epoch: 2500 loss_train: 0.0154\n",
      "Epoch: 3000 loss_train: 0.0037\n",
      "Epoch: 3500 loss_train: 0.0049\n",
      "Epoch: 4000 loss_train: 0.0488\n",
      "Epoch: 4500 loss_train: 0.0025\n",
      "Epoch: 5000 loss_train: 0.0030\n",
      "Epoch: 5500 loss_train: 0.0118\n",
      " total time: 7.4697s\n",
      "0.001994883641600609\n",
      "Epoch: 0000 loss_train: 1.3907\n",
      "Epoch: 0500 loss_train: 0.0779\n",
      "Epoch: 1000 loss_train: 0.0891\n",
      "Epoch: 1500 loss_train: 0.0657\n",
      "Epoch: 2000 loss_train: 0.0102\n",
      "Epoch: 2500 loss_train: 0.0124\n",
      "Epoch: 3000 loss_train: 0.0050\n",
      "Epoch: 3500 loss_train: 0.0091\n",
      "Epoch: 4000 loss_train: 0.0240\n",
      "Epoch: 4500 loss_train: 0.0016\n",
      "Epoch: 5000 loss_train: 0.0047\n",
      "Epoch: 5500 loss_train: 0.0406\n",
      " total time: 7.4729s\n",
      "2.1007049083709717\n",
      "Epoch: 0000 loss_train: 1.3906\n",
      "Epoch: 0500 loss_train: 0.0816\n",
      "Epoch: 1000 loss_train: 0.0837\n",
      "Epoch: 1500 loss_train: 0.0445\n",
      "Epoch: 2000 loss_train: 0.0153\n",
      "Epoch: 2500 loss_train: 0.0407\n",
      "Epoch: 3000 loss_train: 0.0131\n",
      "Epoch: 3500 loss_train: 0.0088\n",
      "Epoch: 4000 loss_train: 0.0283\n",
      "Epoch: 4500 loss_train: 0.0133\n",
      "Epoch: 5000 loss_train: 0.0037\n",
      "Epoch: 5500 loss_train: 0.0127\n",
      " total time: 7.4651s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3901\n",
      "Epoch: 0500 loss_train: 0.0853\n",
      "Epoch: 1000 loss_train: 0.0753\n",
      "Epoch: 1500 loss_train: 0.0357\n",
      "Epoch: 2000 loss_train: 0.0051\n",
      "Epoch: 2500 loss_train: 0.0667\n",
      "Epoch: 3000 loss_train: 0.0033\n",
      "Epoch: 3500 loss_train: 0.0062\n",
      "Epoch: 4000 loss_train: 0.0106\n",
      "Epoch: 4500 loss_train: 0.0071\n",
      "Epoch: 5000 loss_train: 0.0070\n",
      "Epoch: 5500 loss_train: 0.0511\n",
      " total time: 7.4511s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3899\n",
      "Epoch: 0500 loss_train: 0.0714\n",
      "Epoch: 1000 loss_train: 0.1130\n",
      "Epoch: 1500 loss_train: 0.0288\n",
      "Epoch: 2000 loss_train: 0.0081\n",
      "Epoch: 2500 loss_train: 0.0126\n",
      "Epoch: 3000 loss_train: 0.0046\n",
      "Epoch: 3500 loss_train: 0.0033\n",
      "Epoch: 4000 loss_train: 0.0101\n",
      "Epoch: 4500 loss_train: 0.0155\n",
      "Epoch: 5000 loss_train: 0.0056\n",
      "Epoch: 5500 loss_train: 0.0009\n",
      " total time: 7.4514s\n",
      "11.866033554077148\n",
      "Epoch: 0000 loss_train: 1.3909\n",
      "Epoch: 0500 loss_train: 0.0843\n",
      "Epoch: 1000 loss_train: 0.1041\n",
      "Epoch: 1500 loss_train: 0.0460\n",
      "Epoch: 2000 loss_train: 0.0070\n",
      "Epoch: 2500 loss_train: 0.0155\n",
      "Epoch: 3000 loss_train: 0.0046\n",
      "Epoch: 3500 loss_train: 0.0025\n",
      "Epoch: 4000 loss_train: 0.0221\n",
      "Epoch: 4500 loss_train: 0.0073\n",
      "Epoch: 5000 loss_train: 0.0158\n",
      "Epoch: 5500 loss_train: 0.0206\n",
      " total time: 7.4615s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3908\n",
      "Epoch: 0500 loss_train: 0.0852\n",
      "Epoch: 1000 loss_train: 0.1062\n",
      "Epoch: 1500 loss_train: 0.0422\n",
      "Epoch: 2000 loss_train: 0.0052\n",
      "Epoch: 2500 loss_train: 0.0175\n",
      "Epoch: 3000 loss_train: 0.0144\n",
      "Epoch: 3500 loss_train: 0.0040\n",
      "Epoch: 4000 loss_train: 0.0055\n",
      "Epoch: 4500 loss_train: 0.0162\n",
      "Epoch: 5000 loss_train: 0.0043\n",
      "Epoch: 5500 loss_train: 0.0331\n",
      " total time: 7.4562s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3908\n",
      "Epoch: 0500 loss_train: 0.0834\n",
      "Epoch: 1000 loss_train: 0.0894\n",
      "Epoch: 1500 loss_train: 0.0444\n",
      "Epoch: 2000 loss_train: 0.0084\n",
      "Epoch: 2500 loss_train: 0.0289\n",
      "Epoch: 3000 loss_train: 0.0044\n",
      "Epoch: 3500 loss_train: 0.0034\n",
      "Epoch: 4000 loss_train: 0.0042\n",
      "Epoch: 4500 loss_train: 0.0195\n",
      "Epoch: 5000 loss_train: 0.0300\n",
      "Epoch: 5500 loss_train: 0.0396\n",
      " total time: 7.4691s\n",
      "2.50339189733495e-06\n",
      "Epoch: 0000 loss_train: 1.3917\n",
      "Epoch: 0500 loss_train: 0.0969\n",
      "Epoch: 1000 loss_train: 0.0922\n",
      "Epoch: 1500 loss_train: 0.0487\n",
      "Epoch: 2000 loss_train: 0.0102\n",
      "Epoch: 2500 loss_train: 0.0102\n",
      "Epoch: 3000 loss_train: 0.0026\n",
      "Epoch: 3500 loss_train: 0.0034\n",
      "Epoch: 4000 loss_train: 0.0107\n",
      "Epoch: 4500 loss_train: 0.0152\n",
      "Epoch: 5000 loss_train: 0.0042\n",
      "Epoch: 5500 loss_train: 0.0493\n",
      " total time: 7.4706s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3933\n",
      "Epoch: 0500 loss_train: 0.0606\n",
      "Epoch: 1000 loss_train: 0.0780\n",
      "Epoch: 1500 loss_train: 0.0548\n",
      "Epoch: 2000 loss_train: 0.0154\n",
      "Epoch: 2500 loss_train: 0.0190\n",
      "Epoch: 3000 loss_train: 0.0044\n",
      "Epoch: 3500 loss_train: 0.0045\n",
      "Epoch: 4000 loss_train: 0.0150\n",
      "Epoch: 4500 loss_train: 0.0026\n",
      "Epoch: 5000 loss_train: 0.0072\n",
      "Epoch: 5500 loss_train: 0.0292\n",
      " total time: 7.4668s\n",
      "9.399785995483398\n",
      "Epoch: 0000 loss_train: 1.3937\n",
      "Epoch: 0500 loss_train: 0.0605\n",
      "Epoch: 1000 loss_train: 0.1128\n",
      "Epoch: 1500 loss_train: 0.0294\n",
      "Epoch: 2000 loss_train: 0.0083\n",
      "Epoch: 2500 loss_train: 0.0321\n",
      "Epoch: 3000 loss_train: 0.0047\n",
      "Epoch: 3500 loss_train: 0.0036\n",
      "Epoch: 4000 loss_train: 0.0111\n",
      "Epoch: 4500 loss_train: 0.0190\n",
      "Epoch: 5000 loss_train: 0.0195\n",
      "Epoch: 5500 loss_train: 0.0049\n",
      " total time: 7.4652s\n",
      "6.060853004455566\n",
      "Epoch: 0000 loss_train: 1.3941\n",
      "Epoch: 0500 loss_train: 0.0807\n",
      "Epoch: 1000 loss_train: 0.0990\n",
      "Epoch: 1500 loss_train: 0.0520\n",
      "Epoch: 2000 loss_train: 0.0087\n",
      "Epoch: 2500 loss_train: 0.0271\n",
      "Epoch: 3000 loss_train: 0.0138\n",
      "Epoch: 3500 loss_train: 0.0023\n",
      "Epoch: 4000 loss_train: 0.0626\n",
      "Epoch: 4500 loss_train: 0.0095\n",
      "Epoch: 5000 loss_train: 0.0067\n",
      "Epoch: 5500 loss_train: 0.0385\n",
      " total time: 7.4459s\n",
      "0.01290905848145485\n",
      "Epoch: 0000 loss_train: 1.3945\n",
      "Epoch: 0500 loss_train: 0.0672\n",
      "Epoch: 1000 loss_train: 0.1309\n",
      "Epoch: 1500 loss_train: 0.0451\n",
      "Epoch: 2000 loss_train: 0.0098\n",
      "Epoch: 2500 loss_train: 0.0105\n",
      "Epoch: 3000 loss_train: 0.0041\n",
      "Epoch: 3500 loss_train: 0.0034\n",
      "Epoch: 4000 loss_train: 0.0396\n",
      "Epoch: 4500 loss_train: 0.0093\n",
      "Epoch: 5000 loss_train: 0.0146\n",
      "Epoch: 5500 loss_train: 0.0297\n",
      " total time: 7.4660s\n",
      "23.840656280517578\n",
      "Epoch: 0000 loss_train: 1.3945\n",
      "Epoch: 0500 loss_train: 0.0671\n",
      "Epoch: 1000 loss_train: 0.1241\n",
      "Epoch: 1500 loss_train: 0.0365\n",
      "Epoch: 2000 loss_train: 0.0036\n",
      "Epoch: 2500 loss_train: 0.0209\n",
      "Epoch: 3000 loss_train: 0.0033\n",
      "Epoch: 3500 loss_train: 0.0081\n",
      "Epoch: 4000 loss_train: 0.0052\n",
      "Epoch: 4500 loss_train: 0.0513\n",
      "Epoch: 5000 loss_train: 0.0079\n",
      "Epoch: 5500 loss_train: 0.0180\n",
      " total time: 7.4854s\n",
      "16.64446258544922\n",
      "Epoch: 0000 loss_train: 1.3943\n",
      "Epoch: 0500 loss_train: 0.0724\n",
      "Epoch: 1000 loss_train: 0.1168\n",
      "Epoch: 1500 loss_train: 0.0643\n",
      "Epoch: 2000 loss_train: 0.0048\n",
      "Epoch: 2500 loss_train: 0.0758\n",
      "Epoch: 3000 loss_train: 0.0137\n",
      "Epoch: 3500 loss_train: 0.0024\n",
      "Epoch: 4000 loss_train: 0.0115\n",
      "Epoch: 4500 loss_train: 0.0529\n",
      "Epoch: 5000 loss_train: 0.0102\n",
      "Epoch: 5500 loss_train: 0.0146\n",
      " total time: 7.4619s\n",
      "0.00046528480015695095\n",
      "Epoch: 0000 loss_train: 1.3951\n",
      "Epoch: 0500 loss_train: 0.0680\n",
      "Epoch: 1000 loss_train: 0.1106\n",
      "Epoch: 1500 loss_train: 0.0468\n",
      "Epoch: 2000 loss_train: 0.0098\n",
      "Epoch: 2500 loss_train: 0.0393\n",
      "Epoch: 3000 loss_train: 0.0055\n",
      "Epoch: 3500 loss_train: 0.0094\n",
      "Epoch: 4000 loss_train: 0.0346\n",
      "Epoch: 4500 loss_train: 0.0057\n",
      "Epoch: 5000 loss_train: 0.0027\n",
      "Epoch: 5500 loss_train: 0.0115\n",
      " total time: 7.4873s\n",
      "0.10976565629243851\n",
      "Epoch: 0000 loss_train: 1.3954\n",
      "Epoch: 0500 loss_train: 0.0638\n",
      "Epoch: 1000 loss_train: 0.0981\n",
      "Epoch: 1500 loss_train: 0.0578\n",
      "Epoch: 2000 loss_train: 0.0048\n",
      "Epoch: 2500 loss_train: 0.0548\n",
      "Epoch: 3000 loss_train: 0.0031\n",
      "Epoch: 3500 loss_train: 0.0029\n",
      "Epoch: 4000 loss_train: 0.0101\n",
      "Epoch: 4500 loss_train: 0.0180\n",
      "Epoch: 5000 loss_train: 0.0074\n",
      "Epoch: 5500 loss_train: 0.0205\n",
      " total time: 7.4433s\n",
      "1.407038688659668\n",
      "Epoch: 0000 loss_train: 1.3952\n",
      "Epoch: 0500 loss_train: 0.0705\n",
      "Epoch: 1000 loss_train: 0.1131\n",
      "Epoch: 1500 loss_train: 0.0853\n",
      "Epoch: 2000 loss_train: 0.0088\n",
      "Epoch: 2500 loss_train: 0.0476\n",
      "Epoch: 3000 loss_train: 0.0021\n",
      "Epoch: 3500 loss_train: 0.0038\n",
      "Epoch: 4000 loss_train: 0.0163\n",
      "Epoch: 4500 loss_train: 0.0073\n",
      "Epoch: 5000 loss_train: 0.0161\n",
      "Epoch: 5500 loss_train: 0.0023\n",
      " total time: 7.4577s\n",
      "1.1920928244535389e-07\n",
      "Epoch: 0000 loss_train: 1.3949\n",
      "Epoch: 0500 loss_train: 0.0859\n",
      "Epoch: 1000 loss_train: 0.0855\n",
      "Epoch: 1500 loss_train: 0.0200\n",
      "Epoch: 2000 loss_train: 0.0098\n",
      "Epoch: 2500 loss_train: 0.0078\n",
      "Epoch: 3000 loss_train: 0.0057\n",
      "Epoch: 3500 loss_train: 0.0034\n",
      "Epoch: 4000 loss_train: 0.0135\n",
      "Epoch: 4500 loss_train: 0.0146\n",
      "Epoch: 5000 loss_train: 0.0112\n",
      "Epoch: 5500 loss_train: 0.0094\n",
      " total time: 7.4818s\n",
      "19.85572052001953\n",
      "Epoch: 0000 loss_train: 1.3946\n",
      "Epoch: 0500 loss_train: 0.0612\n",
      "Epoch: 1000 loss_train: 0.0995\n",
      "Epoch: 1500 loss_train: 0.0514\n",
      "Epoch: 2000 loss_train: 0.0157\n",
      "Epoch: 2500 loss_train: 0.0248\n",
      "Epoch: 3000 loss_train: 0.0027\n",
      "Epoch: 3500 loss_train: 0.0055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4000 loss_train: 0.0109\n",
      "Epoch: 4500 loss_train: 0.0047\n",
      "Epoch: 5000 loss_train: 0.0029\n",
      "Epoch: 5500 loss_train: 0.0180\n",
      " total time: 7.4534s\n",
      "2.9444261599564925e-05\n",
      "Epoch: 0000 loss_train: 1.3947\n",
      "Epoch: 0500 loss_train: 0.0717\n",
      "Epoch: 1000 loss_train: 0.1103\n",
      "Epoch: 1500 loss_train: 0.0391\n",
      "Epoch: 2000 loss_train: 0.0071\n",
      "Epoch: 2500 loss_train: 0.0341\n",
      "Epoch: 3000 loss_train: 0.0073\n",
      "Epoch: 3500 loss_train: 0.0021\n",
      "Epoch: 4000 loss_train: 0.0174\n",
      "Epoch: 4500 loss_train: 0.0129\n",
      "Epoch: 5000 loss_train: 0.0184\n",
      "Epoch: 5500 loss_train: 0.0258\n",
      " total time: 7.4566s\n",
      "2.3841855067985307e-07\n",
      "Epoch: 0000 loss_train: 1.3945\n",
      "Epoch: 0500 loss_train: 0.0653\n",
      "Epoch: 1000 loss_train: 0.1003\n",
      "Epoch: 1500 loss_train: 0.0407\n",
      "Epoch: 2000 loss_train: 0.0092\n",
      "Epoch: 2500 loss_train: 0.0242\n",
      "Epoch: 3000 loss_train: 0.0050\n",
      "Epoch: 3500 loss_train: 0.0017\n",
      "Epoch: 4000 loss_train: 0.0205\n",
      "Epoch: 4500 loss_train: 0.0203\n",
      "Epoch: 5000 loss_train: 0.0181\n",
      "Epoch: 5500 loss_train: 0.0249\n",
      " total time: 7.4733s\n",
      "1.9073468138230965e-06\n",
      "Epoch: 0000 loss_train: 1.3943\n",
      "Epoch: 0500 loss_train: 0.0655\n",
      "Epoch: 1000 loss_train: 0.1155\n",
      "Epoch: 1500 loss_train: 0.0489\n",
      "Epoch: 2000 loss_train: 0.0085\n",
      "Epoch: 2500 loss_train: 0.0133\n",
      "Epoch: 3000 loss_train: 0.0138\n",
      "Epoch: 3500 loss_train: 0.0041\n",
      "Epoch: 4000 loss_train: 0.0198\n",
      "Epoch: 4500 loss_train: 0.0163\n",
      "Epoch: 5000 loss_train: 0.0184\n",
      "Epoch: 5500 loss_train: 0.0102\n",
      " total time: 7.4564s\n",
      "0.006768750958144665\n",
      "Epoch: 0000 loss_train: 1.3944\n",
      "Epoch: 0500 loss_train: 0.0784\n",
      "Epoch: 1000 loss_train: 0.1097\n",
      "Epoch: 1500 loss_train: 0.0302\n",
      "Epoch: 2000 loss_train: 0.0088\n",
      "Epoch: 2500 loss_train: 0.0088\n",
      "Epoch: 3000 loss_train: 0.0129\n",
      "Epoch: 3500 loss_train: 0.0020\n",
      "Epoch: 4000 loss_train: 0.0159\n",
      "Epoch: 4500 loss_train: 0.0395\n",
      "Epoch: 5000 loss_train: 0.0226\n",
      "Epoch: 5500 loss_train: 0.0170\n",
      " total time: 7.4584s\n",
      "4.207114219665527\n",
      "Epoch: 0000 loss_train: 1.3946\n",
      "Epoch: 0500 loss_train: 0.0850\n",
      "Epoch: 1000 loss_train: 0.0911\n",
      "Epoch: 1500 loss_train: 0.0459\n",
      "Epoch: 2000 loss_train: 0.0072\n",
      "Epoch: 2500 loss_train: 0.0357\n",
      "Epoch: 3000 loss_train: 0.0043\n",
      "Epoch: 3500 loss_train: 0.0080\n",
      "Epoch: 4000 loss_train: 0.0608\n",
      "Epoch: 4500 loss_train: 0.0024\n",
      "Epoch: 5000 loss_train: 0.0183\n",
      "Epoch: 5500 loss_train: 0.0128\n",
      " total time: 7.4716s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3945\n",
      "Epoch: 0500 loss_train: 0.0685\n",
      "Epoch: 1000 loss_train: 0.1065\n",
      "Epoch: 1500 loss_train: 0.0435\n",
      "Epoch: 2000 loss_train: 0.0114\n",
      "Epoch: 2500 loss_train: 0.0144\n",
      "Epoch: 3000 loss_train: 0.0113\n",
      "Epoch: 3500 loss_train: 0.0052\n",
      "Epoch: 4000 loss_train: 0.0056\n",
      "Epoch: 4500 loss_train: 0.0031\n",
      "Epoch: 5000 loss_train: 0.0086\n",
      "Epoch: 5500 loss_train: 0.0070\n",
      " total time: 7.4819s\n",
      "0.0002454218047205359\n",
      "Epoch: 0000 loss_train: 1.3948\n",
      "Epoch: 0500 loss_train: 0.0660\n",
      "Epoch: 1000 loss_train: 0.1168\n",
      "Epoch: 1500 loss_train: 0.0329\n",
      "Epoch: 2000 loss_train: 0.0095\n",
      "Epoch: 2500 loss_train: 0.0110\n",
      "Epoch: 3000 loss_train: 0.0024\n",
      "Epoch: 3500 loss_train: 0.0020\n",
      "Epoch: 4000 loss_train: 0.0045\n",
      "Epoch: 4500 loss_train: 0.0026\n",
      "Epoch: 5000 loss_train: 0.0113\n",
      "Epoch: 5500 loss_train: 0.0206\n",
      " total time: 7.4706s\n",
      "1.1920928244535389e-07\n",
      "Epoch: 0000 loss_train: 1.3950\n",
      "Epoch: 0500 loss_train: 0.0652\n",
      "Epoch: 1000 loss_train: 0.1124\n",
      "Epoch: 1500 loss_train: 0.0382\n",
      "Epoch: 2000 loss_train: 0.0104\n",
      "Epoch: 2500 loss_train: 0.0576\n",
      "Epoch: 3000 loss_train: 0.0030\n",
      "Epoch: 3500 loss_train: 0.0053\n",
      "Epoch: 4000 loss_train: 0.0129\n",
      "Epoch: 4500 loss_train: 0.0045\n",
      "Epoch: 5000 loss_train: 0.0092\n",
      "Epoch: 5500 loss_train: 0.0008\n",
      " total time: 7.4577s\n",
      "0.00017212340026162565\n",
      "Epoch: 0000 loss_train: 1.3951\n",
      "Epoch: 0500 loss_train: 0.0742\n",
      "Epoch: 1000 loss_train: 0.1007\n",
      "Epoch: 1500 loss_train: 0.0359\n",
      "Epoch: 2000 loss_train: 0.0106\n",
      "Epoch: 2500 loss_train: 0.0224\n",
      "Epoch: 3000 loss_train: 0.0058\n",
      "Epoch: 3500 loss_train: 0.0060\n",
      "Epoch: 4000 loss_train: 0.0073\n",
      "Epoch: 4500 loss_train: 0.0182\n",
      "Epoch: 5000 loss_train: 0.0065\n",
      "Epoch: 5500 loss_train: 0.0288\n",
      " total time: 7.4502s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3951\n",
      "Epoch: 0500 loss_train: 0.0705\n",
      "Epoch: 1000 loss_train: 0.0988\n",
      "Epoch: 1500 loss_train: 0.0368\n",
      "Epoch: 2000 loss_train: 0.0132\n",
      "Epoch: 2500 loss_train: 0.0452\n",
      "Epoch: 3000 loss_train: 0.0026\n",
      "Epoch: 3500 loss_train: 0.0101\n",
      "Epoch: 4000 loss_train: 0.0104\n",
      "Epoch: 4500 loss_train: 0.0219\n",
      "Epoch: 5000 loss_train: 0.0134\n",
      "Epoch: 5500 loss_train: 0.0160\n",
      " total time: 7.4558s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3951\n",
      "Epoch: 0500 loss_train: 0.0758\n",
      "Epoch: 1000 loss_train: 0.1068\n",
      "Epoch: 1500 loss_train: 0.0357\n",
      "Epoch: 2000 loss_train: 0.0151\n",
      "Epoch: 2500 loss_train: 0.0353\n",
      "Epoch: 3000 loss_train: 0.0039\n",
      "Epoch: 3500 loss_train: 0.0031\n",
      "Epoch: 4000 loss_train: 0.0281\n",
      "Epoch: 4500 loss_train: 0.0153\n",
      "Epoch: 5000 loss_train: 0.0239\n",
      "Epoch: 5500 loss_train: 0.0202\n",
      " total time: 7.4561s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3951\n",
      "Epoch: 0500 loss_train: 0.0713\n",
      "Epoch: 1000 loss_train: 0.0975\n",
      "Epoch: 1500 loss_train: 0.0344\n",
      "Epoch: 2000 loss_train: 0.0154\n",
      "Epoch: 2500 loss_train: 0.0521\n",
      "Epoch: 3000 loss_train: 0.0022\n",
      "Epoch: 3500 loss_train: 0.0052\n",
      "Epoch: 4000 loss_train: 0.0500\n",
      "Epoch: 4500 loss_train: 0.0049\n",
      "Epoch: 5000 loss_train: 0.0145\n",
      "Epoch: 5500 loss_train: 0.0121\n",
      " total time: 7.4505s\n",
      "1.1920928244535389e-07\n",
      "Epoch: 0000 loss_train: 1.3943\n",
      "Epoch: 0500 loss_train: 0.0658\n",
      "Epoch: 1000 loss_train: 0.0684\n",
      "Epoch: 1500 loss_train: 0.0189\n",
      "Epoch: 2000 loss_train: 0.0070\n",
      "Epoch: 2500 loss_train: 0.0056\n",
      "Epoch: 3000 loss_train: 0.0035\n",
      "Epoch: 3500 loss_train: 0.0027\n",
      "Epoch: 4000 loss_train: 0.0065\n",
      "Epoch: 4500 loss_train: 0.0092\n",
      "Epoch: 5000 loss_train: 0.0062\n",
      "Epoch: 5500 loss_train: 0.0057\n",
      " total time: 7.4495s\n",
      "3.775259017944336\n",
      "Epoch: 0000 loss_train: 1.3944\n",
      "Epoch: 0500 loss_train: 0.0726\n",
      "Epoch: 1000 loss_train: 0.0867\n",
      "Epoch: 1500 loss_train: 0.0269\n",
      "Epoch: 2000 loss_train: 0.0073\n",
      "Epoch: 2500 loss_train: 0.0209\n",
      "Epoch: 3000 loss_train: 0.0041\n",
      "Epoch: 3500 loss_train: 0.0045\n",
      "Epoch: 4000 loss_train: 0.0072\n",
      "Epoch: 4500 loss_train: 0.0046\n",
      "Epoch: 5000 loss_train: 0.0138\n",
      "Epoch: 5500 loss_train: 0.0157\n",
      " total time: 7.4474s\n",
      "13.14747428894043\n",
      "Epoch: 0000 loss_train: 1.3944\n",
      "Epoch: 0500 loss_train: 0.0730\n",
      "Epoch: 1000 loss_train: 0.0769\n",
      "Epoch: 1500 loss_train: 0.0234\n",
      "Epoch: 2000 loss_train: 0.0049\n",
      "Epoch: 2500 loss_train: 0.0118\n",
      "Epoch: 3000 loss_train: 0.0103\n",
      "Epoch: 3500 loss_train: 0.0020\n",
      "Epoch: 4000 loss_train: 0.0231\n",
      "Epoch: 4500 loss_train: 0.0138\n",
      "Epoch: 5000 loss_train: 0.0037\n",
      "Epoch: 5500 loss_train: 0.0163\n",
      " total time: 7.4812s\n",
      "3.576278118089249e-07\n",
      "Epoch: 0000 loss_train: 1.3946\n",
      "Epoch: 0500 loss_train: 0.0620\n",
      "Epoch: 1000 loss_train: 0.0856\n",
      "Epoch: 1500 loss_train: 0.0198\n",
      "Epoch: 2000 loss_train: 0.0091\n",
      "Epoch: 2500 loss_train: 0.0110\n",
      "Epoch: 3000 loss_train: 0.0055\n",
      "Epoch: 3500 loss_train: 0.0022\n",
      "Epoch: 4000 loss_train: 0.0136\n",
      "Epoch: 4500 loss_train: 0.0382\n",
      "Epoch: 5000 loss_train: 0.0067\n",
      "Epoch: 5500 loss_train: 0.0449\n",
      " total time: 7.4630s\n",
      "32.15609359741211\n",
      "Epoch: 0000 loss_train: 1.3944\n",
      "Epoch: 0500 loss_train: 0.0761\n",
      "Epoch: 1000 loss_train: 0.1194\n",
      "Epoch: 1500 loss_train: 0.0380\n",
      "Epoch: 2000 loss_train: 0.0155\n",
      "Epoch: 2500 loss_train: 0.0142\n",
      "Epoch: 3000 loss_train: 0.0029\n",
      "Epoch: 3500 loss_train: 0.0032\n",
      "Epoch: 4000 loss_train: 0.0221\n",
      "Epoch: 4500 loss_train: 0.0339\n",
      "Epoch: 5000 loss_train: 0.0075\n",
      "Epoch: 5500 loss_train: 0.0354\n",
      " total time: 7.4583s\n",
      "10.702603340148926\n",
      "Epoch: 0000 loss_train: 1.3945\n",
      "Epoch: 0500 loss_train: 0.0859\n",
      "Epoch: 1000 loss_train: 0.1040\n",
      "Epoch: 1500 loss_train: 0.0260\n",
      "Epoch: 2000 loss_train: 0.0122\n",
      "Epoch: 2500 loss_train: 0.0166\n",
      "Epoch: 3000 loss_train: 0.0043\n",
      "Epoch: 3500 loss_train: 0.0040\n",
      "Epoch: 4000 loss_train: 0.0146\n",
      "Epoch: 4500 loss_train: 0.0156\n",
      "Epoch: 5000 loss_train: 0.0054\n",
      "Epoch: 5500 loss_train: 0.0161\n",
      " total time: 7.4559s\n",
      "4.6120686531066895\n",
      "Epoch: 0000 loss_train: 1.3941\n",
      "Epoch: 0500 loss_train: 0.0677\n",
      "Epoch: 1000 loss_train: 0.1045\n",
      "Epoch: 1500 loss_train: 0.0198\n",
      "Epoch: 2000 loss_train: 0.0047\n",
      "Epoch: 2500 loss_train: 0.0256\n",
      "Epoch: 3000 loss_train: 0.0029\n",
      "Epoch: 3500 loss_train: 0.0024\n",
      "Epoch: 4000 loss_train: 0.0024\n",
      "Epoch: 4500 loss_train: 0.0065\n",
      "Epoch: 5000 loss_train: 0.0182\n",
      "Epoch: 5500 loss_train: 0.0236\n",
      " total time: 7.4546s\n",
      "1.815468430519104\n",
      "Epoch: 0000 loss_train: 1.3939\n",
      "Epoch: 0500 loss_train: 0.0758\n",
      "Epoch: 1000 loss_train: 0.0758\n",
      "Epoch: 1500 loss_train: 0.0296\n",
      "Epoch: 2000 loss_train: 0.0091\n",
      "Epoch: 2500 loss_train: 0.0404\n",
      "Epoch: 3000 loss_train: 0.0034\n",
      "Epoch: 3500 loss_train: 0.0090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4000 loss_train: 0.0289\n",
      "Epoch: 4500 loss_train: 0.0107\n",
      "Epoch: 5000 loss_train: 0.0157\n",
      "Epoch: 5500 loss_train: 0.0041\n",
      " total time: 7.4582s\n",
      "0.009262802079319954\n",
      "Epoch: 0000 loss_train: 1.3940\n",
      "Epoch: 0500 loss_train: 0.0759\n",
      "Epoch: 1000 loss_train: 0.0861\n",
      "Epoch: 1500 loss_train: 0.0337\n",
      "Epoch: 2000 loss_train: 0.0062\n",
      "Epoch: 2500 loss_train: 0.0470\n",
      "Epoch: 3000 loss_train: 0.0027\n",
      "Epoch: 3500 loss_train: 0.0017\n",
      "Epoch: 4000 loss_train: 0.0130\n",
      "Epoch: 4500 loss_train: 0.0290\n",
      "Epoch: 5000 loss_train: 0.0048\n",
      "Epoch: 5500 loss_train: 0.0409\n",
      " total time: 7.4082s\n",
      "0.01718476228415966\n",
      "Epoch: 0000 loss_train: 1.3944\n",
      "Epoch: 0500 loss_train: 0.1011\n",
      "Epoch: 1000 loss_train: 0.0834\n",
      "Epoch: 1500 loss_train: 0.0197\n",
      "Epoch: 2000 loss_train: 0.0105\n",
      "Epoch: 2500 loss_train: 0.0220\n",
      "Epoch: 3000 loss_train: 0.0173\n",
      "Epoch: 3500 loss_train: 0.0037\n",
      "Epoch: 4000 loss_train: 0.0357\n",
      "Epoch: 4500 loss_train: 0.0223\n",
      "Epoch: 5000 loss_train: 0.0172\n",
      "Epoch: 5500 loss_train: 0.0142\n",
      " total time: 7.4557s\n",
      "1.1920928244535389e-07\n",
      "Epoch: 0000 loss_train: 1.3945\n",
      "Epoch: 0500 loss_train: 0.0811\n",
      "Epoch: 1000 loss_train: 0.0898\n",
      "Epoch: 1500 loss_train: 0.0289\n",
      "Epoch: 2000 loss_train: 0.0065\n",
      "Epoch: 2500 loss_train: 0.0387\n",
      "Epoch: 3000 loss_train: 0.0068\n",
      "Epoch: 3500 loss_train: 0.0113\n",
      "Epoch: 4000 loss_train: 0.0475\n",
      "Epoch: 4500 loss_train: 0.0147\n",
      "Epoch: 5000 loss_train: 0.0023\n",
      "Epoch: 5500 loss_train: 0.0122\n",
      " total time: 7.4362s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3945\n",
      "Epoch: 0500 loss_train: 0.0875\n",
      "Epoch: 1000 loss_train: 0.0983\n",
      "Epoch: 1500 loss_train: 0.0321\n",
      "Epoch: 2000 loss_train: 0.0165\n",
      "Epoch: 2500 loss_train: 0.0234\n",
      "Epoch: 3000 loss_train: 0.0081\n",
      "Epoch: 3500 loss_train: 0.0041\n",
      "Epoch: 4000 loss_train: 0.0328\n",
      "Epoch: 4500 loss_train: 0.0456\n",
      "Epoch: 5000 loss_train: 0.0038\n",
      "Epoch: 5500 loss_train: 0.0337\n",
      " total time: 7.4594s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3945\n",
      "Epoch: 0500 loss_train: 0.0777\n",
      "Epoch: 1000 loss_train: 0.1019\n",
      "Epoch: 1500 loss_train: 0.0311\n",
      "Epoch: 2000 loss_train: 0.0082\n",
      "Epoch: 2500 loss_train: 0.0194\n",
      "Epoch: 3000 loss_train: 0.0063\n",
      "Epoch: 3500 loss_train: 0.0082\n",
      "Epoch: 4000 loss_train: 0.0106\n",
      "Epoch: 4500 loss_train: 0.0050\n",
      "Epoch: 5000 loss_train: 0.0053\n",
      "Epoch: 5500 loss_train: 0.0211\n",
      " total time: 7.4431s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3945\n",
      "Epoch: 0500 loss_train: 0.0822\n",
      "Epoch: 1000 loss_train: 0.1049\n",
      "Epoch: 1500 loss_train: 0.0362\n",
      "Epoch: 2000 loss_train: 0.0087\n",
      "Epoch: 2500 loss_train: 0.0218\n",
      "Epoch: 3000 loss_train: 0.0035\n",
      "Epoch: 3500 loss_train: 0.0097\n",
      "Epoch: 4000 loss_train: 0.0056\n",
      "Epoch: 4500 loss_train: 0.0968\n",
      "Epoch: 5000 loss_train: 0.0029\n",
      "Epoch: 5500 loss_train: 0.0440\n",
      " total time: 7.4496s\n",
      "0.40944212675094604\n",
      "Epoch: 0000 loss_train: 1.3946\n",
      "Epoch: 0500 loss_train: 0.0711\n",
      "Epoch: 1000 loss_train: 0.0998\n",
      "Epoch: 1500 loss_train: 0.0405\n",
      "Epoch: 2000 loss_train: 0.0095\n",
      "Epoch: 2500 loss_train: 0.0254\n",
      "Epoch: 3000 loss_train: 0.0045\n",
      "Epoch: 3500 loss_train: 0.0050\n",
      "Epoch: 4000 loss_train: 0.0145\n",
      "Epoch: 4500 loss_train: 0.0112\n",
      "Epoch: 5000 loss_train: 0.0025\n",
      "Epoch: 5500 loss_train: 0.0216\n",
      " total time: 7.4526s\n",
      "0.11105602234601974\n",
      "Epoch: 0000 loss_train: 1.3947\n",
      "Epoch: 0500 loss_train: 0.0791\n",
      "Epoch: 1000 loss_train: 0.1269\n",
      "Epoch: 1500 loss_train: 0.0335\n",
      "Epoch: 2000 loss_train: 0.0122\n",
      "Epoch: 2500 loss_train: 0.0181\n",
      "Epoch: 3000 loss_train: 0.0037\n",
      "Epoch: 3500 loss_train: 0.0052\n",
      "Epoch: 4000 loss_train: 0.0066\n",
      "Epoch: 4500 loss_train: 0.0113\n",
      "Epoch: 5000 loss_train: 0.0045\n",
      "Epoch: 5500 loss_train: 0.0355\n",
      " total time: 7.4603s\n",
      "1.1920928244535389e-07\n",
      "Epoch: 0000 loss_train: 1.3947\n",
      "Epoch: 0500 loss_train: 0.0762\n",
      "Epoch: 1000 loss_train: 0.0932\n",
      "Epoch: 1500 loss_train: 0.0275\n",
      "Epoch: 2000 loss_train: 0.0057\n",
      "Epoch: 2500 loss_train: 0.0136\n",
      "Epoch: 3000 loss_train: 0.0061\n",
      "Epoch: 3500 loss_train: 0.0036\n",
      "Epoch: 4000 loss_train: 0.0057\n",
      "Epoch: 4500 loss_train: 0.0373\n",
      "Epoch: 5000 loss_train: 0.0115\n",
      "Epoch: 5500 loss_train: 0.0243\n",
      " total time: 7.4514s\n",
      "4.660974445869215e-05\n",
      "Epoch: 0000 loss_train: 1.3944\n",
      "Epoch: 0500 loss_train: 0.0809\n",
      "Epoch: 1000 loss_train: 0.0817\n",
      "Epoch: 1500 loss_train: 0.0352\n",
      "Epoch: 2000 loss_train: 0.0110\n",
      "Epoch: 2500 loss_train: 0.0233\n",
      "Epoch: 3000 loss_train: 0.0069\n",
      "Epoch: 3500 loss_train: 0.0017\n",
      "Epoch: 4000 loss_train: 0.0025\n",
      "Epoch: 4500 loss_train: 0.0118\n",
      "Epoch: 5000 loss_train: 0.0178\n",
      "Epoch: 5500 loss_train: 0.0308\n",
      " total time: 7.4538s\n",
      "29.989437103271484\n",
      "Epoch: 0000 loss_train: 1.3944\n",
      "Epoch: 0500 loss_train: 0.0800\n",
      "Epoch: 1000 loss_train: 0.0991\n",
      "Epoch: 1500 loss_train: 0.0293\n",
      "Epoch: 2000 loss_train: 0.0125\n",
      "Epoch: 2500 loss_train: 0.0104\n",
      "Epoch: 3000 loss_train: 0.0120\n",
      "Epoch: 3500 loss_train: 0.0044\n",
      "Epoch: 4000 loss_train: 0.0037\n",
      "Epoch: 4500 loss_train: 0.0030\n",
      "Epoch: 5000 loss_train: 0.0034\n",
      "Epoch: 5500 loss_train: 0.0391\n",
      " total time: 7.4454s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3943\n",
      "Epoch: 0500 loss_train: 0.0817\n",
      "Epoch: 1000 loss_train: 0.0907\n",
      "Epoch: 1500 loss_train: 0.0473\n",
      "Epoch: 2000 loss_train: 0.0147\n",
      "Epoch: 2500 loss_train: 0.0335\n",
      "Epoch: 3000 loss_train: 0.0126\n",
      "Epoch: 3500 loss_train: 0.0052\n",
      "Epoch: 4000 loss_train: 0.0052\n",
      "Epoch: 4500 loss_train: 0.0141\n",
      "Epoch: 5000 loss_train: 0.0041\n",
      "Epoch: 5500 loss_train: 0.0142\n",
      " total time: 7.4746s\n",
      "0.0\n",
      "Epoch: 0000 loss_train: 1.3940\n",
      "Epoch: 0500 loss_train: 0.0842\n",
      "Epoch: 1000 loss_train: 0.0975\n",
      "Epoch: 1500 loss_train: 0.0511\n",
      "Epoch: 2000 loss_train: 0.0121\n",
      "Epoch: 2500 loss_train: 0.0420\n",
      "Epoch: 3000 loss_train: 0.0061\n",
      "Epoch: 3500 loss_train: 0.0170\n",
      "Epoch: 4000 loss_train: 0.0112\n",
      "Epoch: 4500 loss_train: 0.0204\n",
      "Epoch: 5000 loss_train: 0.0041\n",
      "Epoch: 5500 loss_train: 0.0225\n",
      " total time: 7.4486s\n",
      "3.814689989667386e-06\n",
      "Epoch: 0000 loss_train: 1.3941\n",
      "Epoch: 0500 loss_train: 0.0936\n",
      "Epoch: 1000 loss_train: 0.1033\n",
      "Epoch: 1500 loss_train: 0.0482\n",
      "Epoch: 2000 loss_train: 0.0127\n",
      "Epoch: 2500 loss_train: 0.0154\n",
      "Epoch: 3000 loss_train: 0.0040\n",
      "Epoch: 3500 loss_train: 0.0054\n",
      "Epoch: 4000 loss_train: 0.0051\n",
      "Epoch: 4500 loss_train: 0.0202\n",
      "Epoch: 5000 loss_train: 0.0054\n",
      "Epoch: 5500 loss_train: 0.0076\n",
      " total time: 7.4503s\n",
      "2.9801878554280847e-05\n"
     ]
    }
   ],
   "source": [
    "inputAll=torch.tensor(inputAll).cuda().float()\n",
    "labelsAll=torch.tensor(labelsAll).cuda().long()\n",
    "\n",
    "testepoch=5800\n",
    "predtest=np.zeros((inputAll.shape[0],np.unique(labels_train).size))\n",
    "for sampleIdx in range(inputAll.shape[0]):\n",
    "\n",
    "    trainIdx=np.arange(inputAll.shape[0])!=sampleIdx\n",
    "    \n",
    "    seed=3\n",
    "    torch.manual_seed(seed)\n",
    "    nclasses=np.unique(labels_train).size\n",
    "    if use_cuda:\n",
    "        torch.cuda.manual_seed(seed)\n",
    "\n",
    "    nfeatures=inputAll.shape[1]\n",
    "    if model_str=='fc3':\n",
    "        model = modelsCNN.FC_l3(nfeatures,fc_dim1,fc_dim2,fc_dim3,nclasses,0.5,regrs=False)\n",
    "        lossCE=torch.nn.CrossEntropyLoss(torch.tensor(weights_train).cuda().float())\n",
    "    if model_str=='fc5':\n",
    "        model = modelsCNN.FC_l5(nfeatures,fc_dim1,fc_dim2,fc_dim3,fc_dim4,fc_dim5,nclasses,0.5,regrs=False)\n",
    "        lossCE=torch.nn.CrossEntropyLoss(torch.tensor(weights_train).cuda().float())\n",
    "    if model_str=='fc1':\n",
    "        model = modelsCNN.FC_l1(nfeatures,fc_dim1,nclasses,regrs=False)\n",
    "        lossCE=torch.nn.CrossEntropyLoss(torch.tensor(weights_train).cuda().float())\n",
    "    if model_str=='fc0':\n",
    "        model = modelsCNN.FC_l0(nfeatures,nclasses,regrs=False)\n",
    "        lossCE=torch.nn.CrossEntropyLoss(torch.tensor(weights_train).cuda().float())\n",
    "\n",
    "    if use_cuda:\n",
    "        model.cuda()\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    train_loss_ep=[None]*epochs\n",
    "    val_loss_ep=[None]*epochs\n",
    "    t_ep=time.time()\n",
    "\n",
    "    for ep in range(epochs):\n",
    "        train_loss_ep[ep]=train(ep,inputAll[trainIdx],labelsAll[trainIdx])\n",
    "\n",
    "\n",
    "        if ep%saveFreq == 0 and ep!=0:\n",
    "            torch.save(model.cpu().state_dict(), os.path.join(modelsavepath,imgNamesAll[sampleIdx]+'_'+str(ep)+'.pt'))\n",
    "        if use_cuda:\n",
    "            model.cuda()\n",
    "            torch.cuda.empty_cache()\n",
    "    print(' total time: {:.4f}s'.format(time.time() - t_ep))\n",
    "\n",
    "    with open(os.path.join(logsavepath,imgNamesAll[sampleIdx]+'_train_loss'), 'wb') as output:\n",
    "        pickle.dump(train_loss_ep, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    model.load_state_dict(torch.load(os.path.join(modelsavepath,imgNamesAll[sampleIdx]+'_'+str(testepoch)+'.pt')))\n",
    "    with torch.no_grad():\n",
    "        model.cuda()\n",
    "        model.eval()\n",
    "        pred = model(inputAll[[sampleIdx]])\n",
    "        predtest[sampleIdx]=pred.cpu().detach().numpy()\n",
    "\n",
    "        loss_test=lossCE(pred,labelsAll[[sampleIdx]]).item()\n",
    "\n",
    "    print(loss_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(logsavepath,'crossVal_loss'), 'wb') as output:\n",
    "    pickle.dump(predtest, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "predtest_label=np.argmax(predtest,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=pd.DataFrame({'sampleName':imgNamesAll,'true':progUnique[labelsAll.cpu().numpy()],'predicted':progUnique[predtest_label]})\n",
    "res.to_csv(os.path.join(plotsavepath,'predictions.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "progInclude=np.array(['Hyperplasia','Atypical hyperplasia','DCIS and breast tissue',  'DCIS with early infiltration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot confusion\n",
    "def plotCTcomp(labels,ctlist,savepath,savenamecluster,byCT,addname='',order=progInclude):\n",
    "    res=np.zeros((order.size,order.size))\n",
    "    for li in range(res.shape[0]):\n",
    "        l=order[li]\n",
    "        nl=np.sum(labels==l)\n",
    "        ctlist_l=ctlist[labels==l]\n",
    "        for ci in range(res.shape[1]):\n",
    "            c=order[ci]\n",
    "            res[li,ci]=np.sum(ctlist_l==c)\n",
    "#             res[li,ci]=np.sum(ctlist_l==c)/nl\n",
    "    if not byCT:\n",
    "        addname+=''\n",
    "        for li in range(res.shape[0]):\n",
    "            l=order[li]\n",
    "            nl=np.sum(labels==l)\n",
    "            res[li]=res[li]/nl\n",
    "    else:\n",
    "        addname+='_normbyCT'\n",
    "        for ci in range(res.shape[1]):\n",
    "            c=order[ci]\n",
    "            nc=np.sum(ctlist==c)\n",
    "            res[:,ci]=res[:,ci]/nc\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    im = ax.imshow(res,cmap='binary',vmin=0,vmax=1)\n",
    "    fig.colorbar(im)\n",
    "    ax.set_yticks(np.arange(order.size))\n",
    "    ax.set_yticklabels(order)\n",
    "    ax.set_xticks(np.arange(order.size))\n",
    "    ax.set_xticklabels(order)\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",rotation_mode=\"anchor\")\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(os.path.join(savepath,savenamecluster+addname+'.pdf'))\n",
    "    plt.close()\n",
    "    \n",
    "plotCTcomp(progUnique[labelsAll.cpu().numpy()],progUnique[predtest_label],plotsavepath,'confusion'+str(testepoch),False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCTcomp(progUnique[labelsAll.cpu().numpy()][:sidx_start.size],progUnique[predtest_label][:sidx_start.size],plotsavepath,'confusion_excludeValSamples'+str(testepoch),False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sampleName</th>\n",
       "      <th>true</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>br1003a_1_cytokeratin_555_aSMA_647_hoechst_I1</td>\n",
       "      <td>Breast tissue</td>\n",
       "      <td>Breast tissue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>br1003a_1_cytokeratin_555_aSMA_647_hoechst_I10</td>\n",
       "      <td>Breast tissue</td>\n",
       "      <td>Breast tissue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>br1003a_1_cytokeratin_555_aSMA_647_hoechst_I2</td>\n",
       "      <td>Breast tissue</td>\n",
       "      <td>DCIS with early infiltration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>br1003a_1_cytokeratin_555_aSMA_647_hoechst_I3</td>\n",
       "      <td>Breast tissue</td>\n",
       "      <td>Breast tissue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>br1003a_1_cytokeratin_555_aSMA_647_hoechst_I7</td>\n",
       "      <td>Breast tissue</td>\n",
       "      <td>Breast tissue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>br8018a_2_cytokeratin_555_ki67_647_hoechst_G6</td>\n",
       "      <td>Invasive ductal carcinoma</td>\n",
       "      <td>Invasive ductal carcinoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>br8018a_2_cytokeratin_555_ki67_647_hoechst_H2</td>\n",
       "      <td>Cancer adjacent normal breast tissue</td>\n",
       "      <td>Invasive ductal carcinoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>br8018a_2_cytokeratin_555_ki67_647_hoechst_H3</td>\n",
       "      <td>Cancer adjacent normal breast tissue</td>\n",
       "      <td>Cancer adjacent normal breast tissue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>br8018a_2_cytokeratin_555_ki67_647_hoechst_H4</td>\n",
       "      <td>Cancer adjacent normal breast tissue</td>\n",
       "      <td>Cancer adjacent normal breast tissue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>br8018a_2_cytokeratin_555_ki67_647_hoechst_H5</td>\n",
       "      <td>Cancer adjacent normal breast tissue</td>\n",
       "      <td>Breast tissue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>412 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         sampleName  \\\n",
       "0     br1003a_1_cytokeratin_555_aSMA_647_hoechst_I1   \n",
       "1    br1003a_1_cytokeratin_555_aSMA_647_hoechst_I10   \n",
       "2     br1003a_1_cytokeratin_555_aSMA_647_hoechst_I2   \n",
       "3     br1003a_1_cytokeratin_555_aSMA_647_hoechst_I3   \n",
       "4     br1003a_1_cytokeratin_555_aSMA_647_hoechst_I7   \n",
       "..                                              ...   \n",
       "407   br8018a_2_cytokeratin_555_ki67_647_hoechst_G6   \n",
       "408   br8018a_2_cytokeratin_555_ki67_647_hoechst_H2   \n",
       "409   br8018a_2_cytokeratin_555_ki67_647_hoechst_H3   \n",
       "410   br8018a_2_cytokeratin_555_ki67_647_hoechst_H4   \n",
       "411   br8018a_2_cytokeratin_555_ki67_647_hoechst_H5   \n",
       "\n",
       "                                     true  \\\n",
       "0                           Breast tissue   \n",
       "1                           Breast tissue   \n",
       "2                           Breast tissue   \n",
       "3                           Breast tissue   \n",
       "4                           Breast tissue   \n",
       "..                                    ...   \n",
       "407             Invasive ductal carcinoma   \n",
       "408  Cancer adjacent normal breast tissue   \n",
       "409  Cancer adjacent normal breast tissue   \n",
       "410  Cancer adjacent normal breast tissue   \n",
       "411  Cancer adjacent normal breast tissue   \n",
       "\n",
       "                                predicted  \n",
       "0                           Breast tissue  \n",
       "1                           Breast tissue  \n",
       "2            DCIS with early infiltration  \n",
       "3                           Breast tissue  \n",
       "4                           Breast tissue  \n",
       "..                                    ...  \n",
       "407             Invasive ductal carcinoma  \n",
       "408             Invasive ductal carcinoma  \n",
       "409  Cancer adjacent normal breast tissue  \n",
       "410  Cancer adjacent normal breast tissue  \n",
       "411                         Breast tissue  \n",
       "\n",
       "[412 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
